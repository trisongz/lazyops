{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"LazyOps","text":"<p> High-performance, async-native tooling for modern Python applications.     Split into zero-dependency core utilities (<code>lzl</code>) and powerful registry patterns (<code>lzo</code>).   </p> <p> </p>"},{"location":"#installation","title":"Installation","text":"<pre><code>$ pip install lazyops\n</code></pre>"},{"location":"#at-a-glance","title":"At a Glance","text":"<p>LazyOps is designed to make Python development faster and cleaner by providing robust utilities that handle the \"boring stuff\" efficiently. It is divided into two primary namespaces:</p> <ul> <li> <p>:material-feather:{ .lg .middle } lzl</p> <p>Lazy Libraries &amp; Utilities</p> <p>A zero-dependency collection of core components. Think of it as <code>itertools</code> + <code>functools</code> + <code>asyncio</code> helpers on steroids.</p> <p>:octicons-arrow-right-24: Explore lzl</p> </li> <li> <p>:material-layers-triple:{ .lg .middle } lzo</p> <p>Lazy Objects &amp; Registries</p> <p>Advanced patterns for state management, object registries, and configuration. Built for scalable application architecture.</p> <p>:octicons-arrow-right-24: Explore lzo</p> </li> </ul>"},{"location":"#flash-examples","title":"Flash Examples","text":"<p>See how LazyOps simplifies common patterns.</p> Lazy LoadingAsync IORobust LoggingSmart RegistryAPI Clients <p>Drastically reduce import times by loading heavy modules only when accessed.</p> <pre><code>from lzl.load import LazyLoad\n\n# pandas is not imported yet!\npd = LazyLoad(\"pandas\")\n\ndef analyze_data(data):\n    # pandas is imported here, on first access\n    df = pd.DataFrame(data)\n    return df.describe()\n</code></pre> <p>Unified, high-performance file operations that work across local and cloud storage.</p> <pre><code>from lzl.io import File\n\nasync def process_logs():\n    # Works with local paths, S3, MinIO, etc.\n    logs = await File(\"s3://my-bucket/app.log\").read_text()\n\n    # Non-blocking write\n    await File(\"local/processed.log\").write_text(logs)\n\n# Check sizes easily\nsize = File(\"s3://my-bucket/large-dataset.parquet\").size\n</code></pre> <p>Zero-config, high-performance structured logging based on <code>loguru</code>.</p> <pre><code>from lzl.logging import logger\n\n# Automatically formatted, colored, and timestamped\nlogger.info(\"Application starting up...\", env=\"production\")\n\ntry:\n    1 / 0\nexcept Exception:\n    # localized tracebacks\n    logger.trace(\"Something went wrong\", error_code=500)\n</code></pre> <p>Build plugin systems or manage global components with <code>MRegistry</code>.</p> <pre><code>from lzo.registry import MRegistry\n\n# Create a registry for your AI Models\nModels = MRegistry(\"models\")\n\n@Models.register(\"gpt-4\")\nclass GPT4:\n    def generate(self): ...\n\n# Lazy instantiation\nmodel = Models.get(\"gpt-4\")\n</code></pre> <p>Pre-configured clients for popular services like OpenAI, Slack, and Kubernetes.</p> <pre><code>from lzl.api import aiohttpx\n\nasync def fetch_data():\n    # A robust, async HTTP client with retries and timeout logic built-in\n    async with aiohttpx.Client() as client:\n        resp = await client.get(\"https://api.example.com/data\")\n        return resp.json()\n</code></pre>"},{"location":"#why-lazyops","title":"Why LazyOps?","text":"<ul> <li> <p>Async Native</p> <p>Built from the ground up for <code>asyncio</code>. Almost every I/O operation has a non-blocking <code>await</code> equivalent, ensuring your event loop never stalls.</p> </li> <li> <p>Zero Overhead</p> <p>The <code>lzl</code> core is designed to be lightweight. You import only what you use, and lazy loading ensures you don't pay for dependencies you don't need.</p> </li> <li> <p>Developer Experience</p> <p>Fully typed with <code>mypy</code> support, comprehensive docstrings, and intuitive APIs. We prioritize readability and ease of use.</p> </li> <li> <p>Production Ready</p> <p>Used in production environments handling high-throughput data processing and microservices orchestration.</p> </li> </ul>"},{"location":"#next-steps","title":"Next Steps","text":"<ul> <li>Get Started with lzl Utilities</li> <li>Learn about lzo Registries</li> <li>View Extension Modules</li> </ul>"},{"location":"code-style/","title":"LazyOps Code Style Guide","text":"<p>This document captures incremental conventions as we touch the codebase.  Keep it updated so new contributors have a single reference for style expectations.</p>"},{"location":"code-style/#typing-and-imports","title":"Typing and Imports","text":"<ul> <li>Always import the typing module as <code>import typing as t</code>; prefer <code>t.Dict</code>,   <code>t.Optional</code>, etc., over direct names from <code>typing</code>.</li> <li>Forward references should remain in quotes and grouped near their usage to   minimise runtime import overhead.</li> <li>Add <code>__all__</code> lists when modules act as fa\u00e7ades or re-export symbols to make   the public surface explicit for documentation generators.</li> <li>Aggregator modules (for example <code>lzo.registry</code> and <code>lzo.utils</code>) should   populate <code>__all__</code> with the curated public API so Mintlify exports remain   predictable.</li> </ul>"},{"location":"code-style/#documentation","title":"Documentation","text":"<ul> <li>Every module modified during this effort should include a narrative   module-level docstring that explains its role within the <code>lzl</code>/<code>lzo</code>   ecosystem.  Keep the tone practical so Mintlify can produce helpful   summaries.</li> <li>Expand class and function docstrings with concise context-first language,   followed by parameter descriptions when behaviour is not self-evident.</li> <li>Avoid documenting implementation details that may change; focus on intent and   usage to prevent churn when functionality evolves.</li> </ul>"},{"location":"code-style/#general-style","title":"General Style","text":"<ul> <li>Prefer enriching existing structures (docstrings, typing, comments) over   altering runtime behaviour during documentation-focused sprints.</li> <li>When adding clarifying comments, keep them short and purpose-driven.  Do not   annotate trivial assignments or control flow.</li> <li>Maintain ASCII encoding in source files unless there is a clear reason to do   otherwise and the file already uses non-ASCII characters.</li> </ul>"},{"location":"code-style/#testing","title":"Testing","text":"<ul> <li>Prefer deterministic transports (for example <code>httpx.MockTransport</code>) when   exercising HTTP clients to keep tests network-free and CI friendly.</li> <li>Use <code>tmp_path</code>/<code>tmp_path_factory</code> for filesystem-heavy utilities such as   <code>lzl.io.persistence</code> to avoid leaving artefacts on developer machines.</li> <li>Prefer standard-library modules (for example <code>math</code>) when exercising   <code>LazyLoad</code> to keep tests deterministic and dependency-free.</li> <li>When testing <code>ThreadPool</code>, await background tasks or consume futures so the   event loop does not emit \"task was destroyed\" warnings during teardown.</li> <li>Reset class-level caches (for example <code>ProxyDict._dict</code>) in tests that   mutate proxied registries to avoid leaking state between cases.</li> <li>Mark coroutine tests with <code>@pytest.mark.asyncio</code> rather than managing event   loops manually when exercising async utilities such as <code>retryable</code>.</li> <li>When exercising <code>WorkerContext</code>/<code>MLContext</code>, stub <code>logger.info</code> and resource   fetchers so tests do not rely on real hardware metrics.</li> </ul> <p>Last updated: September 18, 2025</p>"},{"location":"future-updates/","title":"Future Enhancements","text":"<p>Tracks potential improvements discovered while documenting the codebase.  These items should be evaluated in a dedicated refactor sprint so behaviour changes remain intentional.</p>"},{"location":"future-updates/#lzlapiaiohttpx","title":"lzl.api.aiohttpx","text":"<ul> <li>Consider handling environments where <code>os.cpu_count()</code> returns <code>None</code> when   computing preset connection limits; today we mirror the original behaviour   which raises.</li> <li>Evaluate exposing a public API for registering custom preset profiles to   reduce reliance on the mutable <code>PresetMap</code> dictionary.</li> <li>Explore replacing the global monkey patch of <code>httpx.Response.raise_for_status</code>   with a scoped wrapper to avoid affecting consumers outside <code>lzl</code>.</li> </ul>"},{"location":"future-updates/#lzldb","title":"lzl.db","text":"<ul> <li>Several backend helper methods (for example sqlite <code>get_table_column_size</code>)   remain unimplemented placeholders; document desired semantics before adding   behaviour in a future sprint.</li> <li>Evaluate whether importing heavy SQLAlchemy dependencies at module import time   can be deferred to improve startup performance for non-database use cases.</li> </ul>"},{"location":"future-updates/#lzlio","title":"lzl.io","text":"<ul> <li><code>lzl.io.queue.background</code> references an <code>EventQueue</code> class that is not   defined within the package.  Confirm intended implementation and wire in the   missing queue before advertising the API publicly.</li> <li><code>PersistentDict</code> still mixes legacy <code>typing</code> aliases (<code>Optional</code>,   <code>Dict</code>, \u2026); migrate the remainder to <code>import typing as t</code> once behaviour   stabilises to keep type hints consistent with newer modules.</li> </ul>"},{"location":"future-updates/#lzlload","title":"lzl.load","text":"<ul> <li>Investigate whether the default <code>install_missing=True</code> flag for   :class:<code>LazyLoad</code> should be scoped behind an explicit opt-in to avoid   surprising installations at runtime.</li> <li>Consider exposing a public API for clearing the module/object caches managed   by <code>lazy_import</code> to support long-lived processes that hot-reload   configuration.</li> </ul>"},{"location":"future-updates/#lzlpool","title":"lzl.pool","text":"<ul> <li><code>ThreadPool.run</code> currently requires <code>anyio</code>; evaluate providing a graceful   fallback or clearer error message when the optional dependency is missing.</li> <li>Consider pooling executors across interpreter restarts to avoid spinning up   multiple thread pools in short-lived CLI contexts.</li> </ul>"},{"location":"future-updates/#lzlproxied","title":"lzl.proxied","text":"<ul> <li><code>ProxyDict</code> shares class-level caches across subclasses; evaluate providing a   context manager or helper to reset state when used in long-lived processes.</li> <li>Explore exposing thread-safety controls for <code>ProxyObject</code> beyond a simple   boolean to support custom lock strategies when profiling indicates issues.</li> </ul>"},{"location":"future-updates/#lzlsysmon","title":"lzl.sysmon","text":"<ul> <li>GPU/CPU sampling currently depends on <code>lzo.utils.system</code>; consider adding   graceful degradation when those utilities are unavailable.</li> <li>Evaluate emitting structured data (JSON) alongside formatted strings so the   metrics can be ingested by observability tooling without parsing log text.</li> </ul>"},{"location":"future-updates/#lzoregistry","title":"lzo.registry","text":"<ul> <li><code>lzo.registry.objects</code> is still a partial stub that references undefined   client registries; determine whether it should mirror the client registry or   be removed before publishing the API.</li> <li><code>MRegistry</code> currently stores all class-level state on the class itself; consider   migrating to instance-level storage to support multiple independent registries.</li> </ul>"},{"location":"future-updates/#lzotypes","title":"lzo.types","text":"<ul> <li>Explore simplifying the <code>BaseSettings</code> inheritance chain so it no longer needs   to import logging utilities at runtime, reducing the risk of circular   dependencies when documentation generators import the module.</li> <li>Investigate whether <code>set_app_env</code> should call <code>AppEnv.from_env</code> directly   instead of delegating via the potentially <code>None</code> <code>self.app_env</code> attribute.</li> </ul>"},{"location":"future-updates/#lzoutils","title":"lzo.utils","text":"<ul> <li>Several helper modules still use legacy <code>from typing import</code> patterns; sweep   the remaining files (<code>helpers.dates</code>, <code>helpers.caching</code>, etc.) so typing   imports are consistent across the package.</li> <li>The optional bcrypt dependency in <code>keygen.generate_htpasswd_key</code> is lazily   imported; consider surfacing a clearer error message when the dependency is   missing to aid downstream users.</li> </ul>"},{"location":"mintlify/","title":"Mintlify Documentation Workflow","text":"<p>Use the Mintlify CLI (<code>mint</code>) to preview and validate documentation locally. The commands below assume <code>docs.json</code> lives at the project root (next to <code>pyproject.toml</code>).</p> <pre><code># Install or update the CLI\nnpm i -g mint\nmint update\n\n# Preview documentation locally on http://localhost:3000\nmint dev\n\n# Run validation checks\nmint broken-links\nmint openapi-check &lt;openapiFilenameOrUrl&gt;\n</code></pre> <p>When the documentation site is ready, deploy via the Mintlify dashboard or your existing CI workflow.</p>"},{"location":"mintlify/#makefile-shortcuts","title":"Makefile Shortcuts","text":"<p>The project Makefile wraps the common commands above:</p> <pre><code>make docs-preview   # mint dev\nmake docs-generate  # mint broken-links (and optional openapi-check)\nmake docs-publish   # git push origin main (override via DOCS_REMOTE/BRANCH)\n</code></pre>"},{"location":"mkdocs-setup/","title":"MkDocs Setup Guide","text":"<p>This guide explains how to use MkDocs with Material theme for the LazyOps documentation.</p>"},{"location":"mkdocs-setup/#overview","title":"Overview","text":"<p>LazyOps uses MkDocs with the Material theme for generating beautiful, searchable documentation from Markdown files and Python docstrings.</p>"},{"location":"mkdocs-setup/#prerequisites","title":"Prerequisites","text":"<p>Install the documentation dependencies:</p> <pre><code>pip install mkdocs mkdocs-material \"mkdocstrings[python]\" pymdown-extensions\n</code></pre> <p>Or install all docs extras:</p> <pre><code>pip install -e \".[docs]\"\n</code></pre>"},{"location":"mkdocs-setup/#local-development","title":"Local Development","text":""},{"location":"mkdocs-setup/#serve-documentation-locally","title":"Serve Documentation Locally","text":"<p>Run the development server to preview documentation with live reload:</p> <pre><code>make mkdocs-serve\n# or\nmkdocs serve\n</code></pre> <p>The documentation will be available at <code>http://127.0.0.1:8000/</code>.</p>"},{"location":"mkdocs-setup/#build-documentation","title":"Build Documentation","text":"<p>Build the static site:</p> <pre><code>make mkdocs-build\n# or\nmkdocs build\n</code></pre> <p>The built site will be in the <code>site/</code> directory.</p>"},{"location":"mkdocs-setup/#documentation-structure","title":"Documentation Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md                 # Homepage\n\u251c\u2500\u2500 code-style.md           # Coding standards\n\u251c\u2500\u2500 future-updates.md       # Roadmap\n\u251c\u2500\u2500 todo.md                 # Task tracking\n\u251c\u2500\u2500 mintlify.md            # Mintlify workflow reference\n\u251c\u2500\u2500 mkdocs-setup.md        # This file\n\u2514\u2500\u2500 api/                    # API documentation\n    \u251c\u2500\u2500 lzl/               # lzl namespace docs\n    \u2502   \u251c\u2500\u2500 index.md\n    \u2502   \u251c\u2500\u2500 io.md\n    \u2502   \u251c\u2500\u2500 load.md\n    \u2502   \u251c\u2500\u2500 logging.md\n    \u2502   \u251c\u2500\u2500 pool.md\n    \u2502   \u251c\u2500\u2500 proxied.md\n    \u2502   \u251c\u2500\u2500 require.md\n    \u2502   \u2514\u2500\u2500 sysmon.md\n    \u2514\u2500\u2500 lzo/               # lzo namespace docs\n        \u251c\u2500\u2500 index.md\n        \u251c\u2500\u2500 registry.md\n        \u251c\u2500\u2500 types.md\n        \u2514\u2500\u2500 utils.md\n</code></pre>"},{"location":"mkdocs-setup/#adding-new-documentation","title":"Adding New Documentation","text":""},{"location":"mkdocs-setup/#creating-new-pages","title":"Creating New Pages","text":"<ol> <li>Create a new Markdown file in the <code>docs/</code> directory</li> <li>Add it to the navigation in <code>mkdocs.yml</code></li> </ol> <p>Example:</p> <pre><code>nav:\n  - New Section:\n    - New Page: new-page.md\n</code></pre>"},{"location":"mkdocs-setup/#auto-generating-api-documentation","title":"Auto-generating API Documentation","text":"<p>Use the <code>mkdocstrings</code> plugin to automatically generate documentation from docstrings:</p> <pre><code># My Module\n\n::: my_module.my_function\n    options:\n      show_source: true\n</code></pre> <p>This will render the docstring and source code of <code>my_function</code>.</p>"},{"location":"mkdocs-setup/#supported-features","title":"Supported Features","text":"<ul> <li>Code Blocks: Syntax highlighting for Python and other languages</li> <li>Admonitions: Notes, warnings, tips, etc.</li> <li>Tables: Markdown tables with alignment</li> <li>Links: Internal and external links</li> <li>Images: Embedded images with captions</li> <li>Math: LaTeX math rendering</li> <li>Tabs: Tabbed content sections</li> </ul>"},{"location":"mkdocs-setup/#configuration","title":"Configuration","text":"<p>The documentation configuration is in <code>mkdocs.yml</code>:</p> <ul> <li>Theme: Material theme with custom colors</li> <li>Navigation: Organized into sections and subsections</li> <li>Plugins: Search and mkdocstrings for API docs</li> <li>Extensions: Syntax highlighting, admonitions, etc.</li> </ul>"},{"location":"mkdocs-setup/#deployment","title":"Deployment","text":""},{"location":"mkdocs-setup/#manual-deployment","title":"Manual Deployment","text":"<p>Deploy to GitHub Pages:</p> <pre><code>make mkdocs-deploy\n# or\nmkdocs gh-deploy --force\n</code></pre>"},{"location":"mkdocs-setup/#automatic-deployment","title":"Automatic Deployment","text":"<p>The documentation is automatically deployed to GitHub Pages on every push to <code>main</code> that affects: - Files in <code>docs/</code> - <code>mkdocs.yml</code> - <code>.github/workflows/docs.yml</code></p> <p>The GitHub Actions workflow is defined in <code>.github/workflows/docs.yml</code>.</p>"},{"location":"mkdocs-setup/#tips-and-best-practices","title":"Tips and Best Practices","text":"<ol> <li>Preview Changes: Always preview locally before committing</li> <li>Link Checking: Use relative links for internal pages</li> <li>Code Examples: Include working code examples</li> <li>Docstrings: Use Google-style docstrings for consistency</li> <li>Images: Store images in <code>docs/assets/</code> (create if needed)</li> <li>Search: The search functionality works on the built site</li> </ol>"},{"location":"mkdocs-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"mkdocs-setup/#build-warnings","title":"Build Warnings","text":"<ul> <li>Unrecognized links: Ensure link paths are correct (include <code>.md</code> extension)</li> <li>Missing modules: Ensure all Python modules can be imported</li> <li>Syntax errors: Check Python source files for syntax issues</li> </ul>"},{"location":"mkdocs-setup/#local-server-issues","title":"Local Server Issues","text":"<p>If the local server doesn't start: - Check if port 8000 is already in use - Use <code>mkdocs serve -a 127.0.0.1:8001</code> to use a different port</p>"},{"location":"mkdocs-setup/#resources","title":"Resources","text":"<ul> <li>MkDocs Documentation</li> <li>Material for MkDocs</li> <li>mkdocstrings</li> <li>PyMdown Extensions</li> </ul>"},{"location":"todo/","title":"Todo","text":"<ul> <li>[ ] Add Documentation (mintlify)</li> <li>[ ] Add Documentation (readme)</li> <li>[ ] Remove v1</li> <li>[ ] Add proper tests</li> <li>[ ] Rework / refactor code</li> <li>[ ] Rework fileio module</li> </ul>"},{"location":"api/lzl/","title":"lzl - Lazy Libraries/Utilities","text":"<p>The <code>lzl</code> namespace contains foundational utilities, asynchronous helpers, common API client interfaces, I/O operations, logging, type definitions, and more.</p>"},{"location":"api/lzl/#key-modules","title":"Key Modules","text":"<ul> <li>IO: Input/output operations including serialization, persistence, and file handling</li> <li>Load: Lazy loading utilities for deferred imports</li> <li>Logging: Logging configuration and utilities</li> <li>Pool: Thread pool and async execution helpers</li> <li>Proxied: Proxy object patterns for lazy initialization</li> <li>Require: Dependency resolution and requirement management</li> <li>Sysmon: System monitoring and resource tracking</li> </ul>"},{"location":"api/lzl/#overview","title":"Overview","text":"<p>The <code>lzl</code> toolkit provides a comprehensive set of utilities that are commonly used across internal development projects. These utilities are designed to be lightweight, performant, and easy to integrate into existing codebases.</p>"},{"location":"api/lzl/#installation","title":"Installation","text":"<p>The <code>lzl</code> module is included with the base <code>lazyops</code> installation:</p> <pre><code>pip install lazyops\n</code></pre>"},{"location":"api/lzl/#quick-example","title":"Quick Example","text":"<pre><code>import lzl\nfrom lzl.logging import logger\nfrom lzl.load import LazyLoad\n\n# Use lazy loading\nlazy_module = LazyLoad('expensive.module')\n\n# Configure logging\nlogger.info(\"Starting application\")\n</code></pre>"},{"location":"api/lzl/#architecture","title":"Architecture","text":"<p>The <code>lzl</code> namespace is organized into several key areas:</p> <ul> <li>API Clients: HTTP clients, database connectors, and external service integrations</li> <li>I/O Operations: File handling, serialization, and data persistence</li> <li>Utilities: Common helpers for async operations, caching, and more</li> <li>Extensions: Optional integrations with FastAPI, Temporal, and other frameworks</li> </ul> <p>Browse the sidebar to explore specific modules and their documentation.</p>"},{"location":"api/lzl/api/","title":"lzl.api - API Clients","text":"<p>The <code>lzl.api</code> module contains clients and integrations for various external services and APIs.</p>"},{"location":"api/lzl/api/#http-clients","title":"HTTP Clients","text":""},{"location":"api/lzl/api/#aiohttpx","title":"aiohttpx","text":""},{"location":"api/lzl/api/#lzl.api.aiohttpx","title":"<code>lzl.api.aiohttpx</code>","text":""},{"location":"api/lzl/api/#aioreq","title":"aioreq","text":""},{"location":"api/lzl/api/#lzl.api.aioreq","title":"<code>lzl.api.aioreq</code>","text":""},{"location":"api/lzl/api/#service-integrations","title":"Service Integrations","text":""},{"location":"api/lzl/api/#openai","title":"OpenAI","text":""},{"location":"api/lzl/api/#lzl.api.openai","title":"<code>lzl.api.openai</code>","text":"<p>Fork of <code>async_openai</code> to continue extending the library</p>"},{"location":"api/lzl/api/#slack","title":"Slack","text":""},{"location":"api/lzl/api/#lzl.api.slack","title":"<code>lzl.api.slack</code>","text":"<p>This package implements the Slack Client API as a unified async/sync client</p>"},{"location":"api/lzl/api/#keycloak","title":"Keycloak","text":""},{"location":"api/lzl/api/#lzl.api.keycloak","title":"<code>lzl.api.keycloak</code>","text":""},{"location":"api/lzl/api/#argo","title":"Argo","text":""},{"location":"api/lzl/api/#lzl.api.argo","title":"<code>lzl.api.argo</code>","text":""},{"location":"api/lzl/api/#hatchet","title":"Hatchet","text":""},{"location":"api/lzl/api/#lzl.api.hatchet","title":"<code>lzl.api.hatchet</code>","text":"<p>Hatchet API with Modifications</p>"},{"location":"api/lzl/api/#qdrant","title":"Qdrant","text":""},{"location":"api/lzl/api/#lzl.api.qdrant","title":"<code>lzl.api.qdrant</code>","text":"<p>Qdrant Client with Unified Async / Sync</p>"},{"location":"api/lzl/api/#searxng","title":"SearxNG","text":""},{"location":"api/lzl/api/#lzl.api.searxng","title":"<code>lzl.api.searxng</code>","text":"<p>SearxNG API Client</p>"},{"location":"api/lzl/api/#rqlite","title":"RQLite","text":""},{"location":"api/lzl/api/#lzl.api.aiorqlite","title":"<code>lzl.api.aiorqlite</code>","text":""},{"location":"api/lzl/cmd/","title":"lzl.cmd - Command Line Utilities","text":"<p>The <code>lzl.cmd</code> module provides tools for building CLI applications and handling environment variables.</p>"},{"location":"api/lzl/cmd/#builder","title":"Builder","text":""},{"location":"api/lzl/cmd/#lzl.cmd.builder","title":"<code>lzl.cmd.builder</code>","text":""},{"location":"api/lzl/cmd/#lzl.cmd.builder.CustomInstaller","title":"<code>CustomInstaller</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Custom Installer</p> <p>These run during the stage 1 of the builder</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>class CustomInstaller(BaseModel):\n    \"\"\"\n    Custom Installer\n\n    These run during the stage 1 of the builder\n    \"\"\"\n    name: str = Field(None, description = \"The name of the custom installer\")\n    cmds: List[str] = Field(default_factory = list, description = \"The commands to run\")\n\n    @classmethod\n    def load_defaults(cls) -&gt; List[CustomInstaller]:\n        \"\"\"\n        Loads the default installers\n        \"\"\"\n        default_file = ASSETS_PATH.joinpath('default_installers.yaml')\n        if not default_file.exists(): return []\n        data = yaml.safe_load(default_file.read_text())\n        return [CustomInstaller.model_validate(item) for item in data]\n\n    def run(self):\n        \"\"\"\n        Runs the custom installer\n        \"\"\"\n        echo(f'Running Custom Installer: {COLOR.BLUE}{self.name}{COLOR.END}')\n        for cmdstr in self.cmds:\n            os.system(cmdstr)\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.CustomInstaller.load_defaults","title":"<code>load_defaults()</code>  <code>classmethod</code>","text":"<p>Loads the default installers</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>@classmethod\ndef load_defaults(cls) -&gt; List[CustomInstaller]:\n    \"\"\"\n    Loads the default installers\n    \"\"\"\n    default_file = ASSETS_PATH.joinpath('default_installers.yaml')\n    if not default_file.exists(): return []\n    data = yaml.safe_load(default_file.read_text())\n    return [CustomInstaller.model_validate(item) for item in data]\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.CustomInstaller.run","title":"<code>run()</code>","text":"<p>Runs the custom installer</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def run(self):\n    \"\"\"\n    Runs the custom installer\n    \"\"\"\n    echo(f'Running Custom Installer: {COLOR.BLUE}{self.name}{COLOR.END}')\n    for cmdstr in self.cmds:\n        os.system(cmdstr)\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.CustomCommand","title":"<code>CustomCommand</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Custom Command</p> <p>These run during the stage 2 of the builder</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>class CustomCommand(BaseModel):\n    \"\"\"\n    Custom Command\n\n    These run during the stage 2 of the builder\n    \"\"\"\n    name: str = Field(None, description = \"The name of the custom command\")\n    cmds: List[str] = Field(default_factory = list, description = \"The commands to run\")\n\n    def run(self):\n        \"\"\"\n        Runs the custom command\n        \"\"\"\n        echo(f'Running Custom Command: {COLOR.BLUE}{self.name}{COLOR.END}')\n        for cmdstr in self.cmds:\n            os.system(cmdstr)\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.CustomCommand.run","title":"<code>run()</code>","text":"<p>Runs the custom command</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def run(self):\n    \"\"\"\n    Runs the custom command\n    \"\"\"\n    echo(f'Running Custom Command: {COLOR.BLUE}{self.name}{COLOR.END}')\n    for cmdstr in self.cmds:\n        os.system(cmdstr)\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuildRef","title":"<code>BuildRef</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Build Ref</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>class BuildRef(BaseModel):\n    \"\"\"\n    Build Ref\n    \"\"\"\n    name: str = Field('server', description = \"The name of the build reference\")\n    refs: List[str] = Field(default_factory = list, description = \"The names of the build reference\")\n    enabled: Optional[bool] = Field(None, description = \"Whether the build reference is enabled\")\n    custom_install: List[str] = Field(default_factory = list, description = \"Custom Install Commands\")\n    custom_commands: List[str] = Field(default_factory = list, description = \"Custom Commands\")\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig","title":"<code>BuilderConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Builder Config</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>class BuilderConfig(BaseModel):\n    \"\"\"\n    Builder Config\n    \"\"\"\n    app_name: Optional[str] = Field(os.getenv('APP_NAME'), description=\"The name of the app\")\n    refs: List[BuildRef] = Field(default_factory = list, description = \"The build references\")\n    custom_installers: List[CustomInstaller] = Field(default_factory = list, description = \"Custom Installers\")\n    custom_commands: List[CustomCommand] = Field(default_factory = list, description = \"Custom Commands\")\n    enabled_refs: List[str] = Field(BUILDS_ENABLED_REFS, description = \"The enabled build references\")\n\n    extra: Dict[str, Any] = Field(default_factory = dict)\n\n    @model_validator(mode = 'after')\n    def validate_refs(self):\n        \"\"\"\n        Validate the build references\n        \"\"\"\n        if self.extra.get('validated'): return\n        for ref in self.refs:\n            if ref.enabled is None:\n                ref.enabled = ref.name in self.enabled_refs\n\n        if ENABLE_DEFAULT_INSTALLERS:\n            existing = [c.name for c in self.custom_installers]\n            default_installers = CustomInstaller.load_defaults()\n            for installer in default_installers:\n                if installer.name not in existing:\n                    self.custom_installers.append(installer)\n\n        self.extra['validated'] = True\n        return self\n\n    @property\n    def builds(self) -&gt; Dict[str, BuildRef]:\n        \"\"\"\n        Returns the build references\n        \"\"\"\n        return {\n            ref.name: ref\n            for ref in self.refs if ref.enabled\n        }\n\n    @property\n    def enabled_builds(self) -&gt; List[str]:\n        \"\"\"\n        Returns the enabled build services\n        \"\"\"\n        return [ref.name for ref in self.refs if ref.enabled]\n\n    @property\n    def installers(self) -&gt; Dict[str, CustomInstaller]:\n        \"\"\"\n        Returns the custom installers\n        \"\"\"\n        return {\n            installer.name: installer\n            for installer in self.custom_installers\n        }\n\n    @property\n    def commands(self) -&gt; Dict[str, CustomCommand]:\n        \"\"\"\n        Returns the custom commands\n        \"\"\"\n        return {\n            command.name: command\n            for command in self.custom_commands\n        }\n\n    @property\n    def stage(self) -&gt; int:\n        \"\"\"\n        Returns the stage\n        \"\"\"\n        return self.extra.get('stage', 0)\n\n    @stage.setter\n    def stage(self, value: int):\n        \"\"\"\n        Sets the stage\n        \"\"\"\n        self.extra['stage'] = value\n        self.save()\n\n    def show_env(self, step: str):\n        \"\"\"\n        Show the environment\n        \"\"\"\n        echo(f\"Starting Step: {COLOR.GREEN}{step}{COLOR.END}\\n\")\n        echo(f\"[Enabled Builds]: {COLOR.BLUE}{self.enabled_builds}{COLOR.END}\")\n\n    @classmethod\n    def load(cls, path: Optional[Path] = None) -&gt; 'BuilderConfig':\n        \"\"\"\n        Load the build config\n        \"\"\"\n        if path is None:\n            path = BUILD_CONFIG_PATH if BUILD_CONFIG_PATH.exists() else DEFAULT_CONFIG_PATH\n        return cls.model_validate(yaml.safe_load(path.read_text()))\n\n    def save(self):\n        \"\"\"\n        Save the build config\n        \"\"\"\n        BUILD_CONFIG_PATH.write_text(yaml.dump(self.model_dump(), default_flow_style = False))\n\n    def update_config(self, path: Optional[Path] = None, **config: Any):\n        \"\"\"\n        Update the build config\n        \"\"\"\n        data = self.model_dump()\n        if path: \n            update_data = yaml.safe_load(path.read_text())\n            data.update(update_data)\n        if config: data.update(config)\n        BUILD_CONFIG_PATH.write_text(yaml.dump(data, default_flow_style = False))\n\n\n    def get_apt_packages(self, ref: str) -&gt; List[str]:\n        \"\"\"\n        Helper for getting the apt packages for a given ref name\n        \"\"\"\n        pkg_dir = PKGS_PATH\n        if ref not in self.builds: return []\n        for alias in self.builds[ref].refs:\n            pkg_file = pkg_dir.joinpath(f'{alias}.txt')\n            if pkg_file.exists():\n                return parse_text_file(pkg_file)\n        return []\n\n\n    def get_pip_requirements(self, ref: str) -&gt; Optional[str]:\n        \"\"\"\n        Helper for getting the pip requirements file for a given ref name\n        \"\"\"\n        pkg_dir = REQUIREMENTS_PATH.joinpath(ref)\n        if ref not in self.builds: return None\n        for alias in self.builds[ref].refs:\n            req_file = pkg_dir.joinpath(f'{alias}.txt')\n            if req_file.exists():\n                req_file.write_text(req_file.read_text().replace('GITHUB_TOKEN', GITHUB_TOKEN))\n                return req_file.as_posix()\n            req_file = pkg_dir.joinpath(f'requirements.{alias}.txt')\n            if req_file.exists():\n                return req_file.as_posix()\n        return None\n\n\n\n    \"\"\"\n    Step 1: Install Apt Packages\n    \"\"\"\n\n    @property\n    def apt_pkgs(self) -&gt; List[str]:\n        \"\"\"\n        Returns the apt packages\n        \"\"\"\n        if 'apt_pkgs' not in self.extra:\n            self.extra['apt_pkgs'] = []\n        return self.extra['apt_pkgs']\n\n\n    def add_to_apt_pkgs(self, *pkg: str):\n        \"\"\"\n        Helper for adding to the apt packages\n        \"\"\"\n        self.apt_pkgs.extend(pkg)\n\n    def run_apt_install(self):\n        \"\"\"\n        Helper for running apt install\n        \"\"\"\n        if not self.apt_pkgs: return\n        _pkgs = ' '.join(list(set(self.apt_pkgs)))\n        echo(f\"Installing Apt Packages: {COLOR.BLUE}{_pkgs}{COLOR.END}\")\n        os.system(f\"apt-get update &amp;&amp; apt-get -yq install --no-install-recommends {_pkgs}\")\n\n    def get_apt_pkg_requirements(self):\n        \"\"\"\n        Helper for getting the apt package requirements\n        \"\"\"\n        for ref in self.enabled_builds:\n            if service_pkgs := self.get_apt_packages(ref):\n                echo(f'{COLOR.BLUE}[{ref}]{COLOR.END} Adding {COLOR.BOLD}{ref}{COLOR.END} requirements\\n\\n - {COLOR.BOLD}{service_pkgs}{COLOR.END}\\n')\n                self.add_to_apt_pkgs(*service_pkgs)\n        self.save()\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.builds","title":"<code>builds</code>  <code>property</code>","text":"<p>Returns the build references</p>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.enabled_builds","title":"<code>enabled_builds</code>  <code>property</code>","text":"<p>Returns the enabled build services</p>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.installers","title":"<code>installers</code>  <code>property</code>","text":"<p>Returns the custom installers</p>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.commands","title":"<code>commands</code>  <code>property</code>","text":"<p>Returns the custom commands</p>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.stage","title":"<code>stage</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the stage</p>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.apt_pkgs","title":"<code>apt_pkgs</code>  <code>property</code>","text":"<p>Returns the apt packages</p>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.validate_refs","title":"<code>validate_refs()</code>","text":"<p>Validate the build references</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>@model_validator(mode = 'after')\ndef validate_refs(self):\n    \"\"\"\n    Validate the build references\n    \"\"\"\n    if self.extra.get('validated'): return\n    for ref in self.refs:\n        if ref.enabled is None:\n            ref.enabled = ref.name in self.enabled_refs\n\n    if ENABLE_DEFAULT_INSTALLERS:\n        existing = [c.name for c in self.custom_installers]\n        default_installers = CustomInstaller.load_defaults()\n        for installer in default_installers:\n            if installer.name not in existing:\n                self.custom_installers.append(installer)\n\n    self.extra['validated'] = True\n    return self\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.show_env","title":"<code>show_env(step)</code>","text":"<p>Show the environment</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def show_env(self, step: str):\n    \"\"\"\n    Show the environment\n    \"\"\"\n    echo(f\"Starting Step: {COLOR.GREEN}{step}{COLOR.END}\\n\")\n    echo(f\"[Enabled Builds]: {COLOR.BLUE}{self.enabled_builds}{COLOR.END}\")\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.load","title":"<code>load(path=None)</code>  <code>classmethod</code>","text":"<p>Load the build config</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>@classmethod\ndef load(cls, path: Optional[Path] = None) -&gt; 'BuilderConfig':\n    \"\"\"\n    Load the build config\n    \"\"\"\n    if path is None:\n        path = BUILD_CONFIG_PATH if BUILD_CONFIG_PATH.exists() else DEFAULT_CONFIG_PATH\n    return cls.model_validate(yaml.safe_load(path.read_text()))\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.save","title":"<code>save()</code>","text":"<p>Save the build config</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def save(self):\n    \"\"\"\n    Save the build config\n    \"\"\"\n    BUILD_CONFIG_PATH.write_text(yaml.dump(self.model_dump(), default_flow_style = False))\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.update_config","title":"<code>update_config(path=None, **config)</code>","text":"<p>Update the build config</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def update_config(self, path: Optional[Path] = None, **config: Any):\n    \"\"\"\n    Update the build config\n    \"\"\"\n    data = self.model_dump()\n    if path: \n        update_data = yaml.safe_load(path.read_text())\n        data.update(update_data)\n    if config: data.update(config)\n    BUILD_CONFIG_PATH.write_text(yaml.dump(data, default_flow_style = False))\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.get_apt_packages","title":"<code>get_apt_packages(ref)</code>","text":"<p>Helper for getting the apt packages for a given ref name</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def get_apt_packages(self, ref: str) -&gt; List[str]:\n    \"\"\"\n    Helper for getting the apt packages for a given ref name\n    \"\"\"\n    pkg_dir = PKGS_PATH\n    if ref not in self.builds: return []\n    for alias in self.builds[ref].refs:\n        pkg_file = pkg_dir.joinpath(f'{alias}.txt')\n        if pkg_file.exists():\n            return parse_text_file(pkg_file)\n    return []\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.get_pip_requirements","title":"<code>get_pip_requirements(ref)</code>","text":"<p>Helper for getting the pip requirements file for a given ref name</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def get_pip_requirements(self, ref: str) -&gt; Optional[str]:\n    \"\"\"\n    Helper for getting the pip requirements file for a given ref name\n    \"\"\"\n    pkg_dir = REQUIREMENTS_PATH.joinpath(ref)\n    if ref not in self.builds: return None\n    for alias in self.builds[ref].refs:\n        req_file = pkg_dir.joinpath(f'{alias}.txt')\n        if req_file.exists():\n            req_file.write_text(req_file.read_text().replace('GITHUB_TOKEN', GITHUB_TOKEN))\n            return req_file.as_posix()\n        req_file = pkg_dir.joinpath(f'requirements.{alias}.txt')\n        if req_file.exists():\n            return req_file.as_posix()\n    return None\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.add_to_apt_pkgs","title":"<code>add_to_apt_pkgs(*pkg)</code>","text":"<p>Helper for adding to the apt packages</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def add_to_apt_pkgs(self, *pkg: str):\n    \"\"\"\n    Helper for adding to the apt packages\n    \"\"\"\n    self.apt_pkgs.extend(pkg)\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.run_apt_install","title":"<code>run_apt_install()</code>","text":"<p>Helper for running apt install</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def run_apt_install(self):\n    \"\"\"\n    Helper for running apt install\n    \"\"\"\n    if not self.apt_pkgs: return\n    _pkgs = ' '.join(list(set(self.apt_pkgs)))\n    echo(f\"Installing Apt Packages: {COLOR.BLUE}{_pkgs}{COLOR.END}\")\n    os.system(f\"apt-get update &amp;&amp; apt-get -yq install --no-install-recommends {_pkgs}\")\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.get_apt_pkg_requirements","title":"<code>get_apt_pkg_requirements()</code>","text":"<p>Helper for getting the apt package requirements</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def get_apt_pkg_requirements(self):\n    \"\"\"\n    Helper for getting the apt package requirements\n    \"\"\"\n    for ref in self.enabled_builds:\n        if service_pkgs := self.get_apt_packages(ref):\n            echo(f'{COLOR.BLUE}[{ref}]{COLOR.END} Adding {COLOR.BOLD}{ref}{COLOR.END} requirements\\n\\n - {COLOR.BOLD}{service_pkgs}{COLOR.END}\\n')\n            self.add_to_apt_pkgs(*service_pkgs)\n    self.save()\n</code></pre>"},{"location":"api/lzl/cmd/#environment-variables","title":"Environment Variables","text":""},{"location":"api/lzl/cmd/#lzl.cmd.envvars","title":"<code>lzl.cmd.envvars</code>","text":""},{"location":"api/lzl/cmd/#static-files","title":"Static Files","text":""},{"location":"api/lzl/cmd/#lzl.cmd.static","title":"<code>lzl.cmd.static</code>","text":""},{"location":"api/lzl/cmd/#lzl.cmd.static.COLOR","title":"<code>COLOR</code>","text":"<p>Color Constants</p> Source code in <code>src/lzl/cmd/static.py</code> <pre><code>class COLOR:\n    \"\"\"\n    Color Constants\n    \"\"\"\n    RED = '\\033[91m'\n    GREEN = '\\033[92m'\n    YELLOW = '\\033[93m'\n    BLUE = '\\033[94m'\n    PURPLE = '\\033[95m'\n    CYAN = '\\033[96m'\n    WHITE = '\\033[97m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'\n    END = '\\033[0m'\n</code></pre>"},{"location":"api/lzl/cmd/#utilities","title":"Utilities","text":""},{"location":"api/lzl/cmd/#lzl.cmd.utils","title":"<code>lzl.cmd.utils</code>","text":""},{"location":"api/lzl/cmd/#lzl.cmd.utils.build_aliases","title":"<code>build_aliases(name, additional_names=None)</code>","text":"<p>Create the aliases for a given service name</p> Source code in <code>src/lzl/cmd/utils.py</code> <pre><code>def build_aliases(name: str, additional_names: Optional[List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    Create the aliases for a given service name\n    \"\"\"\n    aliases = [name]\n    if '.' not in name:\n        if '-' in name: aliases.append(name.replace('-', '.'))\n        elif '_' in name: aliases.append(name.replace('_', '.'))\n    if '-' not in name:\n        if '.' in name: aliases.append(name.replace('.', '-'))\n        elif '_' in name: aliases.append(name.replace('_', '-'))\n    if '_' not in name:\n        if '.' in name: aliases.append(name.replace('.', '_'))\n        elif '-' in name: aliases.append(name.replace('-', '_'))\n    if additional_names: aliases.extend(additional_names)\n    return list(set(aliases))\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.utils.add_to_env","title":"<code>add_to_env(envvar, envval, envpath='~/.bashrc')</code>","text":"<p>Helper for adding to the environment variable</p> Source code in <code>src/lzl/cmd/utils.py</code> <pre><code>def add_to_env(\n    envvar: str,\n    envval: Any,\n    envpath: Optional[str] = '~/.bashrc',\n):\n    \"\"\"\n    Helper for adding to the environment variable\n    \"\"\"\n    envval = str(envval)\n    if ' ' in envval: envval = f'\"{envval}\"'\n    os.system(f\"echo 'export {envvar}={envval}' &gt;&gt; {envpath}\")\n    os.environ[envvar] = envval\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.utils.parse_text_file","title":"<code>parse_text_file(path)</code>","text":"<p>Parses a text file</p> Source code in <code>src/lzl/cmd/utils.py</code> <pre><code>def parse_text_file(path: Path) -&gt; List[str]:\n    \"\"\"\n    Parses a text file\n    \"\"\"\n    text_lines = path.read_text().split('\\n')\n    return [line.strip() for line in text_lines if ('#' not in line[:5] and line.strip())]\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.utils.echo","title":"<code>echo(message)</code>","text":"<p>Helper for printing a message</p> Source code in <code>src/lzl/cmd/utils.py</code> <pre><code>def echo(message: str):\n    \"\"\" \n    Helper for printing a message\n    \"\"\"\n    typer.echo(message, color = True)\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.utils.run_cmd","title":"<code>run_cmd(cmdstr)</code>","text":"<p>Helper for running a command</p> Source code in <code>src/lzl/cmd/utils.py</code> <pre><code>def run_cmd(cmdstr: str):\n    \"\"\"\n    Helper for running a command\n    \"\"\"\n    try:\n        data = subprocess.check_output(cmdstr, shell=True, text=True, stderr=subprocess.PIPE, stdin=subprocess.PIPE)\n        if data[-1:] == '\\n': data = data[:-1]\n        echo(data)\n\n    except subprocess.CalledProcessError as e:\n        echo(f'{COLOR.RED}Failed to run command: {cmdstr}{COLOR.END}')\n        echo(f'{COLOR.RED}Error: {e.stderr}{COLOR.END}')\n        raise e\n</code></pre>"},{"location":"api/lzl/db/","title":"lzl.db - Database Utilities","text":"<p>The <code>lzl.db</code> module provides database adapters, configuration helpers, and backend registries.</p>"},{"location":"api/lzl/db/#configuration","title":"Configuration","text":""},{"location":"api/lzl/db/#lzl.db.configs","title":"<code>lzl.db.configs</code>","text":""},{"location":"api/lzl/db/#backends","title":"Backends","text":""},{"location":"api/lzl/db/#lzl.db.backends","title":"<code>lzl.db.backends</code>","text":""},{"location":"api/lzl/db/#postgres","title":"Postgres","text":""},{"location":"api/lzl/db/#lzl.db.postgres","title":"<code>lzl.db.postgres</code>","text":""},{"location":"api/lzl/db/#sqlite","title":"SQLite","text":""},{"location":"api/lzl/db/#lzl.db.sqlite","title":"<code>lzl.db.sqlite</code>","text":""},{"location":"api/lzl/ext/","title":"lzl.ext - Extensions","text":"<p>The <code>lzl.ext</code> module provides integrations with third-party frameworks and libraries.</p>"},{"location":"api/lzl/ext/#fastapi","title":"FastAPI","text":""},{"location":"api/lzl/ext/#utilities","title":"Utilities","text":""},{"location":"api/lzl/ext/#lzl.ext.fast.utils","title":"<code>lzl.ext.fast.utils</code>","text":""},{"location":"api/lzl/ext/#middlewares","title":"Middlewares","text":""},{"location":"api/lzl/ext/#lzl.ext.fast.middlewares","title":"<code>lzl.ext.fast.middlewares</code>","text":"<p>FastAPI Extensions: Middlewares</p>"},{"location":"api/lzl/ext/#temporal","title":"Temporal","text":""},{"location":"api/lzl/ext/#client","title":"Client","text":""},{"location":"api/lzl/ext/#lzl.ext.temporal.client","title":"<code>lzl.ext.temporal.client</code>","text":""},{"location":"api/lzl/ext/#lzl.ext.temporal.client.TemporalClient","title":"<code>TemporalClient</code>","text":"<p>               Bases: <code>Client</code></p> Source code in <code>src/lzl/ext/temporal/client.py</code> <pre><code>class TemporalClient(Client):\n\n\n    # @staticmethod\n    @classmethod\n    async def connect(\n        cls: t.Type['TemporalClient'],\n        target_host: t.Optional[str] = None,\n        namespace: t.Optional[str] = None,\n        api_key: t.Optional[str] = None,\n        data_converter: t.Optional['DataConverter'] = None,\n        interceptors: t.Sequence['Interceptor'] = [],\n        default_workflow_query_reject_condition: t.Optional[\n            'QueryRejectCondition'\n        ] = None,\n        tls: t.Union[bool, 'TLSConfig'] = False,\n        retry_config: t.Optional['RetryConfig'] = None,\n        keep_alive_config: t.Optional['KeepAliveConfig'] = KeepAliveConfig.default,\n        rpc_metadata: t.Mapping[str, str] = {},\n        identity: t.Optional[str] = None,\n        lazy: bool = False,\n        runtime: t.Optional['Runtime'] = None,\n        http_connect_proxy_config: t.Optional['HttpConnectProxyConfig'] = None,\n        default_task_queue: t.Optional[str] = None,\n        config: t.Optional['TemporalSettings'] = None,\n        **kwargs,\n    ) -&gt; TemporalClient:  # sourcery skip: default-mutable-arg\n        \"\"\"Connect to a Temporal server.\n\n        Args:\n            target_host: ``host:port`` for the Temporal server. For local\n                development, this is often \"localhost:7233\".\n            namespace: Namespace to use for client calls.\n            api_key: API key for Temporal. This becomes the \"Authorization\"\n                HTTP header with \"Bearer \" prepended. This is only set if RPC\n                metadata doesn't already have an \"authorization\" key.\n            data_converter: Data converter to use for all data conversions\n                to/from payloads.\n            interceptors: Set of interceptors that are chained together to allow\n                intercepting of client calls. The earlier interceptors wrap the\n                later ones.\n\n                Any interceptors that also implement\n                :py:class:`temporalio.worker.Interceptor` will be used as worker\n                interceptors too so they should not be given when creating a\n                worker.\n            default_workflow_query_reject_condition: The default rejection\n                condition for workflow queries if not set during query. See\n                :py:meth:`WorkflowHandle.query` for details on the rejection\n                condition.\n            tls: If false, the default, do not use TLS. If true, use system\n                default TLS configuration. If TLS configuration present, that\n                TLS configuration will be used.\n            retry_config: Retry configuration for direct service calls (when\n                opted in) or all high-level calls made by this client (which all\n                opt-in to retries by default). If unset, a default retry\n                configuration is used.\n            keep_alive_config: Keep-alive configuration for the client\n                connection. Default is to check every 30s and kill the\n                connection if a response doesn't come back in 15s. Can be set to\n                ``None`` to disable.\n            rpc_metadata: Headers to use for all calls to the server. Keys here\n                can be overriden by per-call RPC metadata keys.\n            identity: Identity for this client. If unset, a default is created\n                based on the version of the SDK.\n            lazy: If true, the client will not connect until the first call is\n                attempted or a worker is created with it. Lazy clients cannot be\n                used for workers.\n            runtime: The runtime for this client, or the default if unset.\n            http_connect_proxy_config: Configuration for HTTP CONNECT proxy.\n            default_task_queue: The default task queue to use for this client.\n            config: The configuration for this client.\n        \"\"\"\n        if config is None:\n            from lzl.ext.temporal.configs import get_temporal_settings\n            config = get_temporal_settings()\n\n        if not target_host: target_host = config.host\n        # print('target_host: ', target_host)\n        if not namespace and config.namespace: namespace = config.namespace\n        if not api_key and config.api_key: api_key = config.api_key\n        if not default_task_queue and config.default_task_queue: default_task_queue = config.default_task_queue\n        if not tls and config.tls is not None: tls = config.tls\n        if not identity and config.identity: identity = config.identity\n        if not lazy and config.lazy is not None: lazy = config.lazy\n        if data_converter is None: data_converter = config.data_converter\n\n        from temporalio.service import ServiceClient, ConnectConfig\n        connect_config = ConnectConfig(\n            target_host=target_host,\n            api_key=api_key,\n            tls=tls,\n            retry_config=retry_config,\n            keep_alive_config=keep_alive_config,\n            rpc_metadata=rpc_metadata,\n            identity=identity or \"\",\n            lazy=lazy,\n            runtime=runtime,\n            http_connect_proxy_config=http_connect_proxy_config,\n        )\n        new = cls(\n            await ServiceClient.connect(connect_config),\n            namespace=namespace,\n            data_converter=data_converter,\n            interceptors=interceptors,\n            default_workflow_query_reject_condition=default_workflow_query_reject_condition,\n        )\n        new._postinit_config_(config = config, **kwargs)\n        return new\n\n    def _postinit_config_(self, config: t.Optional['TemporalSettings'] = None, **kwargs) -&gt; None:\n        \"\"\"\n        Some post-init config\n        \"\"\"\n        if config is None:\n            from lzl.ext.temporal.configs import get_temporal_settings\n            config = get_temporal_settings()\n        self.tmprl_config = config\n        self.tmprl_registry = self.tmprl_config.registry\n        self._extra: t.Dict[str, t.Any] = {}\n        self.tmprl_registry.register_client(self)\n        # self.tmprl_registry.clients[self.namespace] = self\n        # self.tmprl_registry.client = self\n\n    async def run_worker(\n        self,\n        worker: 'Worker',\n        event: asyncio.Event,\n        **kwargs,\n    ):\n        \"\"\"\n        Runs a Temporal Worker\n        \"\"\"\n        from lzo.utils import Timer\n        ts = Timer(format_short = 1)\n        extra = f'|g|NS|e|: `{self.namespace}`' if self.namespace else ''\n        if worker.task_queue: extra += f', |g|TQ|e|: `{worker.task_queue}`'\n        extra = f' ({extra.strip()})' if extra else ''\n        logger.info(f'Starting Temporal Worker{extra}', colored = True)\n        await worker.run()\n        try:\n            await event.wait()\n        finally:\n            logger.info(f'Shutting Down Temporal Worker. (|g|TTL|e|: {ts.total_s})', prefix = worker.task_queue, colored = True)\n\n    # def run_worker(\n    #     self,\n    #     worker: 'Worker',\n    #     event: t.Optional[asyncio.Event] = None,\n    #     **kwargs,\n    # ):\n    #     \"\"\"\n    #     Runs a Temporal Worker\n    #     \"\"\"\n    #     if event is None: event = asyncio.Event()\n    #     loop = asyncio.get_running_loop()\n    #     try:\n\n    #         loop.run_until_complete(self._run_worker(worker, event, **kwargs))\n    #     except Exception as e:\n    #         logger.error(f'Error Running Temporal Worker: {e}')\n    #         raise e\n    #     finally:\n    #         event.set()\n    #         loop.run_until_complete(loop.shutdown_asyncgens())\n    if t.TYPE_CHECKING:\n        def get_workflow_handle(\n            self,\n            workflow_id: str,\n            *,\n            run_id: t.Optional[str] = None,\n            first_execution_run_id: t.Optional[str] = None,\n            result_type: t.Optional[t.Type] = None,\n        ) -&gt; patches.WorkflowHandle[t.Any, t.Any]:\n            \"\"\"Get a workflow handle to an existing workflow by its ID.\n\n            Args:\n                workflow_id: Workflow ID to get a handle to.\n                run_id: Run ID that will be used for all calls.\n                first_execution_run_id: First execution run ID used for cancellation\n                    and termination.\n                result_type: The result type to deserialize into if known.\n\n            Returns:\n                The workflow handle.\n            \"\"\"\n            ...\n\n\n\n\n    if not t.TYPE_CHECKING:\n        # async def start_workflow(\n        #     self,\n        #     workflow: t.Callable[\n        #         t.Concatenate['SelfType', 'MultiParamSpec'], t.Awaitable['ReturnType']\n        #     ],\n        #     arg: t.Any, \n        #     *,\n        #     args: t.Sequence[t.Any] = [], \n        #     id: str,\n        #     task_queue: t.Optional[str] = None,\n        #     **kwargs,\n        # ):\n        #     if task_queue is None and self._tconf.default_task_queue: task_queue = self._tconf.default_task_queue\n        #     return await super().start_workflow(workflow, arg, args = args, task_queue = task_queue, id = id, **kwargs)\n\n        async def execute_workflow(\n            self,\n            workflow: 'MethodAsyncSingleParam[SelfType, ParamType, ReturnType]',\n            arg: t.Any, \n            *,\n            args: t.Sequence[t.Any] = [], \n            id: str,\n            task_queue: t.Optional[str] = None,\n            **kwargs,\n        ):\n            if task_queue is None and self.tmprl_config.default_task_queue: task_queue = self.tmprl_config.default_task_queue\n            return await super().execute_workflow(workflow, arg, args = args,  task_queue = task_queue, id = id, **kwargs)\n</code></pre>"},{"location":"api/lzl/ext/#lzl.ext.temporal.client.TemporalClient.connect","title":"<code>connect(target_host=None, namespace=None, api_key=None, data_converter=None, interceptors=[], default_workflow_query_reject_condition=None, tls=False, retry_config=None, keep_alive_config=KeepAliveConfig.default, rpc_metadata={}, identity=None, lazy=False, runtime=None, http_connect_proxy_config=None, default_task_queue=None, config=None, **kwargs)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Connect to a Temporal server.</p> <p>Parameters:</p> Name Type Description Default <code>target_host</code> <code>Optional[str]</code> <p><code>host:port</code> for the Temporal server. For local development, this is often \"localhost:7233\".</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Namespace to use for client calls.</p> <code>None</code> <code>api_key</code> <code>Optional[str]</code> <p>API key for Temporal. This becomes the \"Authorization\" HTTP header with \"Bearer \" prepended. This is only set if RPC metadata doesn't already have an \"authorization\" key.</p> <code>None</code> <code>data_converter</code> <code>Optional['DataConverter']</code> <p>Data converter to use for all data conversions to/from payloads.</p> <code>None</code> <code>interceptors</code> <code>Sequence['Interceptor']</code> <p>Set of interceptors that are chained together to allow intercepting of client calls. The earlier interceptors wrap the later ones.</p> <p>Any interceptors that also implement :py:class:<code>temporalio.worker.Interceptor</code> will be used as worker interceptors too so they should not be given when creating a worker.</p> <code>[]</code> <code>default_workflow_query_reject_condition</code> <code>Optional['QueryRejectCondition']</code> <p>The default rejection condition for workflow queries if not set during query. See :py:meth:<code>WorkflowHandle.query</code> for details on the rejection condition.</p> <code>None</code> <code>tls</code> <code>Union[bool, 'TLSConfig']</code> <p>If false, the default, do not use TLS. If true, use system default TLS configuration. If TLS configuration present, that TLS configuration will be used.</p> <code>False</code> <code>retry_config</code> <code>Optional['RetryConfig']</code> <p>Retry configuration for direct service calls (when opted in) or all high-level calls made by this client (which all opt-in to retries by default). If unset, a default retry configuration is used.</p> <code>None</code> <code>keep_alive_config</code> <code>Optional['KeepAliveConfig']</code> <p>Keep-alive configuration for the client connection. Default is to check every 30s and kill the connection if a response doesn't come back in 15s. Can be set to <code>None</code> to disable.</p> <code>default</code> <code>rpc_metadata</code> <code>Mapping[str, str]</code> <p>Headers to use for all calls to the server. Keys here can be overriden by per-call RPC metadata keys.</p> <code>{}</code> <code>identity</code> <code>Optional[str]</code> <p>Identity for this client. If unset, a default is created based on the version of the SDK.</p> <code>None</code> <code>lazy</code> <code>bool</code> <p>If true, the client will not connect until the first call is attempted or a worker is created with it. Lazy clients cannot be used for workers.</p> <code>False</code> <code>runtime</code> <code>Optional['Runtime']</code> <p>The runtime for this client, or the default if unset.</p> <code>None</code> <code>http_connect_proxy_config</code> <code>Optional['HttpConnectProxyConfig']</code> <p>Configuration for HTTP CONNECT proxy.</p> <code>None</code> <code>default_task_queue</code> <code>Optional[str]</code> <p>The default task queue to use for this client.</p> <code>None</code> <code>config</code> <code>Optional['TemporalSettings']</code> <p>The configuration for this client.</p> <code>None</code> Source code in <code>src/lzl/ext/temporal/client.py</code> <pre><code>@classmethod\nasync def connect(\n    cls: t.Type['TemporalClient'],\n    target_host: t.Optional[str] = None,\n    namespace: t.Optional[str] = None,\n    api_key: t.Optional[str] = None,\n    data_converter: t.Optional['DataConverter'] = None,\n    interceptors: t.Sequence['Interceptor'] = [],\n    default_workflow_query_reject_condition: t.Optional[\n        'QueryRejectCondition'\n    ] = None,\n    tls: t.Union[bool, 'TLSConfig'] = False,\n    retry_config: t.Optional['RetryConfig'] = None,\n    keep_alive_config: t.Optional['KeepAliveConfig'] = KeepAliveConfig.default,\n    rpc_metadata: t.Mapping[str, str] = {},\n    identity: t.Optional[str] = None,\n    lazy: bool = False,\n    runtime: t.Optional['Runtime'] = None,\n    http_connect_proxy_config: t.Optional['HttpConnectProxyConfig'] = None,\n    default_task_queue: t.Optional[str] = None,\n    config: t.Optional['TemporalSettings'] = None,\n    **kwargs,\n) -&gt; TemporalClient:  # sourcery skip: default-mutable-arg\n    \"\"\"Connect to a Temporal server.\n\n    Args:\n        target_host: ``host:port`` for the Temporal server. For local\n            development, this is often \"localhost:7233\".\n        namespace: Namespace to use for client calls.\n        api_key: API key for Temporal. This becomes the \"Authorization\"\n            HTTP header with \"Bearer \" prepended. This is only set if RPC\n            metadata doesn't already have an \"authorization\" key.\n        data_converter: Data converter to use for all data conversions\n            to/from payloads.\n        interceptors: Set of interceptors that are chained together to allow\n            intercepting of client calls. The earlier interceptors wrap the\n            later ones.\n\n            Any interceptors that also implement\n            :py:class:`temporalio.worker.Interceptor` will be used as worker\n            interceptors too so they should not be given when creating a\n            worker.\n        default_workflow_query_reject_condition: The default rejection\n            condition for workflow queries if not set during query. See\n            :py:meth:`WorkflowHandle.query` for details on the rejection\n            condition.\n        tls: If false, the default, do not use TLS. If true, use system\n            default TLS configuration. If TLS configuration present, that\n            TLS configuration will be used.\n        retry_config: Retry configuration for direct service calls (when\n            opted in) or all high-level calls made by this client (which all\n            opt-in to retries by default). If unset, a default retry\n            configuration is used.\n        keep_alive_config: Keep-alive configuration for the client\n            connection. Default is to check every 30s and kill the\n            connection if a response doesn't come back in 15s. Can be set to\n            ``None`` to disable.\n        rpc_metadata: Headers to use for all calls to the server. Keys here\n            can be overriden by per-call RPC metadata keys.\n        identity: Identity for this client. If unset, a default is created\n            based on the version of the SDK.\n        lazy: If true, the client will not connect until the first call is\n            attempted or a worker is created with it. Lazy clients cannot be\n            used for workers.\n        runtime: The runtime for this client, or the default if unset.\n        http_connect_proxy_config: Configuration for HTTP CONNECT proxy.\n        default_task_queue: The default task queue to use for this client.\n        config: The configuration for this client.\n    \"\"\"\n    if config is None:\n        from lzl.ext.temporal.configs import get_temporal_settings\n        config = get_temporal_settings()\n\n    if not target_host: target_host = config.host\n    # print('target_host: ', target_host)\n    if not namespace and config.namespace: namespace = config.namespace\n    if not api_key and config.api_key: api_key = config.api_key\n    if not default_task_queue and config.default_task_queue: default_task_queue = config.default_task_queue\n    if not tls and config.tls is not None: tls = config.tls\n    if not identity and config.identity: identity = config.identity\n    if not lazy and config.lazy is not None: lazy = config.lazy\n    if data_converter is None: data_converter = config.data_converter\n\n    from temporalio.service import ServiceClient, ConnectConfig\n    connect_config = ConnectConfig(\n        target_host=target_host,\n        api_key=api_key,\n        tls=tls,\n        retry_config=retry_config,\n        keep_alive_config=keep_alive_config,\n        rpc_metadata=rpc_metadata,\n        identity=identity or \"\",\n        lazy=lazy,\n        runtime=runtime,\n        http_connect_proxy_config=http_connect_proxy_config,\n    )\n    new = cls(\n        await ServiceClient.connect(connect_config),\n        namespace=namespace,\n        data_converter=data_converter,\n        interceptors=interceptors,\n        default_workflow_query_reject_condition=default_workflow_query_reject_condition,\n    )\n    new._postinit_config_(config = config, **kwargs)\n    return new\n</code></pre>"},{"location":"api/lzl/ext/#lzl.ext.temporal.client.TemporalClient.run_worker","title":"<code>run_worker(worker, event, **kwargs)</code>  <code>async</code>","text":"<p>Runs a Temporal Worker</p> Source code in <code>src/lzl/ext/temporal/client.py</code> <pre><code>async def run_worker(\n    self,\n    worker: 'Worker',\n    event: asyncio.Event,\n    **kwargs,\n):\n    \"\"\"\n    Runs a Temporal Worker\n    \"\"\"\n    from lzo.utils import Timer\n    ts = Timer(format_short = 1)\n    extra = f'|g|NS|e|: `{self.namespace}`' if self.namespace else ''\n    if worker.task_queue: extra += f', |g|TQ|e|: `{worker.task_queue}`'\n    extra = f' ({extra.strip()})' if extra else ''\n    logger.info(f'Starting Temporal Worker{extra}', colored = True)\n    await worker.run()\n    try:\n        await event.wait()\n    finally:\n        logger.info(f'Shutting Down Temporal Worker. (|g|TTL|e|: {ts.total_s})', prefix = worker.task_queue, colored = True)\n</code></pre>"},{"location":"api/lzl/ext/#lzl.ext.temporal.client.TemporalClient.get_workflow_handle","title":"<code>get_workflow_handle(workflow_id, *, run_id=None, first_execution_run_id=None, result_type=None)</code>","text":"<p>Get a workflow handle to an existing workflow by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>workflow_id</code> <code>str</code> <p>Workflow ID to get a handle to.</p> required <code>run_id</code> <code>Optional[str]</code> <p>Run ID that will be used for all calls.</p> <code>None</code> <code>first_execution_run_id</code> <code>Optional[str]</code> <p>First execution run ID used for cancellation and termination.</p> <code>None</code> <code>result_type</code> <code>Optional[Type]</code> <p>The result type to deserialize into if known.</p> <code>None</code> <p>Returns:</p> Type Description <code>WorkflowHandle[Any, Any]</code> <p>The workflow handle.</p> Source code in <code>src/lzl/ext/temporal/client.py</code> <pre><code>def get_workflow_handle(\n    self,\n    workflow_id: str,\n    *,\n    run_id: t.Optional[str] = None,\n    first_execution_run_id: t.Optional[str] = None,\n    result_type: t.Optional[t.Type] = None,\n) -&gt; patches.WorkflowHandle[t.Any, t.Any]:\n    \"\"\"Get a workflow handle to an existing workflow by its ID.\n\n    Args:\n        workflow_id: Workflow ID to get a handle to.\n        run_id: Run ID that will be used for all calls.\n        first_execution_run_id: First execution run ID used for cancellation\n            and termination.\n        result_type: The result type to deserialize into if known.\n\n    Returns:\n        The workflow handle.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/lzl/ext/#utils","title":"Utils","text":""},{"location":"api/lzl/ext/#lzl.ext.temporal.utils","title":"<code>lzl.ext.temporal.utils</code>","text":""},{"location":"api/lzl/ext/#jinja2","title":"Jinja2","text":""},{"location":"api/lzl/ext/#lzl.ext.jinja","title":"<code>lzl.ext.jinja</code>","text":"<p>Jinja2 Extension</p> <ul> <li>Unifies the Jinja2 Environment handle both sync and async</li> </ul>"},{"location":"api/lzl/ext/#server","title":"Server","text":""},{"location":"api/lzl/ext/#lzl.ext.server","title":"<code>lzl.ext.server</code>","text":"<p>Server Extensions</p>"},{"location":"api/lzl/io/","title":"lzl.io - I/O Operations","text":"<p>The <code>lzl.io</code> module provides comprehensive input/output operations including serialization, persistence, file handling, and data compression.</p>"},{"location":"api/lzl/io/#modules","title":"Modules","text":""},{"location":"api/lzl/io/#lzl.io","title":"<code>lzl.io</code>","text":""},{"location":"api/lzl/io/#lzl.io.File","title":"<code>File</code>","text":"<p>               Bases: <code>Generic[FileLikeT]</code></p> <p>Factory that instantiates concrete path objects for various backends.</p>"},{"location":"api/lzl/io/#lzl.io.File.get_dir","title":"<code>get_dir(path)</code>  <code>classmethod</code>","text":"<p>Return the parent directory for the provided path-like value.</p>"},{"location":"api/lzl/io/#lzl.io.File.get_object_size","title":"<code>get_object_size(obj)</code>  <code>classmethod</code>","text":"<p>Return a convenience wrapper reporting object size in bytes.</p>"},{"location":"api/lzl/io/#lzl.io.File.register_loader","title":"<code>register_loader(ext, loader, overwrite=None)</code>  <code>classmethod</code>","text":"<p>Register a loader callback for the given file extension.</p> <p>Parameters:</p> Name Type Description Default <code>ext</code> <code>str</code> <p>Extension (<code>.json</code>, <code>.csv</code>\u2026) to register the loader against.  A leading dot is optional.</p> required <code>loader</code> <code>Union[Callable[['FileLike'], None], Awaitable['FileLike', None]]</code> <p>Callable that receives the resolved :class:<code>FileLike</code> instance and should return either a processed value or coroutine.</p> required <code>overwrite</code> <code>Optional[bool]</code> <p>When <code>True</code> the loader replaces any existing registration for <code>ext</code>.</p> <code>None</code>"},{"location":"api/lzl/io/#serialization","title":"Serialization","text":"<p>The serialization submodule provides various serializers for common data formats:</p>"},{"location":"api/lzl/io/#lzl.io.ser","title":"<code>lzl.io.ser</code>","text":""},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer","title":"<code>BaseSerializer</code>","text":"<p>               Bases: <code>ABC</code></p> <p>The Base Serializer Class</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>class BaseSerializer(abc.ABC):\n    \"\"\"\n    The Base Serializer Class\n    \"\"\"\n    name: Optional[str] = None\n    encoding: Optional[str] = None\n    binary: Optional[bool] = False\n    compressor: Optional['CompressionT'] = None\n    previous_compressor: Optional['CompressionT'] = None\n    enforce_string_value: Optional[bool] = False\n    enforce_byte_value: Optional[bool] = False\n    ser_mode: Optional[SerMode] = 'auto'\n    _is_ser: Optional[bool] = True\n\n    def __init__(\n        self,\n        compression: Optional[str] = None,\n        compression_level: Optional[int] = None,\n        encoding: Optional[str] = None,\n        raise_errors: bool = False,\n        enforce_string_value: Optional[bool] = None,\n        enforce_byte_value: Optional[bool] = None,\n        ser_mode: Optional[SerMode] = None,\n        deprecated_compression: Optional[str] = None,\n        schema_map: Optional[Dict[str, str]] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Initializes the serializer\n        \"\"\"\n        if compression is not None or compression_level is not None:\n            from ..compression import get_compression\n            compression_kwargs = kwargs.pop(\"compression_kwargs\", None)\n            decompression_kwargs = kwargs.pop(\"decompression_kwargs\", None)\n            deprecated_compression = kwargs.pop(\"deprecated_compression\", None)\n            self.compressor = get_compression(\n                compression, \n                compression_level = compression_level, \n                compression_kwargs = compression_kwargs, \n                decompression_kwargs = decompression_kwargs,\n            )\n            if deprecated_compression is not None and deprecated_compression != compression:\n                self.previous_compressor = get_compression(deprecated_compression)\n        if encoding is not None: self.encoding = encoding\n        if enforce_string_value is not None: self.enforce_string_value = enforce_string_value\n        if enforce_byte_value is not None: self.enforce_byte_value = enforce_byte_value\n        if ser_mode is not None: self.ser_mode = ser_mode\n        self.schema_map = schema_map\n        self.raise_errors = raise_errors\n        self._kwargs = kwargs\n\n    @property\n    def compression_enabled(self) -&gt; bool:\n        \"\"\"\n        Returns if compression is enabled\n        \"\"\"\n        return self.compressor is not None\n\n    @property\n    def compression_level(self) -&gt; Optional[int]:\n        \"\"\"\n        Returns the compression level\n        \"\"\"\n        return self.compressor.compression_level if self.compressor is not None else None\n\n    @property\n    def is_binary(self) -&gt; bool:\n        \"\"\"\n        Returns whether the serializer output is binary\n        \"\"\"\n        if self.enforce_byte_value: return True\n        if self.enforce_string_value: return False\n        return self.binary or self.compression_enabled\n\n    @staticmethod\n    def fetch_object_classname(obj: ObjectValue, is_type: Optional[bool] = False) -&gt; str:\n        \"\"\"\n        Fetches the object classname\n        \"\"\"\n        return get_object_classname(obj, is_type = is_type)\n\n    @staticmethod\n    def fetch_object_class(name: str) -&gt; Type[SerializableObject]:\n        \"\"\"\n        Gets the object class\n        \"\"\"\n        return get_object_class(name)\n\n    @staticmethod\n    def register_schema(schema: Dict[str, str]) -&gt; None:\n        \"\"\"\n        Registers the schema\n        \"\"\"\n        register_schema_mapping(schema)\n\n    @staticmethod\n    def register_object_class(obj: SerializableObject, is_type: Optional[bool] = False) -&gt; str:\n        \"\"\"\n        Registers the object class\n        \"\"\"\n        return register_object_class(obj, is_type = is_type)\n\n    def create_hash(self, obj: ObjectValue) -&gt; str:\n        \"\"\"\n        Creates a hash for the object\n        \"\"\"\n        return create_object_hash(obj)\n\n    async def acreate_hash(self, obj: ObjectValue) -&gt; str:\n        \"\"\"\n        Creates a hash for the object asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.create_hash, obj)\n\n    def coerce_output_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Coerces the output value\n        \"\"\"\n        if self.enforce_string_value and isinstance(value, bytes): value = value.decode(self.encoding)\n        elif self.enforce_byte_value and not isinstance(value, bytes): value = value.encode(self.encoding)\n        return value\n\n    def compress_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Compresses the value\n        \"\"\"\n        if self.compression_enabled:\n            if isinstance(value, str): value = value.encode(self.encoding)\n            return self.coerce_output_value(self.compressor.compress(value))\n        return self.coerce_output_value(value)\n\n    def deprecated_decompress_value(self, value: Union[str, bytes], **kwargs) -&gt; Optional[Union[str, bytes]]:\n        \"\"\"\n        Attempts to decompress the value using the deprecated compressor\n        \"\"\"\n        e = None\n        attempt_msg = f\"{self.name}\"\n        if self.previous_compressor is not None:\n            try:\n                return self.previous_compressor.decompress(value)\n            except Exception as e:\n                attempt_msg += f\"-&gt; {self.previous_compressor.name}\"\n        try:\n            return zlib.decompress(value)\n        except Exception as e:\n            attempt_msg += \" -&gt; ZLib\"\n            logger.trace(f'[{attempt_msg}] Error in Decompression: {str(value)[:100]}', e)\n            if self.raise_errors: raise e\n            return None\n\n\n    def decompress_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n        # sourcery skip: extract-duplicate-method\n        \"\"\"\n        Decompresses the value\n        \"\"\"\n        if not self.compression_enabled: return value\n        try:\n            value = self.compressor.decompress(value, **kwargs)\n        except Exception as e:\n            if self.previous_compressor is not None:\n                value = self.deprecated_decompress_value(value, **kwargs)\n        if value is not None and not self.binary: value = value.decode(self.encoding)\n        return value\n\n    def encode_value(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Encodes the value\n        \"\"\"\n        raise NotImplementedError\n\n    def encode(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Encodes the value\n        \"\"\"\n        return self.compress_value(self.encode_value(value, **kwargs))\n\n    async def aencode(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Encodes the value asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.encode, value, **kwargs)\n\n    def decode_value(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value\n        \"\"\"\n        raise NotImplementedError\n\n    def decode(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value\n        \"\"\"\n        return self.decode_value(self.decompress_value(value, **kwargs), **kwargs)\n\n    async def adecode(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.decode, value, **kwargs)\n\n    def dumps(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        # sourcery skip: class-extract-method\n        \"\"\"\n        Dumps the value\n        \"\"\"\n        try:\n            return self.encode(value, **kwargs)\n        except Exception as e:\n            logger.trace(f'[{self.name}] Error in Encoding: {str(value)[:500]}', e)\n            if self.raise_errors: raise e\n            return None\n\n    async def adumps(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Dumps the value asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.dumps, value, **kwargs)\n\n    def loads(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Loads the value\n        \"\"\"\n        try:\n            return self.decode(value, **kwargs)\n        except Exception as e:\n            logger.trace(f'[{self.name}] Error in Decoding: {str(value)[:500]}', e)\n            if self.raise_errors: raise e\n            return None\n\n    async def aloads(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Loads the value asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.loads, value, **kwargs)\n\n\n    def serialize_obj(self, obj: SerializableObject, mode: Optional[SerMode] = None, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Serializes the object\n        \"\"\"\n        mode = mode or self.ser_mode\n        return serialize_object(obj, mode = mode, **kwargs)\n\n    def deserialize_obj(\n        self, \n        obj: Union[Dict[str, Any], List[Dict[str, Any]], Any], \n        schema_map: Optional[Dict[str, str]] = None, \n        allow_failed_import: Optional[bool] = False,\n        **kwargs\n    ) -&gt; SerializableObject:\n        \"\"\"\n        Deserializes the object\n        \"\"\"\n        return deserialize_object(obj, schema_map = schema_map or self.schema_map, allow_failed_import = allow_failed_import, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.compression_enabled","title":"<code>compression_enabled</code>  <code>property</code>","text":"<p>Returns if compression is enabled</p>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.compression_level","title":"<code>compression_level</code>  <code>property</code>","text":"<p>Returns the compression level</p>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.is_binary","title":"<code>is_binary</code>  <code>property</code>","text":"<p>Returns whether the serializer output is binary</p>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.fetch_object_classname","title":"<code>fetch_object_classname(obj, is_type=False)</code>  <code>staticmethod</code>","text":"<p>Fetches the object classname</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>@staticmethod\ndef fetch_object_classname(obj: ObjectValue, is_type: Optional[bool] = False) -&gt; str:\n    \"\"\"\n    Fetches the object classname\n    \"\"\"\n    return get_object_classname(obj, is_type = is_type)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.fetch_object_class","title":"<code>fetch_object_class(name)</code>  <code>staticmethod</code>","text":"<p>Gets the object class</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>@staticmethod\ndef fetch_object_class(name: str) -&gt; Type[SerializableObject]:\n    \"\"\"\n    Gets the object class\n    \"\"\"\n    return get_object_class(name)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.register_schema","title":"<code>register_schema(schema)</code>  <code>staticmethod</code>","text":"<p>Registers the schema</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>@staticmethod\ndef register_schema(schema: Dict[str, str]) -&gt; None:\n    \"\"\"\n    Registers the schema\n    \"\"\"\n    register_schema_mapping(schema)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.register_object_class","title":"<code>register_object_class(obj, is_type=False)</code>  <code>staticmethod</code>","text":"<p>Registers the object class</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>@staticmethod\ndef register_object_class(obj: SerializableObject, is_type: Optional[bool] = False) -&gt; str:\n    \"\"\"\n    Registers the object class\n    \"\"\"\n    return register_object_class(obj, is_type = is_type)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.create_hash","title":"<code>create_hash(obj)</code>","text":"<p>Creates a hash for the object</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def create_hash(self, obj: ObjectValue) -&gt; str:\n    \"\"\"\n    Creates a hash for the object\n    \"\"\"\n    return create_object_hash(obj)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.acreate_hash","title":"<code>acreate_hash(obj)</code>  <code>async</code>","text":"<p>Creates a hash for the object asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def acreate_hash(self, obj: ObjectValue) -&gt; str:\n    \"\"\"\n    Creates a hash for the object asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.create_hash, obj)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.coerce_output_value","title":"<code>coerce_output_value(value, **kwargs)</code>","text":"<p>Coerces the output value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def coerce_output_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Coerces the output value\n    \"\"\"\n    if self.enforce_string_value and isinstance(value, bytes): value = value.decode(self.encoding)\n    elif self.enforce_byte_value and not isinstance(value, bytes): value = value.encode(self.encoding)\n    return value\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.compress_value","title":"<code>compress_value(value, **kwargs)</code>","text":"<p>Compresses the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def compress_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Compresses the value\n    \"\"\"\n    if self.compression_enabled:\n        if isinstance(value, str): value = value.encode(self.encoding)\n        return self.coerce_output_value(self.compressor.compress(value))\n    return self.coerce_output_value(value)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.deprecated_decompress_value","title":"<code>deprecated_decompress_value(value, **kwargs)</code>","text":"<p>Attempts to decompress the value using the deprecated compressor</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def deprecated_decompress_value(self, value: Union[str, bytes], **kwargs) -&gt; Optional[Union[str, bytes]]:\n    \"\"\"\n    Attempts to decompress the value using the deprecated compressor\n    \"\"\"\n    e = None\n    attempt_msg = f\"{self.name}\"\n    if self.previous_compressor is not None:\n        try:\n            return self.previous_compressor.decompress(value)\n        except Exception as e:\n            attempt_msg += f\"-&gt; {self.previous_compressor.name}\"\n    try:\n        return zlib.decompress(value)\n    except Exception as e:\n        attempt_msg += \" -&gt; ZLib\"\n        logger.trace(f'[{attempt_msg}] Error in Decompression: {str(value)[:100]}', e)\n        if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.decompress_value","title":"<code>decompress_value(value, **kwargs)</code>","text":"<p>Decompresses the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def decompress_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n    # sourcery skip: extract-duplicate-method\n    \"\"\"\n    Decompresses the value\n    \"\"\"\n    if not self.compression_enabled: return value\n    try:\n        value = self.compressor.decompress(value, **kwargs)\n    except Exception as e:\n        if self.previous_compressor is not None:\n            value = self.deprecated_decompress_value(value, **kwargs)\n    if value is not None and not self.binary: value = value.decode(self.encoding)\n    return value\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.encode_value","title":"<code>encode_value(value, **kwargs)</code>","text":"<p>Encodes the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def encode_value(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Encodes the value\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.encode","title":"<code>encode(value, **kwargs)</code>","text":"<p>Encodes the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def encode(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Encodes the value\n    \"\"\"\n    return self.compress_value(self.encode_value(value, **kwargs))\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.aencode","title":"<code>aencode(value, **kwargs)</code>  <code>async</code>","text":"<p>Encodes the value asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def aencode(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Encodes the value asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.encode, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.decode_value","title":"<code>decode_value(value, **kwargs)</code>","text":"<p>Decodes the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def decode_value(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.decode","title":"<code>decode(value, **kwargs)</code>","text":"<p>Decodes the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def decode(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value\n    \"\"\"\n    return self.decode_value(self.decompress_value(value, **kwargs), **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.adecode","title":"<code>adecode(value, **kwargs)</code>  <code>async</code>","text":"<p>Decodes the value asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def adecode(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.decode, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.dumps","title":"<code>dumps(value, **kwargs)</code>","text":"<p>Dumps the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def dumps(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    # sourcery skip: class-extract-method\n    \"\"\"\n    Dumps the value\n    \"\"\"\n    try:\n        return self.encode(value, **kwargs)\n    except Exception as e:\n        logger.trace(f'[{self.name}] Error in Encoding: {str(value)[:500]}', e)\n        if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.adumps","title":"<code>adumps(value, **kwargs)</code>  <code>async</code>","text":"<p>Dumps the value asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def adumps(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Dumps the value asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.dumps, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.loads","title":"<code>loads(value, **kwargs)</code>","text":"<p>Loads the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def loads(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Loads the value\n    \"\"\"\n    try:\n        return self.decode(value, **kwargs)\n    except Exception as e:\n        logger.trace(f'[{self.name}] Error in Decoding: {str(value)[:500]}', e)\n        if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.aloads","title":"<code>aloads(value, **kwargs)</code>  <code>async</code>","text":"<p>Loads the value asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def aloads(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Loads the value asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.loads, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.serialize_obj","title":"<code>serialize_obj(obj, mode=None, **kwargs)</code>","text":"<p>Serializes the object</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def serialize_obj(self, obj: SerializableObject, mode: Optional[SerMode] = None, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Serializes the object\n    \"\"\"\n    mode = mode or self.ser_mode\n    return serialize_object(obj, mode = mode, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.deserialize_obj","title":"<code>deserialize_obj(obj, schema_map=None, allow_failed_import=False, **kwargs)</code>","text":"<p>Deserializes the object</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def deserialize_obj(\n    self, \n    obj: Union[Dict[str, Any], List[Dict[str, Any]], Any], \n    schema_map: Optional[Dict[str, str]] = None, \n    allow_failed_import: Optional[bool] = False,\n    **kwargs\n) -&gt; SerializableObject:\n    \"\"\"\n    Deserializes the object\n    \"\"\"\n    return deserialize_object(obj, schema_map = schema_map or self.schema_map, allow_failed_import = allow_failed_import, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer","title":"<code>JsonSerializer</code>","text":"<p>               Bases: <code>BaseSerializer</code></p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>class JsonSerializer(BaseSerializer):\n\n    name: Optional[str] = \"json\"\n    encoding: Optional[str] = \"utf-8\"\n    jsonlib: JsonLibT = default_json\n    disable_object_serialization: Optional[bool] = False\n    disable_nested_values: Optional[bool] = None\n    allow_failed_import: Optional[bool] = False\n\n    def __init__(\n        self, \n        jsonlib: Optional[Union[str, Any]] = None,\n        compression: Optional[str] = None,\n        compression_level: int | None = None, \n        encoding: str | None = None, \n        serialization_obj: Optional[Type[BaseModel]] = None,\n        serialization_obj_kwargs: Optional[Dict[str, Any]] = None,\n        disable_object_serialization: Optional[bool] = None,\n        disable_nested_values: Optional[bool] = None,\n        verbosity: Optional[int] = None,\n        **kwargs\n    ):\n        super().__init__(compression = compression, compression_level = compression_level, encoding = encoding, **kwargs)\n        self.serialization_obj = serialization_obj\n        self.serialization_obj_kwargs = serialization_obj_kwargs or {}\n        self.serialization_schemas: Dict[str, Type[BaseModel]] = {}\n        if disable_object_serialization is not None:\n            self.disable_object_serialization = disable_object_serialization\n        if disable_nested_values is not None:\n            self.disable_nested_values = disable_nested_values\n        if jsonlib is not None:\n            if isinstance(jsonlib, str):\n                jsonlib = lazy_import(jsonlib, is_module=True)\n            assert hasattr(jsonlib, \"dumps\") and hasattr(jsonlib, \"loads\"), f\"Invalid JSON Library: {jsonlib}\"\n            self.jsonlib = jsonlib\n        self.verbosity = verbosity\n        self.jsonlib_name: str = self.jsonlib.__name__\n        if 'bindings' in self.jsonlib_name.lower():\n            self.jsonlib_name = self.jsonlib_name.rsplit('_', 1)[-1]\n\n    @classmethod\n    def set_default_lib(cls, lib: Union[str, JsonLibT, ModuleType]) -&gt; None:\n        \"\"\"\n        Sets the default JSON library\n        \"\"\"\n        global default_json\n        if isinstance(lib, str):\n            lib = lazy_import(lib, is_module=True)\n        assert hasattr(lib, \"dumps\") and hasattr(lib, \"loads\"), f\"Invalid JSON Library: {lib}\"\n        cls.jsonlib = lib\n        default_json = lib\n\n    @property\n    def _is_verbose(self) -&gt; bool:\n        \"\"\"\n        Returns whether the serializer is verbose\n        \"\"\"\n        return self.verbosity is None or self.verbosity &gt;= 1\n\n    @property\n    def _is_silenced(self) -&gt; bool:\n        \"\"\"\n        Returns whether the serializer is verbose\n        \"\"\"\n        return self.verbosity and self.verbosity &lt; 0\n\n    def serialize_obj(self, obj: SerializableObject, mode: Optional[SerMode] = None, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Serializes the object\n        \"\"\"\n        mode = mode or self.ser_mode\n        if 'disable_nested_values' not in kwargs and self.disable_nested_values is not None:\n            kwargs['disable_nested_values'] = self.disable_nested_values\n        if 'disable_object_serialization' in kwargs:\n            disable_object_serialization = kwargs.pop('disable_object_serialization')\n            mode = 'raw' if disable_object_serialization else mode\n        elif self.disable_object_serialization:\n            mode = 'raw'\n        return serialize_object(obj, mode = mode, **kwargs)\n\n    def encode_value(self, value: Union[Any, SchemaType], mode: Optional[SerMode] = None, **kwargs) -&gt; str:\n        \"\"\"\n        Encode the value with the JSON Library\n        \"\"\"\n        try:\n            value_dict = self.serialize_obj(value, mode = mode, **kwargs, **self.serialization_obj_kwargs)\n            encoded = self.jsonlib.dumps(value_dict, **kwargs)\n            return self.coerce_output_value(encoded)\n\n        except Exception as e:\n            if not self._is_silenced: logger.trace(f'Error Encoding Value: |r|({type(value)})|e| {str(value)[:1000]}', e, colored = True)\n        try:\n            encoded = self.jsonlib.dumps(value, **kwargs)\n            return self.coerce_output_value(encoded)\n        except Exception as e:\n            if not self._is_silenced: logger.info(f'Error Encoding Value: |r|({type(value)}) {e}|e| {str(value)[:1000]}', colored = True, prefix = self.jsonlib_name)\n            if self.raise_errors: raise e\n        return None\n\n\n    def decode(self, value: Union[str, bytes], schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value\n        \"\"\"\n        try:\n            decompressed_value = self.decompress_value(value, **kwargs)\n            if decompressed_value is not None:\n                value = decompressed_value\n        except Exception as e:\n            if not self._is_silenced: logger.info(f'Error Decompressing Value: |r|({type(value)}) {e}|e| {str(value)[:100]}', colored = True, prefix = self.jsonlib_name)\n            if raise_errors or self.raise_errors: raise ValueError(f\"[{self.name}] Error in Decompression: {str(value)[:100]}\") from e\n            # return self.decode_value(value, **kwargs)\n        return self.decode_value(value, schema_map = schema_map, raise_errors = raise_errors, **kwargs)\n\n\n    def decode_value(self, value: str, schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n        \"\"\"\n        Decode the value with the JSON Library\n        \"\"\"\n        if value is None: return None\n        if isinstance(value, (str, bytes)):\n            try:\n                # value = self.check_encoded_value(value)\n                value = self.jsonlib.loads(value, **kwargs)\n            except Exception as e:\n                if isinstance(value, str) and 'Exception' in value or 'Traceback (most recent call last):' in value:\n                    return value\n                str_value = str(value)\n                if not schema_map: str_value = str_value[:1000]\n                if self._is_verbose: logger.info(f'Error JSON Decoding Value: |r|({type(value)}) {e}|e| {str_value}', colored = True, prefix = self.jsonlib_name)\n                if raise_errors or self.raise_errors: raise e\n        try:\n            return self.deserialize_obj(value, schema_map = schema_map, allow_failed_import = self.allow_failed_import)\n        except Exception as e:\n            str_value = str(value)\n            if not schema_map: str_value = str_value[:1000]\n            if not self._is_silenced: logger.trace(f'Error Deserializing Object: ({type(value)}) {str_value}', e, prefix = self.jsonlib_name)\n            if raise_errors or self.raise_errors: raise e\n        return None\n\n\n    async def adecode(self, value: Union[str, bytes], schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value asynchronously\n        \"\"\"\n        return await ThreadPool.arun(self.decode, value, schema_map = schema_map, raise_errors = raise_errors, **kwargs)\n\n\n    if TYPE_CHECKING:\n        def dumps(\n            self, \n            value: ObjectValue, \n            skipkeys: bool = False, \n            ensure_ascii: bool = True, \n            check_circular: bool = True,\n            allow_nan: bool = True, \n            cls: Optional[Any] = None, \n            indent: Optional[int] = None, \n            separators: Optional[Tuple[str, str]] = None,\n            default: Optional[Any] = None, \n            sort_keys: bool = False,\n            mode: Optional[SerMode] = None,\n            **kwargs\n        ) -&gt; Union[str, bytes]:\n            \"\"\"Serialize ``obj`` to a JSON formatted ``str``.\n\n            If ``skipkeys`` is true then ``dict`` keys that are not basic types\n            (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n            instead of raising a ``TypeError``.\n\n            If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n            characters if they appear in strings contained in ``obj``. Otherwise, all\n            such characters are escaped in JSON strings.\n\n            If ``check_circular`` is false, then the circular reference check\n            for container types will be skipped and a circular reference will\n            result in an ``RecursionError`` (or worse).\n\n            If ``allow_nan`` is false, then it will be a ``ValueError`` to\n            serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n            strict compliance of the JSON specification, instead of using the\n            JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n\n            If ``indent`` is a non-negative integer, then JSON array elements and\n            object members will be pretty-printed with that indent level. An indent\n            level of 0 will only insert newlines. ``None`` is the most compact\n            representation.\n\n            If specified, ``separators`` should be an ``(item_separator, key_separator)``\n            tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n            ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n            you should specify ``(',', ':')`` to eliminate whitespace.\n\n            ``default(obj)`` is a function that should return a serializable version\n            of obj or raise TypeError. The default simply raises TypeError.\n\n            If *sort_keys* is true (default: ``False``), then the output of\n            dictionaries will be sorted by key.\n\n            To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n            ``.default()`` method to serialize additional types), specify it with\n            the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n\n            \"\"\"\n            ...\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.set_default_lib","title":"<code>set_default_lib(lib)</code>  <code>classmethod</code>","text":"<p>Sets the default JSON library</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>@classmethod\ndef set_default_lib(cls, lib: Union[str, JsonLibT, ModuleType]) -&gt; None:\n    \"\"\"\n    Sets the default JSON library\n    \"\"\"\n    global default_json\n    if isinstance(lib, str):\n        lib = lazy_import(lib, is_module=True)\n    assert hasattr(lib, \"dumps\") and hasattr(lib, \"loads\"), f\"Invalid JSON Library: {lib}\"\n    cls.jsonlib = lib\n    default_json = lib\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.serialize_obj","title":"<code>serialize_obj(obj, mode=None, **kwargs)</code>","text":"<p>Serializes the object</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def serialize_obj(self, obj: SerializableObject, mode: Optional[SerMode] = None, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Serializes the object\n    \"\"\"\n    mode = mode or self.ser_mode\n    if 'disable_nested_values' not in kwargs and self.disable_nested_values is not None:\n        kwargs['disable_nested_values'] = self.disable_nested_values\n    if 'disable_object_serialization' in kwargs:\n        disable_object_serialization = kwargs.pop('disable_object_serialization')\n        mode = 'raw' if disable_object_serialization else mode\n    elif self.disable_object_serialization:\n        mode = 'raw'\n    return serialize_object(obj, mode = mode, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.encode_value","title":"<code>encode_value(value, mode=None, **kwargs)</code>","text":"<p>Encode the value with the JSON Library</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def encode_value(self, value: Union[Any, SchemaType], mode: Optional[SerMode] = None, **kwargs) -&gt; str:\n    \"\"\"\n    Encode the value with the JSON Library\n    \"\"\"\n    try:\n        value_dict = self.serialize_obj(value, mode = mode, **kwargs, **self.serialization_obj_kwargs)\n        encoded = self.jsonlib.dumps(value_dict, **kwargs)\n        return self.coerce_output_value(encoded)\n\n    except Exception as e:\n        if not self._is_silenced: logger.trace(f'Error Encoding Value: |r|({type(value)})|e| {str(value)[:1000]}', e, colored = True)\n    try:\n        encoded = self.jsonlib.dumps(value, **kwargs)\n        return self.coerce_output_value(encoded)\n    except Exception as e:\n        if not self._is_silenced: logger.info(f'Error Encoding Value: |r|({type(value)}) {e}|e| {str(value)[:1000]}', colored = True, prefix = self.jsonlib_name)\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.decode","title":"<code>decode(value, schema_map=None, raise_errors=None, **kwargs)</code>","text":"<p>Decodes the value</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def decode(self, value: Union[str, bytes], schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value\n    \"\"\"\n    try:\n        decompressed_value = self.decompress_value(value, **kwargs)\n        if decompressed_value is not None:\n            value = decompressed_value\n    except Exception as e:\n        if not self._is_silenced: logger.info(f'Error Decompressing Value: |r|({type(value)}) {e}|e| {str(value)[:100]}', colored = True, prefix = self.jsonlib_name)\n        if raise_errors or self.raise_errors: raise ValueError(f\"[{self.name}] Error in Decompression: {str(value)[:100]}\") from e\n        # return self.decode_value(value, **kwargs)\n    return self.decode_value(value, schema_map = schema_map, raise_errors = raise_errors, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.decode_value","title":"<code>decode_value(value, schema_map=None, raise_errors=None, **kwargs)</code>","text":"<p>Decode the value with the JSON Library</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def decode_value(self, value: str, schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n    \"\"\"\n    Decode the value with the JSON Library\n    \"\"\"\n    if value is None: return None\n    if isinstance(value, (str, bytes)):\n        try:\n            # value = self.check_encoded_value(value)\n            value = self.jsonlib.loads(value, **kwargs)\n        except Exception as e:\n            if isinstance(value, str) and 'Exception' in value or 'Traceback (most recent call last):' in value:\n                return value\n            str_value = str(value)\n            if not schema_map: str_value = str_value[:1000]\n            if self._is_verbose: logger.info(f'Error JSON Decoding Value: |r|({type(value)}) {e}|e| {str_value}', colored = True, prefix = self.jsonlib_name)\n            if raise_errors or self.raise_errors: raise e\n    try:\n        return self.deserialize_obj(value, schema_map = schema_map, allow_failed_import = self.allow_failed_import)\n    except Exception as e:\n        str_value = str(value)\n        if not schema_map: str_value = str_value[:1000]\n        if not self._is_silenced: logger.trace(f'Error Deserializing Object: ({type(value)}) {str_value}', e, prefix = self.jsonlib_name)\n        if raise_errors or self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.adecode","title":"<code>adecode(value, schema_map=None, raise_errors=None, **kwargs)</code>  <code>async</code>","text":"<p>Decodes the value asynchronously</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>async def adecode(self, value: Union[str, bytes], schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value asynchronously\n    \"\"\"\n    return await ThreadPool.arun(self.decode, value, schema_map = schema_map, raise_errors = raise_errors, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.dumps","title":"<code>dumps(value, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, mode=None, **kwargs)</code>","text":"<p>Serialize <code>obj</code> to a JSON formatted <code>str</code>.</p> <p>If <code>skipkeys</code> is true then <code>dict</code> keys that are not basic types (<code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>None</code>) will be skipped instead of raising a <code>TypeError</code>.</p> <p>If <code>ensure_ascii</code> is false, then the return value can contain non-ASCII characters if they appear in strings contained in <code>obj</code>. Otherwise, all such characters are escaped in JSON strings.</p> <p>If <code>check_circular</code> is false, then the circular reference check for container types will be skipped and a circular reference will result in an <code>RecursionError</code> (or worse).</p> <p>If <code>allow_nan</code> is false, then it will be a <code>ValueError</code> to serialize out of range <code>float</code> values (<code>nan</code>, <code>inf</code>, <code>-inf</code>) in strict compliance of the JSON specification, instead of using the JavaScript equivalents (<code>NaN</code>, <code>Infinity</code>, <code>-Infinity</code>).</p> <p>If <code>indent</code> is a non-negative integer, then JSON array elements and object members will be pretty-printed with that indent level. An indent level of 0 will only insert newlines. <code>None</code> is the most compact representation.</p> <p>If specified, <code>separators</code> should be an <code>(item_separator, key_separator)</code> tuple.  The default is <code>(', ', ': ')</code> if indent is <code>None</code> and <code>(',', ': ')</code> otherwise.  To get the most compact JSON representation, you should specify <code>(',', ':')</code> to eliminate whitespace.</p> <p><code>default(obj)</code> is a function that should return a serializable version of obj or raise TypeError. The default simply raises TypeError.</p> <p>If sort_keys is true (default: <code>False</code>), then the output of dictionaries will be sorted by key.</p> <p>To use a custom <code>JSONEncoder</code> subclass (e.g. one that overrides the <code>.default()</code> method to serialize additional types), specify it with the <code>cls</code> kwarg; otherwise <code>JSONEncoder</code> is used.</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def dumps(\n    self, \n    value: ObjectValue, \n    skipkeys: bool = False, \n    ensure_ascii: bool = True, \n    check_circular: bool = True,\n    allow_nan: bool = True, \n    cls: Optional[Any] = None, \n    indent: Optional[int] = None, \n    separators: Optional[Tuple[str, str]] = None,\n    default: Optional[Any] = None, \n    sort_keys: bool = False,\n    mode: Optional[SerMode] = None,\n    **kwargs\n) -&gt; Union[str, bytes]:\n    \"\"\"Serialize ``obj`` to a JSON formatted ``str``.\n\n    If ``skipkeys`` is true then ``dict`` keys that are not basic types\n    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n    instead of raising a ``TypeError``.\n\n    If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n    characters if they appear in strings contained in ``obj``. Otherwise, all\n    such characters are escaped in JSON strings.\n\n    If ``check_circular`` is false, then the circular reference check\n    for container types will be skipped and a circular reference will\n    result in an ``RecursionError`` (or worse).\n\n    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n    strict compliance of the JSON specification, instead of using the\n    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n\n    If ``indent`` is a non-negative integer, then JSON array elements and\n    object members will be pretty-printed with that indent level. An indent\n    level of 0 will only insert newlines. ``None`` is the most compact\n    representation.\n\n    If specified, ``separators`` should be an ``(item_separator, key_separator)``\n    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n    you should specify ``(',', ':')`` to eliminate whitespace.\n\n    ``default(obj)`` is a function that should return a serializable version\n    of obj or raise TypeError. The default simply raises TypeError.\n\n    If *sort_keys* is true (default: ``False``), then the output of\n    dictionaries will be sorted by key.\n\n    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n    ``.default()`` method to serialize additional types), specify it with\n    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.MsgPackSerializer","title":"<code>MsgPackSerializer</code>","text":"<p>               Bases: <code>BinaryBaseSerializer</code></p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>class MsgPackSerializer(BinaryBaseSerializer):\n    name: Optional[str] = \"msgpack\"\n    encoding: Optional[str] = \"utf-8\"\n    disable_object_serialization: Optional[bool] = False\n    jsonlib: JsonLibT = default_json\n    msgpacklib: MsgPackLibT = default_msgpack\n\n    def __init__(\n        self, \n        msgpacklib: Optional[Union[str, Any]] = None,\n        compression: Optional[str] = None,\n        compression_level: int | None = None, \n        encoding: str | None = None, \n        serialization_obj: Optional[Type[BaseModel]] = None,\n        serialization_obj_kwargs: Optional[Dict[str, Any]] = None,\n        disable_object_serialization: Optional[bool] = None,\n        jsonlib: Optional[Union[str, Any]] = None,\n        **kwargs\n    ):\n        if not default_msgpack:\n            raise ImportError(\"MsgPack Serializer is not available. Please install `msgpack`\")\n        super().__init__(compression = compression, compression_level = compression_level, encoding = encoding, **kwargs)\n        self.serialization_obj = serialization_obj\n        self.serialization_obj_kwargs = serialization_obj_kwargs or {}\n        self.serialization_schemas: Dict[str, Type[BaseModel]] = {}\n        if disable_object_serialization is not None:\n            self.disable_object_serialization = disable_object_serialization\n\n        if msgpacklib is not None:\n            if isinstance(msgpacklib, str):\n                msgpacklib = lazy_import(msgpacklib, is_module=True)\n            assert hasattr(msgpacklib, \"packb\") and hasattr(msgpacklib, \"unpackb\"), f\"Invalid MsgPack Library: {msgpacklib}\"\n            self.msgpacklib = msgpacklib\n        self.msgpacklib_name = self.msgpacklib.__name__\n        if jsonlib is not None:\n            if isinstance(jsonlib, str):\n                jsonlib = lazy_import(jsonlib, is_module=True)\n            assert hasattr(jsonlib, \"dumps\") and hasattr(jsonlib, \"loads\"), f\"Invalid JSON Library: {jsonlib}\"\n            self.jsonlib = jsonlib\n        self.jsonlib_name = self.jsonlib.__name__\n\n\n    @classmethod\n    def set_default_lib(cls, lib: Union[str, MsgPackLibT, ModuleType]) -&gt; None:\n        \"\"\"\n        Sets the default MsgPack library\n        \"\"\"\n        global default_msgpack\n        if isinstance(lib, str):\n            lib = lazy_import(lib, is_module=True)\n        assert hasattr(lib, \"packb\") and hasattr(lib, \"unpackb\"), f\"Invalid Msgpack Library: `{lib}`\"\n        cls.msgpacklib = lib\n        default_msgpack = lib\n\n    def default_serialization_hook(self, obj: ObjectValue):\n        \"\"\"\n        Default Serialization Hook\n        \"\"\"\n        if not isinstance(obj, BaseModel) and not hasattr(obj, 'model_dump'):\n            logger.info(f'Invalid Object Type: |r|{type(obj)}|e| {obj}', colored = True, prefix = \"msgpack\")\n            return obj\n\n        if self.disable_object_serialization: \n            return obj.model_dump_json(**self.serialization_obj_kwargs)\n\n        obj_class_name = self.fetch_object_classname(obj)\n        if obj_class_name not in self.serialization_schemas:\n            self.serialization_schemas[obj_class_name] = obj.__class__\n        data = obj.model_dump(mode = 'json', **self.serialization_obj_kwargs)\n        data['__class__'] = obj_class_name\n        return self.msgpacklib.ExtType(2, self.jsonlib.dumps(data).encode(self.encoding))\n\n    def default_deserialization_hook(self, code: int, data: Union[str, bytes]) -&gt; ObjectValue:\n        \"\"\"\n        Default Deserialization Hook\n        \"\"\"\n        if code != 2: return data\n        if isinstance(data, bytes): data = data.decode(self.encoding)\n        try:\n            data = self.jsonlib.loads(data)\n        except Exception as e:\n            logger.info(f'Error Decoding Value: |r|({type(data)}) {e}|e| {str(data)[:500]}', colored = True, prefix = \"msgpack\")\n            if self.raise_errors: raise e\n            return data\n        if not self.disable_object_serialization:\n            _class = data.pop('__class__', None)\n            if _class is not None:\n                if _class not in self.serialization_schemas:\n                    self.serialization_schemas[_class] = lazy_import(_class)\n                _class = self.serialization_schemas[_class]\n                return _class.model_validate(data, **self.serialization_obj_kwargs)\n        elif self.serialization_obj is not None:\n            return self.serialization_obj.model_validate(data, **self.serialization_obj_kwargs)\n        return data\n\n    def encode_value(self, value: Union[Any, SchemaType], **kwargs) -&gt; bytes:\n        \"\"\"\n        Encode the value with the Pickle Library\n        \"\"\"\n        if 'use_bin_type' not in kwargs: kwargs['use_bin_type'] = True\n        if 'default' not in kwargs: kwargs['default'] = self.default_serialization_hook\n        try:\n            return self.msgpacklib.packb(value, **kwargs)\n        except Exception as e:\n            logger.info(f'Error Encoding Value: |r|({type(value)}) {e}|e| {str(value)[:500]}', colored = True, prefix = \"msgpack\")\n            if self.raise_errors: raise e\n        return None\n\n    def decode_value(self, value: bytes, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n        \"\"\"\n        Decode the value with the Pickle Library\n        \"\"\"\n        try:\n            if 'raw' not in kwargs: kwargs['raw'] = False\n            if 'ext_hook' not in kwargs: kwargs['ext_hook'] = self.default_deserialization_hook\n            return self.msgpacklib.unpackb(value, **kwargs)\n        except Exception as e:\n            logger.info(f'Error Decoding Value: |r|({type(value)}) {e}|e| {str(value)[:500]}', colored = True, prefix = \"msgpack\")\n            if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.MsgPackSerializer.set_default_lib","title":"<code>set_default_lib(lib)</code>  <code>classmethod</code>","text":"<p>Sets the default MsgPack library</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>@classmethod\ndef set_default_lib(cls, lib: Union[str, MsgPackLibT, ModuleType]) -&gt; None:\n    \"\"\"\n    Sets the default MsgPack library\n    \"\"\"\n    global default_msgpack\n    if isinstance(lib, str):\n        lib = lazy_import(lib, is_module=True)\n    assert hasattr(lib, \"packb\") and hasattr(lib, \"unpackb\"), f\"Invalid Msgpack Library: `{lib}`\"\n    cls.msgpacklib = lib\n    default_msgpack = lib\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.MsgPackSerializer.default_serialization_hook","title":"<code>default_serialization_hook(obj)</code>","text":"<p>Default Serialization Hook</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>def default_serialization_hook(self, obj: ObjectValue):\n    \"\"\"\n    Default Serialization Hook\n    \"\"\"\n    if not isinstance(obj, BaseModel) and not hasattr(obj, 'model_dump'):\n        logger.info(f'Invalid Object Type: |r|{type(obj)}|e| {obj}', colored = True, prefix = \"msgpack\")\n        return obj\n\n    if self.disable_object_serialization: \n        return obj.model_dump_json(**self.serialization_obj_kwargs)\n\n    obj_class_name = self.fetch_object_classname(obj)\n    if obj_class_name not in self.serialization_schemas:\n        self.serialization_schemas[obj_class_name] = obj.__class__\n    data = obj.model_dump(mode = 'json', **self.serialization_obj_kwargs)\n    data['__class__'] = obj_class_name\n    return self.msgpacklib.ExtType(2, self.jsonlib.dumps(data).encode(self.encoding))\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.MsgPackSerializer.default_deserialization_hook","title":"<code>default_deserialization_hook(code, data)</code>","text":"<p>Default Deserialization Hook</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>def default_deserialization_hook(self, code: int, data: Union[str, bytes]) -&gt; ObjectValue:\n    \"\"\"\n    Default Deserialization Hook\n    \"\"\"\n    if code != 2: return data\n    if isinstance(data, bytes): data = data.decode(self.encoding)\n    try:\n        data = self.jsonlib.loads(data)\n    except Exception as e:\n        logger.info(f'Error Decoding Value: |r|({type(data)}) {e}|e| {str(data)[:500]}', colored = True, prefix = \"msgpack\")\n        if self.raise_errors: raise e\n        return data\n    if not self.disable_object_serialization:\n        _class = data.pop('__class__', None)\n        if _class is not None:\n            if _class not in self.serialization_schemas:\n                self.serialization_schemas[_class] = lazy_import(_class)\n            _class = self.serialization_schemas[_class]\n            return _class.model_validate(data, **self.serialization_obj_kwargs)\n    elif self.serialization_obj is not None:\n        return self.serialization_obj.model_validate(data, **self.serialization_obj_kwargs)\n    return data\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.MsgPackSerializer.encode_value","title":"<code>encode_value(value, **kwargs)</code>","text":"<p>Encode the value with the Pickle Library</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>def encode_value(self, value: Union[Any, SchemaType], **kwargs) -&gt; bytes:\n    \"\"\"\n    Encode the value with the Pickle Library\n    \"\"\"\n    if 'use_bin_type' not in kwargs: kwargs['use_bin_type'] = True\n    if 'default' not in kwargs: kwargs['default'] = self.default_serialization_hook\n    try:\n        return self.msgpacklib.packb(value, **kwargs)\n    except Exception as e:\n        logger.info(f'Error Encoding Value: |r|({type(value)}) {e}|e| {str(value)[:500]}', colored = True, prefix = \"msgpack\")\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.MsgPackSerializer.decode_value","title":"<code>decode_value(value, **kwargs)</code>","text":"<p>Decode the value with the Pickle Library</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>def decode_value(self, value: bytes, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n    \"\"\"\n    Decode the value with the Pickle Library\n    \"\"\"\n    try:\n        if 'raw' not in kwargs: kwargs['raw'] = False\n        if 'ext_hook' not in kwargs: kwargs['ext_hook'] = self.default_deserialization_hook\n        return self.msgpacklib.unpackb(value, **kwargs)\n    except Exception as e:\n        logger.info(f'Error Decoding Value: |r|({type(value)}) {e}|e| {str(value)[:500]}', colored = True, prefix = \"msgpack\")\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.PickleSerializer","title":"<code>PickleSerializer</code>","text":"<p>               Bases: <code>BinaryBaseSerializer</code></p> Source code in <code>src/lzl/io/ser/_pickle.py</code> <pre><code>class PickleSerializer(BinaryBaseSerializer):\n    name: Optional[str] = \"pickle\"\n    encoding: Optional[str] = \"utf-8\"\n    picklelib: PickleLibT = default_pickle\n\n    def __init__(\n        self, \n        picklelib: Optional[Union[str, Any]] = None,\n        compression: Optional[str] = None,\n        compression_level: int | None = None, \n        encoding: str | None = None, \n        **kwargs\n    ):\n        super().__init__(compression = compression, compression_level = compression_level, encoding = encoding, **kwargs)\n        if picklelib is not None:\n            if isinstance(picklelib, str):\n                picklelib = lazy_import(picklelib, is_module=True)\n            assert hasattr(picklelib, \"dumps\") and hasattr(picklelib, \"loads\"), f\"Invalid Pickle Library: {picklelib}\"\n            self.picklelib = picklelib\n        self.picklelib_name = self.picklelib.__name__\n\n    @classmethod\n    def set_default_lib(cls, lib: Union[str, PickleLibT, ModuleType]) -&gt; None:\n        \"\"\"\n        Sets the default Pickle library\n        \"\"\"\n        global default_pickle\n        if isinstance(lib, str):\n            lib = lazy_import(lib, is_module=True)\n        assert hasattr(lib, \"loads\") and hasattr(lib, \"dumps\"), f\"Invalid Pickle Library: `{lib}`\"\n        cls.picklelib = lib\n        default_pickle = lib\n\n    def encode_value(self, value: Union[Any, SchemaType], **kwargs) -&gt; bytes:\n        \"\"\"\n        Encode the value with the Pickle Library\n        \"\"\"\n        try:\n            return self.picklelib.dumps(value, **kwargs)\n        except Exception as e:\n            logger.trace(f'Error Encoding Object: ({type(value)}) {str(value)[:1000]}', e, prefix = self.picklelib_name)\n            if self.raise_errors: raise e\n        return None\n\n    def decode_value(self, value: bytes, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n        \"\"\"\n        Decode the value with the Pickle Library\n        \"\"\"\n        try:\n            if self.picklelib_name == 'cloudpickle':\n                if 'encoding' not in kwargs:\n                    kwargs['encoding'] = self.encoding\n                if 'fix_imports' not in kwargs:\n                    kwargs['fix_imports'] = False\n            return self.picklelib.loads(value, **kwargs)\n        except Exception as e:\n            logger.trace(f'Error Deserializing Object: ({type(value)}) {str(value)[:1000]}', e, prefix = self.picklelib_name)\n            if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.PickleSerializer.set_default_lib","title":"<code>set_default_lib(lib)</code>  <code>classmethod</code>","text":"<p>Sets the default Pickle library</p> Source code in <code>src/lzl/io/ser/_pickle.py</code> <pre><code>@classmethod\ndef set_default_lib(cls, lib: Union[str, PickleLibT, ModuleType]) -&gt; None:\n    \"\"\"\n    Sets the default Pickle library\n    \"\"\"\n    global default_pickle\n    if isinstance(lib, str):\n        lib = lazy_import(lib, is_module=True)\n    assert hasattr(lib, \"loads\") and hasattr(lib, \"dumps\"), f\"Invalid Pickle Library: `{lib}`\"\n    cls.picklelib = lib\n    default_pickle = lib\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.PickleSerializer.encode_value","title":"<code>encode_value(value, **kwargs)</code>","text":"<p>Encode the value with the Pickle Library</p> Source code in <code>src/lzl/io/ser/_pickle.py</code> <pre><code>def encode_value(self, value: Union[Any, SchemaType], **kwargs) -&gt; bytes:\n    \"\"\"\n    Encode the value with the Pickle Library\n    \"\"\"\n    try:\n        return self.picklelib.dumps(value, **kwargs)\n    except Exception as e:\n        logger.trace(f'Error Encoding Object: ({type(value)}) {str(value)[:1000]}', e, prefix = self.picklelib_name)\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.PickleSerializer.decode_value","title":"<code>decode_value(value, **kwargs)</code>","text":"<p>Decode the value with the Pickle Library</p> Source code in <code>src/lzl/io/ser/_pickle.py</code> <pre><code>def decode_value(self, value: bytes, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n    \"\"\"\n    Decode the value with the Pickle Library\n    \"\"\"\n    try:\n        if self.picklelib_name == 'cloudpickle':\n            if 'encoding' not in kwargs:\n                kwargs['encoding'] = self.encoding\n            if 'fix_imports' not in kwargs:\n                kwargs['fix_imports'] = False\n        return self.picklelib.loads(value, **kwargs)\n    except Exception as e:\n        logger.trace(f'Error Deserializing Object: ({type(value)}) {str(value)[:1000]}', e, prefix = self.picklelib_name)\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.deserialize_object","title":"<code>deserialize_object(obj, schema_map=None, allow_failed_import=False)</code>","text":"<p>Deserialize an object</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>the object to deserialize</p> required Source code in <code>src/lzl/io/ser/utils.py</code> <pre><code>def deserialize_object(\n    obj: Union[Dict[str, Any], List[Dict[str, Any]], Any], \n    schema_map: Optional[Dict[str, str]] = None, \n    allow_failed_import: Optional[bool] = False\n) -&gt; SerializableObject:\n    # sourcery skip: extract-duplicate-method, low-code-quality\n    \"\"\"\n    Deserialize an object\n\n    Args:\n        obj: the object to deserialize\n    \"\"\"\n    if obj is None: return None\n    if isinstance(obj, (list, tuple)):\n        return [deserialize_object(item, schema_map = schema_map, allow_failed_import = allow_failed_import) for item in obj]\n\n    if isinstance(obj, dict):\n        if \"__type__\" not in obj:\n            return {key: deserialize_object(value, schema_map = schema_map, allow_failed_import = allow_failed_import) for key, value in obj.items()}\n\n        # obj_type = obj[\"__type__\"]\n        obj_type = obj.pop(\"__type__\")\n        if '__class__' in obj:\n            if schema_map is not None and obj['__class__'] in schema_map:\n                obj['__class__'] = schema_map[obj['__class__']]\n            elif obj['__class__'] in _alias_schema_mapping:\n                obj['__class__'] = _alias_schema_mapping[obj['__class__']]\n\n        obj_class_type = obj.pop('__class__', None)\n        if obj_type == \"type\":\n            return get_object_class(obj_class_type)\n\n        obj_value = obj[\"value\"] if len(obj) == 1 and \"value\" in obj else obj\n        if obj_type == \"pydantic\":\n            try:\n                obj_class = get_object_class(obj_class_type)\n                # for k,v in obj_value.items():\n                #     if not is_primitive(v):\n                #         obj_value[k] = deserialize_object(v)\n                if hasattr(obj_class, 'model_validate'):\n                    return obj_class.model_validate(obj_value, context = {'source': 'io', 'method': 'deserializer'})\n                return obj_class(**obj_value)\n            except ImportError as e:\n                if allow_failed_import:\n                    return deserialize_object(obj_value, schema_map = schema_map, allow_failed_import = allow_failed_import)\n                raise e\n\n        if obj_type == \"serializable\":\n            try:\n                obj_class = get_object_class(obj_class_type)\n                return obj_class(**obj_value)\n            except ImportError as e:\n                if allow_failed_import:\n                    return deserialize_object(obj_value, schema_map = schema_map, allow_failed_import = allow_failed_import)\n                raise e\n\n        if obj_type == \"numpy\" and np is not None:\n            # dtype = obj.get(\"__class__\")\n            dtype = obj_class_type\n            if dtype: dtype = dtype.replace(\"numpy.\", \"\")\n            return np.array(obj_value, dtype = dtype)\n\n        if obj_type == \"pickle\":\n            try:\n                obj_value = bytes.fromhex(obj_value)\n                return default_pickle.loads(obj_value)\n            except Exception as e:\n                raise TypeError(f\"Cannot deserialize object of type {obj_type}: {e}\") from e\n\n        if obj_type == \"datetime\":\n            return datetime.datetime.fromisoformat(obj_value)\n\n        if obj_type == \"timedelta\":\n            return datetime.timedelta(seconds=obj_value)\n\n        if obj_type == \"dataclass\":\n            # obj_class_type = obj[\"__class__\"]\n            # if schema_map is not None and obj_class_type in schema_map:\n            #     obj_class_type = schema_map[obj_class_type]\n\n            obj_class = get_object_class(obj_class_type)\n            return obj_class(**obj_value)\n\n        if obj_type == \"path\":\n            obj_class = get_object_class(obj_class_type)\n            return obj_class(obj_value)\n\n        if obj_type == \"enum\":\n            obj_class = get_object_class(obj_class_type)\n            return obj_class(obj_value)\n\n        if obj_type == \"uuid\":\n            return UUID(obj_value)\n\n        if obj_type == \"bytes\":\n            return bytes.fromhex(obj_value)\n\n        if obj_type == \"set\":\n            return set(obj_value)\n\n\n        if obj_type == \"tensor\":\n            return float(obj_value) if (isinstance(obj_value, (int, float)) or not np) else np.array(obj_value)\n\n        raise TypeError(f\"Cannot deserialize object of type {obj_type} - {obj_class_type} with value {obj_value}\")\n\n    if isinstance(obj, bytes):\n        # Try to deserialize with pickle\n        with contextlib.suppress(Exception):\n            return default_pickle.loads(obj)\n\n    return obj\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.get_object_class","title":"<code>get_object_class(name)</code>","text":"<p>Get the class of an object</p> Source code in <code>src/lzl/io/ser/utils.py</code> <pre><code>def get_object_class(name: str) -&gt; Type[SerializableObject]:\n    \"\"\"\n    Get the class of an object\n    \"\"\"\n    global serialization_class_registry\n    if name not in serialization_class_registry:\n        serialization_class_registry[name] = lazy_import(name)\n    return serialization_class_registry[name]\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.get_object_classname","title":"<code>get_object_classname(obj, is_type=False)</code>","text":"<p>Get the classname of an object</p> Source code in <code>src/lzl/io/ser/utils.py</code> <pre><code>def get_object_classname(obj: SerializableObject, is_type: Optional[bool] = False) -&gt; str:\n    \"\"\"\n    Get the classname of an object\n    \"\"\"\n    if is_type: return f'{obj.__module__}.{obj.__name__}'\n    return f\"{obj.__class__.__module__}.{obj.__class__.__name__}\"\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.register_schema_mapping","title":"<code>register_schema_mapping(schemas)</code>","text":"<p>Register the schema mapping</p> Source code in <code>src/lzl/io/ser/utils.py</code> <pre><code>def register_schema_mapping(schemas: Dict[str, str]):\n    \"\"\"\n    Register the schema mapping\n    \"\"\"\n    global _alias_schema_mapping\n    _alias_schema_mapping.update(schemas)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.serialize_object","title":"<code>serialize_object(obj, mode='auto', **kwargs)</code>","text":"<p>Helper to serialize an object</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>SerializableObject</code> <p>the object to serialize</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>the serialized object in dict</p> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>if not disable_nested_values:</p> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>{ \"type\": ..., \"value\": ...,</p> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>}</p> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>otherwise for JSON Objects:</p> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>{ \"type\": ..., ...,</p> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>}</p> Source code in <code>src/lzl/io/ser/utils.py</code> <pre><code>def serialize_object(\n    obj: SerializableObject,\n    mode: Optional[SerMode] = 'auto',\n    **kwargs\n) -&gt; Union[Dict[str, Any], List[Dict[str, Any]], Any]:\n    # sourcery skip: extract-duplicate-method\n    \"\"\"\n    Helper to serialize an object\n\n    Args:\n        obj: the object to serialize\n\n    Returns:\n        the serialized object in dict\n\n        if not disable_nested_values:\n        {\n            \"__type__\": ...,\n            \"value\": ...,\n        }\n\n        otherwise for JSON Objects:\n\n        {\n            \"__type__\": ...,\n            ...,\n        }\n\n    \"\"\"\n    if obj is None: return None\n    disable_nested_values: Optional[bool] = kwargs.get('disable_nested_values')\n\n    if isinstance(obj, BaseModel) or hasattr(obj, 'model_dump'):\n        obj_class_name = register_object_class(obj)\n        obj_value = obj.model_dump(mode = 'json', round_trip = True, context = {'source': 'io', 'method': 'serializer'}, **extract_model_dumps_kwargs(kwargs))\n        if mode == 'raw': return obj_value\n        if disable_nested_values:\n            return {\n                \"__type__\": \"pydantic\",\n                \"__class__\": obj_class_name,\n                **obj_value,\n            }\n        return {\n            \"__type__\": \"pydantic\",\n            \"__class__\": obj_class_name,\n            \"value\": obj_value,\n        }\n\n    # Move this to the top before primitives\n    if np is not None:\n        # if isinstance(obj, (np.int_, np.intc, np.intp, np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint16, np.uint32, np.uint64)):\n        if isinstance(obj, np_int_types):\n            if mode == 'raw': return int(obj)\n            obj_class_name = register_object_class(obj)\n            return {\n                \"__type__\": \"numpy\",\n                \"__class__\": obj_class_name,\n                \"value\": int(obj),\n            }\n\n\n        # if isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n        if isinstance(obj, np_float_types):\n            if mode == 'raw': return float(obj)\n            obj_class_name = register_object_class(obj)\n            return {\n                \"__type__\": \"numpy\",\n                \"__class__\": obj_class_name,\n                \"value\": float(obj),\n            }\n\n\n    if is_primitive(obj, exclude_bytes = True):\n        return obj\n\n    if isinstance(obj, type):\n        obj_class_name = register_object_class(obj, is_type = True)\n        if mode == 'raw': return obj_class_name\n        return {\n            \"__type__\": \"type\",\n            \"__class__\": obj_class_name,\n            \"value\": obj_class_name,\n        }\n\n    if isinstance(obj, (list, tuple)):\n        return [serialize_object(item, mode = mode, **kwargs) for item in obj]\n\n    if isinstance(obj, dict):\n        if \"__type__\" in obj: \n            return obj['value'] if mode == 'raw' and obj.get('value') else obj\n        return {key: serialize_object(value, mode = mode, **kwargs) for key, value in obj.items()}\n\n    if isinstance(obj, (datetime.datetime, datetime.date, datetime.time)):\n        if mode == 'raw': return obj.isoformat()\n        return {\n            \"__type__\": \"datetime\",\n            \"value\": obj.isoformat(),\n        }\n\n    if isinstance(obj, datetime.timedelta):\n        if mode == 'raw': return obj.total_seconds()\n        return {\n            \"__type__\": \"timedelta\",\n            \"value\": obj.total_seconds(),\n        }\n\n    if isinstance(obj, dataclasses.InitVar) or dataclasses.is_dataclass(obj):\n        if mode == 'raw': return dataclasses.asdict(obj)\n        obj_class_name = register_object_class(obj)\n        if disable_nested_values:\n            return {\n                \"__type__\": \"dataclass\",\n                \"__class__\": obj_class_name,\n                **dataclasses.asdict(obj),\n            }\n        return {\n            \"__type__\": \"dataclass\",\n            \"__class__\": obj_class_name,\n            \"value\": dataclasses.asdict(obj),\n        }\n\n    if hasattr(obj, 'as_posix'):\n        if mode == 'raw': return obj.as_posix()\n        obj_class_name = register_object_class(obj)\n        return {\n            \"__type__\": \"path\",\n            \"__class__\": obj_class_name,\n            \"value\": obj.as_posix(),\n        }\n\n    if isinstance(obj, (bytes, bytearray)):\n        if mode == 'raw': return obj\n        return {\n            \"__type__\": \"bytes\",\n            \"value\": obj.hex(),\n        }\n\n    if isinstance(obj, (set, frozenset)):\n        if mode == 'raw': return list(obj)\n        return {\n            \"__type__\": \"set\",\n            \"value\": list(obj),\n        }\n\n    if isinstance(obj, Enum):\n        if mode == 'raw': return obj.value\n        obj_class_name = register_object_class(obj)\n        return {\n            \"__type__\": \"enum\",\n            \"__class__\": obj_class_name,\n            \"value\": obj.value,\n        }\n\n    if isinstance(obj, UUID):\n        if mode == 'raw': return str(obj)\n        return {\n            \"__type__\": \"uuid\",\n            \"value\": str(obj),\n        }\n\n    if hasattr(obj, 'serialize'):\n        if mode == 'raw': return obj.serialize()\n        obj_class_name = register_object_class(obj)\n        return {\n            \"__type__\": \"serializable\",\n            \"__class__\": obj_class_name,\n            \"value\": obj.serialize(),\n        }\n\n    if isinstance(obj, abc.ABC):\n        logger.info(f'Pickle Serializing ABC Object: |r|({type(obj)}) {str(obj)[:1000]}', colored = True)\n        # if mode == 'raw': raise TypeError(f\"Cannot serialize object of type in raw mode {type(obj)}\")\n        obj_bytes = default_pickle.dumps(obj)\n        if mode == 'raw': return obj_bytes\n        return {\n            \"__type__\": \"pickle\",\n            \"value\": obj_bytes.hex(),\n        }\n\n\n    if hasattr(obj, \"numpy\"):  # Checks for TF tensors without needing the import\n        if mode == 'raw': return obj.numpy().tolist()\n        return {\n            \"__type__\": \"tensor\",\n            \"value\": obj.numpy().tolist(),\n        }\n\n    if hasattr(obj, 'tolist'): # Checks for torch tensors without importing\n        if mode == 'raw': return obj.tolist()\n        return {\n            \"__type__\": \"tensor\",\n            \"value\": obj.tolist(),\n        }\n\n    # Try one shot encoding objects\n    # with contextlib.suppress(Exception):\n\n    try:\n        logger.info(f'Pickle Serializing Object: |r|({type(obj)}) {str(obj)[:1000]}', colored = True)\n        obj_bytes = default_pickle.dumps(obj)\n        if mode == 'raw': return obj_bytes\n        return {\n            \"__type__\": \"pickle\",\n            \"value\": obj_bytes.hex(),\n        }\n    except Exception as e:\n\n        logger.info(f'Error Serializing Object: |r|({type(obj)}) {e}|e| {str(obj)[:1000]}', colored = True)\n\n    raise TypeError(f\"Cannot serialize object of type {type(obj)}\")\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.get_default_serializer","title":"<code>get_default_serializer()</code>","text":"<p>Return the globally configured default serializer name.</p> Source code in <code>src/lzl/io/ser/__init__.py</code> <pre><code>def get_default_serializer() -&gt; str:\n    \"\"\"Return the globally configured default serializer name.\"\"\"\n\n    return DEFAULT_SERIALIZER\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.set_default_serializer","title":"<code>set_default_serializer(serializer)</code>","text":"<p>Update the global default serializer.</p> <p>Parameters:</p> Name Type Description Default <code>serializer</code> <code>str</code> <p>Name used when resolving serializers via :func:<code>get_serializer</code>.</p> required Source code in <code>src/lzl/io/ser/__init__.py</code> <pre><code>def set_default_serializer(serializer: str) -&gt; None:\n    \"\"\"Update the global default serializer.\n\n    Args:\n        serializer: Name used when resolving serializers via :func:`get_serializer`.\n    \"\"\"\n\n    global DEFAULT_SERIALIZER\n    DEFAULT_SERIALIZER = serializer\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.register_serializer","title":"<code>register_serializer(name, serializer, override=False, set_as_default=False)</code>","text":"<p>Register a :class:<code>BaseSerializer</code> factory for use throughout LazyOps.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Identifier that callers pass into :func:<code>get_serializer</code>.</p> required <code>serializer</code> <code>SerializerFactory</code> <p>Concrete serializer class implementing the :class:<code>BaseSerializer</code> contract.</p> required <code>override</code> <code>bool | None</code> <p>When <code>True</code> replace an existing registration with the same <code>name</code>; otherwise a :class:<code>ValueError</code> is raised.</p> <code>False</code> <code>set_as_default</code> <code>bool | None</code> <p>When <code>True</code> call :func:<code>set_default_serializer</code> with <code>name</code> to make the serializer the global default.</p> <code>False</code> Source code in <code>src/lzl/io/ser/__init__.py</code> <pre><code>def register_serializer(\n    name: str,\n    serializer: SerializerFactory,\n    override: bool | None = False,\n    set_as_default: bool | None = False,\n) -&gt; None:\n    \"\"\"Register a :class:`BaseSerializer` factory for use throughout LazyOps.\n\n    Args:\n        name: Identifier that callers pass into :func:`get_serializer`.\n        serializer: Concrete serializer class implementing the\n            :class:`BaseSerializer` contract.\n        override: When ``True`` replace an existing registration with the same\n            ``name``; otherwise a :class:`ValueError` is raised.\n        set_as_default: When ``True`` call :func:`set_default_serializer` with\n            ``name`` to make the serializer the global default.\n    \"\"\"\n\n    global RegisteredSerializers\n    if name in RegisteredSerializers and not override:\n        existing = RegisteredSerializers[name]\n        raise ValueError(\n            f\"Serializer `{name}` already registered with {existing} and override is False\"\n        )\n    RegisteredSerializers[name] = serializer\n    if set_as_default:\n        set_default_serializer(name)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.set_default_serializer_lib","title":"<code>set_default_serializer_lib(serializer, lib)</code>","text":"<p>Set the preferred underlying library for a known serializer.</p> Source code in <code>src/lzl/io/ser/__init__.py</code> <pre><code>def set_default_serializer_lib(serializer: str, lib: ModuleType | str) -&gt; None:\n    \"\"\"Set the preferred underlying library for a known serializer.\"\"\"\n\n    if serializer not in RegisteredSerializers:\n        raise ValueError(\n            f\"Serializer `{serializer}` is not registered. Please register the serializer first\"\n        )\n    RegisteredSerializers[serializer].set_default_lib(lib)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.register_serializer_lib","title":"<code>register_serializer_lib(serializer, lib, set_as_default_lib=False)</code>","text":"<p>Register a library backend that a serializer implementation understands.</p> <p>Parameters:</p> Name Type Description Default <code>serializer</code> <code>str</code> <p>Name of the serializer to attach the backend to.</p> required <code>lib</code> <code>ModuleType | str</code> <p>Either the module object or its dotted import path.</p> required <code>set_as_default_lib</code> <code>bool | None</code> <p>When <code>True</code> update the serializer so that <code>lib</code> is used as the default backend for subsequent serializer instances.</p> <code>False</code> Source code in <code>src/lzl/io/ser/__init__.py</code> <pre><code>def register_serializer_lib(\n    serializer: str,\n    lib: ModuleType | str,\n    set_as_default_lib: bool | None = False,\n) -&gt; None:\n    \"\"\"Register a library backend that a serializer implementation understands.\n\n    Args:\n        serializer: Name of the serializer to attach the backend to.\n        lib: Either the module object or its dotted import path.\n        set_as_default_lib: When ``True`` update the serializer so that ``lib``\n            is used as the default backend for subsequent serializer instances.\n    \"\"\"\n\n    global RegisteredSerializerLibs\n    if serializer not in RegisteredSerializers:\n        raise ValueError(\n            f\"Serializer `{serializer}` is not registered. Please register the serializer first\"\n        )\n    if serializer not in RegisteredSerializerLibs:\n        RegisteredSerializerLibs[serializer] = []\n    if isinstance(lib, ModuleType):\n        lib = lib.__name__\n    if lib not in RegisteredSerializerLibs[serializer]:\n        RegisteredSerializerLibs[serializer].append(lib)\n    if set_as_default_lib:\n        RegisteredSerializers[serializer].set_default_lib(lib)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.get_serializer","title":"<code>get_serializer(serializer=None, **kwargs)</code>","text":"<pre><code>get_serializer(serializer: t.Literal['json'] = ..., jsonlib: str | ModuleType | None = ..., compression: str | None = ..., compression_level: int | None = ..., encoding: str | None = ..., serialization_obj: t.Type[object] | None = ..., serialization_obj_kwargs: dict[str, t.Any] | None = ..., disable_object_serialization: bool | None = ..., disable_nested_values: bool | None = ..., verbosity: int | None = ..., raise_errors: bool = ..., enforce_string_value: bool | None = ..., enforce_byte_value: bool | None = ..., ser_mode: SerMode | None = ..., deprecated_compression: str | None = ..., schema_map: dict[str, str] | None = ..., **kwargs: t.Any) -&gt; JsonSerializer\n</code></pre> <p>Return a serializer instance matching <code>serializer</code> and <code>kwargs</code>.</p> <p>The helper caches instances keyed by their configuration so the same serializer can be reused across the process without repeatedly instantiating identical objects.</p> Source code in <code>src/lzl/io/ser/__init__.py</code> <pre><code>def get_serializer(serializer: str | None = None, **kwargs: t.Any) -&gt; SerT:\n    \"\"\"Return a serializer instance matching ``serializer`` and ``kwargs``.\n\n    The helper caches instances keyed by their configuration so the same\n    serializer can be reused across the process without repeatedly\n    instantiating identical objects.\n    \"\"\"\n\n    global _initialized_sers\n\n    if serializer == \"auto\":\n        serializer = None\n    serializer = serializer or get_default_serializer()\n    ser_hash = create_hash_from_args_and_kwargs(serializer, **kwargs)\n    if ser_hash in _initialized_sers:\n        return _initialized_sers[ser_hash]\n\n    if serializer in RegisteredSerializers:\n        new = RegisteredSerializers[serializer](**kwargs)\n        _initialized_sers[ser_hash] = new\n        return new\n\n    for kind, libs in RegisteredSerializerLibs.items():\n        if serializer in libs:\n            if f\"{kind}lib\" not in kwargs:\n                kwargs[f\"{kind}lib\"] = serializer\n            new = RegisteredSerializers[kind](**kwargs)\n            _initialized_sers[ser_hash] = new\n            return new\n    raise ValueError(f\"Invalid Serializer Type: {serializer}\")\n</code></pre>"},{"location":"api/lzl/io/#persistence","title":"Persistence","text":"<p>Persistent storage backends for caching and data persistence:</p>"},{"location":"api/lzl/io/#lzl.io.persistence","title":"<code>lzl.io.persistence</code>","text":"<p>Persistence Module that supports both local and remote persistence</p> <p>The PersistentDict offers a dict-like interface with some powerful features: - Mutability: Changes to the dict are automatically persisted - Serialization: Values are automatically serialized and deserialized   - Supports JSON, Pickle, MsgPack, and Custom Serializers - Compression: Values are automatically compressed and decompressed     - Supports Zlib Compression - Remote Persistence: Supports Redis as a remote persistence backend - Local Persistence: Supports Local Filesystem as a local persistence backend - Supports async operations</p> <p>Usage:</p> <pre><code>from lzl.io import PersistentDict\n\n# Create a new PersistentDict\n# with default settings\n\ncache = PersistentDict(\"my_cache\")\n\n# Set a key\ncache[\"foo\"] = \"bar\"\ncache[\"x\"] = 1\n\n# Get a key\nprint(cache[\"foo\"])\nprint(cache[\"x\"])\n\n# Mutate a key\ncache[\"x\"] += 1\nprint(cache[\"x\"])\n\n# Delete a key\ndel cache[\"foo\"]\nprint(cache[\"foo\"])\n\n# Check if a key exists\nprint(\"foo\" in cache)\n\n# Get all keys\nprint(cache.keys())\n\n# Get all values\nprint(cache.values())\n\n# Get all items\nprint(cache.items())\n\n# Get the length of the cache\nprint(len(cache))\n\n# Clear the cache\ncache.clear()\n</code></pre>"},{"location":"api/lzl/io/#file-operations","title":"File Operations","text":"<p>File system operations with support for local and cloud storage:</p>"},{"location":"api/lzl/io/#lzl.io.file","title":"<code>lzl.io.file</code>","text":""},{"location":"api/lzl/io/#compression","title":"Compression","text":"<p>Data compression utilities:</p>"},{"location":"api/lzl/io/#lzl.io.compression","title":"<code>lzl.io.compression</code>","text":""},{"location":"api/lzl/io/#lzl.io.compression.get_default_compression","title":"<code>get_default_compression()</code>","text":"<p>Returns the default serializer</p> Source code in <code>src/lzl/io/compression/__init__.py</code> <pre><code>def get_default_compression() -&gt; str:\n    \"\"\"\n    Returns the default serializer\n    \"\"\"\n    return DEFAULT_COMPRESSION\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.compression.set_default_compression","title":"<code>set_default_compression(compression)</code>","text":"<p>Sets the default compression</p> <p>:param compression: The compression to use</p> Source code in <code>src/lzl/io/compression/__init__.py</code> <pre><code>def set_default_compression(\n    compression: str,\n) -&gt; None:\n    \"\"\"\n    Sets the default compression\n\n    :param compression: The compression to use\n    \"\"\"\n    global DEFAULT_COMPRESSION\n    DEFAULT_COMPRESSION = compression\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.compression.get_compression","title":"<code>get_compression(compression_type=None, compression_level=None, **kwargs)</code>","text":"<p>Returns a Compression</p> Source code in <code>src/lzl/io/compression/__init__.py</code> <pre><code>def get_compression(\n    compression_type: Optional[str] = None,\n    compression_level: Optional[int] = None,\n    **kwargs\n) -&gt; CompressionT:\n    \"\"\"\n    Returns a Compression\n    \"\"\"\n    from lzo.utils.hashing import create_hash_from_args_and_kwargs\n    if compression_type == 'auto': compression_type = None\n    compression_type = compression_type or get_default_compression()\n    comp_hash = create_hash_from_args_and_kwargs(compression_type, compression_level = compression_level, **kwargs)\n    if comp_hash in _initialized_compressors:\n        return _initialized_compressors[comp_hash]\n    if compression_type == \"gzip\":\n        new = GzipCompression(compression_level = compression_level, **kwargs)\n    elif compression_type == \"lz4\":\n        new = Lz4Compression(compression_level = compression_level, **kwargs)\n    elif compression_type == \"zlib\":\n        new = ZlibCompression(compression_level = compression_level, **kwargs)\n    elif compression_type == \"zstd\":\n        new = ZstdCompression(compression_level = compression_level, **kwargs)\n    else: raise ValueError(f\"Invalid Compression Type: {compression_type}\")\n    _initialized_compressors[comp_hash] = new\n    return new\n</code></pre>"},{"location":"api/lzl/io/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzl/io/#basic-serialization","title":"Basic Serialization","text":"<pre><code>from lzl.io.ser import serialize, deserialize\n\n# Serialize data\ndata = {\"key\": \"value\", \"number\": 42}\nserialized = serialize(data)\n\n# Deserialize data\nrestored = deserialize(serialized)\n</code></pre>"},{"location":"api/lzl/io/#persistent-storage","title":"Persistent Storage","text":"<pre><code>from lzl.io.persistence import PersistentDict\n\n# Create a persistent dictionary\ncache = PersistentDict(\"my_cache.db\")\ncache[\"key\"] = \"value\"\ncache.sync()  # Save to disk\n</code></pre>"},{"location":"api/lzl/io/#file-operations_1","title":"File Operations","text":"<pre><code>from lzl.io.file import read_file, write_file\n\n# Read and write files\ncontent = await read_file(\"input.txt\")\nawait write_file(\"output.txt\", content)\n</code></pre>"},{"location":"api/lzl/kops/","title":"lzl.kops - Kubernetes Operations","text":"<p>The <code>lzl.kops</code> module provides utilities for Kubernetes operations.</p>"},{"location":"api/lzl/kops/#leader-election","title":"Leader Election","text":""},{"location":"api/lzl/kops/#lzl.kops.leader_election","title":"<code>lzl.kops.leader_election</code>","text":""},{"location":"api/lzl/kops/#lzl.kops.leader_election.KubernetesLeaderElection","title":"<code>KubernetesLeaderElection</code>","text":"<p>Implements leader election using Kubernetes Lease objects.</p> <p>This class ensures that only one instance (pod/worker) can hold the leadership role at any given time, with automatic failover if the leader fails.</p> Source code in <code>src/lzl/kops/leader_election.py</code> <pre><code>class KubernetesLeaderElection:\n    \"\"\"\n    Implements leader election using Kubernetes Lease objects.\n\n    This class ensures that only one instance (pod/worker) can hold the leadership\n    role at any given time, with automatic failover if the leader fails.\n    \"\"\"\n\n    def __init__(\n        self,\n        lease_name: str,\n        namespace: str = None,\n        lease_duration_seconds: int = 15,\n        renew_deadline_seconds: int = 10,\n        retry_period_seconds: int = 2,\n        identity: str = None\n    ):\n        \"\"\"\n        Initialize the leader election manager.\n\n        Args:\n            lease_name: Name of the Kubernetes Lease object\n            namespace: Kubernetes namespace (defaults to current pod's namespace)\n            lease_duration_seconds: How long the lease is valid\n            renew_deadline_seconds: How long before lease expires to renew\n            retry_period_seconds: How often to retry acquiring the lease\n            identity: Unique identifier for this instance (defaults to pod name + worker id)\n        \"\"\"\n        self.lease_name = lease_name\n        self.namespace = namespace or self._get_namespace()\n        self.lease_duration_seconds = lease_duration_seconds\n        self.renew_deadline_seconds = renew_deadline_seconds\n        self.retry_period_seconds = retry_period_seconds\n        self.identity = identity or self._generate_identity()\n\n        self.is_leader = False\n        self._stop_election = False\n        self._election_task = None\n\n        # Initialize Kubernetes client\n        try:\n            kubernetes.config.load_incluster_config()\n        except kubernetes.config.ConfigException:\n            # Fallback for local development\n            kubernetes.config.load_kube_config()\n\n        self.coordination_v1 = kubernetes.client.CoordinationV1Api()\n\n    def _get_namespace(self) -&gt; str:\n        \"\"\"Get the current pod's namespace.\"\"\"\n        namespace_path = \"/var/run/secrets/kubernetes.io/serviceaccount/namespace\"\n        if os.path.exists(namespace_path):\n            with open(namespace_path, 'r') as f:\n                return f.read().strip()\n        return \"default\"\n\n    def _generate_identity(self) -&gt; str:\n        \"\"\"Generate a unique identity for this instance.\"\"\"\n        from lzo.utils.system import get_host_name\n        pod_name = os.environ.get(\"HOSTNAME\", f\"{get_host_name()}-{uuid.uuid4().hex[:8]}\")\n        worker_id = os.environ.get(\"WORKER_ID\", str(os.getpid()))\n        return f\"{pod_name}-{worker_id}\"\n\n    def _create_or_get_lease(self) -&gt; Optional['kubernetes.client.V1Lease']:\n        \"\"\"Create or retrieve the lease object.\"\"\"\n        try:\n            return self.coordination_v1.read_namespaced_lease(\n                name=self.lease_name,\n                namespace=self.namespace\n            )\n        except kubernetes.client.rest.ApiException as e:\n            if e.status == 404:\n                # Lease doesn't exist, create it\n                now = datetime.now(timezone.utc)\n                lease = kubernetes.client.V1Lease(\n                    metadata=kubernetes.client.V1ObjectMeta(\n                        name=self.lease_name,\n                        namespace=self.namespace\n                    ),\n                    spec=kubernetes.client.V1LeaseSpec(\n                        holder_identity=self.identity,\n                        lease_duration_seconds=self.lease_duration_seconds,\n                        acquire_time=now,\n                        renew_time=now\n                    )\n                )\n                try:\n                    return self.coordination_v1.create_namespaced_lease(\n                        namespace=self.namespace,\n                        body=lease\n                    )\n                except kubernetes.client.rest.ApiException as create_error:\n                    if create_error.status == 409:\n                        # Another instance created it concurrently\n                        return self.coordination_v1.read_namespaced_lease(\n                            name=self.lease_name,\n                            namespace=self.namespace\n                        )\n                    raise\n            raise\n\n\n    def _parse_k8s_datetime(self, dt_value) -&gt; datetime:\n        \"\"\"Parse datetime from Kubernetes, handling both string and datetime objects.\"\"\"\n        if dt_value is None:\n            return None\n\n        if isinstance(dt_value, datetime):\n            # Already a datetime object\n            if dt_value.tzinfo is None:\n                # Assume UTC if no timezone\n                return dt_value.replace(tzinfo=timezone.utc)\n            return dt_value\n\n        if isinstance(dt_value, str):\n            # Handle various datetime string formats from Kubernetes\n            # Remove microseconds if present (everything after the dot before timezone)\n            if '.' in dt_value:\n                # Split at the dot and reconstruct without microseconds\n                base, remainder = dt_value.split('.', 1)\n                # Find where timezone info starts (Z, +, or -)\n                for i, char in enumerate(remainder):\n                    if char in ['Z', '+', '-']:\n                        dt_value = base + remainder[i:]\n                        break\n                else:\n                    dt_value = base  # No timezone found\n\n            # Replace Z with +00:00 for ISO format compatibility\n            dt_value = dt_value.replace('Z', '+00:00')\n\n            try:\n                return datetime.fromisoformat(dt_value)\n            except ValueError:\n                # Fallback to parsing without timezone and assume UTC\n                try:\n                    dt_clean = dt_value.split('+')[0].split('-')[0] if '+' in dt_value or dt_value.count('-') &gt; 2 else dt_value\n                    return datetime.fromisoformat(dt_clean).replace(tzinfo=timezone.utc)\n                except Exception as e:\n                    logger.warning(f\"Could not parse datetime: {dt_value}, using current time: {e}\")\n                    return datetime.now(timezone.utc)\n\n        # Fallback for unexpected types\n        logger.warning(f\"Unexpected datetime type: {type(dt_value)}, using current time\")\n        return datetime.now(timezone.utc)\n\n    def _try_acquire_or_renew(self) -&gt; bool:\n        # sourcery skip: extract-duplicate-method, hoist-statement-from-if, remove-unnecessary-else, swap-if-else-branches\n        \"\"\"Try to acquire or renew the lease.\"\"\"\n        lease = self._create_or_get_lease()\n        if not lease:\n            return False\n\n        now = datetime.now(timezone.utc)\n\n        # Check if we can acquire the lease\n        if lease.spec.holder_identity == self.identity:\n            # We already hold the lease, renew it\n            lease.spec.renew_time = now\n        elif lease.spec.renew_time:\n            # Check if the current lease has expired\n            renew_time = self._parse_k8s_datetime(lease.spec.renew_time)\n            expiry_time = renew_time + timedelta(seconds=self.lease_duration_seconds)\n\n            if now &gt; expiry_time:\n                # Lease has expired, we can acquire it\n                lease.spec.holder_identity = self.identity\n                lease.spec.acquire_time = now\n                lease.spec.renew_time = now\n            else:\n                # Lease is held by another instance\n                return False\n        else:\n            # No renew time set, acquire the lease\n            lease.spec.holder_identity = self.identity\n            lease.spec.acquire_time = now\n            lease.spec.renew_time = now\n\n        # Try to update the lease\n        try:\n            self.coordination_v1.replace_namespaced_lease(\n                name=self.lease_name,\n                namespace=self.namespace,\n                body=lease\n            )\n            return lease.spec.holder_identity == self.identity\n        except kubernetes.client.rest.ApiException as e:\n            if e.status == 409:\n                # Conflict - another instance updated the lease\n                return False\n            raise\n\n    async def _election_loop(self):  # sourcery skip: remove-redundant-if\n        \"\"\"Main election loop that runs continuously.\"\"\"\n        retry_count = 0\n        max_retries = 5\n\n        while not self._stop_election:\n            try:\n                acquired = self._try_acquire_or_renew()\n                retry_count = 0  # Reset retry count on success\n\n                if acquired and not self.is_leader:\n                    logger.info(f\"Leadership acquired: |g|{self.identity}|e|\", colored = True)\n                    self.is_leader = True\n                    if hasattr(self, '_on_elected_callback'):\n                        await self._on_elected_callback()\n                elif not acquired and self.is_leader:\n                    logger.info(f\"Leadership lost: |y|{self.identity}|e|\", colored = True)\n                    self.is_leader = False\n                    if hasattr(self, '_on_lost_callback'):\n                        await self._on_lost_callback()\n                elif acquired and self.is_leader:\n                    logger.debug(f\"Leadership renewed: |g|{self.identity}|e|\", colored = True)\n\n                # Sleep before next attempt\n                if self.is_leader:\n                    # If we're the leader, renew more frequently\n                    await asyncio.sleep(self.renew_deadline_seconds)\n                else:\n                    # If we're not the leader, check less frequently\n                    await asyncio.sleep(self.retry_period_seconds)\n\n            except kubernetes.client.rest.ApiException as e:\n                retry_count += 1\n                logger.error(f\"Kubernetes API error in election loop (attempt {retry_count}/{max_retries}): {e.status} - {e.reason}\")\n\n                if e.status == 401:\n                    logger.error(\"Authentication failed. Check service account permissions.\")\n                elif e.status == 403:\n                    logger.error(\"Authorization failed. Check RBAC permissions for leases.\")\n\n                if retry_count &gt;= max_retries:\n                    logger.error(f\"Max retries ({max_retries}) reached. Giving up leadership.\")\n                    self.is_leader = False\n                    retry_count = 0  # Reset for next cycle\n\n                await asyncio.sleep(self.retry_period_seconds * retry_count)  # Exponential backoff\n\n            except Exception as e:\n                retry_count += 1\n                logger.error(f\"Unexpected error in election loop (attempt {retry_count}/{max_retries}): {e}\", exc_info=True)\n\n                if retry_count &gt;= max_retries:\n                    logger.error(f\"Max retries ({max_retries}) reached. Giving up leadership.\")\n                    self.is_leader = False\n                    retry_count = 0\n\n                await asyncio.sleep(self.retry_period_seconds * retry_count)\n\n    async def start(\n        self,\n        on_elected: Optional[Callable] = None,\n        on_lost: Optional[Callable] = None\n    ):\n        \"\"\"\n        Start the leader election process.\n\n        Args:\n            on_elected: Async callback when leadership is acquired\n            on_lost: Async callback when leadership is lost\n        \"\"\"\n        if on_elected:\n            self._on_elected_callback = on_elected\n        if on_lost:\n            self._on_lost_callback = on_lost\n\n        self._stop_election = False\n        self._election_task = asyncio.create_task(self._election_loop())\n        logger.info(f\"Leader election started for {self.identity}\"\n                    )\n\n    async def stop(self):\n        \"\"\"Stop the leader election process.\"\"\"\n        self._stop_election = True\n        if self._election_task:\n            await self._election_task\n        self.is_leader = False\n        logger.info(f\"Leader election stopped for {self.identity}\")\n\n    def leader_only(self, func: Callable) -&gt; Callable:\n        \"\"\"\n        Decorator to ensure a function only runs on the leader.\n\n        Usage:\n            @leader_election.leader_only\n            async def process_batch():\n                # This will only run on the leader\n                pass\n        \"\"\"\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            if not self.is_leader:\n                raise fastapi.HTTPException(\n                    status_code=503,\n                    detail=\"This instance is not the leader\"\n                )\n            return await func(*args, **kwargs)\n        return wrapper\n\n    @asynccontextmanager\n    async def as_leader(self):\n        \"\"\"\n        Context manager that only executes if this instance is the leader.\n\n        Usage:\n            async with leader_election.as_leader():\n                # Code here only runs on the leader\n                await process_important_task()\n        \"\"\"\n        if self.is_leader:\n            yield\n        else:\n            raise fastapi.HTTPException(\n                status_code=503,\n                detail=\"This instance is not the leader\"\n            )\n</code></pre>"},{"location":"api/lzl/kops/#lzl.kops.leader_election.KubernetesLeaderElection.start","title":"<code>start(on_elected=None, on_lost=None)</code>  <code>async</code>","text":"<p>Start the leader election process.</p> <p>Parameters:</p> Name Type Description Default <code>on_elected</code> <code>Optional[Callable]</code> <p>Async callback when leadership is acquired</p> <code>None</code> <code>on_lost</code> <code>Optional[Callable]</code> <p>Async callback when leadership is lost</p> <code>None</code> Source code in <code>src/lzl/kops/leader_election.py</code> <pre><code>async def start(\n    self,\n    on_elected: Optional[Callable] = None,\n    on_lost: Optional[Callable] = None\n):\n    \"\"\"\n    Start the leader election process.\n\n    Args:\n        on_elected: Async callback when leadership is acquired\n        on_lost: Async callback when leadership is lost\n    \"\"\"\n    if on_elected:\n        self._on_elected_callback = on_elected\n    if on_lost:\n        self._on_lost_callback = on_lost\n\n    self._stop_election = False\n    self._election_task = asyncio.create_task(self._election_loop())\n    logger.info(f\"Leader election started for {self.identity}\"\n                )\n</code></pre>"},{"location":"api/lzl/kops/#lzl.kops.leader_election.KubernetesLeaderElection.stop","title":"<code>stop()</code>  <code>async</code>","text":"<p>Stop the leader election process.</p> Source code in <code>src/lzl/kops/leader_election.py</code> <pre><code>async def stop(self):\n    \"\"\"Stop the leader election process.\"\"\"\n    self._stop_election = True\n    if self._election_task:\n        await self._election_task\n    self.is_leader = False\n    logger.info(f\"Leader election stopped for {self.identity}\")\n</code></pre>"},{"location":"api/lzl/kops/#lzl.kops.leader_election.KubernetesLeaderElection.leader_only","title":"<code>leader_only(func)</code>","text":"<p>Decorator to ensure a function only runs on the leader.</p> Usage <p>@leader_election.leader_only async def process_batch():     # This will only run on the leader     pass</p> Source code in <code>src/lzl/kops/leader_election.py</code> <pre><code>def leader_only(self, func: Callable) -&gt; Callable:\n    \"\"\"\n    Decorator to ensure a function only runs on the leader.\n\n    Usage:\n        @leader_election.leader_only\n        async def process_batch():\n            # This will only run on the leader\n            pass\n    \"\"\"\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        if not self.is_leader:\n            raise fastapi.HTTPException(\n                status_code=503,\n                detail=\"This instance is not the leader\"\n            )\n        return await func(*args, **kwargs)\n    return wrapper\n</code></pre>"},{"location":"api/lzl/kops/#lzl.kops.leader_election.KubernetesLeaderElection.as_leader","title":"<code>as_leader()</code>  <code>async</code>","text":"<p>Context manager that only executes if this instance is the leader.</p> Usage <p>async with leader_election.as_leader():     # Code here only runs on the leader     await process_important_task()</p> Source code in <code>src/lzl/kops/leader_election.py</code> <pre><code>@asynccontextmanager\nasync def as_leader(self):\n    \"\"\"\n    Context manager that only executes if this instance is the leader.\n\n    Usage:\n        async with leader_election.as_leader():\n            # Code here only runs on the leader\n            await process_important_task()\n    \"\"\"\n    if self.is_leader:\n        yield\n    else:\n        raise fastapi.HTTPException(\n            status_code=503,\n            detail=\"This instance is not the leader\"\n        )\n</code></pre>"},{"location":"api/lzl/load/","title":"lzl.load - Lazy Loading","text":"<p>The <code>lzl.load</code> module provides the <code>LazyLoad</code> proxy and other utilities for deferred imports. This pattern drastically reduces application startup time by only loading heavy dependencies when they are first accessed.</p>"},{"location":"api/lzl/load/#key-components","title":"Key Components","text":""},{"location":"api/lzl/load/#lazyload","title":"LazyLoad","text":"<p>The core proxy class. It intercepts attribute access to trigger the import.</p>"},{"location":"api/lzl/load/#lzl.load.main","title":"<code>lzl.load.main</code>","text":""},{"location":"api/lzl/load/#lzl.load.main.LazyLoad","title":"<code>LazyLoad</code>","text":"<p>               Bases: <code>Generic[_M]</code></p> <p>Proxy object that defers importing a module until it is accessed.</p>"},{"location":"api/lzl/load/#lzl.load.main.LazyLoad--parameters","title":"Parameters","text":"<p>name:     The absolute or relative module name that should be imported lazily. package:     Package name used as the anchor for relative imports.  Mirrors     :func:<code>importlib.import_module</code>. install_missing:     When <code>True</code> (default) missing dependencies are installed via     :mod:<code>lzl.require</code>.  This mirrors the legacy behaviour and is kept for     backwards compatibility. install_options:     Keyword arguments forwarded to     :meth:<code>lzl.require.LazyLib.install_pip_package</code> if installation is     required. dependencies:     An optional dependency or iterable of dependencies that should be     loaded before the target module becomes available.  Each dependency is     expected to be another :class:<code>LazyLoad</code> instance.</p> Source code in <code>src/lzl/load/main.py</code> <pre><code>class LazyLoad(t.Generic[_M]):\n    \"\"\"Proxy object that defers importing a module until it is accessed.\n\n    Parameters\n    ----------\n    name:\n        The absolute or relative module name that should be imported lazily.\n    package:\n        Package name used as the anchor for relative imports.  Mirrors\n        :func:`importlib.import_module`.\n    install_missing:\n        When ``True`` (default) missing dependencies are installed via\n        :mod:`lzl.require`.  This mirrors the legacy behaviour and is kept for\n        backwards compatibility.\n    install_options:\n        Keyword arguments forwarded to\n        :meth:`lzl.require.LazyLib.install_pip_package` if installation is\n        required.\n    dependencies:\n        An optional dependency or iterable of dependencies that should be\n        loaded before the target module becomes available.  Each dependency is\n        expected to be another :class:`LazyLoad` instance.\n    \"\"\"\n\n    def __init__(\n        self, \n        name: str, \n        package: str | None = None, \n        install_missing: bool = True,\n        install_options: t.Optional[t.Dict[str, t.Any]] = None,\n        dependencies: t.Optional[t.Union['LazyLoad', t.Iterable['LazyLoad']]] = None,\n    ) -&gt; None:\n        self._lzlname = name  # Ridiculous name avoids name clash with module\n        if dependencies and not isinstance(dependencies, list):\n            dependencies = [dependencies]\n        self._lzldeps: t.Optional[t.Iterable['LazyLoad']] = dependencies\n        self._lzlpackage = package  # Ridiculous name avoids name clash with module\n        self._lzlinstall = install_missing\n        if install_missing:\n            install_options = install_options or {}\n            if 'package' not in install_options: install_options['package'] = package or name\n            self._lzlinstall_options = install_options\n        self.__module__: ModuleType | None = None\n\n    def __do_import__(self) -&gt; _M:\n        \"\"\"Import the target module, optionally installing missing deps.\"\"\"\n        try:\n            return importlib.import_module(self._lzlname, self._lzlpackage)\n        except Exception as e:\n            if self._lzlinstall:\n                from lzl.require import LazyLib\n                LazyLib.install_pip_package(**self._lzlinstall_options)\n                return importlib.import_module(self._lzlname, self._lzlpackage)\n            raise e\n\n    def __do_load_dependencies__(self) -&gt; None:\n        \"\"\"Ensure any declared lazy dependencies are loaded.\"\"\"\n        if not self._lzldeps: return\n        for dep in self._lzldeps:\n            dep.__load__()\n\n    def __do_reload_dependencies__(self) -&gt; None:\n        \"\"\"Force reload on dependencies before returning the module.\"\"\"\n        if not self._lzldeps: return\n        for dep in self._lzldeps:\n            dep.__reload__()\n\n\n    def __load__(self) -&gt; _M:\n        \"\"\"Explicitly load the import if it has not already been resolved.\"\"\"\n        if self.__module__ is None:\n            self.__module__ = self.__do_import__()\n            self.__do_load_dependencies__()\n        return self.__module__\n\n    def __reload__(self) -&gt; _M:\n        \"\"\"Force a reload of the proxied module and its dependencies.\"\"\"\n        try:\n            self.__module__ = importlib.reload(self.__module__)\n            self.__do_reload_dependencies__()\n        except Exception as exc:\n            try:\n                self.__module__ = self.__do_import__()\n                self.__do_load_dependencies__()\n            except Exception as e:\n                raise exc from e\n        return self.__module__\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a helpful representation regardless of load state.\"\"\"\n        if self.__module__ is None:\n            if self._lzlpackage:\n                return f\"&lt;Uninitialized module '{self._lzlname}' @ '{self._lzlpackage}'&gt;\"\n            return f\"&lt;Uninitialized module '{self._lzlname}'&gt;\"\n        try:\n            return self.__module__.__repr__()\n        # Shouldn't happen unless someone del'd module __repr__ method for some reason\n        except AttributeError:\n            if self._lzlpackage:\n                return f\"&lt;Initialized module '{self._lzlname}' @ '{self._lzlpackage}'&gt;\"\n            return f\"&lt;Initialized module '{self._lzlname}'&gt;\"\n\n    def __getattribute__(self, __name: str) -&gt; t.Any:\n        \"\"\"Proxy attribute access to the resolved module when available.\"\"\"\n        if __name in {\n            \"_lzlname\",\n            \"_lzlpackage\",\n            \"_lzlinstall\",\n            \"_lzldeps\",\n            \"_lzlinstall_options\",\n            \"__module__\",\n            \"__load__\",\n            \"__reload__\",\n            \"__do_import__\",\n            \"__do_load_dependencies__\",\n            \"__do_reload_dependencies__\",\n        }:\n            return super().__getattribute__(__name)\n        if self.__module__ is None:\n            self.__module__ = self.__do_import__()\n            self.__do_load_dependencies__()\n        return getattr(self.__module__, __name)\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.main.lazy_load","title":"<code>lazy_load(name, package=None, install_missing=True, install_options=None, dependencies=None)</code>","text":"<p>Create a :class:<code>LazyLoad</code> proxy for a module import.</p>"},{"location":"api/lzl/load/#lzl.load.main.lazy_load--returns","title":"Returns","text":"<p>LazyLoad     A proxy object that defers the import until attribute access occurs.</p> Source code in <code>src/lzl/load/main.py</code> <pre><code>def lazy_load(\n    name: str,\n    package: str | None = None,\n    install_missing: bool = True,\n    install_options: t.Optional[t.Dict[str, t.Any]] = None,\n    dependencies: t.Optional[t.Union[\"LazyLoad\", t.Iterable[\"LazyLoad\"]]] = None,\n) -&gt; LazyLoad:\n    \"\"\"Create a :class:`LazyLoad` proxy for a module import.\n\n    Returns\n    -------\n    LazyLoad\n        A proxy object that defers the import until attribute access occurs.\n    \"\"\"\n\n    return LazyLoad(\n        name,\n        package=package,\n        install_missing=install_missing,\n        install_options=install_options,\n        dependencies=dependencies,\n    )\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.main.load","title":"<code>load(__module)</code>","text":"<p>Eagerly resolve a lazy module and return the imported module object.</p> Source code in <code>src/lzl/load/main.py</code> <pre><code>def load(__module: LazyLoad | _M) -&gt; _M:\n    \"\"\"Eagerly resolve a lazy module and return the imported module object.\"\"\"\n\n    return __module.__load__() if isinstance(__module, LazyLoad) else __module\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.main.reload","title":"<code>reload(__module)</code>","text":"<p>Reload a module regardless of whether it is proxied or real.</p> Source code in <code>src/lzl/load/main.py</code> <pre><code>def reload(__module: LazyLoad | _M) -&gt; _M:\n    \"\"\"Reload a module regardless of whether it is proxied or real.\"\"\"\n\n    if isinstance(__module, LazyLoad):\n        return __module.__reload__()\n    return importlib.reload(__module)\n</code></pre>"},{"location":"api/lzl/load/#usage-guide","title":"Usage Guide","text":""},{"location":"api/lzl/load/#basic-lazy-loading","title":"Basic Lazy Loading","text":"<p>Instead of top-level imports, define a proxy.</p> <pre><code>from lzl.load import LazyLoad\n\n# 'numpy' is NOT imported yet\nnp = LazyLoad(\"numpy\")\n\ndef process_data(data):\n    # 'numpy' is imported here, on the first attribute access\n    return np.array(data)\n</code></pre>"},{"location":"api/lzl/load/#handling-optional-dependencies","title":"Handling Optional Dependencies","text":"<p>You can configure <code>LazyLoad</code> to automatically install missing packages (though use with caution in production).</p> <pre><code># If 'pandas' is missing, it will attempt to pip install it\npd = LazyLoad(\"pandas\", install_missing=True)\n</code></pre>"},{"location":"api/lzl/load/#dependency-chains","title":"Dependency Chains","text":"<p>If a module depends on another lazy module being loaded first (e.g., for side effects), you can declare dependencies.</p> <pre><code># specific_setup must be loaded before my_module\nsetup = LazyLoad(\"my_app.specific_setup\")\nmod = LazyLoad(\"my_app.my_module\", dependencies=setup)\n</code></pre>"},{"location":"api/lzl/load/#type-checking","title":"Type Checking","text":"<p>For static analysis (mypy/pyright), you can use <code>TYPE_CHECKING</code> blocks to keep type hints working while using lazy loading at runtime.</p> <pre><code>from typing import TYPE_CHECKING\nfrom lzl.load import LazyLoad\n\nif TYPE_CHECKING:\n    import pandas as pd\nelse:\n    pd = LazyLoad(\"pandas\")\n\ndef get_df() -&gt; \"pd.DataFrame\":\n    return pd.DataFrame()\n</code></pre>"},{"location":"api/lzl/logging/","title":"lzl.logging - Structured Logging","text":"<p>The <code>lzl.logging</code> module provides a zero-config, high-performance structured logging system built on top of <code>loguru</code>.</p>"},{"location":"api/lzl/logging/#core-logger","title":"Core Logger","text":""},{"location":"api/lzl/logging/#lzl.logging.main","title":"<code>lzl.logging.main</code>","text":""},{"location":"api/lzl/logging/#lzl.logging.main.create_global_logger","title":"<code>create_global_logger(name='lzl', level='INFO', format=None, filter=None, handlers=None, settings=None, **kwargs)</code>","text":"<p>Instantiate the shared global Loguru logger used across LazyOps.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Registry key for the logger instance.  Defaults to <code>\"lzl\"</code>.</p> <code>'lzl'</code> <code>level</code> <code>str | int</code> <p>Log level for newly attached handlers.  Accepts both string and numeric values recognised by Loguru.</p> <code>'INFO'</code> <code>format</code> <code>Callable[['LogRecord'], str] | None</code> <p>Optional callable used to format log records.</p> <code>None</code> <code>filter</code> <code>Callable[['LogRecord'], bool] | None</code> <p>Optional predicate used to filter records.</p> <code>None</code> <code>handlers</code> <code>Sequence['LoggingHandler'] | None</code> <p>Additional :mod:<code>logging</code> handlers to bridge into Loguru.</p> <code>None</code> <code>settings</code> <code>'BaseSettings' | None</code> <p>Optional settings object attached to the logger for runtime reference.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments forwarded to :meth:<code>loguru.Logger.add</code>.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Logger</code> <code>Logger</code> <p>The configured Loguru logger instance.</p> Source code in <code>src/lzl/logging/main.py</code> <pre><code>def create_global_logger(\n    name: str | None = \"lzl\",\n    level: str | int = \"INFO\",\n    format: t.Callable[[\"LogRecord\"], str] | None = None,\n    filter: t.Callable[[\"LogRecord\"], bool] | None = None,\n    handlers: t.Sequence[\"LoggingHandler\"] | None = None,\n    settings: \"BaseSettings\" | None = None,\n    **kwargs: t.Any,\n) -&gt; Logger:\n    \"\"\"Instantiate the shared global Loguru logger used across LazyOps.\n\n    Args:\n        name: Registry key for the logger instance.  Defaults to ``\"lzl\"``.\n        level: Log level for newly attached handlers.  Accepts both string and\n            numeric values recognised by Loguru.\n        format: Optional callable used to format log records.\n        filter: Optional predicate used to filter records.\n        handlers: Additional :mod:`logging` handlers to bridge into Loguru.\n        settings: Optional settings object attached to the logger for runtime\n            reference.\n        **kwargs: Additional keyword arguments forwarded to\n            :meth:`loguru.Logger.add`.\n\n    Returns:\n        Logger: The configured Loguru logger instance.\n    \"\"\"\n    global _logger_contexts\n\n    # &lt; 0.7.0\n    try:\n        _logger = Logger(\n            core=_Core(),\n            exception=None,\n            depth=0,\n            record=False,\n            lazy=False,\n            colors=True,\n            raw=False,\n            capture=True,\n            patcher=None,\n            extra={},\n        )\n    # &gt;= 0.7.0\n    except Exception as e:\n        _logger = Logger(\n            core=_Core(),\n            exception=None,\n            depth=0,\n            record=False,\n            lazy=False,\n            colors=False,\n            raw=False,\n            capture=True,\n            patchers=[run_record_patching_hook],\n            extra={},\n        )\n\n    _logger.name = 'lzl'\n    _logger.is_global = True\n    dev_level = _logger.level(name='DEV', no=19, color=\"&lt;blue&gt;\", icon=\"@\")\n\n    if _defaults.LOGURU_AUTOINIT and sys.stderr: _logger.add(sys.stderr)\n    _atexit.register(_logger.remove)\n\n    _logger.remove()\n    _logger.add_if_condition('dev', _logger._is_dev_condition)\n    import logging\n    logging.basicConfig(\n        handlers = handlers or [InterceptHandler()],  level = 0\n    )\n\n    _logger.add(\n        sys.stdout,\n        enqueue = not _DISABLE_QUEUE,\n        backtrace = True,\n        colorize = True,\n        level = level,\n        format = format if format is not None else LoggerFormatter.default_formatter,\n        filter = filter if filter is not None else _logger._filter,\n        **kwargs,\n    )\n    if settings: _logger.settings = settings\n    _logger_contexts[name] = _logger\n    return _logger\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.main.create_default_logger","title":"<code>create_default_logger(name=None, level='INFO', format=None, filter=None, handlers=None, settings=None, **kwargs)</code>","text":"<p>Return a named logger that proxies calls to the global instance.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Optional logger namespace.  If omitted the global logger is returned.</p> <code>None</code> <code>level</code> <code>str | int</code> <p>Minimum log level once the logger is registered.</p> <code>'INFO'</code> <code>format</code> <code>Callable[['LogRecord'], str] | None</code> <p>Formatter applied when a dedicated handler is configured.</p> <code>None</code> <code>filter</code> <code>Callable[['LogRecord'], bool] | None</code> <p>Optional filtering callable.</p> <code>None</code> <code>handlers</code> <code>Sequence['LoggingHandler'] | None</code> <p>Additional logging handlers to attach.</p> <code>None</code> <code>settings</code> <code>'BaseSettings' | None</code> <p>Optional settings object attached to the logger for runtime reference.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Extra keyword arguments forwarded to the Loguru <code>add</code> call.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Logger</code> <code>Logger</code> <p>Either the global logger or a namespaced proxy.</p> Source code in <code>src/lzl/logging/main.py</code> <pre><code>def create_default_logger(\n    name: str | None = None,\n    level: str | int = \"INFO\",\n    format: t.Callable[[\"LogRecord\"], str] | None = None,\n    filter: t.Callable[[\"LogRecord\"], bool] | None = None,\n    handlers: t.Sequence['LoggingHandler'] | None = None,\n    settings: 'BaseSettings' | None = None,\n    **kwargs: t.Any,\n) -&gt; Logger:\n    \"\"\"Return a named logger that proxies calls to the global instance.\n\n    Args:\n        name: Optional logger namespace.  If omitted the global logger is\n            returned.\n        level: Minimum log level once the logger is registered.\n        format: Formatter applied when a dedicated handler is configured.\n        filter: Optional filtering callable.\n        handlers: Additional logging handlers to attach.\n        settings: Optional settings object attached to the logger for runtime\n            reference.\n        **kwargs: Extra keyword arguments forwarded to the Loguru ``add`` call.\n\n    Returns:\n        Logger: Either the global logger or a namespaced proxy.\n    \"\"\"\n    global _logger_contexts\n    if name:\n        if name.upper() in REVERSE_LOGLEVEL_MAPPING:\n            # If name is a level, then set level to name\n            level = name\n            name = None\n        else:\n            name = extract_module_name(name)\n\n    if name is None: name = 'lzl'\n    if name in _logger_contexts:\n        return _logger_contexts[name]\n\n    with _lock:\n        if name == 'lzl':\n            return create_global_logger(\n                name = name,\n                level = level,\n                format = format,\n                filter = filter,\n                handlers = handlers,\n                settings = settings,\n            )\n\n        if isinstance(level, str): level = level.upper()\n        _logger = _logger_contexts['lzl']\n\n        if name and format is not None:\n            # Add a new handler\n            def _filter_func(record: 'LogRecord') -&gt; bool:\n                \"\"\"\n                Filter out messages from other modules\n                \"\"\"\n                return extract_module_name(record.name) == name\n\n            _logger.add(\n                sys.stdout,\n                enqueue = not _DISABLE_QUEUE,\n                backtrace = True,\n                colorize = True,\n                level = level,\n                format = format,\n                filter = _filter_func,\n                **kwargs,\n            )\n            return _logger\n\n        *options, extra = _logger._options\n        new_logger = Logger(_logger._core, *options, {**extra})\n        if name: \n            _logger_contexts[name] = new_logger\n            new_logger.name = name\n            register_logger_module(name)\n\n        if settings: new_logger.settings = settings\n        # if _is_global_logger: new_logger.is_global = True\n        return new_logger\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.main.change_logger_level","title":"<code>change_logger_level(name=None, level='INFO', verbose=False, **kwargs)</code>","text":"<p>Update the minimum level for the global or named logger.</p> Source code in <code>src/lzl/logging/main.py</code> <pre><code>def change_logger_level(\n    name: str | None = None,\n    level: str | int = \"INFO\",\n    verbose: bool = False,\n    **kwargs: t.Any,\n) -&gt; None:\n    \"\"\"Update the minimum level for the global or named logger.\"\"\"\n    global logger, logger_level\n    if isinstance(level, str): level = level.upper()\n    # Skip if the level is the same\n    if level == logger_level: return\n    name = name or 'lzl'\n    name = name.split('.')[0]\n    logger_level = level\n    if name != 'lzl':\n        __logger = get_logger(name, logger_level, **kwargs)\n    else:\n        __logger = logger\n    if verbose: __logger.info(f\"[{name}] Changing logger level from {logger_level} -&gt; {level}\")\n    __logger._core.min_level = float(REVERSE_LOGLEVEL_MAPPING[logger_level.upper()])\n</code></pre>"},{"location":"api/lzl/logging/#configuration","title":"Configuration","text":""},{"location":"api/lzl/logging/#lzl.logging.base","title":"<code>lzl.logging.base</code>","text":""},{"location":"api/lzl/logging/#lzl.logging.base.Logger","title":"<code>Logger</code>","text":"<p>               Bases: <code>Logger</code>, <code>LoggingMixin</code></p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>class Logger(_Logger, LoggingMixin):\n\n    name: str = None\n    settings: Type['BaseSettings'] = None\n    conditions: Dict[str, Tuple[Union[Callable, bool], str]] = {}\n    default_trace_depth: Optional[int] = None\n    is_global: bool = False\n    _colored_opts = None\n    _current_level: Optional[str] = None\n\n    @property\n    def colored_opts(self):\n        \"\"\"\n        Returns the colored options\n        \"\"\"\n        if not self._colored_opts:\n            (exception, depth, record, lazy, colors, raw, capture, patchers, extra) = self._options\n            self._colored_opts = (exception, depth, record, lazy, True, raw, capture, patchers, extra)\n        return self._colored_opts\n\n    def _get_opts(self, colored: Optional[bool] = False, **kwargs):\n        \"\"\"\n        Returns the options\n        \"\"\"\n        return self.colored_opts if colored else self._options\n\n    def get_log_mode(self, level: str = \"info\"):\n        \"\"\"\n        Returns the log mode based on the level\n        \"\"\"\n        return self.dev if level.upper() in {'DEV'} else getattr(self, level.lower())\n\n    def add_if_condition(\n        self, \n        name: str, \n        condition: Union[Callable, bool],\n        level: Optional[Union[str, int]] = 'INFO',\n    ):\n        \"\"\"\n        Adds a condition to the logger\n        \"\"\"\n        self.conditions[name] = (condition, self._get_level(level))\n\n    def remove_if_condition(self, name: str):\n        \"\"\"\n        Removes a condition from the logger\n        \"\"\"\n        if name in self.conditions:\n            del self.conditions[name]\n\n    def _is_dev_condition(self, record: logging.LogRecord) -&gt; bool:\n        \"\"\"\n        Returns whether the dev condition is met\n        \"\"\"\n        if not self.settings: return True\n        if record.levelname == 'DEV':\n            for key in {'api_dev_mode', 'debug_enabled'}:\n                if (\n                    hasattr(self.settings, key)\n                    and getattr(self.settings, key) is False\n                ):\n                    return False\n        return True\n\n    def _filter_if(self, name: str, record: Optional[logging.LogRecord] = None, message: Optional[Any] = None, level: Optional[Union[str, int]] = None) -&gt; Tuple[bool, str]:\n        \"\"\"\n        Filters out messages based on conditions\n        \"\"\"\n        if name in self.conditions:\n            condition, clevel = self.conditions[name]\n            if isinstance(condition, bool):\n                return condition, clevel\n            elif isinstance(condition, type(None)):\n                return False, clevel\n            elif isinstance(condition, Callable):\n                return condition(record or message), clevel\n        return True, (record.levelname if record else self._get_level(level or 'INFO'))\n\n    def _filter_module_name(self, name: str) -&gt; bool:\n        \"\"\"\n        Filter based on module name\n\n        - True if the module is not registered and is_global is False \n        - False if the module is registered and is_global is False\n        \"\"\"\n        _is_registered = is_registered_logger_module(name)\n        if self.is_global: \n            return _is_registered is not False\n        return _is_registered is False\n\n\n    def _filter(self, record: logging.LogRecord, name: Optional[str] = None) -&gt; bool:\n        \"\"\"\n        Filters out messages based on conditions\n\n        - True if the message should be filtered out\n        - False if the message should be logged\n        \"\"\"\n        if self.check_silenced(record):\n            return True\n        if self._filter_module_name(record['name']): \n            return True\n\n        if name is not None:\n            return self._filter_if(name, record)[0]\n        if not self.conditions: return False\n        return not any(\n            isinstance(value, bool)\n            and value is False\n            or not isinstance(value, bool)\n            and isinstance(value, Callable)\n            and value(record) is False\n            for key, value in self.conditions.items()\n        )\n\n    def _filter_dev(self, record: logging.LogRecord, **kwargs):\n        if not self.settings:\n            return True\n        if record.levelname == 'DEV':\n            for key in {'api_dev_mode', 'debug_enabled'}:\n                if (\n                    hasattr(self.settings, key)\n                    and getattr(self.settings, key) is False\n                ):\n                    return False\n        return True\n\n    def opt(\n        self,\n        *,\n        exception=None,\n        record=False,\n        lazy=False,\n        colors=False,\n        raw=False,\n        capture=True,\n        depth=0,\n        ansi=False\n    ):\n        \"\"\"\n        Return a new logger with the specified options changed.\n        \"\"\"\n        if ansi: colors = True\n        args = self._options[-2:]\n        return type(self)(self._core, exception, depth, record, lazy, colors, raw, capture, *args)\n\n\n\n    \"\"\"\n    Newly Added APIs\n    \"\"\"\n\n    def _get_level(self, level: Union[str, int]) -&gt; str:\n        \"\"\"\n        Returns the log level\n        \"\"\"\n        return get_logging_level(level)\n\n    def _format_item(\n        self,\n        msg: 'MsgItem',\n        max_length: Optional[int] = None,\n        colored: Optional[bool] = False,\n        level: Optional[str] = None,\n        _is_part: Optional[bool] = False,\n    ) -&gt; str:  # sourcery skip: extract-duplicate-method, low-code-quality, split-or-ifs\n        \"\"\"\n        Formats an item\n        \"\"\"\n        return format_item(msg, max_length = max_length, colored = colored, level = level, _is_part = _is_part)\n\n\n    def _format_message(\n        self, \n        message: 'MsgItem',\n        *args,\n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        level: Optional[str] = None,\n        colored: Optional[bool] = False,\n        extra: Optional[Dict[str, Any]] = None,\n    ) -&gt; str:\n        \"\"\"\n        Formats the message\n\n        \"example |b|msg|e|\"\n        -&gt; \"example &lt;blue&gt;msg&lt;/&gt;&lt;reset&gt;\"\n        \"\"\"\n        return format_message(\n            message,\n            *args,\n            prefix = prefix,\n            max_length = max_length,\n            level = level,\n            colored = colored,\n            extra = extra,\n        )\n\n    def log_if(\n        self, \n        name: str, \n        message: 'MsgItem',\n        *args, \n        level: Optional[Union[str, int]] = None, \n        **kwargs\n    ):  # noqa: N805\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``level`` if condition is met.\n        \"\"\"\n        condition, clevel = self._filter_if(name, message = message, level = level)\n        if condition:\n            return self.log((level or clevel), message, *args, **kwargs)\n\n    def log(\n        self, \n        level: Union[str, int], \n        message: 'MsgItem',\n        *args, \n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        colored: Optional[bool] = False,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):  # noqa: N805\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``level``.\n        \"\"\"\n        level = self._get_level(level)\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = level,\n            extra = extra,\n        )\n        try:\n            self._log(level, False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            # level_id, static_level_no, from_decorator, options, message, args, kwargs\n            static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 20)\n            self._log(level, static_log_no, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def info(\n        self, \n        message: 'MsgItem',\n        *args, \n        colored: Optional[bool] = None, \n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):  # noqa: N805\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``'INFO'``.\n        \"\"\"\n        if colored is None and isinstance(message, str) and '|e|' in message: colored = True\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            *args,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'INFO',\n            extra = extra,\n        )\n        if not is_global_muted():\n            try:\n                self._log(\"INFO\", False, self._get_opts(colored = colored), message, args, kwargs)\n            except TypeError:\n                # Compatibility with &lt; 0.6.0\n                self._log(\"INFO\", 20, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def success(\n        self, \n        message: 'MsgItem', \n        *args, \n        colored: Optional[bool] = False, \n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):  # noqa: N805\n        r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'SUCCESS'``.\"\"\"\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            *args,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'SUCCESS',\n            extra = extra,\n        )\n        if not is_global_muted():\n            try:\n                self._log(\"SUCCESS\", False, self._get_opts(colored = colored), message, args, kwargs)\n            except TypeError:\n                # Compatibility with &lt; 0.6.0\n                self._log(\"SUCCESS\", 20, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def warning(\n        self, \n        message, \n        *args, \n        colored: Optional[bool] = False, \n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):  # noqa: N805\n        r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'WARNING'``.\"\"\"\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'WARNING',\n            extra = extra,\n        )\n\n        try:\n            self._log(\"WARNING\", False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            self._log(\"WARNING\", 30, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def error(\n        self,\n        message: Any,\n        *args,\n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        colored: Optional[bool] = False,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        exc_info: Optional[bool] = False,\n        **kwargs\n    ) -&gt; None:\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``'ERROR'``.\n        \"\"\"\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'ERROR',\n            extra = extra,\n        )\n        if exc_info: message += f\"\\n{traceback.format_exc()}\"\n\n        try:\n            self._log(\"ERROR\", False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            self._log(\"ERROR\", 40, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def trace(\n        self, \n        msg: 'MsgItem',\n        error: Optional[Type[Exception]] = None, \n        level: str = \"ERROR\",\n        limit: Optional[int] = None,\n        chain: Optional[bool] = True,\n        colored: Optional[bool] = False,\n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        This method logs the traceback of an exception.\n\n        :param error: The exception to log.\n        \"\"\"\n        _depth = kwargs.pop('depth', None)\n        extra = kwargs.pop('extra', None)\n        if _depth is not None: limit = _depth\n        if isinstance(msg, str):\n            _msg = msg\n            if extra:\n                extras_rendered = format_item(extra, max_length = max_length, colored = colored, level = level)\n                extras_rendered = extras_rendered.lstrip('\\n')\n                if extras_rendered:\n                    if _msg:\n                        _msg += f\"\\n{extras_rendered}\"\n                    else:\n                        _msg = extras_rendered\n        else:\n            _msg = self._format_message(\n                msg,\n                colored = colored,\n                level = level,\n                prefix = prefix,\n                max_length = max_length,\n                extra = extra,\n            )\n        # pprint.pformat(msg)\n        _msg += f\"\\n{traceback.format_exc(chain = chain, limit = limit)}\"\n        if error: _msg += f\" - {error}\"\n\n        try:\n            self._log(level, False, self._get_opts(colored = colored), _msg, (), {})\n        except TypeError:\n            static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 40)\n            self._log(level, static_log_no, False, self._get_opts(colored = colored), _msg, (), {})\n        self.run_logging_hooks(_msg, hook = hook)\n\n    def exception(\n        self,\n        message: 'MsgItem',\n        *args,\n        colored: Optional[bool] = False,\n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``'ERROR'``.\n        \"\"\"\n        extra = kwargs.get('extra')\n        message = self._format_message(\n            message,\n            *args,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'ERROR',\n            extra = extra,\n        )\n        super().exception(message, *args, **kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n\n    def __call__(self, message: 'MsgItem', *args, level: str = 'info', **kwargs):\n        r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'INFO'``.\"\"\"\n        if isinstance(message, list):\n            __message = \"\".join(f'- {item}\\n' for item in message)\n        elif isinstance(message, dict):\n            __message = \"\".join(f'- {key}: {value}\\n' for key, value in message.items())\n        else:\n            __message = str(message)\n        _log = self.get_log_mode(level)\n        _log(__message.strip(), *args, **kwargs)\n\n    def _logcompat(\n        self, level, from_decorator, options, message, args, kwargs\n    ):\n        \"\"\"\n        Compatible to &lt; 0.6.0\n        \"\"\"\n        try:\n            self._log(level, from_decorator, options, message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            # level_id, static_level_no, from_decorator, options, message, args, kwargs\n            static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 20)\n            self._log(level, static_log_no, from_decorator, options, message, args, kwargs)\n\n\n    \"\"\"\n    Utilties\n    \"\"\"\n\n    def change_logger_level(\n        self,\n        level: str,\n    ):\n        \"\"\"\n        Changes the logger level\n\n        :TODO\n        \"\"\"\n        return\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.colored_opts","title":"<code>colored_opts</code>  <code>property</code>","text":"<p>Returns the colored options</p>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.get_log_mode","title":"<code>get_log_mode(level='info')</code>","text":"<p>Returns the log mode based on the level</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def get_log_mode(self, level: str = \"info\"):\n    \"\"\"\n    Returns the log mode based on the level\n    \"\"\"\n    return self.dev if level.upper() in {'DEV'} else getattr(self, level.lower())\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.add_if_condition","title":"<code>add_if_condition(name, condition, level='INFO')</code>","text":"<p>Adds a condition to the logger</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def add_if_condition(\n    self, \n    name: str, \n    condition: Union[Callable, bool],\n    level: Optional[Union[str, int]] = 'INFO',\n):\n    \"\"\"\n    Adds a condition to the logger\n    \"\"\"\n    self.conditions[name] = (condition, self._get_level(level))\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.remove_if_condition","title":"<code>remove_if_condition(name)</code>","text":"<p>Removes a condition from the logger</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def remove_if_condition(self, name: str):\n    \"\"\"\n    Removes a condition from the logger\n    \"\"\"\n    if name in self.conditions:\n        del self.conditions[name]\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.opt","title":"<code>opt(*, exception=None, record=False, lazy=False, colors=False, raw=False, capture=True, depth=0, ansi=False)</code>","text":"<p>Return a new logger with the specified options changed.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def opt(\n    self,\n    *,\n    exception=None,\n    record=False,\n    lazy=False,\n    colors=False,\n    raw=False,\n    capture=True,\n    depth=0,\n    ansi=False\n):\n    \"\"\"\n    Return a new logger with the specified options changed.\n    \"\"\"\n    if ansi: colors = True\n    args = self._options[-2:]\n    return type(self)(self._core, exception, depth, record, lazy, colors, raw, capture, *args)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.log_if","title":"<code>log_if(name, message, *args, level=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>level</code> if condition is met.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def log_if(\n    self, \n    name: str, \n    message: 'MsgItem',\n    *args, \n    level: Optional[Union[str, int]] = None, \n    **kwargs\n):  # noqa: N805\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``level`` if condition is met.\n    \"\"\"\n    condition, clevel = self._filter_if(name, message = message, level = level)\n    if condition:\n        return self.log((level or clevel), message, *args, **kwargs)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.log","title":"<code>log(level, message, *args, prefix=None, max_length=None, colored=False, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>level</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def log(\n    self, \n    level: Union[str, int], \n    message: 'MsgItem',\n    *args, \n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    colored: Optional[bool] = False,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):  # noqa: N805\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``level``.\n    \"\"\"\n    level = self._get_level(level)\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = level,\n        extra = extra,\n    )\n    try:\n        self._log(level, False, self._get_opts(colored = colored), message, args, kwargs)\n    except TypeError:\n        # Compatibility with &lt; 0.6.0\n        # level_id, static_level_no, from_decorator, options, message, args, kwargs\n        static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 20)\n        self._log(level, static_log_no, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.info","title":"<code>info(message, *args, colored=None, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'INFO'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def info(\n    self, \n    message: 'MsgItem',\n    *args, \n    colored: Optional[bool] = None, \n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):  # noqa: N805\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``'INFO'``.\n    \"\"\"\n    if colored is None and isinstance(message, str) and '|e|' in message: colored = True\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        *args,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'INFO',\n        extra = extra,\n    )\n    if not is_global_muted():\n        try:\n            self._log(\"INFO\", False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            self._log(\"INFO\", 20, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.success","title":"<code>success(message, *args, colored=False, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'SUCCESS'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def success(\n    self, \n    message: 'MsgItem', \n    *args, \n    colored: Optional[bool] = False, \n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):  # noqa: N805\n    r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'SUCCESS'``.\"\"\"\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        *args,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'SUCCESS',\n        extra = extra,\n    )\n    if not is_global_muted():\n        try:\n            self._log(\"SUCCESS\", False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            self._log(\"SUCCESS\", 20, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.warning","title":"<code>warning(message, *args, colored=False, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'WARNING'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def warning(\n    self, \n    message, \n    *args, \n    colored: Optional[bool] = False, \n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):  # noqa: N805\n    r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'WARNING'``.\"\"\"\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'WARNING',\n        extra = extra,\n    )\n\n    try:\n        self._log(\"WARNING\", False, self._get_opts(colored = colored), message, args, kwargs)\n    except TypeError:\n        # Compatibility with &lt; 0.6.0\n        self._log(\"WARNING\", 30, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.error","title":"<code>error(message, *args, prefix=None, max_length=None, colored=False, hook=None, exc_info=False, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'ERROR'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def error(\n    self,\n    message: Any,\n    *args,\n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    colored: Optional[bool] = False,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    exc_info: Optional[bool] = False,\n    **kwargs\n) -&gt; None:\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``'ERROR'``.\n    \"\"\"\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'ERROR',\n        extra = extra,\n    )\n    if exc_info: message += f\"\\n{traceback.format_exc()}\"\n\n    try:\n        self._log(\"ERROR\", False, self._get_opts(colored = colored), message, args, kwargs)\n    except TypeError:\n        self._log(\"ERROR\", 40, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.trace","title":"<code>trace(msg, error=None, level='ERROR', limit=None, chain=True, colored=False, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>This method logs the traceback of an exception.</p> <p>:param error: The exception to log.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def trace(\n    self, \n    msg: 'MsgItem',\n    error: Optional[Type[Exception]] = None, \n    level: str = \"ERROR\",\n    limit: Optional[int] = None,\n    chain: Optional[bool] = True,\n    colored: Optional[bool] = False,\n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    This method logs the traceback of an exception.\n\n    :param error: The exception to log.\n    \"\"\"\n    _depth = kwargs.pop('depth', None)\n    extra = kwargs.pop('extra', None)\n    if _depth is not None: limit = _depth\n    if isinstance(msg, str):\n        _msg = msg\n        if extra:\n            extras_rendered = format_item(extra, max_length = max_length, colored = colored, level = level)\n            extras_rendered = extras_rendered.lstrip('\\n')\n            if extras_rendered:\n                if _msg:\n                    _msg += f\"\\n{extras_rendered}\"\n                else:\n                    _msg = extras_rendered\n    else:\n        _msg = self._format_message(\n            msg,\n            colored = colored,\n            level = level,\n            prefix = prefix,\n            max_length = max_length,\n            extra = extra,\n        )\n    # pprint.pformat(msg)\n    _msg += f\"\\n{traceback.format_exc(chain = chain, limit = limit)}\"\n    if error: _msg += f\" - {error}\"\n\n    try:\n        self._log(level, False, self._get_opts(colored = colored), _msg, (), {})\n    except TypeError:\n        static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 40)\n        self._log(level, static_log_no, False, self._get_opts(colored = colored), _msg, (), {})\n    self.run_logging_hooks(_msg, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.exception","title":"<code>exception(message, *args, colored=False, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'ERROR'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def exception(\n    self,\n    message: 'MsgItem',\n    *args,\n    colored: Optional[bool] = False,\n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``'ERROR'``.\n    \"\"\"\n    extra = kwargs.get('extra')\n    message = self._format_message(\n        message,\n        *args,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'ERROR',\n        extra = extra,\n    )\n    super().exception(message, *args, **kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.base.Logger.change_logger_level","title":"<code>change_logger_level(level)</code>","text":"<p>Changes the logger level</p> <p>:TODO</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def change_logger_level(\n    self,\n    level: str,\n):\n    \"\"\"\n    Changes the logger level\n\n    :TODO\n    \"\"\"\n    return\n</code></pre>"},{"location":"api/lzl/logging/#formatters","title":"Formatters","text":""},{"location":"api/lzl/logging/#lzl.logging.formatters","title":"<code>lzl.logging.formatters</code>","text":""},{"location":"api/lzl/logging/#lzl.logging.formatters.LoggerFormatter","title":"<code>LoggerFormatter</code>","text":"Source code in <code>src/lzl/logging/formatters.py</code> <pre><code>class LoggerFormatter:\n\n    max_extra_lengths: Dict[str, int] = {}\n\n    @classmethod\n    def get_extra_length(cls, key: str, value: str) -&gt; int:\n        \"\"\"\n        Returns the max length of an extra key\n        \"\"\"\n        if key not in cls.max_extra_lengths:\n            cls.max_extra_lengths[key] = len(key)\n        if len(value) &gt; cls.max_extra_lengths[key]:\n            cls.max_extra_lengths[key] = len(value)\n        return cls.max_extra_lengths[key]\n\n    @classmethod\n    def queue_logger_formatter(cls, record: Dict[str, Union[Dict[str, Any], Any]]) -&gt; str:\n        \"\"\"\n        Formats the log message for the queue.\n        \"\"\"\n        _extra: Dict[str, Union[Dict[str, Any], Any]] = record.get('extra', {})\n        if not record['extra'].get('worker_name'):\n            record['extra']['worker_name'] = ''\n\n        status = _extra.get('status')\n        kind: str = _extra.get('kind')\n        if status and isinstance(status, Enum): status = status.name\n\n        kind_color = QUEUE_STATUS_COLORS.get(kind.lower(), FALLBACK_STATUS_COLOR)\n        if '&lt;' not in kind_color: kind_color = f'&lt;{kind_color}&gt;'\n        extra = kind_color + '{extra[kind]}&lt;/&gt;:'\n        if _extra.get('queue_name'):\n            queue_name_length = cls.get_extra_length('queue_name', _extra['queue_name'])\n            extra += '&lt;b&gt;&lt;fg #006d77&gt;{extra[queue_name]:&lt;' + str(queue_name_length) + '}&lt;/&gt;&lt;/&gt;:'\n        if _extra.get('worker_name'):\n            worker_name_length = cls.get_extra_length('worker_name', _extra['worker_name'])\n            extra += '&lt;fg #83c5be&gt;{extra[worker_name]:&lt;' + str(worker_name_length) + '}&lt;/&gt;:'\n        # extra += '&lt;fg #83c5be&gt;{extra[worker_name]}&lt;/&gt;:&lt;b&gt;&lt;fg #006d77&gt;{extra[queue_name]:&lt;18}&lt;/&gt;&lt;/&gt;:'\n        if _extra.get('job_id'):\n            extra += '&lt;fg #005f73&gt;{extra[job_id]}&lt;/&gt;'\n        if status:\n            status_color = QUEUE_STATUS_COLORS.get(status.lower(), FALLBACK_STATUS_COLOR)\n            if '&lt;' not in status_color: status_color = f'&lt;{status_color}&gt;'\n            extra += f':{status_color}' + '{extra[status]}&lt;/&gt;: '\n        # extra += RESET_COLOR\n        # print(extra)\n        return extra\n\n\n    @classmethod\n    def default_formatter(cls, record: Dict[str, Union[Dict[str, Any], Any]]) -&gt; str:\n        \"\"\"\n        To add a custom format for a module, add another `elif` clause with code to determine `extra` and `level`.\n\n        From that module and all submodules, call logger with `logger.bind(foo='bar').info(msg)`.\n        Then you can access it with `record['extra'].get('foo')`.\n        \"\"\"        \n        _extra = record.get('extra', {})\n        if _extra.get('module_name'):\n            extra = DEFAULT_CLASS_COLOR + '{extra[module_name]}&lt;/&gt;:' + DEFAULT_FUNCTION_COLOR + '{function}&lt;/&gt;: '\n        else:\n            extra = DEFAULT_CLASS_COLOR + '{name}&lt;/&gt;:' + DEFAULT_FUNCTION_COLOR + '{function}&lt;/&gt;: '\n        if _extra.get('worker_name') or _extra.get('queue_name'):\n            extra = cls.queue_logger_formatter(record)\n\n        if 'result=tensor([' not in str(record['message']):\n            return \"&lt;level&gt;{level: &lt;8}&lt;/&gt; &lt;green&gt;{time:YYYY-MM-DD HH:mm:ss.SSS}&lt;/&gt;: \" \\\n                       + extra + \"&lt;level&gt;{message}&lt;/level&gt;\" + RESET_COLOR + \"\\n\"\n\n        msg = str(record['message'])[:100].replace('{', '(').replace('}', ')')\n        return \"&lt;level&gt;{level: &lt;8}&lt;/&gt; &lt;green&gt;{time:YYYY-MM-DD HH:mm:ss.SSS}&lt;/&gt;: \"\\\n                   + extra + \"&lt;level&gt;\" + msg + f\"&lt;/level&gt;{RESET_COLOR}\\n\"\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.formatters.LoggerFormatter.get_extra_length","title":"<code>get_extra_length(key, value)</code>  <code>classmethod</code>","text":"<p>Returns the max length of an extra key</p> Source code in <code>src/lzl/logging/formatters.py</code> <pre><code>@classmethod\ndef get_extra_length(cls, key: str, value: str) -&gt; int:\n    \"\"\"\n    Returns the max length of an extra key\n    \"\"\"\n    if key not in cls.max_extra_lengths:\n        cls.max_extra_lengths[key] = len(key)\n    if len(value) &gt; cls.max_extra_lengths[key]:\n        cls.max_extra_lengths[key] = len(value)\n    return cls.max_extra_lengths[key]\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.formatters.LoggerFormatter.queue_logger_formatter","title":"<code>queue_logger_formatter(record)</code>  <code>classmethod</code>","text":"<p>Formats the log message for the queue.</p> Source code in <code>src/lzl/logging/formatters.py</code> <pre><code>@classmethod\ndef queue_logger_formatter(cls, record: Dict[str, Union[Dict[str, Any], Any]]) -&gt; str:\n    \"\"\"\n    Formats the log message for the queue.\n    \"\"\"\n    _extra: Dict[str, Union[Dict[str, Any], Any]] = record.get('extra', {})\n    if not record['extra'].get('worker_name'):\n        record['extra']['worker_name'] = ''\n\n    status = _extra.get('status')\n    kind: str = _extra.get('kind')\n    if status and isinstance(status, Enum): status = status.name\n\n    kind_color = QUEUE_STATUS_COLORS.get(kind.lower(), FALLBACK_STATUS_COLOR)\n    if '&lt;' not in kind_color: kind_color = f'&lt;{kind_color}&gt;'\n    extra = kind_color + '{extra[kind]}&lt;/&gt;:'\n    if _extra.get('queue_name'):\n        queue_name_length = cls.get_extra_length('queue_name', _extra['queue_name'])\n        extra += '&lt;b&gt;&lt;fg #006d77&gt;{extra[queue_name]:&lt;' + str(queue_name_length) + '}&lt;/&gt;&lt;/&gt;:'\n    if _extra.get('worker_name'):\n        worker_name_length = cls.get_extra_length('worker_name', _extra['worker_name'])\n        extra += '&lt;fg #83c5be&gt;{extra[worker_name]:&lt;' + str(worker_name_length) + '}&lt;/&gt;:'\n    # extra += '&lt;fg #83c5be&gt;{extra[worker_name]}&lt;/&gt;:&lt;b&gt;&lt;fg #006d77&gt;{extra[queue_name]:&lt;18}&lt;/&gt;&lt;/&gt;:'\n    if _extra.get('job_id'):\n        extra += '&lt;fg #005f73&gt;{extra[job_id]}&lt;/&gt;'\n    if status:\n        status_color = QUEUE_STATUS_COLORS.get(status.lower(), FALLBACK_STATUS_COLOR)\n        if '&lt;' not in status_color: status_color = f'&lt;{status_color}&gt;'\n        extra += f':{status_color}' + '{extra[status]}&lt;/&gt;: '\n    # extra += RESET_COLOR\n    # print(extra)\n    return extra\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.formatters.LoggerFormatter.default_formatter","title":"<code>default_formatter(record)</code>  <code>classmethod</code>","text":"<p>To add a custom format for a module, add another <code>elif</code> clause with code to determine <code>extra</code> and <code>level</code>.</p> <p>From that module and all submodules, call logger with <code>logger.bind(foo='bar').info(msg)</code>. Then you can access it with <code>record['extra'].get('foo')</code>.</p> Source code in <code>src/lzl/logging/formatters.py</code> <pre><code>@classmethod\ndef default_formatter(cls, record: Dict[str, Union[Dict[str, Any], Any]]) -&gt; str:\n    \"\"\"\n    To add a custom format for a module, add another `elif` clause with code to determine `extra` and `level`.\n\n    From that module and all submodules, call logger with `logger.bind(foo='bar').info(msg)`.\n    Then you can access it with `record['extra'].get('foo')`.\n    \"\"\"        \n    _extra = record.get('extra', {})\n    if _extra.get('module_name'):\n        extra = DEFAULT_CLASS_COLOR + '{extra[module_name]}&lt;/&gt;:' + DEFAULT_FUNCTION_COLOR + '{function}&lt;/&gt;: '\n    else:\n        extra = DEFAULT_CLASS_COLOR + '{name}&lt;/&gt;:' + DEFAULT_FUNCTION_COLOR + '{function}&lt;/&gt;: '\n    if _extra.get('worker_name') or _extra.get('queue_name'):\n        extra = cls.queue_logger_formatter(record)\n\n    if 'result=tensor([' not in str(record['message']):\n        return \"&lt;level&gt;{level: &lt;8}&lt;/&gt; &lt;green&gt;{time:YYYY-MM-DD HH:mm:ss.SSS}&lt;/&gt;: \" \\\n                   + extra + \"&lt;level&gt;{message}&lt;/level&gt;\" + RESET_COLOR + \"\\n\"\n\n    msg = str(record['message'])[:100].replace('{', '(').replace('}', ')')\n    return \"&lt;level&gt;{level: &lt;8}&lt;/&gt; &lt;green&gt;{time:YYYY-MM-DD HH:mm:ss.SSS}&lt;/&gt;: \"\\\n               + extra + \"&lt;level&gt;\" + msg + f\"&lt;/level&gt;{RESET_COLOR}\\n\"\n</code></pre>"},{"location":"api/lzl/logging/#usage","title":"Usage","text":"<pre><code>from lzl.logging import logger\n\n# Basic usage\nlogger.info(\"Application started\")\n\n# Structured context\nlogger.info(\"Processing request\", request_id=\"req-123\", user_id=456)\n\n# Exception handling\ntry:\n    1 / 0\nexcept Exception:\n    logger.exception(\"Something went wrong\")\n</code></pre>"},{"location":"api/lzl/pool/","title":"lzl.pool - Thread &amp; Async Utilities","text":"<p>The <code>lzl.pool</code> module provides a unified interface for concurrency, bridging the gap between synchronous threading and <code>asyncio</code> event loops.</p>"},{"location":"api/lzl/pool/#threadpool","title":"ThreadPool","text":"<p>A singleton-style proxy that manages a global <code>ThreadPoolExecutor</code> and <code>ProcessPoolExecutor</code>.</p>"},{"location":"api/lzl/pool/#lzl.pool.base","title":"<code>lzl.pool.base</code>","text":""},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool","title":"<code>ThreadPool</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Singleton-style proxy wrapping LazyOps thread/process pools.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>@proxied\nclass ThreadPool(abc.ABC):\n    \"\"\"Singleton-style proxy wrapping LazyOps thread/process pools.\"\"\"\n\n    allow_task_completion: Optional[bool] = True\n    register_exit: Optional[bool] = True\n\n    def __init__(\n        self,\n        max_workers: Optional[int] = None,\n        allow_task_completion: Optional[bool] = None,\n        register_exit: Optional[bool] = None,\n        **kwargs\n    ):\n        \"\"\"Initialise backing executors and configure automatic shutdown hooks.\"\"\"\n        if allow_task_completion is not None: self.allow_task_completion = allow_task_completion\n        if register_exit is not None: self.register_exit = register_exit\n        if max_workers is None:\n            max_workers = int(os.getenv(\"MAX_WORKERS\", os.cpu_count()))\n\n        self.max_workers = max_workers\n        self.tasks: Optional[Set[asyncio.Task]] = set()\n        self._pool: Optional[futures.ThreadPoolExecutor] = None\n        self._ppool: Optional[futures.ProcessPoolExecutor] = None\n\n        self._kwargs = kwargs\n        if self.register_exit:\n            import atexit\n            atexit.register(self.on_exit)\n\n    @staticmethod\n    def is_coro(obj: Any) -&gt; bool:\n        \"\"\"Return ``True`` when ``obj`` is a coroutine function or awaitable.\"\"\"\n        return is_coro_func(obj)\n\n    def ensure_coro(self, func: Callable[..., RT]) -&gt; Callable[..., Awaitable[RT]]:\n        \"\"\"Return an awaitable wrapper around ``func`` when it is sync.\"\"\"\n        if asyncio.iscoroutinefunction(func): return func\n        @functools.wraps(func)\n        async def inner(*args, **kwargs):\n            return await self.arun(func, *args, **kwargs)\n        return inner\n\n    def ensure_coro_function(self, func: Callable[..., RT]) -&gt; Callable[..., Awaitable[RT]]:\n        \"\"\"Return an awaitable wrapper preserving context variables.\"\"\"\n        if asyncio.iscoroutinefunction(func): return func\n        @functools.wraps(func)\n        async def inner(*args, **kwargs):\n            loop = asyncio.get_running_loop()\n            ctx = contextvars.copy_context()\n            return await loop.run_in_executor(\n                executor = self.pool, \n                func = lambda: ctx.run(func, *args, **kwargs)\n            )\n        return inner\n\n    @property\n    def pool(self) -&gt; futures.ThreadPoolExecutor:\n        \"\"\"Return (and lazily create) the shared thread pool executor.\"\"\"\n        if self._pool is None:\n            self._pool = futures.ThreadPoolExecutor(max_workers = self.max_workers)\n        return self._pool\n\n    @property\n    def ppool(self) -&gt; futures.ProcessPoolExecutor:\n        \"\"\"Return (and lazily create) the shared process pool executor.\"\"\"\n        if self._ppool is None:\n            self._ppool = futures.ProcessPoolExecutor(max_workers = self.max_workers)\n        return self._ppool\n\n    @property\n    def in_async_loop(self) -&gt; bool:\n        \"\"\"Return ``True`` when executed inside a running event loop.\"\"\"\n        try:\n            return asyncio.get_running_loop() is not None\n        except RuntimeError:\n            return False\n\n    def get_pool(\n        self, \n        num_workers: Optional[int] = None, \n        process_pool: bool = False\n    ) -&gt; futures.Executor:\n        \"\"\"Create a dedicated executor honouring ``num_workers`` preferences.\"\"\"\n        pool_cls = futures.ProcessPoolExecutor if process_pool else futures.ThreadPoolExecutor\n        if num_workers is None: num_workers = self.max_workers\n        return pool_cls(max_workers = num_workers)\n\n    def add_task(\n        self, \n        task: asyncio.Task, \n        callback: Optional[Callable] = None,\n        callback_args: Optional[Tuple] = None,\n        callback_kwargs: Optional[Dict] = None\n    ):\n        \"\"\"Track ``task`` and optionally invoke ``callback`` when it completes.\"\"\"\n        self.tasks.add(task)\n        if callback is not None:\n            if callback_args or callback_kwargs:\n                callback_args = callback_args or ()\n                callback_kwargs = callback_kwargs or {}\n                callback = functools.partial(callback, *callback_args, **callback_kwargs)\n            task.add_done_callback(callback)\n        task.add_done_callback(self.tasks.discard)\n\n\n    def on_exit(self):\n        \"\"\"Cancel tracked tasks and shut down executors at interpreter exit.\"\"\"\n        for task in self.tasks:\n            with contextlib.suppress(Exception):\n                task.cancel()\n        with contextlib.suppress(Exception):\n            if self._pool is not None: self._pool.shutdown(wait = self.allow_task_completion, cancel_futures = not self.allow_task_completion)\n        with contextlib.suppress(Exception):\n            if self._ppool is not None: self._ppool.shutdown(wait = self.allow_task_completion, cancel_futures = not self.allow_task_completion)\n\n    \"\"\"\n    Core\n    \"\"\"\n\n    def run(self, func: Coroutine[RT], *args, **kwargs) -&gt; RT:\n        \"\"\"Execute ``func`` synchronously, bridging any active AnyIO loop.\"\"\"\n        current_async_module = getattr(anyio._core._eventloop.threadlocals, \"current_async_module\", None)\n        partial_f = functools.partial(func, *args, **kwargs)\n        if current_async_module is None:\n            return anyio.run(partial_f)\n        return anyio.from_thread.run(partial_f)\n\n\n    async def arun(self, func: Callable[..., RT], *args, **kwargs) -&gt; RT:\n        \"\"\"Execute ``func`` in the shared thread pool and await the result.\"\"\"\n        blocking = functools.partial(func, *args, **kwargs)\n        loop = asyncio.get_running_loop()\n        return await loop.run_in_executor(self.pool, blocking)\n\n    async def asyncish(self, func: Callable[..., RT], *args, **kwargs) -&gt; RT:\n        \"\"\"Await ``func`` when async, otherwise delegate to :meth:`arun`.\"\"\"\n        if is_coro_func(func): return await func(*args, **kwargs)\n        return await self.arun(func, *args, **kwargs)\n\n    run_async = arun\n    run_sync = run\n\n    \"\"\"\n    Background Tasks\n    \"\"\"    \n\n    def threadpool_task(\n        self, \n        func: Callable, \n        *args, \n        task_callback: Optional[Callable[..., RT]] = None, \n        task_callback_args: Optional[Tuple] = None,\n        task_callback_kwargs: Optional[Dict] = None,\n        **kwargs\n    ) -&gt; futures.Future[RT]:\n        \"\"\"Submit ``func`` to the thread pool and return the future.\"\"\"\n        task = self.pool.submit(func, *args, **kwargs)\n        self.add_task(task, task_callback, callback_args=task_callback_args, callback_kwargs=task_callback_kwargs)\n        return task\n\n    def background_task(\n        self, \n        func: Callable[..., RT],\n        *args, \n        task_callback: Optional[Callable] = None, \n        task_callback_args: Optional[Tuple] = None,\n        task_callback_kwargs: Optional[Dict] = None,\n        **kwargs\n    ) -&gt; Awaitable[RT]:\n        \"\"\"Schedule ``func`` in the appropriate executor based on loop state.\"\"\"\n        if inspect.isawaitable(func): task = asyncio.create_task(func)\n        else: task = asyncio.create_task(self.asyncish(func, *args, **kwargs))\n        self.add_task(task, task_callback, callback_args = task_callback_args, callback_kwargs=task_callback_kwargs)\n        return task\n\n    def background(\n        self, \n        func: Callable[..., RT], \n        *args, \n        task_callback: Optional[Callable] = None, \n        task_callback_args: Optional[Tuple] = None,\n        task_callback_kwargs: Optional[Dict] = None,\n        **kwargs\n    ) -&gt; Awaitable[RT]:\n        \"\"\"\n        Runs a function in the background.\n        If the current thread is in an async loop, it runs the function as an async function.\n        Otherwise, it runs the function as a sync function in the threadpool.\n\n        Returns a `asyncio.Task` if the current thread is in an async loop.\n        Otherwise, it returns a `futures.Future`.\n        \"\"\"\n        method = self.background_task if self.in_async_loop else self.threadpool_task\n        return method(func, *args, task_callback = task_callback, task_callback_args = task_callback_args, task_callback_kwargs = task_callback_kwargs, **kwargs)\n\n    create_threadpool_task = threadpool_task\n    create_background_task = background_task\n    create_background = background\n\n    \"\"\"\n    Iterators\n    \"\"\"\n\n    def map(\n        self,\n        func: Callable[..., RT],\n        iterable: Iterable[Any],\n        *args,\n        return_ordered: Optional[bool] = True,\n        use_process_pool: Optional[bool] = False, \n        **kwargs\n    ) -&gt; List[RT]:  # sourcery skip: assign-if-exp\n        \"\"\"Return the results of applying ``func`` across ``iterable``.\"\"\"\n        num_workers = kwargs.pop('num_workers', None)\n        partial_func = functools.partial(func, *args, **kwargs)\n        with self.get_pool(num_workers = num_workers, process_pool = use_process_pool) as executor:\n            _futures = [\n                executor.submit(partial_func, item) for item in iterable\n            ]\n            if not return_ordered: return [f.result() for f in futures.as_completed(_futures)]\n            futures.wait(_futures)\n            return [f.result() for f in _futures]\n\n\n    def iterate(\n        self,\n        func: Callable[..., RT],\n        iterable: Iterable[Any],\n        *args,\n        use_process_pool: Optional[bool] = False, \n        return_ordered: Optional[bool] = True,\n        **kwargs\n    ) -&gt; Generator[RT, None, None]:  # sourcery skip: assign-if-exp\n        \"\"\"Yield items produced by applying ``func`` across ``iterable``.\"\"\"\n        num_workers = kwargs.pop('num_workers', None)\n        partial_func = functools.partial(func, *args, **kwargs)\n        with self.get_pool(num_workers = num_workers, process_pool = use_process_pool) as executor:\n            _futures = [\n                executor.submit(partial_func, item) for item in iterable\n            ]\n            if not return_ordered:\n                for f in futures.as_completed(_futures):\n                    yield f.result()\n            else:\n                futures.wait(_futures)\n                for f in _futures:\n                    yield f.result()\n\n    async def amap(\n        self,\n        func: Callable[..., Awaitable[RT]],\n        iterable: Iterable[Any], \n        *args,\n        return_ordered: Optional[bool] = True,\n        concurrency_limit: Optional[int] = None,\n        **kwargs,\n    ) -&gt; List[RT]:\n        \"\"\"Await results serially while respecting the concurrency limit.\"\"\"\n        return_when = kwargs.pop('return_when', 'ALL_COMPLETED' if return_ordered else 'FIRST_COMPLETED')\n        concurrency_limit = kwargs.pop('limit', concurrency_limit)\n        func = self.ensure_coro(func)\n        partial = functools.partial(func, *args, **kwargs)\n        try: mapped_iterable = map(partial, iterable)\n        except TypeError: mapped_iterable = (partial(x) async for x in iterable)\n        results = []\n        async for result in amap_iterable(\n            mapped_iterable, \n            return_when = return_when, \n            concurrency_limit = concurrency_limit\n        ):\n            results.append(await result)\n        return results\n\n    async def aiterate(\n        self,\n        func: Callable[..., Awaitable[RT]],\n        iterable: Iterable[Any], \n        *args,\n        return_ordered: Optional[bool] = True,\n        concurrency_limit: Optional[int] = None,\n        **kwargs,\n    ) -&gt; AsyncGenerator[RT, None]:\n        \"\"\"Async generator yielding results as soon as underlying tasks finish.\"\"\"\n        return_when = kwargs.pop('return_when', 'ALL_COMPLETED' if return_ordered else 'FIRST_COMPLETED')\n        concurrency_limit = kwargs.pop('limit', concurrency_limit)\n        func = self.ensure_coro(func)\n        partial = functools.partial(func, *args, **kwargs)\n        try: mapped_iterable = map(partial, iterable)\n        except TypeError: mapped_iterable = (partial(x) async for x in iterable)\n        async for result in amap_iterable(\n            mapped_iterable, \n            return_when = return_when, \n            concurrency_limit = concurrency_limit\n        ):\n            yield await result\n\n    sync_map = map\n    sync_iterate = iterate\n    async_map = amap\n    async_iterate = aiterate\n\n    \"\"\"\n    CMD\n    \"\"\"\n\n    @staticmethod\n    def cmd(\n        command: Union[List[str], str], \n        shell: bool = True, \n        raise_error: bool = True, \n        **kwargs\n    ):\n        if isinstance(command, list): command = \" \".join(command)\n        try:\n            out = subprocess.check_output(command, shell=shell, **kwargs)\n            if isinstance(out, bytes): out = out.decode('utf8')\n            return out.strip()\n        except Exception as e:\n            if not raise_error: return \"\"\n            raise e\n\n    @staticmethod\n    async def acmd(\n        command: Union[str, List[str]], \n        output_only: bool = True, \n        stdout = asyncio.subprocess.PIPE, \n        stderr = asyncio.subprocess.PIPE, \n        output_encoding: str = 'UTF-8', \n        output_errors: str = 'ignore', \n        *args,\n        **kwargs\n    ) -&gt; Union[str, asyncio.subprocess.Process]:\n        \"\"\"Execute a shell command asynchronously, optionally returning stdout.\"\"\"\n        if isinstance(command, list): command = ' '.join(command)\n        p = await asyncio.subprocess.create_subprocess_shell(command, *args, stdout = stdout, stderr = stderr, **kwargs)\n        if not output_only: return p\n        stdout, _ = await p.communicate()\n        return stdout.decode(encoding = output_encoding, errors = output_errors).strip()\n\n    run_command = cmd\n    async_run_command = acmd\n\n\n    @staticmethod\n    async def acmd_exec(\n        command: Union[str, List[str]], \n        output_only: bool = True, \n        stdout = asyncio.subprocess.PIPE, \n        stderr = asyncio.subprocess.PIPE, \n        output_encoding: str = 'UTF-8', \n        output_errors: str = 'ignore', \n        **kwargs\n    ) -&gt; Union[str, asyncio.subprocess.Process]:\n        \"\"\"Execute a command using ``create_subprocess_exec`` and return stdout when requested.\"\"\"\n        if isinstance(command, str): command = shlex.split(command)\n        p = await asyncio.subprocess.create_subprocess_exec(*command, stdout = stdout, stderr = stderr, **kwargs)\n        if not output_only: return p\n        stdout, _ = await p.communicate()\n        return stdout.decode(encoding = output_encoding, errors = output_errors).strip()\n\n    @staticmethod\n    async def acmd_stream(\n        command: Union[str, List[str]], \n        stdout_cb: t.Union[t.Callable, t.Awaitable], \n        stderr_cb: t.Optional[t.Union[t.Callable, t.Awaitable]] = None,\n        **kwargs \n    ) -&gt; asyncio.subprocess.Process:\n        \"\"\"Stream subprocess output into the supplied callbacks.\"\"\"\n        return await _stream_subprocess(command, stdout_cb, stderr_cb, **kwargs)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.pool","title":"<code>pool</code>  <code>property</code>","text":"<p>Return (and lazily create) the shared thread pool executor.</p>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.ppool","title":"<code>ppool</code>  <code>property</code>","text":"<p>Return (and lazily create) the shared process pool executor.</p>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.in_async_loop","title":"<code>in_async_loop</code>  <code>property</code>","text":"<p>Return <code>True</code> when executed inside a running event loop.</p>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.run_sync","title":"<code>run_sync = run</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Background Tasks</p>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.create_background","title":"<code>create_background = background</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Iterators</p>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.async_iterate","title":"<code>async_iterate = aiterate</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>CMD</p>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.is_coro","title":"<code>is_coro(obj)</code>  <code>staticmethod</code>","text":"<p>Return <code>True</code> when <code>obj</code> is a coroutine function or awaitable.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>@staticmethod\ndef is_coro(obj: Any) -&gt; bool:\n    \"\"\"Return ``True`` when ``obj`` is a coroutine function or awaitable.\"\"\"\n    return is_coro_func(obj)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.ensure_coro","title":"<code>ensure_coro(func)</code>","text":"<p>Return an awaitable wrapper around <code>func</code> when it is sync.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def ensure_coro(self, func: Callable[..., RT]) -&gt; Callable[..., Awaitable[RT]]:\n    \"\"\"Return an awaitable wrapper around ``func`` when it is sync.\"\"\"\n    if asyncio.iscoroutinefunction(func): return func\n    @functools.wraps(func)\n    async def inner(*args, **kwargs):\n        return await self.arun(func, *args, **kwargs)\n    return inner\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.ensure_coro_function","title":"<code>ensure_coro_function(func)</code>","text":"<p>Return an awaitable wrapper preserving context variables.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def ensure_coro_function(self, func: Callable[..., RT]) -&gt; Callable[..., Awaitable[RT]]:\n    \"\"\"Return an awaitable wrapper preserving context variables.\"\"\"\n    if asyncio.iscoroutinefunction(func): return func\n    @functools.wraps(func)\n    async def inner(*args, **kwargs):\n        loop = asyncio.get_running_loop()\n        ctx = contextvars.copy_context()\n        return await loop.run_in_executor(\n            executor = self.pool, \n            func = lambda: ctx.run(func, *args, **kwargs)\n        )\n    return inner\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.get_pool","title":"<code>get_pool(num_workers=None, process_pool=False)</code>","text":"<p>Create a dedicated executor honouring <code>num_workers</code> preferences.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def get_pool(\n    self, \n    num_workers: Optional[int] = None, \n    process_pool: bool = False\n) -&gt; futures.Executor:\n    \"\"\"Create a dedicated executor honouring ``num_workers`` preferences.\"\"\"\n    pool_cls = futures.ProcessPoolExecutor if process_pool else futures.ThreadPoolExecutor\n    if num_workers is None: num_workers = self.max_workers\n    return pool_cls(max_workers = num_workers)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.add_task","title":"<code>add_task(task, callback=None, callback_args=None, callback_kwargs=None)</code>","text":"<p>Track <code>task</code> and optionally invoke <code>callback</code> when it completes.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def add_task(\n    self, \n    task: asyncio.Task, \n    callback: Optional[Callable] = None,\n    callback_args: Optional[Tuple] = None,\n    callback_kwargs: Optional[Dict] = None\n):\n    \"\"\"Track ``task`` and optionally invoke ``callback`` when it completes.\"\"\"\n    self.tasks.add(task)\n    if callback is not None:\n        if callback_args or callback_kwargs:\n            callback_args = callback_args or ()\n            callback_kwargs = callback_kwargs or {}\n            callback = functools.partial(callback, *callback_args, **callback_kwargs)\n        task.add_done_callback(callback)\n    task.add_done_callback(self.tasks.discard)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.on_exit","title":"<code>on_exit()</code>","text":"<p>Cancel tracked tasks and shut down executors at interpreter exit.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def on_exit(self):\n    \"\"\"Cancel tracked tasks and shut down executors at interpreter exit.\"\"\"\n    for task in self.tasks:\n        with contextlib.suppress(Exception):\n            task.cancel()\n    with contextlib.suppress(Exception):\n        if self._pool is not None: self._pool.shutdown(wait = self.allow_task_completion, cancel_futures = not self.allow_task_completion)\n    with contextlib.suppress(Exception):\n        if self._ppool is not None: self._ppool.shutdown(wait = self.allow_task_completion, cancel_futures = not self.allow_task_completion)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.run","title":"<code>run(func, *args, **kwargs)</code>","text":"<p>Execute <code>func</code> synchronously, bridging any active AnyIO loop.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def run(self, func: Coroutine[RT], *args, **kwargs) -&gt; RT:\n    \"\"\"Execute ``func`` synchronously, bridging any active AnyIO loop.\"\"\"\n    current_async_module = getattr(anyio._core._eventloop.threadlocals, \"current_async_module\", None)\n    partial_f = functools.partial(func, *args, **kwargs)\n    if current_async_module is None:\n        return anyio.run(partial_f)\n    return anyio.from_thread.run(partial_f)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.arun","title":"<code>arun(func, *args, **kwargs)</code>  <code>async</code>","text":"<p>Execute <code>func</code> in the shared thread pool and await the result.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>async def arun(self, func: Callable[..., RT], *args, **kwargs) -&gt; RT:\n    \"\"\"Execute ``func`` in the shared thread pool and await the result.\"\"\"\n    blocking = functools.partial(func, *args, **kwargs)\n    loop = asyncio.get_running_loop()\n    return await loop.run_in_executor(self.pool, blocking)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.asyncish","title":"<code>asyncish(func, *args, **kwargs)</code>  <code>async</code>","text":"<p>Await <code>func</code> when async, otherwise delegate to :meth:<code>arun</code>.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>async def asyncish(self, func: Callable[..., RT], *args, **kwargs) -&gt; RT:\n    \"\"\"Await ``func`` when async, otherwise delegate to :meth:`arun`.\"\"\"\n    if is_coro_func(func): return await func(*args, **kwargs)\n    return await self.arun(func, *args, **kwargs)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.threadpool_task","title":"<code>threadpool_task(func, *args, task_callback=None, task_callback_args=None, task_callback_kwargs=None, **kwargs)</code>","text":"<p>Submit <code>func</code> to the thread pool and return the future.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def threadpool_task(\n    self, \n    func: Callable, \n    *args, \n    task_callback: Optional[Callable[..., RT]] = None, \n    task_callback_args: Optional[Tuple] = None,\n    task_callback_kwargs: Optional[Dict] = None,\n    **kwargs\n) -&gt; futures.Future[RT]:\n    \"\"\"Submit ``func`` to the thread pool and return the future.\"\"\"\n    task = self.pool.submit(func, *args, **kwargs)\n    self.add_task(task, task_callback, callback_args=task_callback_args, callback_kwargs=task_callback_kwargs)\n    return task\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.background_task","title":"<code>background_task(func, *args, task_callback=None, task_callback_args=None, task_callback_kwargs=None, **kwargs)</code>","text":"<p>Schedule <code>func</code> in the appropriate executor based on loop state.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def background_task(\n    self, \n    func: Callable[..., RT],\n    *args, \n    task_callback: Optional[Callable] = None, \n    task_callback_args: Optional[Tuple] = None,\n    task_callback_kwargs: Optional[Dict] = None,\n    **kwargs\n) -&gt; Awaitable[RT]:\n    \"\"\"Schedule ``func`` in the appropriate executor based on loop state.\"\"\"\n    if inspect.isawaitable(func): task = asyncio.create_task(func)\n    else: task = asyncio.create_task(self.asyncish(func, *args, **kwargs))\n    self.add_task(task, task_callback, callback_args = task_callback_args, callback_kwargs=task_callback_kwargs)\n    return task\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.background","title":"<code>background(func, *args, task_callback=None, task_callback_args=None, task_callback_kwargs=None, **kwargs)</code>","text":"<p>Runs a function in the background. If the current thread is in an async loop, it runs the function as an async function. Otherwise, it runs the function as a sync function in the threadpool.</p> <p>Returns a <code>asyncio.Task</code> if the current thread is in an async loop. Otherwise, it returns a <code>futures.Future</code>.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def background(\n    self, \n    func: Callable[..., RT], \n    *args, \n    task_callback: Optional[Callable] = None, \n    task_callback_args: Optional[Tuple] = None,\n    task_callback_kwargs: Optional[Dict] = None,\n    **kwargs\n) -&gt; Awaitable[RT]:\n    \"\"\"\n    Runs a function in the background.\n    If the current thread is in an async loop, it runs the function as an async function.\n    Otherwise, it runs the function as a sync function in the threadpool.\n\n    Returns a `asyncio.Task` if the current thread is in an async loop.\n    Otherwise, it returns a `futures.Future`.\n    \"\"\"\n    method = self.background_task if self.in_async_loop else self.threadpool_task\n    return method(func, *args, task_callback = task_callback, task_callback_args = task_callback_args, task_callback_kwargs = task_callback_kwargs, **kwargs)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.map","title":"<code>map(func, iterable, *args, return_ordered=True, use_process_pool=False, **kwargs)</code>","text":"<p>Return the results of applying <code>func</code> across <code>iterable</code>.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def map(\n    self,\n    func: Callable[..., RT],\n    iterable: Iterable[Any],\n    *args,\n    return_ordered: Optional[bool] = True,\n    use_process_pool: Optional[bool] = False, \n    **kwargs\n) -&gt; List[RT]:  # sourcery skip: assign-if-exp\n    \"\"\"Return the results of applying ``func`` across ``iterable``.\"\"\"\n    num_workers = kwargs.pop('num_workers', None)\n    partial_func = functools.partial(func, *args, **kwargs)\n    with self.get_pool(num_workers = num_workers, process_pool = use_process_pool) as executor:\n        _futures = [\n            executor.submit(partial_func, item) for item in iterable\n        ]\n        if not return_ordered: return [f.result() for f in futures.as_completed(_futures)]\n        futures.wait(_futures)\n        return [f.result() for f in _futures]\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.iterate","title":"<code>iterate(func, iterable, *args, use_process_pool=False, return_ordered=True, **kwargs)</code>","text":"<p>Yield items produced by applying <code>func</code> across <code>iterable</code>.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def iterate(\n    self,\n    func: Callable[..., RT],\n    iterable: Iterable[Any],\n    *args,\n    use_process_pool: Optional[bool] = False, \n    return_ordered: Optional[bool] = True,\n    **kwargs\n) -&gt; Generator[RT, None, None]:  # sourcery skip: assign-if-exp\n    \"\"\"Yield items produced by applying ``func`` across ``iterable``.\"\"\"\n    num_workers = kwargs.pop('num_workers', None)\n    partial_func = functools.partial(func, *args, **kwargs)\n    with self.get_pool(num_workers = num_workers, process_pool = use_process_pool) as executor:\n        _futures = [\n            executor.submit(partial_func, item) for item in iterable\n        ]\n        if not return_ordered:\n            for f in futures.as_completed(_futures):\n                yield f.result()\n        else:\n            futures.wait(_futures)\n            for f in _futures:\n                yield f.result()\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.amap","title":"<code>amap(func, iterable, *args, return_ordered=True, concurrency_limit=None, **kwargs)</code>  <code>async</code>","text":"<p>Await results serially while respecting the concurrency limit.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>async def amap(\n    self,\n    func: Callable[..., Awaitable[RT]],\n    iterable: Iterable[Any], \n    *args,\n    return_ordered: Optional[bool] = True,\n    concurrency_limit: Optional[int] = None,\n    **kwargs,\n) -&gt; List[RT]:\n    \"\"\"Await results serially while respecting the concurrency limit.\"\"\"\n    return_when = kwargs.pop('return_when', 'ALL_COMPLETED' if return_ordered else 'FIRST_COMPLETED')\n    concurrency_limit = kwargs.pop('limit', concurrency_limit)\n    func = self.ensure_coro(func)\n    partial = functools.partial(func, *args, **kwargs)\n    try: mapped_iterable = map(partial, iterable)\n    except TypeError: mapped_iterable = (partial(x) async for x in iterable)\n    results = []\n    async for result in amap_iterable(\n        mapped_iterable, \n        return_when = return_when, \n        concurrency_limit = concurrency_limit\n    ):\n        results.append(await result)\n    return results\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.aiterate","title":"<code>aiterate(func, iterable, *args, return_ordered=True, concurrency_limit=None, **kwargs)</code>  <code>async</code>","text":"<p>Async generator yielding results as soon as underlying tasks finish.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>async def aiterate(\n    self,\n    func: Callable[..., Awaitable[RT]],\n    iterable: Iterable[Any], \n    *args,\n    return_ordered: Optional[bool] = True,\n    concurrency_limit: Optional[int] = None,\n    **kwargs,\n) -&gt; AsyncGenerator[RT, None]:\n    \"\"\"Async generator yielding results as soon as underlying tasks finish.\"\"\"\n    return_when = kwargs.pop('return_when', 'ALL_COMPLETED' if return_ordered else 'FIRST_COMPLETED')\n    concurrency_limit = kwargs.pop('limit', concurrency_limit)\n    func = self.ensure_coro(func)\n    partial = functools.partial(func, *args, **kwargs)\n    try: mapped_iterable = map(partial, iterable)\n    except TypeError: mapped_iterable = (partial(x) async for x in iterable)\n    async for result in amap_iterable(\n        mapped_iterable, \n        return_when = return_when, \n        concurrency_limit = concurrency_limit\n    ):\n        yield await result\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.acmd","title":"<code>acmd(command, output_only=True, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE, output_encoding='UTF-8', output_errors='ignore', *args, **kwargs)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>Execute a shell command asynchronously, optionally returning stdout.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>@staticmethod\nasync def acmd(\n    command: Union[str, List[str]], \n    output_only: bool = True, \n    stdout = asyncio.subprocess.PIPE, \n    stderr = asyncio.subprocess.PIPE, \n    output_encoding: str = 'UTF-8', \n    output_errors: str = 'ignore', \n    *args,\n    **kwargs\n) -&gt; Union[str, asyncio.subprocess.Process]:\n    \"\"\"Execute a shell command asynchronously, optionally returning stdout.\"\"\"\n    if isinstance(command, list): command = ' '.join(command)\n    p = await asyncio.subprocess.create_subprocess_shell(command, *args, stdout = stdout, stderr = stderr, **kwargs)\n    if not output_only: return p\n    stdout, _ = await p.communicate()\n    return stdout.decode(encoding = output_encoding, errors = output_errors).strip()\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.acmd_exec","title":"<code>acmd_exec(command, output_only=True, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE, output_encoding='UTF-8', output_errors='ignore', **kwargs)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>Execute a command using <code>create_subprocess_exec</code> and return stdout when requested.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>@staticmethod\nasync def acmd_exec(\n    command: Union[str, List[str]], \n    output_only: bool = True, \n    stdout = asyncio.subprocess.PIPE, \n    stderr = asyncio.subprocess.PIPE, \n    output_encoding: str = 'UTF-8', \n    output_errors: str = 'ignore', \n    **kwargs\n) -&gt; Union[str, asyncio.subprocess.Process]:\n    \"\"\"Execute a command using ``create_subprocess_exec`` and return stdout when requested.\"\"\"\n    if isinstance(command, str): command = shlex.split(command)\n    p = await asyncio.subprocess.create_subprocess_exec(*command, stdout = stdout, stderr = stderr, **kwargs)\n    if not output_only: return p\n    stdout, _ = await p.communicate()\n    return stdout.decode(encoding = output_encoding, errors = output_errors).strip()\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ThreadPool.acmd_stream","title":"<code>acmd_stream(command, stdout_cb, stderr_cb=None, **kwargs)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>Stream subprocess output into the supplied callbacks.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>@staticmethod\nasync def acmd_stream(\n    command: Union[str, List[str]], \n    stdout_cb: t.Union[t.Callable, t.Awaitable], \n    stderr_cb: t.Optional[t.Union[t.Callable, t.Awaitable]] = None,\n    **kwargs \n) -&gt; asyncio.subprocess.Process:\n    \"\"\"Stream subprocess output into the supplied callbacks.\"\"\"\n    return await _stream_subprocess(command, stdout_cb, stderr_cb, **kwargs)\n</code></pre>"},{"location":"api/lzl/pool/#concurrency-helpers","title":"Concurrency Helpers","text":"<p>Utilities for running functions in the background, mapping iterables concurrently, and more.</p>"},{"location":"api/lzl/pool/#lzl.pool.base","title":"<code>lzl.pool.base</code>","text":""},{"location":"api/lzl/pool/#lzl.pool.base.amap_iterable","title":"<code>amap_iterable(mapped_iterable, concurrency_limit=None, return_when='FIRST_COMPLETED')</code>  <code>async</code>","text":"<p>Yield tasks from <code>mapped_iterable</code> while respecting <code>concurrency_limit</code>.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>async def amap_iterable(\n    mapped_iterable: Union[Callable[[], Awaitable[Any]], Awaitable[Any], Coroutine[Any, Any, Any], Callable[[], Any]],\n    concurrency_limit: Optional[int] = None,\n    return_when: Optional[str] = 'FIRST_COMPLETED',\n):\n    \"\"\"Yield tasks from ``mapped_iterable`` while respecting ``concurrency_limit``.\"\"\"\n    try:\n        iterable = aiter(mapped_iterable)\n        is_async = True\n    except (TypeError, AttributeError):\n        iterable = iter(mapped_iterable)\n        is_async = False\n\n    iterable_ended: bool = False\n    pending = set()\n    concurrency_limit = get_concurrency_limit() if concurrency_limit is None else concurrency_limit\n    return_when = getattr(asyncio, return_when) if isinstance(return_when, str) else return_when\n\n    while pending or not iterable_ended:\n        while len(pending) &lt; concurrency_limit and not iterable_ended:\n            try: iter_item = await anext(iterable) if is_async else next(iterable)\n            except StopAsyncIteration if is_async else StopIteration:\n                iterable_ended = True\n            else: pending.add(asyncio.ensure_future(iter_item))\n\n        if not pending: return\n        done, pending = await asyncio.wait(pending,  return_when = return_when)\n        while done: yield done.pop()\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.async_map","title":"<code>async_map(func, iterable, *args, limit=None, return_when='FIRST_COMPLETED', **kwargs)</code>  <code>async</code>","text":"<p>Yield results from applying <code>func</code> to <code>iterable</code> as tasks complete.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>async def async_map(\n    func: Callable[..., Awaitable[Any]],\n    iterable: Iterable[Any], \n    *args,\n    limit: Optional[int] = None,\n    return_when: Optional[str] = 'FIRST_COMPLETED',\n    **kwargs,\n) -&gt; AsyncGenerator[RT, None]:\n    \"\"\"Yield results from applying ``func`` to ``iterable`` as tasks complete.\"\"\"\n    func = ensure_coro(func)\n    partial = functools.partial(func, *args, **kwargs)\n    try:\n        mapped_iterable = map(partial, iterable)\n    except TypeError:\n        mapped_iterable = (partial(x) async for x in iterable)\n    async for task in amap_iterable(mapped_iterable, limit = limit, return_when = return_when):\n        yield await task\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.ensure_coro","title":"<code>ensure_coro(func)</code>","text":"<p>Return an awaitable wrapper around <code>func</code> using :class:<code>ThreadPool</code>.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def ensure_coro(\n    func: Callable[..., Any]\n) -&gt; Callable[..., Awaitable[Any]]:\n    \"\"\"Return an awaitable wrapper around ``func`` using :class:`ThreadPool`.\"\"\"\n    if asyncio.iscoroutinefunction(func): return func\n    @functools.wraps(func)\n    async def inner(*args, **kwargs):\n        return await ThreadPool.arun(func, *args, **kwargs)\n    return inner\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.base.is_coro_func","title":"<code>is_coro_func(obj, func_name=None)</code>","text":"<p>Return <code>True</code> when <code>obj</code> (or <code>obj.func_name</code>) is awaitable.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def is_coro_func(obj, func_name: str = None) -&gt; bool:\n    \"\"\"Return ``True`` when ``obj`` (or ``obj.func_name``) is awaitable.\"\"\"\n    try:\n        if inspect.iscoroutinefunction(obj): return True\n        if inspect.isawaitable(obj): return True\n        if func_name and hasattr(obj, func_name) and inspect.iscoroutinefunction(getattr(obj, func_name)):\n            return True\n        return bool(hasattr(obj, '__call__') and inspect.iscoroutinefunction(obj.__call__))\n\n    except Exception:\n        return False\n</code></pre>"},{"location":"api/lzl/pool/#usage-guide","title":"Usage Guide","text":""},{"location":"api/lzl/pool/#running-sync-code-asynchronously","title":"Running Sync Code Asynchronously","text":"<p>Use <code>ThreadPool</code> to offload blocking operations to a worker thread while awaiting them in an async function.</p> <pre><code>from lzl.pool import ThreadPool\n\ndef blocking_io():\n    # Simulate heavy work\n    import time\n    time.sleep(1)\n    return \"done\"\n\nasync def main():\n    # Runs in a thread, non-blocking for the event loop\n    result = await ThreadPool.arun(blocking_io)\n    print(result)\n</code></pre>"},{"location":"api/lzl/pool/#background-tasks","title":"Background Tasks","text":"<p>Fire-and-forget background tasks that work regardless of whether you are in a sync or async context.</p> <pre><code>from lzl.pool import ThreadPool\n\ndef background_job(user_id):\n    print(f\"Processing {user_id}...\")\n\n# Works from async functions\nawait ThreadPool.background(background_job, 123)\n\n# Works from sync functions too\nThreadPool.background(background_job, 456)\n</code></pre>"},{"location":"api/lzl/pool/#parallel-execution","title":"Parallel Execution","text":"<p>Concurrent mapping over iterables.</p> <pre><code>from lzl.pool import ThreadPool\n\nitems = [1, 2, 3, 4, 5]\n\ndef process(x):\n    return x * x\n\n# Parallel execution using threads\nresults = ThreadPool.map(process, items, num_workers=4)\n</code></pre>"},{"location":"api/lzl/proxied/","title":"lzl.proxied - Proxy Objects","text":"<p>The <code>lzl.proxied</code> module provides the <code>ProxyObject</code> pattern, allowing for objects that are lazily initialized, thread-safe, and transparently proxied.</p>"},{"location":"api/lzl/proxied/#proxyobject","title":"ProxyObject","text":"<p>The generic proxy wrapper.</p>"},{"location":"api/lzl/proxied/#lzl.proxied.base","title":"<code>lzl.proxied.base</code>","text":"<p>Lightweight proxy object that defers object creation until first use.</p>"},{"location":"api/lzl/proxied/#lzl.proxied.base.ProxyObject","title":"<code>ProxyObject</code>","text":"<p>               Bases: <code>Generic[ProxyObjT]</code></p> Source code in <code>src/lzl/proxied/base.py</code> <pre><code>class ProxyObject(t.Generic[ProxyObjT]):\n\n    _wrapped = None\n\n    if t.TYPE_CHECKING:\n        def __new__(cls: t.Type[ProxyObjT], *args, **kwargs) -&gt; ProxyObjT:\n            ...\n\n    def __init__(\n        self,\n        obj_cls: t.Optional[t.Union[t.Type[ProxyObjT], str]] = None,\n        obj_getter: t.Optional[t.Union[t.Callable[..., ProxyObjT], str]] = None,\n        obj_args: t.Optional[t.Union[str, t.Callable[..., t.Iterable[t.Any]], t.Iterable[t.Any]]] = None,\n        obj_kwargs: t.Optional[t.Union[str, t.Callable[..., t.Dict[str, t.Any]], t.Dict[str, t.Any]]] = None,\n        obj_initialize: t.Optional[bool] = True,\n        threadsafe: t.Optional[bool] = True,\n    ) -&gt; ProxyObjT:\n        \"\"\"Create a lazily-evaluated proxy.\n\n        Args:\n            obj_cls: Class or import string for the wrapped object.  Used when\n                no ``obj_getter`` is provided.\n            obj_getter: Callable or import string that constructs the wrapped\n                object on demand.\n            obj_args: Positional arguments (or callable returning positional\n                arguments) forwarded to the constructor.\n            obj_kwargs: Keyword arguments (or callable returning keyword\n                arguments) forwarded to the constructor.\n            obj_initialize: When ``True`` the proxy will immediately instantiate\n                ``obj_cls`` on first access; otherwise the class itself is\n                returned.\n            threadsafe: When ``True`` access to the underlying object is\n                protected by a re-entrant lock.\n        \"\"\"\n\n        assert obj_cls or obj_getter, \"Either `obj_cls` or `obj_getter` must be provided\"\n        self._wrapped = empty\n        self.__dict__['__obj_cls_'] = obj_cls\n        # Defer until called.\n        self.__dict__['__obj_getter_'] = obj_getter\n        self.__dict__['__threadlock_'] = None if threadsafe else threading.Lock()\n        self.__dict__['__obj_args_'] = obj_args or []\n        self.__dict__['__obj_kwargs_'] = obj_kwargs or {}\n        self.__dict__['__obj_initialize_'] = obj_initialize\n        # self.__dict__['__debug_enabled_'] = debug_enabled\n        self.__dict__['__last_attrs_'] = {}\n\n\n    @contextlib.contextmanager\n    def _objlock_(self):\n        \"\"\"Context manager guarding the underlying object lock.\"\"\"\n        if self.__dict__['__threadlock_'] is not None:\n            try:\n                with self.__dict__['__threadlock_']:\n                    yield\n            except Exception as e:\n                raise e\n        else:\n            yield\n\n    __getattr__ = new_method_proxy(getattr)\n\n    def __setattr__(self, name, value):\n        if name == \"_wrapped\":\n            # Assign to __dict__ to avoid infinite __setattr__ loops.\n            self.__dict__[\"_wrapped\"] = value\n        else:\n            if self._wrapped is empty:\n                self._setup()\n            setattr(self._wrapped, name, value)\n\n    def __delattr__(self, name):\n        if name == \"_wrapped\":\n            raise TypeError(\"can't delete _wrapped.\")\n        if self._wrapped is empty:\n            self._setup()\n        delattr(self._wrapped, name)\n\n    def __call__(self, *args: t.Any, **kwargs: t.Any) -&gt; t.Any:\n        \"\"\"Proxy call invocations to the wrapped object.\"\"\"\n        if self._wrapped is empty:\n            self._setup()\n        return self._wrapped(*args, **kwargs)\n\n    def _setup_init(self) -&gt; None:\n        \"\"\"Load callables/import strings used to build the underlying object.\"\"\"\n        from lzl.load import lazy_import\n        # from lazyops.utils.helpers import lazy_import\n        if self.__dict__['__obj_args_'] is not None and not isinstance(self.__dict__['__obj_args_'], (list, tuple)):\n            if isinstance(self.__dict__['__obj_args_'], str):\n                self.__dict__['__obj_args_'] = lazy_import(self.__dict__['__obj_args_'])\n            if callable(self.__dict__['__obj_args_']):\n                self.__dict__['__obj_args_'] = self.__dict__['__obj_args_']()\n\n        if self.__dict__['__obj_kwargs_'] is not None and not isinstance(self.__dict__['__obj_kwargs_'], dict):\n            if isinstance(self.__dict__['__obj_kwargs_'], str):\n                self.__dict__['__obj_kwargs_'] = lazy_import(self.__dict__['__obj_kwargs_'])\n            if callable(self.__dict__['__obj_kwargs_']):\n                self.__dict__['__obj_kwargs_'] = self.__dict__['__obj_kwargs_']()\n\n        if self.__dict__['__obj_getter_'] is not None and isinstance(self.__dict__['__obj_getter_'], str):\n            self.__dict__['__obj_getter_'] = lazy_import(self.__dict__['__obj_getter_'])\n\n        elif self.__dict__['__obj_cls_'] is not None and isinstance(self.__dict__['__obj_cls_'], str):\n            self.__dict__['__obj_cls_'] = lazy_import(self.__dict__['__obj_cls_'])\n\n\n    def _setup(self) -&gt; None:\n        \"\"\"Instantiate (or fetch) the wrapped object if it isn't available.\"\"\"\n        # if self.__dict__['__obj_'] is not None: return\n\n        with self._objlock_():\n            self._setup_init()    \n            if self.__dict__['__obj_getter_'] is not None:\n                self.__dict__['_wrapped'] = self.__dict__['__obj_getter_'](*self.__dict__['__obj_args_'], **self.__dict__['__obj_kwargs_'])\n\n            elif self.__dict__['__obj_cls_']:\n                if self.__dict__['__obj_initialize_']:\n                    self.__dict__['_wrapped'] = self.__dict__['__obj_cls_'](*self.__dict__['__obj_args_'], **self.__dict__['__obj_kwargs_'])\n                else:\n                    self.__dict__['_wrapped'] = self.__dict__['__obj_cls_']\n\n\n    # Because we have messed with __class__ below, we confuse pickle as to what\n    # class we are pickling. It also appears to stop __reduce__ from being\n    # called. So, we define __getstate__ in a way that cooperates with the way\n    # that pickle interprets this class.  This fails when the wrapped class is\n    # a builtin, but it is better than nothing.\n    def __getstate__(self):\n        if self._wrapped is empty:\n            self._setup()\n        return self._wrapped.__dict__\n\n    # Python 3.3 will call __reduce__ when pickling; this method is needed\n    # to serialize and deserialize correctly.\n    @classmethod\n    def __newobj__(cls, *args):\n        return cls.__new__(cls, *args)\n\n    def __reduce_ex__(self, proto):\n        return (self.__newobj__, (self.__class__,), self.__getstate__())\n\n\n    def __deepcopy__(self, memo):\n        if self._wrapped is empty:\n            # We have to use type(self), not self.__class__, because the\n            # latter is proxied.\n            result = type(self)()\n            memo[id(self)] = result # type: ignore\n            return result\n        return copy.deepcopy(self._wrapped, memo)\n\n    __bytes__ = new_method_proxy(bytes)\n    __str__ = new_method_proxy(str)\n    __bool__ = new_method_proxy(bool)\n    # Introspection support\n    __dir__ = new_method_proxy(dir)\n\n    # Need to pretend to be the wrapped class, for the sake of objects that\n    # care about this (especially in equality tests)\n    __class__ = property(new_method_proxy(operator.attrgetter(\"__class__\")))\n    __eq__ = new_method_proxy(operator.eq)\n    __ne__ = new_method_proxy(operator.ne)\n    __hash__ = new_method_proxy(hash)\n\n    # Dictionary methods support\n    __getitem__ = new_method_proxy(operator.getitem)\n    __setitem__ = new_method_proxy(operator.setitem)\n    __delitem__ = new_method_proxy(operator.delitem)\n\n    __len__ = new_method_proxy(len)\n    __contains__ = new_method_proxy(operator.contains)\n\n    # Additions for DotObject\n    __gt__ = new_method_proxy(operator.gt)\n    __lt__ = new_method_proxy(operator.lt)\n    __ge__ = new_method_proxy(operator.ge)\n    __le__ = new_method_proxy(operator.le)\n    __add__ = new_method_proxy(operator.add)\n    __radd__ = new_method_proxy(operator.add)\n    __sub__ = new_method_proxy(operator.sub)\n    __rsub__ = new_method_proxy(operator.sub)\n    __mul__ = new_method_proxy(operator.mul)\n    __rmul__ = new_method_proxy(operator.mul)\n    __floordiv__ = new_method_proxy(operator.floordiv)\n    __div__ = new_method_proxy(operator.truediv)\n    __rdiv__ = new_method_proxy(operator.truediv)\n    __truediv__ = new_method_proxy(operator.truediv)\n    __rtruediv__ = new_method_proxy(operator.truediv)\n    __mod__ = new_method_proxy(operator.mod)\n    __rmod__ = new_method_proxy(operator.mod)\n    __pow__ = new_method_proxy(operator.pow)\n    __rpow__ = new_method_proxy(operator.pow)\n    __lshift__ = new_method_proxy(operator.lshift)\n    __rshift__ = new_method_proxy(operator.rshift)\n    __and__ = new_method_proxy(operator.and_)\n    __or__ = new_method_proxy(operator.or_)\n    __xor__ = new_method_proxy(operator.xor)\n</code></pre>"},{"location":"api/lzl/proxied/#lzl.proxied.base.new_method_proxy","title":"<code>new_method_proxy(func)</code>","text":"<p>Return a wrapper that forwards calls to the proxied object.</p> Source code in <code>src/lzl/proxied/base.py</code> <pre><code>def new_method_proxy(func: t.Callable[..., t.Any]) -&gt; t.Callable[..., t.Any]:\n    \"\"\"Return a wrapper that forwards calls to the proxied object.\"\"\"\n\n    def inner(self: 'ProxyObject', *args: t.Any):\n        if self._wrapped is empty:\n            self._setup()\n        return func(self._wrapped, *args)\n    return inner\n</code></pre>"},{"location":"api/lzl/proxied/#usage-guide","title":"Usage Guide","text":""},{"location":"api/lzl/proxied/#deferred-initialization","title":"Deferred Initialization","text":"<p>Create an object that isn't instantiated until you access one of its attributes.</p> <pre><code>from lzl.proxied import ProxyObject\n\ndef connect_db():\n    print(\"Connecting to DB...\")\n    return DatabaseConnection()\n\n# Connection is NOT established here\ndb = ProxyObject(obj_getter=connect_db)\n\ndef query():\n    # Connection happens here, on first access\n    return db.execute(\"SELECT * FROM users\")\n</code></pre>"},{"location":"api/lzl/proxied/#thread-safety","title":"Thread Safety","text":"<p>By default, <code>ProxyObject</code> includes a lock to ensure that initialization is thread-safe.</p> <pre><code># Safe to share across threads\nglobal_resource = ProxyObject(\n    obj_cls=\"my_lib.HeavyResource\",\n    threadsafe=True\n)\n</code></pre>"},{"location":"api/lzl/require/","title":"lzl.require - Dependency Management","text":"<p>The <code>lzl.require</code> module provides dependency resolution and requirement management utilities.</p>"},{"location":"api/lzl/require/#module-reference","title":"Module Reference","text":""},{"location":"api/lzl/require/#lzl.require","title":"<code>lzl.require</code>","text":""},{"location":"api/lzl/require/#lzl.require.LazyLib","title":"<code>LazyLib</code>","text":"<p>Concrete helper exposing <code>LazyLibType</code> utilities via attribute access.</p> Source code in <code>src/lzl/require/base.py</code> <pre><code>class LazyLib(metaclass=LazyLibType):\n    \"\"\"Concrete helper exposing ``LazyLibType`` utilities via attribute access.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/lzl/require/#lzl.require.LazyLibType","title":"<code>LazyLibType</code>","text":"<p>               Bases: <code>type</code></p> <p>Metaclass providing lazy import/install helpers.</p> Source code in <code>src/lzl/require/base.py</code> <pre><code>class LazyLibType(type):\n    \"\"\"Metaclass providing lazy import/install helpers.\"\"\"\n\n    @classmethod\n    def install_binary(cls, binary: str, flags: list[str] | None = None) -&gt; None:\n        if cls.get_binary_path(binary):\n            return\n        args = PkgInstall.get_args(binary, flags)\n        subprocess.check_call(args, stdout=subprocess.DEVNULL)\n\n    @classmethod\n    def get_requirement(cls, name: str, clean: bool = True) -&gt; str:\n        name = name.replace(\"-\", \"_\")\n        return name.split(\"=\")[0].replace(\"&gt;\", \"\").replace(\"&lt;\", \"\").strip() if clean else name.strip()\n\n    @classmethod\n    def install_library(cls, library: str, upgrade: bool = True) -&gt; None:\n        if _has_uv():\n            try:\n                pip_exec = [\"uv\", \"pip\", \"install\"]\n                if \"=\" not in library or upgrade:\n                    pip_exec.append(\"--upgrade\")\n                pip_exec.append(library)\n                subprocess.check_call(pip_exec, stdout=subprocess.DEVNULL)\n                return\n            except Exception as exc:  # pragma: no cover - fallback path\n                logger.warning(\"Failed to install %s using uv: %s. Falling back to pip.\", library, exc)\n\n        pip_exec = [sys.executable, \"-m\", \"pip\", \"install\"]\n        if \"=\" not in library or upgrade:\n            pip_exec.append(\"--upgrade\")\n        pip_exec.append(library)\n        subprocess.check_call(pip_exec, stdout=subprocess.DEVNULL)\n\n    @classmethod\n    def install_pip_package(\n        cls,\n        package: str,\n        version: str | None = None,\n        **options: t.Any,\n    ) -&gt; None:\n        if _has_uv():\n            try:\n                if version:\n                    if \"=\" not in version:\n                        version = f\"=={version}\"\n                    package = f\"{package}{version}\"\n                pip_exec = [\"uv\", \"pip\", \"install\", package]\n                for key, value in options.items():\n                    opt = key if key.startswith(\"--\") else f\"--{key}\"\n                    if value and not isinstance(value, bool):\n                        pip_exec.append(f\"{opt}={value}\")\n                    else:\n                        pip_exec.append(opt)\n                subprocess.check_call(pip_exec, stdout=subprocess.DEVNULL)\n                return\n            except Exception as exc:  # pragma: no cover - fallback path\n                logger.warning(\"Failed to install %s using uv: %s. Falling back to pip.\", package, exc)\n\n        pip_exec = [sys.executable, \"-m\", \"pip\", \"install\"]\n        for key, value in options.items():\n            opt = key if key.startswith(\"--\") else f\"--{key}\"\n            if value and not isinstance(value, bool):\n                pip_exec.append(f\"{opt}={value}\")\n            else:\n                pip_exec.append(opt)\n        if version:\n            if \"=\" not in version:\n                version = f\"=={version}\"\n            package = f\"{package}{version}\"\n        pip_exec.append(package)\n        subprocess.check_call(pip_exec, stdout=subprocess.DEVNULL)\n\n    @classmethod\n    def is_available(cls, library: str) -&gt; bool:\n        try:\n            importlib.metadata.version(library)\n            return True\n        except importlib.metadata.PackageNotFoundError:\n            return False\n\n    @classmethod\n    def __is_available(cls, library: str) -&gt; bool:\n        try:\n            import pkg_resources\n        except ImportError:\n            cls.install_pip_package(\"setuptools\")\n            import pkg_resources\n        try:\n            pkg_resources.get_distribution(library)\n            return True\n        except pkg_resources.DistributionNotFound:  # pragma: no cover - legacy path\n            return False\n\n    @classmethod\n    def is_imported(cls, library: str) -&gt; bool:\n        return library in sys.modules\n\n    @classmethod\n    def _ensure_lib_imported(cls, library: str) -&gt; ModuleType:\n        clean_lib = cls.get_requirement(library, True)\n        if not cls.is_imported(clean_lib):\n            sys.modules[clean_lib] = importlib.import_module(clean_lib)\n        return sys.modules[clean_lib]\n\n    @classmethod\n    def _ensure_lib_installed(cls, library: str, pip_name: str | None = None, upgrade: bool = False) -&gt; None:\n        clean_lib = cls.get_requirement(library, True)\n        if not cls.is_available(clean_lib):\n            cls.install_library(pip_name or library, upgrade=upgrade)\n\n    @classmethod\n    def _ensure_binary_installed(cls, binary: str, flags: list[str] | None = None) -&gt; None:\n        cls.install_binary(binary, flags)\n\n    @classmethod\n    def import_lib(\n        cls,\n        library: str,\n        pip_name: str | None = None,\n        resolve_missing: bool = True,\n        require: bool = False,\n        upgrade: bool = False,\n    ) -&gt; ModuleType:\n        clean_lib = cls.get_requirement(library, True)\n        if not cls.is_available(clean_lib):\n            if require and not resolve_missing:\n                raise ImportError(f\"Required Lib {library} is not available.\")\n            if not resolve_missing:\n                return None  # type: ignore[return-value]\n            cls.install_library(pip_name or library, upgrade=upgrade)\n        return cls._ensure_lib_imported(library)\n\n    @classmethod\n    def import_module(\n        cls,\n        name: str,\n        library: str | None = None,\n        pip_name: str | None = None,\n        resolve_missing: bool = True,\n        require: bool = False,\n        upgrade: bool = False,\n    ) -&gt; ModuleType:\n        if library:\n            cls.import_lib(library, pip_name, resolve_missing, require, upgrade)\n            return importlib.import_module(name, package=library)\n        return importlib.import_module(name)\n\n    @classmethod\n    def import_module_attr(\n        cls,\n        name: str,\n        module_name: str,\n        library: str | None = None,\n        pip_name: str | None = None,\n        resolve_missing: bool = True,\n        require: bool = False,\n        upgrade: bool = False,\n    ) -&gt; t.Any:\n        module = cls.import_module(\n            name=module_name,\n            library=library,\n            pip_name=pip_name,\n            resolve_missing=resolve_missing,\n            require=require,\n            upgrade=upgrade,\n        )\n        return getattr(module, name)\n\n    @classmethod\n    def import_cmd(\n        cls,\n        binary: str,\n        resolve_missing: bool = True,\n        require: bool = False,\n        flags: list[str] | None = None,\n    ) -&gt; t.Any:\n        if not cls.is_exec_available(binary):\n            if require and not resolve_missing:\n                raise ImportError(f\"Required Executable {binary} is not available.\")\n            if not resolve_missing:\n                return None\n            cls.install_binary(binary, flags=flags)\n        from lazy.cmd import Cmd  # type: ignore\n\n        return Cmd(binary=binary)\n\n    @classmethod\n    def get_binary_path(cls, executable: str) -&gt; str | None:\n        if \"PATH\" not in os.environ:\n            return None\n        for directory in os.environ[\"PATH\"].split(get_variable_separator()):\n            binary = os.path.abspath(os.path.join(directory, executable))\n            if os.path.isfile(binary) and os.access(binary, os.X_OK):\n                return binary\n        return None\n\n    @classmethod\n    def is_exec_available(cls, executable: str) -&gt; bool:\n        return cls.get_binary_path(executable) is not None\n\n    @staticmethod\n    def reload_module(module: ModuleType) -&gt; ModuleType:\n        return importlib.reload(module)\n\n    @staticmethod\n    def get_cwd(*paths: t.Any, string: bool = True) -&gt; str | pathlib.Path:\n        if not paths:\n            return pathlib.Path.cwd().as_posix() if string else pathlib.Path.cwd()\n        resolved = pathlib.Path.cwd().joinpath(*paths)\n        return resolved.as_posix() if string else resolved\n\n    @staticmethod\n    def run_cmd(cmd: str, raise_error: bool = True) -&gt; str:\n        try:\n            out = subprocess.check_output(cmd, shell=True)\n            return out.decode(\"utf8\") if isinstance(out, bytes) else out.strip()\n        except Exception as exc:\n            if not raise_error:\n                return \"\"\n            raise exc\n\n    def __getattr__(cls, key: str) -&gt; t.Any:\n        if key.startswith(\"is_avail_bin_\") or key.startswith(\"is_avail_exec_\"):\n            exec_name = key.split(\"_\", 3)[-1].strip()\n            return cls.is_exec_available(exec_name)\n        if key.startswith(\"is_avail_lib_\") or key.startswith(\"is_avail_\"):\n            lib_name = key.split(\"is_avail_\")[-1].strip()\n            return cls.is_available(lib_name)\n        if key.startswith(\"is_imported_\"):\n            lib_name = key.split(\"is_imported_\")[-1].strip()\n            return cls.is_imported(lib_name)\n        if key.startswith(\"cmd_\"):\n            binary_name = key.split(\"cmd_\")[-1].strip()\n            return cls.import_cmd(binary=binary_name)\n        return cls.import_lib(key, resolve_missing=False, require=False)\n\n    @classmethod\n    def get(\n        cls,\n        name: str,\n        attr_name: str | None = None,\n        pip_name: str | None = None,\n        resolve_missing: bool = True,\n    ) -&gt; ModuleType | t.Any:\n        parsed = cls._parse_name(name)\n        if attr_name is not None:\n            parsed[\"attr_name\"] = attr_name\n        if pip_name is not None:\n            parsed[\"pip_name\"] = pip_name\n\n        library = t.cast(str, parsed[\"library\"])\n        module_name = parsed[\"module_name\"] or library\n\n        if parsed.get(\"attr_name\"):\n            return cls.import_module_attr(\n                parsed[\"attr_name\"],\n                module_name=module_name,\n                library=library,\n                pip_name=parsed[\"pip_name\"],\n                resolve_missing=resolve_missing,\n            )\n        if parsed.get(\"module_name\"):\n            return cls.import_module(\n                module_name,\n                library=library,\n                pip_name=parsed[\"pip_name\"],\n                resolve_missing=resolve_missing,\n            )\n        return cls.import_lib(library, pip_name=parsed[\"pip_name\"], resolve_missing=resolve_missing)\n\n    @classmethod\n    def _parse_name(cls, name: str) -&gt; dict[str, str | None]:\n        result: dict[str, str | None] = {\n            \"library\": \"\",\n            \"pip_name\": None,\n            \"module_name\": None,\n            \"attr_name\": None,\n        }\n        current = name.strip()\n        if \":\" in current:\n            current, attr = current.split(\":\", 1)\n            result[\"attr_name\"] = attr\n        if \"|\" in current:\n            pip, current = current.split(\"|\", 1)\n            result[\"pip_name\"] = pip\n        if \".\" in current:\n            result[\"module_name\"] = current\n            result[\"library\"] = current.split(\".\", 1)[0]\n        else:\n            result[\"library\"] = current\n        return result\n\n    @classmethod\n    def __getitem__(cls, name: str) -&gt; ModuleType:\n        parsed = cls._parse_name(name)\n        library = t.cast(str, parsed[\"library\"])\n        module_name = parsed[\"module_name\"] or library\n        if parsed.get(\"attr_name\"):\n            return cls.import_module_attr(\n                parsed[\"attr_name\"],\n                module_name=module_name,\n                library=library,\n                pip_name=parsed[\"pip_name\"],\n                resolve_missing=True,\n                require=True,\n            )\n        if parsed.get(\"module_name\"):\n            return cls.import_module(\n                name=parsed[\"module_name\"],\n                library=library,\n                pip_name=parsed[\"pip_name\"],\n                resolve_missing=True,\n                require=True,\n            )\n        return cls.import_lib(\n            library,\n            pip_name=parsed[\"pip_name\"],\n            resolve_missing=True,\n            require=True,\n        )\n</code></pre>"},{"location":"api/lzl/require/#lzl.require.PkgInstall","title":"<code>PkgInstall</code>","text":"<p>Platform-specific installer command templates.</p> Source code in <code>src/lzl/require/base.py</code> <pre><code>class PkgInstall:\n    \"\"\"Platform-specific installer command templates.\"\"\"\n\n    win: str = \"choco install [flags]\"\n    mac: str = \"brew [flags] install\"\n    linux: str = \"apt-get -y [flags] install\"\n\n    @classmethod\n    def get_args(cls, binary: str, flags: list[str] | None = None) -&gt; list[str]:\n        \"\"\"Return a shell-escaped argument list for installing ``binary``.\"\"\"\n\n        flag_str = \" \".join(flags) if flags else \"\"\n        if sys.platform.startswith(\"win\"):\n            command = f\"{cls.win} {binary}\".replace(\"[flags]\", flag_str)\n        elif sys.platform.startswith(\"linux\"):\n            command = f\"{cls.linux} {binary}\".replace(\"[flags]\", flag_str)\n        else:\n            command = f\"{cls.mac} {binary}\".replace(\"[flags]\", flag_str)\n        return shlex.split(command)\n</code></pre>"},{"location":"api/lzl/require/#lzl.require.PkgInstall.get_args","title":"<code>get_args(binary, flags=None)</code>  <code>classmethod</code>","text":"<p>Return a shell-escaped argument list for installing <code>binary</code>.</p> Source code in <code>src/lzl/require/base.py</code> <pre><code>@classmethod\ndef get_args(cls, binary: str, flags: list[str] | None = None) -&gt; list[str]:\n    \"\"\"Return a shell-escaped argument list for installing ``binary``.\"\"\"\n\n    flag_str = \" \".join(flags) if flags else \"\"\n    if sys.platform.startswith(\"win\"):\n        command = f\"{cls.win} {binary}\".replace(\"[flags]\", flag_str)\n    elif sys.platform.startswith(\"linux\"):\n        command = f\"{cls.linux} {binary}\".replace(\"[flags]\", flag_str)\n    else:\n        command = f\"{cls.mac} {binary}\".replace(\"[flags]\", flag_str)\n    return shlex.split(command)\n</code></pre>"},{"location":"api/lzl/require/#overview","title":"Overview","text":"<p>The require module helps manage optional dependencies and ensures that required packages are available before use.</p>"},{"location":"api/lzl/require/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzl/require/#basic-requirement-checking","title":"Basic Requirement Checking","text":"<pre><code>from lzl.require import require\n\n# Ensure a package is available\nrequire('numpy')\nimport numpy as np\n\n# Multiple packages\nrequire(['pandas', 'matplotlib'])\n</code></pre>"},{"location":"api/lzl/require/#optional-dependencies","title":"Optional Dependencies","text":"<pre><code>from lzl.require import optional_require\n\n# Try to import, return None if not available\nnumpy = optional_require('numpy')\n\nif numpy is not None:\n    array = numpy.array([1, 2, 3])\nelse:\n    print(\"NumPy not available, using fallback\")\n</code></pre>"},{"location":"api/lzl/require/#version-checking","title":"Version Checking","text":"<pre><code>from lzl.require import require_version\n\n# Ensure minimum version\nrequire_version('requests', '2.28.0')\n</code></pre>"},{"location":"api/lzl/require/#installation-hints","title":"Installation Hints","text":"<pre><code>from lzl.require import require_with_hint\n\n# Provide installation instructions\nrequire_with_hint(\n    'torch',\n    install_hint=\"Install with: pip install torch\"\n)\n</code></pre>"},{"location":"api/lzl/require/#dependency-groups","title":"Dependency Groups","text":"<pre><code>from lzl.require import require_group\n\n# Check for a group of related dependencies\nrequire_group('ml', [\n    'numpy',\n    'pandas',\n    'scikit-learn',\n])\n</code></pre>"},{"location":"api/lzl/require/#features","title":"Features","text":"<ul> <li>Automatic Checking: Verify dependencies at import time</li> <li>Clear Error Messages: Helpful installation instructions</li> <li>Version Validation: Ensure compatible versions are installed</li> <li>Optional Dependencies: Graceful degradation when optional packages are missing</li> <li>Group Management: Manage related dependencies together</li> </ul>"},{"location":"api/lzl/require/#use-cases","title":"Use Cases","text":"<ul> <li>Optional Features: Features that require additional packages</li> <li>Plugin Systems: Validate plugin dependencies</li> <li>Environment Validation: Ensure development environment is properly configured</li> <li>Documentation: Make dependencies explicit in code</li> </ul>"},{"location":"api/lzl/require/#best-practices","title":"Best Practices","text":"<ol> <li>Check requirements early in your module's initialization</li> <li>Provide clear installation instructions in error messages</li> <li>Use optional requirements for non-critical features</li> <li>Group related dependencies for easier management</li> </ol>"},{"location":"api/lzl/sysmon/","title":"lzl.sysmon - System Monitoring","text":"<p>The <code>lzl.sysmon</code> module provides system monitoring and resource tracking capabilities.</p>"},{"location":"api/lzl/sysmon/#module-reference","title":"Module Reference","text":""},{"location":"api/lzl/sysmon/#lzl.sysmon","title":"<code>lzl.sysmon</code>","text":""},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext","title":"<code>WorkerContext</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Capture CPU/GPU statistics around long-running worker operations.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>class WorkerContext(abc.ABC):\n    \"\"\"Capture CPU/GPU statistics around long-running worker operations.\"\"\"\n\n    def __init__(self, **kwargs: t.Any) -&gt; None:\n        \"\"\"Initialise timer/logging helpers used during metric collection.\"\"\"\n\n        from lzl.logging import logger\n        from lzo.utils import Timer\n        from lzo.utils.system import aget_gpu_data, get_gpu_data, get_resource_data\n        from pydantic.types import ByteSize\n\n        self._extra: dict[str, t.Any] = {}\n        self._kwargs = kwargs\n\n        self.timer = Timer\n        self.logger = logger\n        self._bs = ByteSize\n\n        self.get_gpu_data = get_gpu_data\n        self.aget_gpu_data = aget_gpu_data\n        self.get_resource_data = get_resource_data\n\n        self.t = self.timer()\n        self.idx: int = 0\n        self.num_batches: int = 0\n        self.last_batch_size: int = 0\n        self.total_duration: float = 0.0\n        self.last_duration: float = 0.0\n\n        self.last_resource_data: t.Optional[\"ResourceData\"] = None\n        self.last_gpu_data: t.Optional[\"GPUData\"] = None\n\n    # ------------------------------------------------------------------\n    # Properties\n    # ------------------------------------------------------------------\n\n    @eproperty\n    def torch_device_name(self) -&gt; str:\n        \"\"\"Return the active PyTorch device name.\"\"\"\n\n        from lzo.utils.system import get_torch_device_name\n\n        return get_torch_device_name()\n\n    @eproperty\n    def torch_device(self):\n        \"\"\"Return the active PyTorch device instance.\"\"\"\n\n        from lzo.utils.system import get_torch_device\n\n        return get_torch_device()\n\n    @eproperty\n    def has_gpu(self) -&gt; bool:\n        \"\"\"Return ``True`` when the runtime is backed by CUDA.\"\"\"\n\n        return self.torch_device_name.startswith(\"cuda\")\n\n    @eproperty\n    def model_name(self) -&gt; t.Optional[str]:\n        \"\"\"Optional model identifier surfaced in log prefixes.\"\"\"\n\n        return self._extra.get(\"model_name\")\n\n    @eproperty\n    def worker_name(self) -&gt; t.Optional[str]:\n        \"\"\"Optional worker identifier used in log prefixes.\"\"\"\n\n        return self._extra.get(\"worker_name\")\n\n    # ------------------------------------------------------------------\n    # GPU helpers\n    # ------------------------------------------------------------------\n\n    def build_gpu_data_string(\n        self,\n        current_usage: \"GPUData\",\n        compare: bool | None = None,\n        previous_usage: \"GPUData\" | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        \"\"\"Format GPU usage statistics with optional comparison.\"\"\"\n\n        curr_mem_used = current_usage[\"memory_used\"]\n        curr_mem_percent = current_usage[\"utilization_memory\"]\n        curr_mem_total = current_usage[\"memory_total\"]\n        gpu_name = current_usage[\"name\"]\n\n        previous_usage = previous_usage or self.last_gpu_data\n        self.last_gpu_data = current_usage\n\n        if compare and previous_usage:\n            comparison = {\n                \"memory_used\": self._bs(curr_mem_used - previous_usage[\"memory_used\"]),\n                \"utilization_memory\": curr_mem_percent - previous_usage[\"utilization_memory\"],\n            }\n            if not colored:\n                return (\n                    f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; \"\n                    f\"{curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} + \"\n                    f\"{comparison['memory_used'].human_readable()} \"\n                    f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n                )\n            return (\n                f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; |y|{curr_mem_used.human_readable()}|e| / \"\n                f\"|g|{curr_mem_total.human_readable()}|e| + |r|{comparison['memory_used'].human_readable()}|e| \"\n                f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n            )\n\n        if not colored:\n            return (\n                f\"{gpu_name}: {curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} \"\n                f\"({curr_mem_percent}%)\"\n            )\n        return (\n            f\"{gpu_name}: |y|{curr_mem_used.human_readable()}|e| / |g|{curr_mem_total.human_readable()}|e| \"\n            f\"({curr_mem_percent}%)\"\n        )\n\n    def get_gpu_memory(\n        self,\n        compare: bool | None = None,\n        previous_usage: \"GPUData\" | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        \"\"\"Return formatted GPU usage, optionally comparing against a prior sample.\"\"\"\n\n        current_usage = self.get_gpu_data()\n        if not current_usage:\n            return None\n        return self.build_gpu_data_string(\n            current_usage,\n            compare=compare,\n            previous_usage=previous_usage,\n            colored=colored,\n        )\n\n    async def aget_gpu_memory(\n        self,\n        compare: bool | None = None,\n        previous_usage: \"GPUData\" | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        \"\"\"Asynchronous variant of :meth:`get_gpu_memory`.\"\"\"\n\n        current_usage = await self.aget_gpu_data()\n        if not current_usage:\n            return None\n        return self.build_gpu_data_string(\n            current_usage,\n            compare=compare,\n            previous_usage=previous_usage,\n            colored=colored,\n        )\n\n    # ------------------------------------------------------------------\n    # Resource helpers\n    # ------------------------------------------------------------------\n\n    def build_resource_data_string(\n        self,\n        current_usage: \"ResourceData\",\n        compare: bool | None = None,\n        previous_usage: \"ResourceData\" | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        \"\"\"Format CPU/RAM usage into a human-readable string.\"\"\"\n\n        curr_mem_used = current_usage[\"memory_used\"]\n        curr_mem_percent = current_usage[\"utilization_memory\"]\n        curr_mem_total = current_usage[\"memory_total\"]\n        curr_cpu_percent = current_usage[\"utilization_cpu\"]\n        num_cpu = current_usage[\"cpu_count\"]\n\n        previous_usage = previous_usage or self.last_resource_data\n        self.last_resource_data = current_usage\n\n        if compare and previous_usage:\n            comparison = {\n                \"memory_used\": self._bs(curr_mem_used - previous_usage[\"memory_used\"]),\n            }\n            base = (\n                f\"{num_cpu} vCPU: {curr_cpu_percent}% | RAM: {previous_usage['memory_used'].human_readable()} -&gt; \"\n                f\"{curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} + \"\n                f\"{comparison['memory_used'].human_readable()} ({curr_mem_percent}%)\"\n            )\n            if not colored:\n                return base\n            return (\n                f\"{num_cpu} vCPU: |g|{curr_cpu_percent}%|e| | RAM: {previous_usage['memory_used'].human_readable()} -&gt; \"\n                f\"|y|{curr_mem_used.human_readable()}|e| / |g|{curr_mem_total.human_readable()}|e| + \"\n                f\"|r|{comparison['memory_used'].human_readable()}|e| ({curr_mem_percent}%)\"\n            )\n\n        if not colored:\n            return (\n                f\"{num_cpu} vCPU: {curr_cpu_percent}% | RAM: {curr_mem_used.human_readable()} / \"\n                f\"{curr_mem_total.human_readable()} ({curr_mem_percent}%)\"\n            )\n        return (\n            f\"{num_cpu} vCPU: |g|{curr_cpu_percent}%|e| RAM: |y|{curr_mem_used.human_readable()}|e| / \"\n            f\"|g|{curr_mem_total.human_readable()}|e| ({curr_mem_percent}%)\"\n        )\n\n    def get_resource_info(\n        self,\n        compare: bool | None = None,\n        previous_usage: \"ResourceData\" | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        \"\"\"Return formatted CPU/memory usage snapshot.\"\"\"\n\n        current_usage = self.get_resource_data()\n        if not current_usage:\n            return None\n        return self.build_resource_data_string(\n            current_usage,\n            compare=compare,\n            previous_usage=previous_usage,\n            colored=colored,\n        )\n    # ------------------------------------------------------------------\n    # Context managers\n    # ------------------------------------------------------------------\n\n    @contextlib.contextmanager\n    def inference_mode(\n        self,\n        batch_size: int | None = 1,\n        obj_name: str | None = None,\n        enable_gc: bool | None = None,\n        enable_summary: bool | None = None,\n        hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n        **kwargs: t.Any,\n    ):\n        \"\"\"Wrap a block of inference work with resource logging.\"\"\"\n\n        ts = self.timer(format_ms=True, format_short=1)\n        start_text = \"Starting Inference\"\n        if obj_name:\n            start_text += f\" for |g|{obj_name}|e|\"\n        start_text += f\" ({batch_size})\"\n        self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n        start_resource_data = self.get_resource_data()\n        start_gpu_data = self.get_gpu_data() if self.has_gpu else None\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - logging path\n            self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n            raise\n        finally:\n            total_s = ts.total\n            self.total_duration += total_s\n            self.last_duration = total_s\n            self.num_batches += batch_size or 0\n            self.idx += 1\n\n            end_text = \"Inference Completed\"\n            if obj_name:\n                end_text += f\" for |g|{obj_name}|e|\"\n            end_text += f\" ({batch_size}) in {ts.total_s}\"\n            if enable_gc:\n                gc.collect()\n\n            self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n            if enable_summary:\n                self.logger.info(\n                    f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                    f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n                self.logger.info(\n                    f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                    f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n            self.logger.info(\n                self.get_resource_info(compare=True, previous_usage=start_resource_data, colored=True),\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n            if self.has_gpu and start_gpu_data is not None:\n                self.logger.info(\n                    self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n\n    @contextlib.asynccontextmanager\n    async def ainference_mode(\n        self,\n        batch_size: int | None = 1,\n        obj_name: str | None = None,\n        enable_gc: bool | None = None,\n        enable_summary: bool | None = None,\n        hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n        **kwargs: t.Any,\n    ):\n        \"\"\"Async variant of :meth:`inference_mode`.\"\"\"\n\n        ts = self.timer(format_ms=True, format_short=1)\n        start_text = \"Starting Inference\"\n        if obj_name:\n            start_text += f\" for |g|{obj_name}|e|\"\n        start_text += f\" ({batch_size})\"\n        self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n        start_resource_data = self.get_resource_data()\n        start_gpu_data = await self.aget_gpu_data() if self.has_gpu else None\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - logging path\n            self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n            raise\n        finally:\n            total_s = ts.total\n            self.total_duration += total_s\n            self.last_duration = total_s\n            self.num_batches += batch_size or 0\n            self.idx += 1\n\n            end_text = \"Inference Completed\"\n            if obj_name:\n                end_text += f\" for |g|{obj_name}|e|\"\n            end_text += f\" ({batch_size}) in {ts.total_s}\"\n            if enable_gc:\n                gc.collect()\n\n            self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n            if enable_summary:\n                self.logger.info(\n                    f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                    f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n                self.logger.info(\n                    f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                    f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n            self.logger.info(\n                self.get_resource_info(compare=True, previous_usage=start_resource_data, colored=True),\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n            if self.has_gpu and start_gpu_data is not None:\n                self.logger.info(\n                    await self.aget_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n\n    @contextlib.contextmanager\n    def capture(\n        self,\n        message: str | None = None,\n        prefix: str | None = None,\n        hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n        **kwargs: t.Any,\n    ):\n        \"\"\"Capture resources across an arbitrary block of work.\"\"\"\n\n        ts = self.timer(format_ms=True, format_short=1)\n        base_name = self.model_name or self.worker_name\n        prefix = f\"{prefix} {base_name}\" if prefix else base_name\n        start_resource_data = self.get_resource_data()\n        start_gpu_data = self.get_gpu_data() if self.has_gpu else None\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - logging path\n            self.logger.trace(f\"[{prefix}] Error in Capture: \", exc, hook=hook)\n            raise\n        finally:\n            message = (message or \"Capture Complete\") + f\" in {ts.total_s}\"\n            self.logger.info(message, colored=True, prefix=prefix, hook=hook)\n            self.logger.info(\n                self.get_resource_info(compare=True, previous_usage=start_resource_data, colored=True),\n                colored=True,\n                prefix=prefix,\n                hook=hook,\n            )\n            if self.has_gpu and start_gpu_data is not None:\n                self.logger.info(\n                    self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                    colored=True,\n                    prefix=prefix,\n                    hook=hook,\n                )\n\n    @contextlib.contextmanager\n    def start_task(\n        self,\n        batch_size: int | None = 1,\n        obj_name: str | None = None,\n        task_name: str | None = None,\n        enable_gc: bool | None = None,\n        enable_summary: bool | None = None,\n        hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n        **kwargs: t.Any,\n    ):\n        \"\"\"Track a generic worker task, logging CPU/GPU usage.\"\"\"\n\n        ts = self.timer(format_ms=True, format_short=1)\n        base_name = self.model_name or self.worker_name\n        start_text = \"Starting Task\"\n        if task_name:\n            start_text += f\": |g|{task_name}|e|\"\n        if obj_name:\n            start_text += f\" for |g|{obj_name}|e|\"\n        start_text += f\" ({batch_size})\"\n        self.logger.info(start_text, prefix=base_name, colored=True, hook=hook)\n        start_gpu_data = self.get_gpu_data() if self.has_gpu else None\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - logging path\n            self.logger.trace(f\"[{base_name}] Error in Task: \", exc, hook=hook)\n            raise\n        finally:\n            total_s = ts.total\n            self.total_duration += total_s\n            self.last_duration = total_s\n            self.num_batches += batch_size or 0\n            self.idx += 1\n\n            end_text = \"Task Completed\"\n            if task_name:\n                end_text += f\": |g|{task_name}|e|\"\n            if obj_name:\n                end_text += f\" for |g|{obj_name}|e|\"\n            end_text += f\" ({batch_size}) in {ts.total_s}\"\n            if enable_gc:\n                gc.collect()\n\n            self.logger.info(end_text, colored=True, prefix=base_name, hook=hook)\n            if enable_summary:\n                self.logger.info(\n                    f\"Total Tasks: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                    f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                    colored=True,\n                    prefix=base_name,\n                    hook=hook,\n                )\n                self.logger.info(\n                    f\"Total Task Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                    f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                    colored=True,\n                    prefix=base_name,\n                    hook=hook,\n                )\n            self.logger.info(\n                self.get_resource_info(compare=False, colored=True),\n                colored=True,\n                prefix=base_name,\n                hook=hook,\n            )\n            if self.has_gpu and start_gpu_data is not None:\n                self.logger.info(\n                    self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                    colored=True,\n                    prefix=base_name,\n                    hook=hook,\n                )\n\n    def __enter__(self) -&gt; \"WorkerContext\":\n        return self\n\n    def __exit__(self, exc_type, exc, tb) -&gt; None:\n        return None\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.torch_device_name","title":"<code>torch_device_name()</code>","text":"<p>Return the active PyTorch device name.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@eproperty\ndef torch_device_name(self) -&gt; str:\n    \"\"\"Return the active PyTorch device name.\"\"\"\n\n    from lzo.utils.system import get_torch_device_name\n\n    return get_torch_device_name()\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.torch_device","title":"<code>torch_device()</code>","text":"<p>Return the active PyTorch device instance.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@eproperty\ndef torch_device(self):\n    \"\"\"Return the active PyTorch device instance.\"\"\"\n\n    from lzo.utils.system import get_torch_device\n\n    return get_torch_device()\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.has_gpu","title":"<code>has_gpu()</code>","text":"<p>Return <code>True</code> when the runtime is backed by CUDA.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@eproperty\ndef has_gpu(self) -&gt; bool:\n    \"\"\"Return ``True`` when the runtime is backed by CUDA.\"\"\"\n\n    return self.torch_device_name.startswith(\"cuda\")\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.model_name","title":"<code>model_name()</code>","text":"<p>Optional model identifier surfaced in log prefixes.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@eproperty\ndef model_name(self) -&gt; t.Optional[str]:\n    \"\"\"Optional model identifier surfaced in log prefixes.\"\"\"\n\n    return self._extra.get(\"model_name\")\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.worker_name","title":"<code>worker_name()</code>","text":"<p>Optional worker identifier used in log prefixes.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@eproperty\ndef worker_name(self) -&gt; t.Optional[str]:\n    \"\"\"Optional worker identifier used in log prefixes.\"\"\"\n\n    return self._extra.get(\"worker_name\")\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.build_gpu_data_string","title":"<code>build_gpu_data_string(current_usage, compare=None, previous_usage=None, colored=False)</code>","text":"<p>Format GPU usage statistics with optional comparison.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>def build_gpu_data_string(\n    self,\n    current_usage: \"GPUData\",\n    compare: bool | None = None,\n    previous_usage: \"GPUData\" | None = None,\n    colored: bool = False,\n) -&gt; t.Optional[str]:\n    \"\"\"Format GPU usage statistics with optional comparison.\"\"\"\n\n    curr_mem_used = current_usage[\"memory_used\"]\n    curr_mem_percent = current_usage[\"utilization_memory\"]\n    curr_mem_total = current_usage[\"memory_total\"]\n    gpu_name = current_usage[\"name\"]\n\n    previous_usage = previous_usage or self.last_gpu_data\n    self.last_gpu_data = current_usage\n\n    if compare and previous_usage:\n        comparison = {\n            \"memory_used\": self._bs(curr_mem_used - previous_usage[\"memory_used\"]),\n            \"utilization_memory\": curr_mem_percent - previous_usage[\"utilization_memory\"],\n        }\n        if not colored:\n            return (\n                f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; \"\n                f\"{curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} + \"\n                f\"{comparison['memory_used'].human_readable()} \"\n                f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n            )\n        return (\n            f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; |y|{curr_mem_used.human_readable()}|e| / \"\n            f\"|g|{curr_mem_total.human_readable()}|e| + |r|{comparison['memory_used'].human_readable()}|e| \"\n            f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n        )\n\n    if not colored:\n        return (\n            f\"{gpu_name}: {curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} \"\n            f\"({curr_mem_percent}%)\"\n        )\n    return (\n        f\"{gpu_name}: |y|{curr_mem_used.human_readable()}|e| / |g|{curr_mem_total.human_readable()}|e| \"\n        f\"({curr_mem_percent}%)\"\n    )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.get_gpu_memory","title":"<code>get_gpu_memory(compare=None, previous_usage=None, colored=False)</code>","text":"<p>Return formatted GPU usage, optionally comparing against a prior sample.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>def get_gpu_memory(\n    self,\n    compare: bool | None = None,\n    previous_usage: \"GPUData\" | None = None,\n    colored: bool = False,\n) -&gt; t.Optional[str]:\n    \"\"\"Return formatted GPU usage, optionally comparing against a prior sample.\"\"\"\n\n    current_usage = self.get_gpu_data()\n    if not current_usage:\n        return None\n    return self.build_gpu_data_string(\n        current_usage,\n        compare=compare,\n        previous_usage=previous_usage,\n        colored=colored,\n    )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.aget_gpu_memory","title":"<code>aget_gpu_memory(compare=None, previous_usage=None, colored=False)</code>  <code>async</code>","text":"<p>Asynchronous variant of :meth:<code>get_gpu_memory</code>.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>async def aget_gpu_memory(\n    self,\n    compare: bool | None = None,\n    previous_usage: \"GPUData\" | None = None,\n    colored: bool = False,\n) -&gt; t.Optional[str]:\n    \"\"\"Asynchronous variant of :meth:`get_gpu_memory`.\"\"\"\n\n    current_usage = await self.aget_gpu_data()\n    if not current_usage:\n        return None\n    return self.build_gpu_data_string(\n        current_usage,\n        compare=compare,\n        previous_usage=previous_usage,\n        colored=colored,\n    )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.build_resource_data_string","title":"<code>build_resource_data_string(current_usage, compare=None, previous_usage=None, colored=False)</code>","text":"<p>Format CPU/RAM usage into a human-readable string.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>def build_resource_data_string(\n    self,\n    current_usage: \"ResourceData\",\n    compare: bool | None = None,\n    previous_usage: \"ResourceData\" | None = None,\n    colored: bool = False,\n) -&gt; t.Optional[str]:\n    \"\"\"Format CPU/RAM usage into a human-readable string.\"\"\"\n\n    curr_mem_used = current_usage[\"memory_used\"]\n    curr_mem_percent = current_usage[\"utilization_memory\"]\n    curr_mem_total = current_usage[\"memory_total\"]\n    curr_cpu_percent = current_usage[\"utilization_cpu\"]\n    num_cpu = current_usage[\"cpu_count\"]\n\n    previous_usage = previous_usage or self.last_resource_data\n    self.last_resource_data = current_usage\n\n    if compare and previous_usage:\n        comparison = {\n            \"memory_used\": self._bs(curr_mem_used - previous_usage[\"memory_used\"]),\n        }\n        base = (\n            f\"{num_cpu} vCPU: {curr_cpu_percent}% | RAM: {previous_usage['memory_used'].human_readable()} -&gt; \"\n            f\"{curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} + \"\n            f\"{comparison['memory_used'].human_readable()} ({curr_mem_percent}%)\"\n        )\n        if not colored:\n            return base\n        return (\n            f\"{num_cpu} vCPU: |g|{curr_cpu_percent}%|e| | RAM: {previous_usage['memory_used'].human_readable()} -&gt; \"\n            f\"|y|{curr_mem_used.human_readable()}|e| / |g|{curr_mem_total.human_readable()}|e| + \"\n            f\"|r|{comparison['memory_used'].human_readable()}|e| ({curr_mem_percent}%)\"\n        )\n\n    if not colored:\n        return (\n            f\"{num_cpu} vCPU: {curr_cpu_percent}% | RAM: {curr_mem_used.human_readable()} / \"\n            f\"{curr_mem_total.human_readable()} ({curr_mem_percent}%)\"\n        )\n    return (\n        f\"{num_cpu} vCPU: |g|{curr_cpu_percent}%|e| RAM: |y|{curr_mem_used.human_readable()}|e| / \"\n        f\"|g|{curr_mem_total.human_readable()}|e| ({curr_mem_percent}%)\"\n    )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.get_resource_info","title":"<code>get_resource_info(compare=None, previous_usage=None, colored=False)</code>","text":"<p>Return formatted CPU/memory usage snapshot.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>def get_resource_info(\n    self,\n    compare: bool | None = None,\n    previous_usage: \"ResourceData\" | None = None,\n    colored: bool = False,\n) -&gt; t.Optional[str]:\n    \"\"\"Return formatted CPU/memory usage snapshot.\"\"\"\n\n    current_usage = self.get_resource_data()\n    if not current_usage:\n        return None\n    return self.build_resource_data_string(\n        current_usage,\n        compare=compare,\n        previous_usage=previous_usage,\n        colored=colored,\n    )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.inference_mode","title":"<code>inference_mode(batch_size=1, obj_name=None, enable_gc=None, enable_summary=None, hook=None, **kwargs)</code>","text":"<p>Wrap a block of inference work with resource logging.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@contextlib.contextmanager\ndef inference_mode(\n    self,\n    batch_size: int | None = 1,\n    obj_name: str | None = None,\n    enable_gc: bool | None = None,\n    enable_summary: bool | None = None,\n    hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n    **kwargs: t.Any,\n):\n    \"\"\"Wrap a block of inference work with resource logging.\"\"\"\n\n    ts = self.timer(format_ms=True, format_short=1)\n    start_text = \"Starting Inference\"\n    if obj_name:\n        start_text += f\" for |g|{obj_name}|e|\"\n    start_text += f\" ({batch_size})\"\n    self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n    start_resource_data = self.get_resource_data()\n    start_gpu_data = self.get_gpu_data() if self.has_gpu else None\n    try:\n        yield\n    except Exception as exc:  # pragma: no cover - logging path\n        self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n        raise\n    finally:\n        total_s = ts.total\n        self.total_duration += total_s\n        self.last_duration = total_s\n        self.num_batches += batch_size or 0\n        self.idx += 1\n\n        end_text = \"Inference Completed\"\n        if obj_name:\n            end_text += f\" for |g|{obj_name}|e|\"\n        end_text += f\" ({batch_size}) in {ts.total_s}\"\n        if enable_gc:\n            gc.collect()\n\n        self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n        if enable_summary:\n            self.logger.info(\n                f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n            self.logger.info(\n                f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n        self.logger.info(\n            self.get_resource_info(compare=True, previous_usage=start_resource_data, colored=True),\n            colored=True,\n            prefix=self.model_name,\n            hook=hook,\n        )\n        if self.has_gpu and start_gpu_data is not None:\n            self.logger.info(\n                self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.ainference_mode","title":"<code>ainference_mode(batch_size=1, obj_name=None, enable_gc=None, enable_summary=None, hook=None, **kwargs)</code>  <code>async</code>","text":"<p>Async variant of :meth:<code>inference_mode</code>.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@contextlib.asynccontextmanager\nasync def ainference_mode(\n    self,\n    batch_size: int | None = 1,\n    obj_name: str | None = None,\n    enable_gc: bool | None = None,\n    enable_summary: bool | None = None,\n    hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n    **kwargs: t.Any,\n):\n    \"\"\"Async variant of :meth:`inference_mode`.\"\"\"\n\n    ts = self.timer(format_ms=True, format_short=1)\n    start_text = \"Starting Inference\"\n    if obj_name:\n        start_text += f\" for |g|{obj_name}|e|\"\n    start_text += f\" ({batch_size})\"\n    self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n    start_resource_data = self.get_resource_data()\n    start_gpu_data = await self.aget_gpu_data() if self.has_gpu else None\n    try:\n        yield\n    except Exception as exc:  # pragma: no cover - logging path\n        self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n        raise\n    finally:\n        total_s = ts.total\n        self.total_duration += total_s\n        self.last_duration = total_s\n        self.num_batches += batch_size or 0\n        self.idx += 1\n\n        end_text = \"Inference Completed\"\n        if obj_name:\n            end_text += f\" for |g|{obj_name}|e|\"\n        end_text += f\" ({batch_size}) in {ts.total_s}\"\n        if enable_gc:\n            gc.collect()\n\n        self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n        if enable_summary:\n            self.logger.info(\n                f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n            self.logger.info(\n                f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n        self.logger.info(\n            self.get_resource_info(compare=True, previous_usage=start_resource_data, colored=True),\n            colored=True,\n            prefix=self.model_name,\n            hook=hook,\n        )\n        if self.has_gpu and start_gpu_data is not None:\n            self.logger.info(\n                await self.aget_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.capture","title":"<code>capture(message=None, prefix=None, hook=None, **kwargs)</code>","text":"<p>Capture resources across an arbitrary block of work.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@contextlib.contextmanager\ndef capture(\n    self,\n    message: str | None = None,\n    prefix: str | None = None,\n    hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n    **kwargs: t.Any,\n):\n    \"\"\"Capture resources across an arbitrary block of work.\"\"\"\n\n    ts = self.timer(format_ms=True, format_short=1)\n    base_name = self.model_name or self.worker_name\n    prefix = f\"{prefix} {base_name}\" if prefix else base_name\n    start_resource_data = self.get_resource_data()\n    start_gpu_data = self.get_gpu_data() if self.has_gpu else None\n    try:\n        yield\n    except Exception as exc:  # pragma: no cover - logging path\n        self.logger.trace(f\"[{prefix}] Error in Capture: \", exc, hook=hook)\n        raise\n    finally:\n        message = (message or \"Capture Complete\") + f\" in {ts.total_s}\"\n        self.logger.info(message, colored=True, prefix=prefix, hook=hook)\n        self.logger.info(\n            self.get_resource_info(compare=True, previous_usage=start_resource_data, colored=True),\n            colored=True,\n            prefix=prefix,\n            hook=hook,\n        )\n        if self.has_gpu and start_gpu_data is not None:\n            self.logger.info(\n                self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                colored=True,\n                prefix=prefix,\n                hook=hook,\n            )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.start_task","title":"<code>start_task(batch_size=1, obj_name=None, task_name=None, enable_gc=None, enable_summary=None, hook=None, **kwargs)</code>","text":"<p>Track a generic worker task, logging CPU/GPU usage.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@contextlib.contextmanager\ndef start_task(\n    self,\n    batch_size: int | None = 1,\n    obj_name: str | None = None,\n    task_name: str | None = None,\n    enable_gc: bool | None = None,\n    enable_summary: bool | None = None,\n    hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n    **kwargs: t.Any,\n):\n    \"\"\"Track a generic worker task, logging CPU/GPU usage.\"\"\"\n\n    ts = self.timer(format_ms=True, format_short=1)\n    base_name = self.model_name or self.worker_name\n    start_text = \"Starting Task\"\n    if task_name:\n        start_text += f\": |g|{task_name}|e|\"\n    if obj_name:\n        start_text += f\" for |g|{obj_name}|e|\"\n    start_text += f\" ({batch_size})\"\n    self.logger.info(start_text, prefix=base_name, colored=True, hook=hook)\n    start_gpu_data = self.get_gpu_data() if self.has_gpu else None\n    try:\n        yield\n    except Exception as exc:  # pragma: no cover - logging path\n        self.logger.trace(f\"[{base_name}] Error in Task: \", exc, hook=hook)\n        raise\n    finally:\n        total_s = ts.total\n        self.total_duration += total_s\n        self.last_duration = total_s\n        self.num_batches += batch_size or 0\n        self.idx += 1\n\n        end_text = \"Task Completed\"\n        if task_name:\n            end_text += f\": |g|{task_name}|e|\"\n        if obj_name:\n            end_text += f\" for |g|{obj_name}|e|\"\n        end_text += f\" ({batch_size}) in {ts.total_s}\"\n        if enable_gc:\n            gc.collect()\n\n        self.logger.info(end_text, colored=True, prefix=base_name, hook=hook)\n        if enable_summary:\n            self.logger.info(\n                f\"Total Tasks: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                colored=True,\n                prefix=base_name,\n                hook=hook,\n            )\n            self.logger.info(\n                f\"Total Task Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                colored=True,\n                prefix=base_name,\n                hook=hook,\n            )\n        self.logger.info(\n            self.get_resource_info(compare=False, colored=True),\n            colored=True,\n            prefix=base_name,\n            hook=hook,\n        )\n        if self.has_gpu and start_gpu_data is not None:\n            self.logger.info(\n                self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                colored=True,\n                prefix=base_name,\n                hook=hook,\n            )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext","title":"<code>MLContext</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Capture GPU statistics during ML inference workloads.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>class MLContext(abc.ABC):\n    \"\"\"Capture GPU statistics during ML inference workloads.\"\"\"\n\n    def __init__(self, **kwargs: t.Any) -&gt; None:\n        \"\"\"Initialise timer/logging helpers used for metric collection.\"\"\"\n\n        from lzl.logging import logger\n        from lzo.utils import Timer\n        from lzo.utils.system import aget_gpu_data, get_gpu_data\n        from pydantic.types import ByteSize\n\n        self._extra: dict[str, t.Any] = {}\n        self._kwargs = kwargs\n\n        self.timer = Timer\n        self.logger = logger\n        self._bs = ByteSize\n\n        self.get_gpu_data = get_gpu_data\n        self.aget_gpu_data = aget_gpu_data\n\n        self.t = self.timer()\n        self.idx: int = 0\n        self.num_batches: int = 0\n        self.last_batch_size: int = 0\n        self.total_duration: float = 0.0\n        self.last_duration: float = 0.0\n        self.last_gpu_data: t.Optional[t.Dict[str, t.Any]] = None\n\n    @eproperty\n    def torch_device_name(self) -&gt; str:\n        \"\"\"Return the active PyTorch device name.\"\"\"\n\n        from lzo.utils.system import get_torch_device_name\n\n        return get_torch_device_name()\n\n    @eproperty\n    def torch_device(self):\n        \"\"\"Return the active PyTorch device instance.\"\"\"\n\n        from lzo.utils.system import get_torch_device\n\n        return get_torch_device()\n\n    @eproperty\n    def has_gpu(self) -&gt; bool:\n        \"\"\"Return ``True`` when the runtime has a CUDA device.\"\"\"\n\n        return self.torch_device_name.startswith(\"cuda\")\n\n    @eproperty\n    def model_name(self) -&gt; t.Optional[str]:\n        \"\"\"Optional model identifier used in log prefixes.\"\"\"\n\n        return self._extra.get(\"model_name\")\n\n    def build_gpu_data_string(\n        self,\n        current_usage: GPUData,\n        compare: bool | None = None,\n        previous_usage: GPUData | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        \"\"\"Format GPU usage details with optional comparison.\"\"\"\n\n        curr_mem_used = current_usage[\"memory_used\"]\n        curr_mem_percent = current_usage[\"utilization_memory\"]\n        curr_mem_total = current_usage[\"memory_total\"]\n        gpu_name = current_usage[\"name\"]\n\n        previous_usage = previous_usage or self.last_gpu_data\n        self.last_gpu_data = current_usage\n        if compare and previous_usage:\n            comparison: GPUData = {\n                \"memory_used\": self._bs(curr_mem_used - previous_usage[\"memory_used\"]),\n                \"utilization_memory\": curr_mem_percent - previous_usage[\"utilization_memory\"],\n            }\n            if not colored:\n                return (\n                    f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; \"\n                    f\"{curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} + \"\n                    f\"{comparison['memory_used'].human_readable()} \"\n                    f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n                )\n            return (\n                f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; |y|{curr_mem_used.human_readable()}|e| / \"\n                f\"|g|{curr_mem_total.human_readable()}|e| + |r|{comparison['memory_used'].human_readable()}|e| \"\n                f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n            )\n        if not colored:\n            return (\n                f\"{gpu_name}: {curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} \"\n                f\"({curr_mem_percent}%)\"\n            )\n        return (\n            f\"{gpu_name}: |y|{curr_mem_used.human_readable()}|e| / |g|{curr_mem_total.human_readable()}|e| \"\n            f\"({curr_mem_percent}%)\"\n        )\n\n    def get_gpu_memory(\n        self,\n        compare: bool | None = None,\n        previous_usage: GPUData | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        current_usage = self.get_gpu_data()\n        if not current_usage:\n            return None\n        return self.build_gpu_data_string(\n            current_usage,\n            compare=compare,\n            previous_usage=previous_usage,\n            colored=colored,\n        )\n\n    async def aget_gpu_memory(\n        self,\n        compare: bool | None = None,\n        previous_usage: GPUData | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        current_usage = await self.aget_gpu_data()\n        if not current_usage:\n            return None\n        return self.build_gpu_data_string(\n            current_usage,\n            compare=compare,\n            previous_usage=previous_usage,\n            colored=colored,\n        )\n\n    @contextlib.contextmanager\n    def inference_mode(\n        self,\n        batch_size: int | None = 1,\n        obj_name: str | None = None,\n        enable_gc: bool | None = None,\n        enable_summary: bool | None = None,\n        hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n        **kwargs: t.Any,\n    ):\n        \"\"\"Track a block of inference work, logging GPU usage before/after.\"\"\"\n\n        ts = self.timer(format_ms=True, format_short=1)\n        start_text = \"Starting Inference\"\n        if obj_name:\n            start_text += f\" for |g|{obj_name}|e|\"\n        start_text += f\" ({batch_size})\"\n        self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n        start_gpu_data = self.get_gpu_data()\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - logging path\n            self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n            raise\n        finally:\n            total_s = ts.total\n            self.total_duration += total_s\n            self.last_duration = total_s\n            self.num_batches += batch_size or 0\n            self.idx += 1\n\n            end_text = \"Inference Completed\"\n            if obj_name:\n                end_text += f\" for |g|{obj_name}|e|\"\n            end_text += f\" ({batch_size}) in {ts.total_s}\"\n            if enable_gc:\n                gc.collect()\n\n            self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n            if enable_summary:\n                self.logger.info(\n                    f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                    f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n                self.logger.info(\n                    f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                    f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n            self.logger.info(\n                self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n\n    @contextlib.asynccontextmanager\n    async def ainference_mode(\n        self,\n        batch_size: int | None = 1,\n        obj_name: str | None = None,\n        enable_gc: bool | None = None,\n        enable_summary: bool | None = None,\n        hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n        **kwargs: t.Any,\n    ):\n        \"\"\"Async variant of :meth:`inference_mode`.\"\"\"\n\n        ts = self.timer(format_ms=True, format_short=1)\n        start_text = \"Starting Inference\"\n        if obj_name:\n            start_text += f\" for |g|{obj_name}|e|\"\n        start_text += f\" ({batch_size})\"\n        self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n        start_gpu_data = await self.aget_gpu_data()\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - logging path\n            self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n            raise\n        finally:\n            total_s = ts.total\n            self.total_duration += total_s\n            self.last_duration = total_s\n            self.num_batches += batch_size or 0\n            self.idx += 1\n\n            end_text = \"Inference Completed\"\n            if obj_name:\n                end_text += f\" for |g|{obj_name}|e|\"\n            end_text += f\" ({batch_size}) in {ts.total_s}\"\n            if enable_gc:\n                gc.collect()\n\n            self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n            if enable_summary:\n                self.logger.info(\n                    f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                    f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n                self.logger.info(\n                    f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                    f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n            self.logger.info(\n                await self.aget_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.torch_device_name","title":"<code>torch_device_name()</code>","text":"<p>Return the active PyTorch device name.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>@eproperty\ndef torch_device_name(self) -&gt; str:\n    \"\"\"Return the active PyTorch device name.\"\"\"\n\n    from lzo.utils.system import get_torch_device_name\n\n    return get_torch_device_name()\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.torch_device","title":"<code>torch_device()</code>","text":"<p>Return the active PyTorch device instance.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>@eproperty\ndef torch_device(self):\n    \"\"\"Return the active PyTorch device instance.\"\"\"\n\n    from lzo.utils.system import get_torch_device\n\n    return get_torch_device()\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.has_gpu","title":"<code>has_gpu()</code>","text":"<p>Return <code>True</code> when the runtime has a CUDA device.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>@eproperty\ndef has_gpu(self) -&gt; bool:\n    \"\"\"Return ``True`` when the runtime has a CUDA device.\"\"\"\n\n    return self.torch_device_name.startswith(\"cuda\")\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.model_name","title":"<code>model_name()</code>","text":"<p>Optional model identifier used in log prefixes.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>@eproperty\ndef model_name(self) -&gt; t.Optional[str]:\n    \"\"\"Optional model identifier used in log prefixes.\"\"\"\n\n    return self._extra.get(\"model_name\")\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.build_gpu_data_string","title":"<code>build_gpu_data_string(current_usage, compare=None, previous_usage=None, colored=False)</code>","text":"<p>Format GPU usage details with optional comparison.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>def build_gpu_data_string(\n    self,\n    current_usage: GPUData,\n    compare: bool | None = None,\n    previous_usage: GPUData | None = None,\n    colored: bool = False,\n) -&gt; t.Optional[str]:\n    \"\"\"Format GPU usage details with optional comparison.\"\"\"\n\n    curr_mem_used = current_usage[\"memory_used\"]\n    curr_mem_percent = current_usage[\"utilization_memory\"]\n    curr_mem_total = current_usage[\"memory_total\"]\n    gpu_name = current_usage[\"name\"]\n\n    previous_usage = previous_usage or self.last_gpu_data\n    self.last_gpu_data = current_usage\n    if compare and previous_usage:\n        comparison: GPUData = {\n            \"memory_used\": self._bs(curr_mem_used - previous_usage[\"memory_used\"]),\n            \"utilization_memory\": curr_mem_percent - previous_usage[\"utilization_memory\"],\n        }\n        if not colored:\n            return (\n                f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; \"\n                f\"{curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} + \"\n                f\"{comparison['memory_used'].human_readable()} \"\n                f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n            )\n        return (\n            f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; |y|{curr_mem_used.human_readable()}|e| / \"\n            f\"|g|{curr_mem_total.human_readable()}|e| + |r|{comparison['memory_used'].human_readable()}|e| \"\n            f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n        )\n    if not colored:\n        return (\n            f\"{gpu_name}: {curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} \"\n            f\"({curr_mem_percent}%)\"\n        )\n    return (\n        f\"{gpu_name}: |y|{curr_mem_used.human_readable()}|e| / |g|{curr_mem_total.human_readable()}|e| \"\n        f\"({curr_mem_percent}%)\"\n    )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.inference_mode","title":"<code>inference_mode(batch_size=1, obj_name=None, enable_gc=None, enable_summary=None, hook=None, **kwargs)</code>","text":"<p>Track a block of inference work, logging GPU usage before/after.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>@contextlib.contextmanager\ndef inference_mode(\n    self,\n    batch_size: int | None = 1,\n    obj_name: str | None = None,\n    enable_gc: bool | None = None,\n    enable_summary: bool | None = None,\n    hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n    **kwargs: t.Any,\n):\n    \"\"\"Track a block of inference work, logging GPU usage before/after.\"\"\"\n\n    ts = self.timer(format_ms=True, format_short=1)\n    start_text = \"Starting Inference\"\n    if obj_name:\n        start_text += f\" for |g|{obj_name}|e|\"\n    start_text += f\" ({batch_size})\"\n    self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n    start_gpu_data = self.get_gpu_data()\n    try:\n        yield\n    except Exception as exc:  # pragma: no cover - logging path\n        self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n        raise\n    finally:\n        total_s = ts.total\n        self.total_duration += total_s\n        self.last_duration = total_s\n        self.num_batches += batch_size or 0\n        self.idx += 1\n\n        end_text = \"Inference Completed\"\n        if obj_name:\n            end_text += f\" for |g|{obj_name}|e|\"\n        end_text += f\" ({batch_size}) in {ts.total_s}\"\n        if enable_gc:\n            gc.collect()\n\n        self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n        if enable_summary:\n            self.logger.info(\n                f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n            self.logger.info(\n                f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n        self.logger.info(\n            self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n            colored=True,\n            prefix=self.model_name,\n            hook=hook,\n        )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.ainference_mode","title":"<code>ainference_mode(batch_size=1, obj_name=None, enable_gc=None, enable_summary=None, hook=None, **kwargs)</code>  <code>async</code>","text":"<p>Async variant of :meth:<code>inference_mode</code>.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>@contextlib.asynccontextmanager\nasync def ainference_mode(\n    self,\n    batch_size: int | None = 1,\n    obj_name: str | None = None,\n    enable_gc: bool | None = None,\n    enable_summary: bool | None = None,\n    hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n    **kwargs: t.Any,\n):\n    \"\"\"Async variant of :meth:`inference_mode`.\"\"\"\n\n    ts = self.timer(format_ms=True, format_short=1)\n    start_text = \"Starting Inference\"\n    if obj_name:\n        start_text += f\" for |g|{obj_name}|e|\"\n    start_text += f\" ({batch_size})\"\n    self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n    start_gpu_data = await self.aget_gpu_data()\n    try:\n        yield\n    except Exception as exc:  # pragma: no cover - logging path\n        self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n        raise\n    finally:\n        total_s = ts.total\n        self.total_duration += total_s\n        self.last_duration = total_s\n        self.num_batches += batch_size or 0\n        self.idx += 1\n\n        end_text = \"Inference Completed\"\n        if obj_name:\n            end_text += f\" for |g|{obj_name}|e|\"\n        end_text += f\" ({batch_size}) in {ts.total_s}\"\n        if enable_gc:\n            gc.collect()\n\n        self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n        if enable_summary:\n            self.logger.info(\n                f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n            self.logger.info(\n                f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n        self.logger.info(\n            await self.aget_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n            colored=True,\n            prefix=self.model_name,\n            hook=hook,\n        )\n</code></pre>"},{"location":"api/lzl/sysmon/#overview","title":"Overview","text":"<p>The system monitoring module tracks CPU, memory, GPU, and other system resources, providing real-time insights into application performance.</p>"},{"location":"api/lzl/sysmon/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzl/sysmon/#basic-resource-monitoring","title":"Basic Resource Monitoring","text":"<pre><code>from lzl.sysmon import get_system_info\n\ninfo = get_system_info()\nprint(f\"CPU Usage: {info.cpu_percent}%\")\nprint(f\"Memory Usage: {info.memory_percent}%\")\nprint(f\"Available Memory: {info.memory_available_mb}MB\")\n</code></pre>"},{"location":"api/lzl/sysmon/#context-based-monitoring","title":"Context-Based Monitoring","text":"<pre><code>from lzl.sysmon import SystemMonitor\n\nwith SystemMonitor() as monitor:\n    # Your code here\n    expensive_operation()\n\n# Monitor automatically captures metrics\nprint(f\"Peak memory: {monitor.peak_memory_mb}MB\")\nprint(f\"Average CPU: {monitor.avg_cpu_percent}%\")\n</code></pre>"},{"location":"api/lzl/sysmon/#gpu-monitoring","title":"GPU Monitoring","text":"<pre><code>from lzl.sysmon import get_gpu_info\n\nif get_gpu_info().available:\n    gpu = get_gpu_info()\n    print(f\"GPU Memory: {gpu.memory_used_mb}MB / {gpu.memory_total_mb}MB\")\n    print(f\"GPU Utilization: {gpu.utilization_percent}%\")\n</code></pre>"},{"location":"api/lzl/sysmon/#worker-context","title":"Worker Context","text":"<pre><code>from lzl.sysmon import WorkerContext\n\n# Track resources for a worker process\nwith WorkerContext(worker_id=\"worker-1\") as ctx:\n    process_batch(data)\n\nprint(f\"Worker {ctx.worker_id} used {ctx.peak_memory_mb}MB\")\n</code></pre>"},{"location":"api/lzl/sysmon/#ml-context","title":"ML Context","text":"<pre><code>from lzl.sysmon import MLContext\n\n# Specialized monitoring for ML workloads\nwith MLContext(model_name=\"resnet50\") as ctx:\n    train_model(model, data)\n\nprint(f\"Training used {ctx.peak_gpu_memory_mb}MB GPU memory\")\nprint(f\"Total training time: {ctx.elapsed_seconds}s\")\n</code></pre>"},{"location":"api/lzl/sysmon/#features","title":"Features","text":"<ul> <li>Real-Time Monitoring: Track system resources in real-time</li> <li>GPU Support: Monitor NVIDIA GPUs with CUDA</li> <li>Context Managers: Easy integration with Python context managers</li> <li>Metrics Collection: Capture peak, average, and current metrics</li> <li>Low Overhead: Minimal performance impact</li> <li>Cross-Platform: Works on Linux, macOS, and Windows</li> </ul>"},{"location":"api/lzl/sysmon/#metrics-tracked","title":"Metrics Tracked","text":"<ul> <li>CPU: Utilization percentage, core count, load average</li> <li>Memory: Used, available, percentage, swap usage</li> <li>GPU: Memory usage, utilization, temperature (NVIDIA)</li> <li>Disk: I/O operations, read/write speeds</li> <li>Network: Bandwidth usage, connections</li> </ul>"},{"location":"api/lzl/sysmon/#use-cases","title":"Use Cases","text":"<ul> <li>Performance Profiling: Identify resource bottlenecks</li> <li>Capacity Planning: Understand resource requirements</li> <li>ML Training: Monitor GPU utilization during training</li> <li>Production Monitoring: Track application resource usage</li> <li>Debugging: Identify memory leaks and resource issues</li> </ul>"},{"location":"api/lzl/types/","title":"lzl.types - Type Definitions","text":"<p>The <code>lzl.types</code> module provides common type aliases, protocols, and utility types.</p>"},{"location":"api/lzl/types/#common-types","title":"Common Types","text":""},{"location":"api/lzl/types/#lzl.types.common","title":"<code>lzl.types.common</code>","text":"<p>Common Types</p>"},{"location":"api/lzl/types/#lzl.types.common.StrEnumMeta","title":"<code>StrEnumMeta</code>","text":"<p>               Bases: <code>EnumMeta</code></p> Source code in <code>src/lzl/types/common.py</code> <pre><code>class StrEnumMeta(EnumMeta):\n\n    @singledispatchmethod\n    def __getitem__(self, key):\n        return super().__getitem__(key)\n\n    @__getitem__.register\n    def _(self, index: int):\n        return list(self)[index]\n\n    @property\n    def _reversed_members_(cls) -&gt; Dict[str, str]:\n        \"\"\"\n        Returns the reversed members\n        \"\"\"\n        return {v: k for k, v in cls.__members__.items()}\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.StrEnum","title":"<code>StrEnum</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>StrEnum is a string enum that allows for case-insensitive comparisons</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>class StrEnum(str, Enum, metaclass=StrEnumMeta):\n    \"\"\"\n    StrEnum is a string enum that allows for case-insensitive comparisons\n    \"\"\"\n\n    def __eq__(self, other: Any) -&gt; bool:\n        return self.value.lower() == other.lower() if \\\n            isinstance(other, str) else \\\n                super().__eq__(other)\n\n    def __ne__(self, other: Any) -&gt; bool:\n        return self.value.lower() != other.lower() if \\\n            isinstance(other, str) else \\\n                super().__ne__(other)\n\n    def __str__(self) -&gt; str:\n        return str.__str__(self)\n\n    def __hash__(self) -&gt; int:\n        return id(self)\n\n    @classmethod\n    def extend(cls, name: str, value: Any):\n        \"\"\"\n        Dynamically extends the enum with a new member.\n\n        Requires the `aenum` package to be installed.\n\n        Args:\n            name: The name of the new enum member.\n            value: The value of the new enum member.\n\n        Raises:\n            ImportError: If `aenum` is not installed.\n        \"\"\"\n        if not _EXTEND_SUPPORTED: raise ImportError('aenum is not installed. Please install it to use this feature')\n        extend_enum(cls, name, value)\n\n    @classmethod\n    def __validate__(cls, value: Union[str, 'StrEnumT']) -&gt; 'StrEnumT':\n        \"\"\"\n        Validates and converts a value to the corresponding Enum member.\n\n        It attempts to match the value against member names (case-insensitive)\n        and values.\n\n        Args:\n            value: The value to validate.\n\n        Returns:\n            The matching Enum member.\n\n        Raises:\n            ValueError: If the value cannot be mapped to any Enum member.\n        \"\"\"\n        if hasattr(value, '__members__'): return value\n        # return cls(value.__name__)\n        reversed_members = {v: k for k, v in cls.__members__.items()}\n        if value in cls.__members__:\n            return cls.__members__[value]\n        elif value in reversed_members:\n            return cls.__members__[reversed_members[value]]\n        elif value.lower() in cls.__members__:\n            return cls.__members__[value.lower()]\n        elif value.capitalize() in cls.__members__:\n            return cls.__members__[value.capitalize()]\n        elif value.upper() in cls.__members__:\n            return cls.__members__[value.upper()]\n        elif value.lower() in reversed_members:\n            return cls.__members__[reversed_members[value.lower()]]\n        raise ValueError(f\"Invalid {cls.__name__} value: {value}\")\n\n    if TYPE_CHECKING:\n        from pydantic_core import core_schema, SchemaSerializer\n        from pydantic.annotated_handlers import GetCoreSchemaHandler, GetJsonSchemaHandler\n        from pydantic.json_schema import JsonSchemaValue\n\n    if PYDANTIC_VERSION == 2:\n\n        @classmethod\n        def __get_pydantic_json_schema__(\n            cls, \n            _core_schema: 'core_schema.CoreSchema', \n            _handler: 'GetJsonSchemaHandler'\n        ) -&gt; 'JsonSchemaValue':\n            \"\"\"\n            Get the Pydantic JSON Schema for the given source\n            \"\"\"\n            return {'enum': [m.name for m in cls], 'type': 'string'}\n\n        @classmethod\n        def __get_pydantic_core_schema__(\n            cls, \n            source: type[Any], \n            handler: 'GetCoreSchemaHandler'\n        ) -&gt; 'core_schema.CoreSchema':\n            \"\"\"\n            Get the Pydantic CoreSchema for the given source\n            \"\"\"\n            from pydantic_core import core_schema, SchemaSerializer\n            schema = core_schema.no_info_after_validator_function(\n                cls.__validate__,\n                core_schema.any_schema(),\n                serialization = core_schema.plain_serializer_function_ser_schema(_get_serialized_value),\n                # serialization = core_schema.plain_serializer_function_ser_schema(lambda x: x),\n            )\n            cls.__pydantic_serializer__ = SchemaSerializer(schema)\n            return schema\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.StrEnum.extend","title":"<code>extend(name, value)</code>  <code>classmethod</code>","text":"<p>Dynamically extends the enum with a new member.</p> <p>Requires the <code>aenum</code> package to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the new enum member.</p> required <code>value</code> <code>Any</code> <p>The value of the new enum member.</p> required <p>Raises:</p> Type Description <code>ImportError</code> <p>If <code>aenum</code> is not installed.</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef extend(cls, name: str, value: Any):\n    \"\"\"\n    Dynamically extends the enum with a new member.\n\n    Requires the `aenum` package to be installed.\n\n    Args:\n        name: The name of the new enum member.\n        value: The value of the new enum member.\n\n    Raises:\n        ImportError: If `aenum` is not installed.\n    \"\"\"\n    if not _EXTEND_SUPPORTED: raise ImportError('aenum is not installed. Please install it to use this feature')\n    extend_enum(cls, name, value)\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.UpperStrEnum","title":"<code>UpperStrEnum</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>UpperStrEnum is a string enum that allows for case-insensitive comparisons</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>class UpperStrEnum(StrEnum):\n    \"\"\"\n    UpperStrEnum is a string enum that allows for case-insensitive comparisons\n    \"\"\"\n\n    def __eq__(self, other: Any) -&gt; bool:\n        return self.value.upper() == other.upper() if \\\n            isinstance(other, str) else \\\n                super().__eq__(other)\n\n    def __ne__(self, other: Any) -&gt; bool:\n        return self.value.upper() != other.upper() if \\\n            isinstance(other, str) else \\\n                super().__ne__(other)\n\n\n    def __str__(self) -&gt; str:\n        return str.__str__(self)\n\n    def __hash__(self) -&gt; int:\n        return id(self)\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv","title":"<code>AppEnv</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>src/lzl/types/common.py</code> <pre><code>class AppEnv(str, Enum):\n    CICD = \"cicd\"\n    DEVELOPMENT = \"development\"\n    STAGING = \"staging\"\n    PRODUCTION = \"production\"\n    LOCAL = \"local\"\n    TEST = \"test\"\n\n    @classmethod\n    def from_env(cls, env_value: str) -&gt; \"AppEnv\":\n        \"\"\"\n        Determines the AppEnv from a string value, handling various formats and partial matches.\n\n        Args:\n            env_value: The string value to parse (e.g., \"production\", \"prod\", \"ci/cd\").\n\n        Returns:\n            The corresponding AppEnv member.\n\n        Raises:\n            ValueError: If the value cannot be mapped to a known environment.\n        \"\"\"\n        env_value = env_value.lower()\n        if \"cicd\" in env_value or \"ci/cd\" in env_value: return cls.CICD\n        if \"prod\" in env_value: return cls.PRODUCTION\n        if \"dev\" in env_value: return cls.DEVELOPMENT\n        if \"staging\" in env_value: return cls.STAGING\n        if \"local\" in env_value: return cls.LOCAL\n        if \"test\" in env_value: return cls.TEST\n        raise ValueError(f\"Invalid app environment: {env_value} ({type(env_value)})\")\n\n    @classmethod\n    def from_hostname(cls, hostname: str) -&gt; \"AppEnv\":\n        \"\"\"\n        Get the app environment from the hostname\n        \"\"\"\n        hostname = hostname.lower()\n        if \"dev\" in hostname: return cls.DEVELOPMENT\n        if \"staging\" in hostname: return cls.STAGING\n        if \"test\" in hostname: return cls.TEST\n        return cls.LOCAL if \"local\" in hostname else cls.PRODUCTION\n\n\n    @classmethod\n    def from_module_name(cls, module_name: str) -&gt; 'AppEnv':\n        \"\"\"\n        Retrieves the app environment\n        \"\"\"\n        module_name = module_name.replace(\".\", \"_\").upper()\n        for key in {\n            \"SERVER_ENV\",\n            f\"{module_name}_ENV\",\n            \"APP_ENV\",\n            \"ENVIRONMENT\",\n        }:\n            if env_value := os.getenv(key):\n                return cls.from_env(env_value)\n\n        from lzo.utils.system import is_in_kubernetes, get_host_name\n        if is_in_kubernetes():\n            hn = get_host_name()\n            try:\n                parts = hn.split(\"-\")\n                for p in parts:\n                    if all(\n                        e not in p.lower()\n                        for e in {'development', 'test', 'staging', 'local', 'dev', 'prod', 'production'}\n                    ):\n                        parts.remove(p)\n                return cls.from_env(parts[0]) if len(parts) &gt; 0 else cls.PRODUCTION\n                # return cls.PRODUCTION\n                # return cls.from_env(parts[2]) if len(parts) &gt; 3 else cls.PRODUCTION\n            except Exception as e:\n                return cls.from_hostname(hn)\n\n        return cls.LOCAL\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"\n        Equality operator\n        \"\"\"\n        if isinstance(other, str): return self.value == other.lower()\n        return self.value == other.value if isinstance(other, AppEnv) else False\n\n    @property\n    def is_devel(self) -&gt; bool:\n        \"\"\"\n        Returns True if the app environment is development\n        \"\"\"\n        return self in [self.LOCAL, self.CICD, self.DEVELOPMENT, self.STAGING, self.TEST]\n\n    @property\n    def is_local(self) -&gt; bool:\n        \"\"\"\n        Returns True if the app environment is local\n        \"\"\"\n        return self in [self.LOCAL, self.CICD]\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"\n        Returns the name in lower\n        \"\"\"\n        return self.value.lower()\n\n    @property\n    def short_name(self) -&gt; str:\n        \"\"\"\n        Returns the short name in lower\n        \"\"\"\n        if self == self.DEVELOPMENT: return 'dev'\n        return 'prod' if self == self.PRODUCTION else self.name\n\n    def select(self, values: Dict[Union[str, 'AppEnv'], Any], default: Optional[Any] = None) -&gt; Any:\n        \"\"\"\n        Returns the value for the app env\n        \"\"\"\n        return next((value for key, value in values.items() if key == self), default)\n\n\n    @classmethod\n    def extend(cls, name: str, value: Any):\n        \"\"\"\n        Extends the enum with a new value\n        \"\"\"\n        if not _EXTEND_SUPPORTED: raise ImportError('aenum is not installed. Please install it to use this feature')\n        extend_enum(cls, name, value)\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.is_devel","title":"<code>is_devel</code>  <code>property</code>","text":"<p>Returns True if the app environment is development</p>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.is_local","title":"<code>is_local</code>  <code>property</code>","text":"<p>Returns True if the app environment is local</p>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.name","title":"<code>name</code>  <code>property</code>","text":"<p>Returns the name in lower</p>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.short_name","title":"<code>short_name</code>  <code>property</code>","text":"<p>Returns the short name in lower</p>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.from_env","title":"<code>from_env(env_value)</code>  <code>classmethod</code>","text":"<p>Determines the AppEnv from a string value, handling various formats and partial matches.</p> <p>Parameters:</p> Name Type Description Default <code>env_value</code> <code>str</code> <p>The string value to parse (e.g., \"production\", \"prod\", \"ci/cd\").</p> required <p>Returns:</p> Type Description <code>AppEnv</code> <p>The corresponding AppEnv member.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the value cannot be mapped to a known environment.</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef from_env(cls, env_value: str) -&gt; \"AppEnv\":\n    \"\"\"\n    Determines the AppEnv from a string value, handling various formats and partial matches.\n\n    Args:\n        env_value: The string value to parse (e.g., \"production\", \"prod\", \"ci/cd\").\n\n    Returns:\n        The corresponding AppEnv member.\n\n    Raises:\n        ValueError: If the value cannot be mapped to a known environment.\n    \"\"\"\n    env_value = env_value.lower()\n    if \"cicd\" in env_value or \"ci/cd\" in env_value: return cls.CICD\n    if \"prod\" in env_value: return cls.PRODUCTION\n    if \"dev\" in env_value: return cls.DEVELOPMENT\n    if \"staging\" in env_value: return cls.STAGING\n    if \"local\" in env_value: return cls.LOCAL\n    if \"test\" in env_value: return cls.TEST\n    raise ValueError(f\"Invalid app environment: {env_value} ({type(env_value)})\")\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.from_hostname","title":"<code>from_hostname(hostname)</code>  <code>classmethod</code>","text":"<p>Get the app environment from the hostname</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef from_hostname(cls, hostname: str) -&gt; \"AppEnv\":\n    \"\"\"\n    Get the app environment from the hostname\n    \"\"\"\n    hostname = hostname.lower()\n    if \"dev\" in hostname: return cls.DEVELOPMENT\n    if \"staging\" in hostname: return cls.STAGING\n    if \"test\" in hostname: return cls.TEST\n    return cls.LOCAL if \"local\" in hostname else cls.PRODUCTION\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.from_module_name","title":"<code>from_module_name(module_name)</code>  <code>classmethod</code>","text":"<p>Retrieves the app environment</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef from_module_name(cls, module_name: str) -&gt; 'AppEnv':\n    \"\"\"\n    Retrieves the app environment\n    \"\"\"\n    module_name = module_name.replace(\".\", \"_\").upper()\n    for key in {\n        \"SERVER_ENV\",\n        f\"{module_name}_ENV\",\n        \"APP_ENV\",\n        \"ENVIRONMENT\",\n    }:\n        if env_value := os.getenv(key):\n            return cls.from_env(env_value)\n\n    from lzo.utils.system import is_in_kubernetes, get_host_name\n    if is_in_kubernetes():\n        hn = get_host_name()\n        try:\n            parts = hn.split(\"-\")\n            for p in parts:\n                if all(\n                    e not in p.lower()\n                    for e in {'development', 'test', 'staging', 'local', 'dev', 'prod', 'production'}\n                ):\n                    parts.remove(p)\n            return cls.from_env(parts[0]) if len(parts) &gt; 0 else cls.PRODUCTION\n            # return cls.PRODUCTION\n            # return cls.from_env(parts[2]) if len(parts) &gt; 3 else cls.PRODUCTION\n        except Exception as e:\n            return cls.from_hostname(hn)\n\n    return cls.LOCAL\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.select","title":"<code>select(values, default=None)</code>","text":"<p>Returns the value for the app env</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>def select(self, values: Dict[Union[str, 'AppEnv'], Any], default: Optional[Any] = None) -&gt; Any:\n    \"\"\"\n    Returns the value for the app env\n    \"\"\"\n    return next((value for key, value in values.items() if key == self), default)\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.extend","title":"<code>extend(name, value)</code>  <code>classmethod</code>","text":"<p>Extends the enum with a new value</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef extend(cls, name: str, value: Any):\n    \"\"\"\n    Extends the enum with a new value\n    \"\"\"\n    if not _EXTEND_SUPPORTED: raise ImportError('aenum is not installed. Please install it to use this feature')\n    extend_enum(cls, name, value)\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.get_app_env","title":"<code>get_app_env(module_name)</code>","text":"<p>Retrieves the app environment</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>def get_app_env(\n    module_name: str,\n) -&gt; AppEnv:\n    \"\"\"\n    Retrieves the app environment\n    \"\"\"\n    module_name = module_name.replace(\".\", \"_\").upper()\n    for key in {\n        \"SERVER_ENV\",\n        f\"{module_name}_ENV\",\n        \"APP_ENV\",\n        \"ENVIRONMENT\",\n    }:\n        if env_value := os.getenv(key):\n            return AppEnv.from_env(env_value)\n\n    from lzo.utils.system import is_in_kubernetes, get_host_name\n    if is_in_kubernetes():\n        # Name should be\n        # scout-&lt;service&gt;-&lt;index&gt;\n        # or \n        # scout-&lt;service&gt;-&lt;env&gt;-&lt;index&gt;\n        hn = get_host_name()\n        try:\n            parts = hn.split(\"-\")\n            return AppEnv.from_env(parts[1]) if len(parts) &gt; 2 else AppEnv.PRODUCTION\n        except Exception as e:\n            return AppEnv.from_hostname(hn)\n        # parts = get_host_name().split(\"-\")\n        # return AppEnv.from_env(parts[2]) if len(parts) &gt; 3 else AppEnv.PRODUCTION\n\n    return AppEnv.LOCAL\n</code></pre>"},{"location":"api/lzl/types/#dynamic-types","title":"Dynamic Types","text":""},{"location":"api/lzl/types/#lzl.types.dynamic","title":"<code>lzl.types.dynamic</code>","text":""},{"location":"api/lzl/types/#lzl.types.dynamic.BaseDynamicLoader","title":"<code>BaseDynamicLoader</code>","text":"<p>A utility class for dynamically discovering and loading classes from a module structure.</p> <p>This class recursively scans the directory of the specified <code>MODULE</code> for Python files, imports them, and identifies classes that are subclasses of <code>class_to_find</code>.</p> <p>Attributes:</p> Name Type Description <code>MODULE</code> <code>str</code> <p>The dotted module path to start the search from.</p> Source code in <code>src/lzl/types/dynamic.py</code> <pre><code>class BaseDynamicLoader:\n    \"\"\"\n    A utility class for dynamically discovering and loading classes from a module structure.\n\n    This class recursively scans the directory of the specified `MODULE` for Python files,\n    imports them, and identifies classes that are subclasses of `class_to_find`.\n\n    Attributes:\n        MODULE (str): The dotted module path to start the search from.\n    \"\"\"\n    MODULE: str\n\n    def __init__(self, class_to_find: T):\n        \"\"\"\n        Initialize the loader.\n\n        Args:\n            class_to_find: The base class type to search for.\n        \"\"\"\n        self.module = importlib.import_module(self.MODULE)\n        self.class_to_find = class_to_find\n        self._found_classes = self.__dynamic_class_loader()\n\n    def __dynamic_class_loader(self) -&gt; t.Dict[str, T]:\n        \"\"\"\n        Recursively finds and loads classes inheriting from `self.class_to_find` within `self.MODULE`.\n\n        Returns:\n            A dictionary mapping class names to the loaded class objects.\n        \"\"\"\n        found_classes: t.Dict[str, T] = {}\n        logger.info(\n            f\"Loading {self.class_to_find.__name__} classes from &lt;{self.MODULE}&gt;\",\n            prefix = self.__class__.__name__\n        )\n        root_dir = self.module.__path__[0]\n        for root, _, files in os.walk(root_dir):\n            for file in files:\n                # Check if the file is a Python file and not a special file\n                if file.endswith(\".py\") and not file.startswith(\"__\"):\n                    mod_name = os.path.splitext(file)[0]\n                    module = importlib.import_module(f\"{self.MODULE}.{mod_name}\")\n                    for cls in dir(module):\n                        # Check if the class is a subclass of class_to_find\n                        if (\n                            isinstance(getattr(module, cls), type)\n                            and issubclass(getattr(module, cls), self.class_to_find)\n                            and getattr(module, cls) is not self.class_to_find\n                        ):\n                            # Check if the class is a class_to_find\n                            logger.info(\n                                f\"Found {self.class_to_find.__name__} class &lt;{cls}&gt; in &lt;{file}&gt;\",\n                                prefix = self.__class__.__name__\n                            )\n                            found_classes[cls] = getattr(module, cls)\n        return found_classes\n</code></pre>"},{"location":"api/lzl/types/#typed-utilities","title":"Typed Utilities","text":""},{"location":"api/lzl/types/#lzl.types.typed","title":"<code>lzl.types.typed</code>","text":""},{"location":"api/lzl/types/#lzl.types.typed.CallableAsyncNoParam","title":"<code>CallableAsyncNoParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class CallableAsyncNoParam(Protocol[ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(self) -&gt; Awaitable[ProtocolReturnType]:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.CallableSyncNoParam","title":"<code>CallableSyncNoParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class CallableSyncNoParam(Protocol[ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(self) -&gt; ProtocolReturnType:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.CallableAsyncSingleParam","title":"<code>CallableAsyncSingleParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolParamType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class CallableAsyncSingleParam(Protocol[ProtocolParamType, ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(self, __arg: ProtocolParamType) -&gt; Awaitable[ProtocolReturnType]:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.CallableSyncSingleParam","title":"<code>CallableSyncSingleParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolParamType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class CallableSyncSingleParam(Protocol[ProtocolParamType, ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(self, __arg: ProtocolParamType) -&gt; ProtocolReturnType:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.MethodAsyncNoParam","title":"<code>MethodAsyncNoParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolSelfType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class MethodAsyncNoParam(Protocol[ProtocolSelfType, ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(__self, self: ProtocolSelfType) -&gt; Awaitable[ProtocolReturnType]:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.MethodSyncNoParam","title":"<code>MethodSyncNoParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolSelfType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class MethodSyncNoParam(Protocol[ProtocolSelfType, ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(__self, self: ProtocolSelfType) -&gt; ProtocolReturnType:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.MethodAsyncSingleParam","title":"<code>MethodAsyncSingleParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolSelfType, ProtocolParamType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class MethodAsyncSingleParam(\n    Protocol[ProtocolSelfType, ProtocolParamType, ProtocolReturnType]\n):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(\n        self, __self: ProtocolSelfType, __arg: ProtocolParamType, /\n    ) -&gt; Awaitable[ProtocolReturnType]:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.MethodSyncSingleParam","title":"<code>MethodSyncSingleParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolSelfType, ProtocolParamType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class MethodSyncSingleParam(\n    Protocol[ProtocolSelfType, ProtocolParamType, ProtocolReturnType]\n):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(\n        self, __self: ProtocolSelfType, __arg: ProtocolParamType, /\n    ) -&gt; ProtocolReturnType:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.MethodSyncOrAsyncNoParam","title":"<code>MethodSyncOrAsyncNoParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolSelfType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class MethodSyncOrAsyncNoParam(Protocol[ProtocolSelfType, ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(\n        self, __self: ProtocolSelfType\n    ) -&gt; Union[ProtocolReturnType, Awaitable[ProtocolReturnType]]:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.MethodSyncOrAsyncSingleParam","title":"<code>MethodSyncOrAsyncSingleParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolSelfType, ProtocolParamType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class MethodSyncOrAsyncSingleParam(\n    Protocol[ProtocolSelfType, ProtocolParamType, ProtocolReturnType]\n):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(\n        self, __self: ProtocolSelfType, __param: ProtocolParamType, /\n    ) -&gt; Union[ProtocolReturnType, Awaitable[ProtocolReturnType]]:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.AsyncGenerator","title":"<code>AsyncGenerator</code>","text":"<p>               Bases: <code>ABC</code>, <code>AsyncIterator[TYield]</code>, <code>Generic[TYield, TSend]</code></p> <p>Represents a one-shot \"asynchronous generator-iterator\" (as it is referred to in the docs). The concept referred to as an \"asynchronous generator function\" is the function defined with <code>async def</code> that has a return type of AsyncGenerator.</p> <p>In other words, <code>fn</code> here is an asynchronous generator function:</p> <pre><code>async def fn() -&gt; AsyncGenerator[...]:\n    ...\n</code></pre> <p>And <code>agen</code> here is an asynchronous generator-iterator:</p> <pre><code>agen = fn()\n</code></pre> <p>The lifetime of an AsyncGenerator is as follows:</p> <ol> <li> <p>The asynchronous generator-iterator is started by awaiting anext() or asend(None). This begins executing the asynchronous generator function.</p> </li> <li> <p>Once started, you may (but are not required to):</p> <p>2a. Call asend() with a TSend value and await the result, to continue executing the asynchronous generator function.</p> <p>2b. Await athrow() to raise an exception inside the asynchronous generator function, which may respond by yielding a value.</p> </li> <li> <p>You may repeat step 2 as long as the awaitable returned does not raise an exception.</p> </li> <li> <p>At any point, you may await aclose() to raise GeneratorExit inside the asynchronous generator function, requesting that it exit. This has no effect if an awaitable from step 2 already raised an exception, or if the asynchronous generator function never began executing, so it is always safe to invoke.</p> </li> <li> <p>Once the asynchronous generator function has exited (gracefully or through an exception), or the generator has been closed (even if the function was never started), the asynchronous generator-iterator instance may not be restarted. However, a new one can be obtained by calling the function again:</p> <p>agen = fn()</p> </li> </ol> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class AsyncGenerator(ABC, AsyncIterator[TYield], Generic[TYield, TSend]):\n    \"\"\"\n    Represents a one-shot \"asynchronous generator-iterator\" (as it is\n    referred to in the docs). The concept referred to as an \"asynchronous\n    generator _function_\" is the function defined with `async def` that has a\n    return type of AsyncGenerator.\n\n    In other words, `fn` here is an asynchronous generator function:\n\n        async def fn() -&gt; AsyncGenerator[...]:\n            ...\n\n    And `agen` here is an asynchronous generator-iterator:\n\n        agen = fn()\n\n    The lifetime of an AsyncGenerator is as follows:\n\n    1. The asynchronous generator-iterator is started by awaiting __anext__()\n    or asend(None). This begins executing the asynchronous generator\n    function.\n\n    2. Once started, you may (but are not required to):\n\n        2a. Call asend() with a TSend value and await the result, to continue\n        executing the asynchronous generator function.\n\n        2b. Await athrow() to raise an exception inside the asynchronous\n        generator function, which may respond by yielding a value.\n\n    3. You may repeat step 2 as long as the awaitable returned does not raise\n    an exception.\n\n    4. At any point, you may await aclose() to raise GeneratorExit inside the\n    asynchronous generator function, requesting that it exit. This has no\n    effect if an awaitable from step 2 already raised an exception, or if the\n    asynchronous generator function never began executing, so it is always\n    safe to invoke.\n\n    5. Once the asynchronous generator function has exited (gracefully or\n    through an exception), or the generator has been closed (even if the\n    function was never started), the asynchronous generator-iterator instance\n    may not be restarted. However, a new one can be obtained by calling the\n    function again:\n\n        agen = fn()\n    \"\"\"\n\n    def __aiter__(self) -&gt; AsyncIterator[TYield]:\n        return self\n\n    async def __anext__(self) -&gt; TYield:  # throws: StopAsyncIteration, ...\n        \"\"\"\n        Returns an awaitable which, when run, starts to execute the\n        asynchronous generator, or resumes it from the last executed yield\n        expression.\n\n        If the generator has already exited (gracefully or through an\n        exception) or been closed previously, nothing happens, and the\n        awaitable returned by __anext__() will raise a StopAsyncIteration\n        exception.\n\n        If resuming from a yield expression, the expression will evaluate to\n        None inside the generator, because no value is being provided (use\n        asend() if you want that).\n\n        The generator will run until the next yield expression or it exits\n        (e.g., through a return statement).\n\n        If the generator yields a value, the awaitable returned by\n        __anext__() will return that value, and the generator's execution\n        will be re-suspended. (Under the hood, this is implemented as the\n        generator raising StopIteration, but you don't need to care about\n        that.)\n\n        If the generator raises an exception, the awaitable returned by\n        __anext__() will raise the same exception. (Note that if a generator\n        attempts to _explicitly_ raise StopIteration or StopAsyncIteration in\n        its implementation, it will instead be converted into a RuntimeError,\n        per PEP 479.)\n\n        If the generator exits gracefully, the awaitable returned by\n        __anext__() will raise a StopAsyncIteration exception.\n        \"\"\"\n        return await self.asend(None)\n\n    async def asend(\n        self,\n        input: Optional[TSend]\n    ) -&gt; TYield:  # throws: StopAsyncIteration, ...\n        \"\"\"\n        Returns an awaitable which, when run, starts to execute the\n        asynchronous generator, or resumes it from the last executed yield\n        expression.\n\n        If asend() is being called to start the generator, it must be called\n        with None as the argument, because there is no yield expression that\n        could receive the value. (This is the only reason `input` is typed as\n        Optional[TSend].)\n\n        If the generator has already exited (gracefully or through an\n        exception) or been closed previously, nothing happens, and the\n        awaitable returned by asend() will raise a StopAsyncIteration\n        exception.\n\n        If resuming from a yield expression, the expression will evaluate to\n        `input` inside the generator.\n\n        The generator will run until the next yield expression or it exits\n        (e.g., through a return statement).\n\n        If the generator yields a value, the awaitable returned by asend()\n        will return that value, and the generator's execution will be\n        re-suspended. (Under the hood, this is implemented as the generator\n        raising StopIteration, but you don't need to consider that.)\n\n        If the generator raises an exception, the awaitable returned by\n        asend() will raise the same exception. (Note that if a generator\n        attempts to _explicitly_ raise StopIteration or StopAsyncIteration in\n        its implementation, it will instead be converted into a RuntimeError,\n        per PEP 479.)\n\n        If the generator exits gracefully, the awaitable returned by asend()\n        will raise a StopAsyncIteration exception.\n        \"\"\"\n        ...\n\n    async def athrow(\n        self,\n        exc_type: Type[BaseException],\n        exc_value: Optional[BaseException] = None,\n        traceback: Optional[TracebackType] = None,\n    ) -&gt; Optional[TYield]:  # throws: exc_type, StopAsyncIteration, ...\n        \"\"\"\n        Returns an awaitable which, when run, raises an exception _inside_\n        the generator at the point of execution where it was last suspended.\n\n        If the generator has not yet been started, the awaitable returned by\n        athrow() will immediately raise the passed-in exception, and the\n        generator will be closed. In other words, the generator is not given\n        any opportunity to catch the exception, and it will not be able to be\n        started afterward.\n\n        If the generator has already exited (gracefully or through an\n        exception) or been closed previously, nothing happens, and the\n        awaitable returned by athrow() will return None.\n\n        Otherwise, after raising the exception inside the generator, athrow()\n        behaves exactly like __anext__().\n\n        In other words:\n\n        If the generator does not catch the passed-in exception, or raises a\n        different exception, then the awaitable returned by athrow() will\n        propagate that exception. (Note that if a generator attempts to\n        _explicitly_ raise StopIteration or StopAsyncIteration in its\n        implementation, it will instead be converted into a RuntimeError, per\n        PEP 479.)\n\n        If the generator catches the passed-in exception, then yields a\n        value, the awaitable returned by athrow() will return that value, and\n        the generator's execution will be re-suspended. (Under the hood, this\n        is implemented as the generator raising StopIteration, but you don't\n        need to consider that.)\n\n        If the generator catches the passed-in exception, then exits\n        gracefully, the awaitable returned by athrow() will raise a\n        StopAsyncIteration exception.\n        \"\"\"\n        ...\n\n    async def aclose(\n        self\n    ) -&gt; None:  # throws RuntimeError, ...\n        \"\"\"\n        Returns an awaitable which, when run, raises a GeneratorExit\n        exception _inside_ the generator at the point of execution where it\n        was last suspended.\n\n        If the generator has already exited (gracefully or through an\n        exception) or been closed previously, or the generator was never\n        started, nothing happens, and the awaitable returned by aclose() will\n        return gracefully.\n\n        If the generator does not catch the GeneratorExit exception, or\n        catches GeneratorExit then exits gracefully, the awaitable returned\n        by aclose() will return gracefully.\n\n        If the generator raises a different exception, then the awaitable\n        returned by aclose() will propagate that exception.\n\n        The generator _must not_ yield a value. If the generator catches the\n        GeneratorExit exception then yields a value, the awaitable returned\n        by aclose() will raise a RuntimeError.\n        \"\"\"\n\n        try:\n            await self.athrow(GeneratorExit)\n        except (GeneratorExit, StopAsyncIteration):\n            pass\n        else:\n            raise RuntimeError(\"...\")\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.AsyncGenerator.asend","title":"<code>asend(input)</code>  <code>async</code>","text":"<p>Returns an awaitable which, when run, starts to execute the asynchronous generator, or resumes it from the last executed yield expression.</p> <p>If asend() is being called to start the generator, it must be called with None as the argument, because there is no yield expression that could receive the value. (This is the only reason <code>input</code> is typed as Optional[TSend].)</p> <p>If the generator has already exited (gracefully or through an exception) or been closed previously, nothing happens, and the awaitable returned by asend() will raise a StopAsyncIteration exception.</p> <p>If resuming from a yield expression, the expression will evaluate to <code>input</code> inside the generator.</p> <p>The generator will run until the next yield expression or it exits (e.g., through a return statement).</p> <p>If the generator yields a value, the awaitable returned by asend() will return that value, and the generator's execution will be re-suspended. (Under the hood, this is implemented as the generator raising StopIteration, but you don't need to consider that.)</p> <p>If the generator raises an exception, the awaitable returned by asend() will raise the same exception. (Note that if a generator attempts to explicitly raise StopIteration or StopAsyncIteration in its implementation, it will instead be converted into a RuntimeError, per PEP 479.)</p> <p>If the generator exits gracefully, the awaitable returned by asend() will raise a StopAsyncIteration exception.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>async def asend(\n    self,\n    input: Optional[TSend]\n) -&gt; TYield:  # throws: StopAsyncIteration, ...\n    \"\"\"\n    Returns an awaitable which, when run, starts to execute the\n    asynchronous generator, or resumes it from the last executed yield\n    expression.\n\n    If asend() is being called to start the generator, it must be called\n    with None as the argument, because there is no yield expression that\n    could receive the value. (This is the only reason `input` is typed as\n    Optional[TSend].)\n\n    If the generator has already exited (gracefully or through an\n    exception) or been closed previously, nothing happens, and the\n    awaitable returned by asend() will raise a StopAsyncIteration\n    exception.\n\n    If resuming from a yield expression, the expression will evaluate to\n    `input` inside the generator.\n\n    The generator will run until the next yield expression or it exits\n    (e.g., through a return statement).\n\n    If the generator yields a value, the awaitable returned by asend()\n    will return that value, and the generator's execution will be\n    re-suspended. (Under the hood, this is implemented as the generator\n    raising StopIteration, but you don't need to consider that.)\n\n    If the generator raises an exception, the awaitable returned by\n    asend() will raise the same exception. (Note that if a generator\n    attempts to _explicitly_ raise StopIteration or StopAsyncIteration in\n    its implementation, it will instead be converted into a RuntimeError,\n    per PEP 479.)\n\n    If the generator exits gracefully, the awaitable returned by asend()\n    will raise a StopAsyncIteration exception.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.AsyncGenerator.athrow","title":"<code>athrow(exc_type, exc_value=None, traceback=None)</code>  <code>async</code>","text":"<p>Returns an awaitable which, when run, raises an exception inside the generator at the point of execution where it was last suspended.</p> <p>If the generator has not yet been started, the awaitable returned by athrow() will immediately raise the passed-in exception, and the generator will be closed. In other words, the generator is not given any opportunity to catch the exception, and it will not be able to be started afterward.</p> <p>If the generator has already exited (gracefully or through an exception) or been closed previously, nothing happens, and the awaitable returned by athrow() will return None.</p> <p>Otherwise, after raising the exception inside the generator, athrow() behaves exactly like anext().</p> <p>In other words:</p> <p>If the generator does not catch the passed-in exception, or raises a different exception, then the awaitable returned by athrow() will propagate that exception. (Note that if a generator attempts to explicitly raise StopIteration or StopAsyncIteration in its implementation, it will instead be converted into a RuntimeError, per PEP 479.)</p> <p>If the generator catches the passed-in exception, then yields a value, the awaitable returned by athrow() will return that value, and the generator's execution will be re-suspended. (Under the hood, this is implemented as the generator raising StopIteration, but you don't need to consider that.)</p> <p>If the generator catches the passed-in exception, then exits gracefully, the awaitable returned by athrow() will raise a StopAsyncIteration exception.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>async def athrow(\n    self,\n    exc_type: Type[BaseException],\n    exc_value: Optional[BaseException] = None,\n    traceback: Optional[TracebackType] = None,\n) -&gt; Optional[TYield]:  # throws: exc_type, StopAsyncIteration, ...\n    \"\"\"\n    Returns an awaitable which, when run, raises an exception _inside_\n    the generator at the point of execution where it was last suspended.\n\n    If the generator has not yet been started, the awaitable returned by\n    athrow() will immediately raise the passed-in exception, and the\n    generator will be closed. In other words, the generator is not given\n    any opportunity to catch the exception, and it will not be able to be\n    started afterward.\n\n    If the generator has already exited (gracefully or through an\n    exception) or been closed previously, nothing happens, and the\n    awaitable returned by athrow() will return None.\n\n    Otherwise, after raising the exception inside the generator, athrow()\n    behaves exactly like __anext__().\n\n    In other words:\n\n    If the generator does not catch the passed-in exception, or raises a\n    different exception, then the awaitable returned by athrow() will\n    propagate that exception. (Note that if a generator attempts to\n    _explicitly_ raise StopIteration or StopAsyncIteration in its\n    implementation, it will instead be converted into a RuntimeError, per\n    PEP 479.)\n\n    If the generator catches the passed-in exception, then yields a\n    value, the awaitable returned by athrow() will return that value, and\n    the generator's execution will be re-suspended. (Under the hood, this\n    is implemented as the generator raising StopIteration, but you don't\n    need to consider that.)\n\n    If the generator catches the passed-in exception, then exits\n    gracefully, the awaitable returned by athrow() will raise a\n    StopAsyncIteration exception.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.AsyncGenerator.aclose","title":"<code>aclose()</code>  <code>async</code>","text":"<p>Returns an awaitable which, when run, raises a GeneratorExit exception inside the generator at the point of execution where it was last suspended.</p> <p>If the generator has already exited (gracefully or through an exception) or been closed previously, or the generator was never started, nothing happens, and the awaitable returned by aclose() will return gracefully.</p> <p>If the generator does not catch the GeneratorExit exception, or catches GeneratorExit then exits gracefully, the awaitable returned by aclose() will return gracefully.</p> <p>If the generator raises a different exception, then the awaitable returned by aclose() will propagate that exception.</p> <p>The generator must not yield a value. If the generator catches the GeneratorExit exception then yields a value, the awaitable returned by aclose() will raise a RuntimeError.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>async def aclose(\n    self\n) -&gt; None:  # throws RuntimeError, ...\n    \"\"\"\n    Returns an awaitable which, when run, raises a GeneratorExit\n    exception _inside_ the generator at the point of execution where it\n    was last suspended.\n\n    If the generator has already exited (gracefully or through an\n    exception) or been closed previously, or the generator was never\n    started, nothing happens, and the awaitable returned by aclose() will\n    return gracefully.\n\n    If the generator does not catch the GeneratorExit exception, or\n    catches GeneratorExit then exits gracefully, the awaitable returned\n    by aclose() will return gracefully.\n\n    If the generator raises a different exception, then the awaitable\n    returned by aclose() will propagate that exception.\n\n    The generator _must not_ yield a value. If the generator catches the\n    GeneratorExit exception then yields a value, the awaitable returned\n    by aclose() will raise a RuntimeError.\n    \"\"\"\n\n    try:\n        await self.athrow(GeneratorExit)\n    except (GeneratorExit, StopAsyncIteration):\n        pass\n    else:\n        raise RuntimeError(\"...\")\n</code></pre>"},{"location":"api/lzl/io/file/","title":"lzl.io.file - Unified File Operations","text":"<p>The <code>lzl.io.file</code> module provides a powerful, unified abstraction for file system operations, supporting both local and cloud storage (S3, MinIO, R2) with synchronous and asynchronous APIs. It automatically selects the appropriate backend based on the file path scheme.</p>"},{"location":"api/lzl/io/file/#overview","title":"Overview","text":"<p>The <code>File</code> class is the main entry point. It acts as a factory that instantiates the correct concrete path object (e.g., <code>Path</code> for local files, <code>FileS3Path</code> for S3).</p>"},{"location":"api/lzl/io/file/#lzl.io.file","title":"<code>lzl.io.file</code>","text":""},{"location":"api/lzl/io/file/#lzl.io.file.File","title":"<code>File</code>","text":"<p>               Bases: <code>Generic[FileLikeT]</code></p> <p>Factory that instantiates concrete path objects for various backends.</p> Source code in <code>src/lzl/io/file/main.py</code> <pre><code>class File(t.Generic[FileLikeT]):\n    \"\"\"Factory that instantiates concrete path objects for various backends.\"\"\"\n\n    settings: 'FileIOConfig' = fileio_settings\n\n    @classmethod\n    def _get_filelike(cls, *args: t.Any, **kwargs: t.Any) -&gt; 'FileLike':\n        \"\"\"Resolve the correct :class:`FileLike` instance for given input.\n\n        Args:\n            *args: Positional arguments forwarded to\n                :func:`lzl.io.file.spec.main.get_filelike`.\n            **kwargs: Keyword arguments forwarded to the same helper.\n        \"\"\"\n        from .spec.main import get_filelike\n        return get_filelike(*args, **kwargs)\n\n    @classmethod\n    def get_object_size(cls, obj: t.Any) -&gt; 'ObjectSize':\n        \"\"\"Return a convenience wrapper reporting object size in bytes.\"\"\"\n        from .types.misc import ObjectSize\n        return ObjectSize(obj)\n\n    def __new__(\n        cls, \n        *args, \n        **kwargs\n    ) -&gt; 'FileLike':\n        \"\"\"Instantiate a file path object for the configured backend.\"\"\"\n        return cls._get_filelike(*args, **kwargs)\n\n\n    @classmethod\n    def get_dir(cls, path: 'PathLike') -&gt; 'FileLike':\n        \"\"\"Return the parent directory for the provided path-like value.\"\"\"\n        new = cls._get_filelike(path)\n        return new if new.is_dir() else new.parent\n\n\n    @classmethod\n    def register_loader(cls, ext: str, loader: t.Union[t.Callable[['FileLike'], None], t.Awaitable['FileLike', None]], overwrite: t.Optional[bool] = None) -&gt; None:\n        \"\"\"Register a loader callback for the given file extension.\n\n        Args:\n            ext: Extension (``.json``, ``.csv``\u2026) to register the loader\n                against.  A leading dot is optional.\n            loader: Callable that receives the resolved :class:`FileLike`\n                instance and should return either a processed value or\n                coroutine.\n            overwrite: When ``True`` the loader replaces any existing\n                registration for ``ext``.\n        \"\"\"\n        from lzl.io.file.registry import register_loader\n        register_loader(ext, loader, overwrite)\n\n    # Pydantic methods\n    if PYDANTIC_VERSION == 2:\n        from pydantic_core import core_schema, SchemaSerializer\n        from pydantic.annotated_handlers import GetCoreSchemaHandler, GetJsonSchemaHandler\n        from pydantic.json_schema import JsonSchemaValue\n\n        @classmethod\n        def __get_pydantic_json_schema__(\n            cls, core_schema: core_schema.CoreSchema, handler: GetJsonSchemaHandler\n        ) -&gt; JsonSchemaValue:\n\n            field_schema = handler(core_schema)\n            field_schema.update(format = 'path', type = 'string')\n            return field_schema\n\n        @classmethod\n        def __get_pydantic_core_schema__(\n            cls, \n            source: type[t.Any], \n            handler: GetCoreSchemaHandler\n        ) -&gt; core_schema.CoreSchema:\n            \"\"\"Return the Pydantic v2 CoreSchema for :class:`File` fields.\"\"\"\n            from pydantic_core import core_schema, SchemaSerializer\n            schema = core_schema.with_info_plain_validator_function(\n                cls._validate,\n                serialization = core_schema.to_string_ser_schema(),\n            )\n            cls.__pydantic_serializer__ = SchemaSerializer(schema)\n            return schema\n\n\n        @classmethod\n        def _validate(cls, __input_value: t.Any, _: core_schema.ValidationInfo) -&gt; FileLike:\n            \"\"\"Pydantic validator that coerces inputs into :class:`File` objects.\"\"\"\n            return cls._get_filelike(__input_value) if __input_value is not None else None\n\n\n        def __hash__(self: FileLike) -&gt; int:\n            return hash(self.as_posix())\n\n\n    else:\n        @classmethod\n        def __get_validators__(cls):\n            yield cls.validate\n\n        @classmethod\n        def validate(cls, v: t.Union[FileLike, t.Any]) -&gt; FileLike:\n            return cls._get_filelike(v) if v is not None else None\n\n        @classmethod\n        def __modify_schema__(cls, field_schema: t.Dict[str, t.Any]) -&gt; None:\n            field_schema.update(\n                type='string',\n                format='binary',\n            )\n</code></pre>"},{"location":"api/lzl/io/file/#lzl.io.file.File.get_object_size","title":"<code>get_object_size(obj)</code>  <code>classmethod</code>","text":"<p>Return a convenience wrapper reporting object size in bytes.</p> Source code in <code>src/lzl/io/file/main.py</code> <pre><code>@classmethod\ndef get_object_size(cls, obj: t.Any) -&gt; 'ObjectSize':\n    \"\"\"Return a convenience wrapper reporting object size in bytes.\"\"\"\n    from .types.misc import ObjectSize\n    return ObjectSize(obj)\n</code></pre>"},{"location":"api/lzl/io/file/#lzl.io.file.File.get_dir","title":"<code>get_dir(path)</code>  <code>classmethod</code>","text":"<p>Return the parent directory for the provided path-like value.</p> Source code in <code>src/lzl/io/file/main.py</code> <pre><code>@classmethod\ndef get_dir(cls, path: 'PathLike') -&gt; 'FileLike':\n    \"\"\"Return the parent directory for the provided path-like value.\"\"\"\n    new = cls._get_filelike(path)\n    return new if new.is_dir() else new.parent\n</code></pre>"},{"location":"api/lzl/io/file/#lzl.io.file.File.register_loader","title":"<code>register_loader(ext, loader, overwrite=None)</code>  <code>classmethod</code>","text":"<p>Register a loader callback for the given file extension.</p> <p>Parameters:</p> Name Type Description Default <code>ext</code> <code>str</code> <p>Extension (<code>.json</code>, <code>.csv</code>\u2026) to register the loader against.  A leading dot is optional.</p> required <code>loader</code> <code>Union[Callable[['FileLike'], None], Awaitable['FileLike', None]]</code> <p>Callable that receives the resolved :class:<code>FileLike</code> instance and should return either a processed value or coroutine.</p> required <code>overwrite</code> <code>Optional[bool]</code> <p>When <code>True</code> the loader replaces any existing registration for <code>ext</code>.</p> <code>None</code> Source code in <code>src/lzl/io/file/main.py</code> <pre><code>@classmethod\ndef register_loader(cls, ext: str, loader: t.Union[t.Callable[['FileLike'], None], t.Awaitable['FileLike', None]], overwrite: t.Optional[bool] = None) -&gt; None:\n    \"\"\"Register a loader callback for the given file extension.\n\n    Args:\n        ext: Extension (``.json``, ``.csv``\u2026) to register the loader\n            against.  A leading dot is optional.\n        loader: Callable that receives the resolved :class:`FileLike`\n            instance and should return either a processed value or\n            coroutine.\n        overwrite: When ``True`` the loader replaces any existing\n            registration for ``ext``.\n    \"\"\"\n    from lzl.io.file.registry import register_loader\n    register_loader(ext, loader, overwrite)\n</code></pre>"},{"location":"api/lzl/io/file/#supported-schemes","title":"Supported Schemes","text":"<ul> <li>Local Files: <code>/path/to/file</code>, <code>relative/path</code></li> <li>AWS S3: <code>s3://bucket/key</code></li> <li>MinIO: <code>minio://bucket/key</code></li> <li>Cloudflare R2: <code>r2://bucket/key</code></li> </ul>"},{"location":"api/lzl/io/file/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzl/io/file/#basic-file-io","title":"Basic File I/O","text":"<pre><code>from lzl.io import File\n\n# Write text (sync)\nFile(\"data.txt\").write_text(\"Hello World\")\n\n# Read text (async)\ncontent = await File(\"data.txt\").async_read_text()\n\n# Check existence\nif await File(\"data.txt\").async_exists():\n    print(\"File exists!\")\n</code></pre>"},{"location":"api/lzl/io/file/#cloud-storage-s3","title":"Cloud Storage (S3)","text":"<pre><code>from lzl.io import File\n\n# Working with S3 paths\ns3_file = File(\"s3://my-bucket/data.csv\")\n\n# Read bytes\ndata = await s3_file.read_bytes()\n\n# Get metadata\nsize = s3_file.size\nlast_modified = s3_file.stat().st_mtime\n</code></pre>"},{"location":"api/lzl/io/file/#pydantic-integration","title":"Pydantic Integration","text":"<p><code>File</code> is fully compatible with Pydantic v1 and v2, making it ideal for configuration models.</p> <pre><code>from pydantic import BaseModel\nfrom lzl.io import File\n\nclass Config(BaseModel):\n    dataset_path: File\n    output_dir: File\n\n# Validates and converts strings to File objects\nconfig = Config(\n    dataset_path=\"s3://data/sets/train.parquet\",\n    output_dir=\"/tmp/output\"\n)\n\nprint(config.dataset_path.scheme) # 's3'\n</code></pre>"},{"location":"api/lzl/io/file/#custom-loaders","title":"Custom Loaders","text":"<p>You can register custom loaders for specific file extensions.</p> <pre><code>from lzl.io import File\nimport json\n\ndef load_json(file: File):\n    return json.loads(file.read_text())\n\n# Register the loader\nFile.register_loader(\".json\", load_json)\n\n# Now you can load directly (implementation dependent on registered hooks)\n# data = File(\"config.json\").load() \n</code></pre>"},{"location":"api/lzl/io/file/#advanced-features","title":"Advanced Features","text":""},{"location":"api/lzl/io/file/#directory-management","title":"Directory Management","text":"<pre><code># Get the parent directory\nparent = File.get_dir(\"path/to/file.txt\")\n\n# Check object size\nsize = File.get_object_size(\"some data\")\nprint(f\"Size: {size.human_readable}\")\n</code></pre>"},{"location":"api/lzl/io/file/#spec-and-path-types","title":"Spec and Path Types","text":"<p>Deep dive into the underlying path implementations and specifications.</p>"},{"location":"api/lzl/io/file/#lzl.io.file.spec.main","title":"<code>lzl.io.file.spec.main</code>","text":"<p>The Core File Spec for Cloud Filesystems</p>"},{"location":"api/lzl/io/file/#lzl.io.file.spec.main.as_path","title":"<code>as_path(path)</code>","text":"<p>Given a path-like object, return a path-like object</p> <p>Create a generic <code>pathlib.Path</code>-like abstraction. Depending on the input (e.g. <code>gs://</code>, <code>github://</code>, <code>ResourcePath</code>,...), the system (Windows, Linux,...), the function will create the right pathlib-like abstraction.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>PathLike</code> <p>Pathlike object.</p> required <p>Returns:</p> Type Description <code>FileLike</code> <p>A pathlib-like abstraction.</p> Source code in <code>src/lzl/io/file/spec/main.py</code> <pre><code>def as_path(path: PathLike) -&gt; FileLike:\n    \"\"\"\n    Given a path-like object, return a path-like object\n\n    Create a generic `pathlib.Path`-like abstraction.\n    Depending on the input (e.g. `gs://`, `github://`, `ResourcePath`,...), the\n    system (Windows, Linux,...), the function will create the right pathlib-like\n    abstraction.\n\n    Args:\n      path (PathLike): Pathlike object.\n\n    Returns:\n      A pathlib-like abstraction.\n    \"\"\"\n    if isinstance(path, str):\n        uri_splits = path.split('://', maxsplit=1)\n        if len(uri_splits) &gt; 1:    \n            # str is URI (e.g. `gs://`, `github://`,...)\n            return PREFIXES_TO_FP[f'{uri_splits[0]}://'](path)\n        return FilePath(path)\n    elif isinstance(path, _FILESPEC_CLS):\n        return path\n    elif isinstance(path, os.PathLike):\n        return FilePath(path)\n    else: raise TypeError(f'Invalid path type: {path!r}')\n</code></pre>"},{"location":"api/lzl/io/file/#lzl.io.file.spec.main.resolve_relative","title":"<code>resolve_relative(filepath)</code>","text":"<p>If the filepath is a relative path, convert it to an absolute path</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>PathLike</code> <p>The path to the file you want to resolve.</p> required <p>Returns:</p> Type Description <code>str</code> <p>A string.</p> Source code in <code>src/lzl/io/file/spec/main.py</code> <pre><code>def resolve_relative(filepath: PathLike) -&gt; str:\n    \"\"\"\n    If the filepath is a relative path, convert it to an absolute path\n\n    Args:\n      filepath (PathLike): The path to the file you want to resolve.\n\n    Returns:\n      A string.\n    \"\"\"\n    if not isinstance(filepath, str): filepath = filepath.as_posix()\n    if '://' in filepath: return filepath\n    if filepath.startswith('~'): filepath = filepath.replace('~', get_userhome(), 1)\n    elif filepath.startswith('../'): filepath = filepath.replace('..', get_cwd(), 1)\n    elif filepath.startswith('..'): filepath = filepath.replace('..', f'{pathlib.Path(get_cwd()).parent.parent.as_posix()}/', 1)\n    elif filepath.startswith('./'): filepath = filepath.replace('.', get_cwd(), 1)\n    elif filepath.startswith('.'): filepath = filepath.replace('.', f'{pathlib.Path(get_cwd()).parent.as_posix()}/', 1)\n    return filepath\n</code></pre>"},{"location":"api/lzl/io/file/#lzl.io.file.spec.main.get_filelike","title":"<code>get_filelike(path)</code>","text":"<p>Transforms the path into a FileLike</p> Source code in <code>src/lzl/io/file/spec/main.py</code> <pre><code>def get_filelike(path: PathLike) -&gt; FileLike:\n    \"\"\"\n    Transforms the path into a FileLike\n    \"\"\"\n    if hasattr(path, 'is_fsspec'): return path\n    if hasattr(path, 'as_posix'): return get_pathlike(path.as_posix())\n    if isinstance(path, str): return get_pathlike(path)\n    if hasattr(path, 'file') and hasattr(getattr(path, 'file'), 'name'): \n        return get_pathlike(path.file.name)\n    return get_pathlike(path.name) if hasattr(path, 'name') else path\n</code></pre>"},{"location":"api/lzl/io/file/#lzl.io.file.path","title":"<code>lzl.io.file.path</code>","text":""},{"location":"api/lzl/io/file/#configuration","title":"Configuration","text":"<p>Configure storage backends and behavior.</p>"},{"location":"api/lzl/io/file/#lzl.io.file.configs","title":"<code>lzl.io.file.configs</code>","text":""},{"location":"api/lzl/io/file/#utilities","title":"Utilities","text":"<p>Helper functions for file operations.</p>"},{"location":"api/lzl/io/file/#lzl.io.file.utils","title":"<code>lzl.io.file.utils</code>","text":""},{"location":"api/lzl/io/persistence/","title":"lzl.io.persistence - Data Persistence","text":"<p>The <code>lzl.io.persistence</code> module offers robust persistence mechanisms, providing a dictionary-like interface backed by various storage engines (SQLite, Redis, Object Storage). It supports caching, asynchronous access, and data serialization.</p>"},{"location":"api/lzl/io/persistence/#persistent-dictionary","title":"Persistent Dictionary","text":"<p>The <code>PersistentDict</code> is the core class. It mimics a standard Python dictionary but persists its contents.</p>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main","title":"<code>lzl.io.persistence.main</code>","text":""},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict","title":"<code>PersistentDict</code>","text":"<p>               Bases: <code>MutableMapping</code>, <code>MutableMapping[KT, VT]</code></p> <p>Dictionary-like fa\u00e7ade around the configured persistence backend.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>class PersistentDict(collections.abc.MutableMapping, MutableMapping[KT, VT]):\n    \"\"\"Dictionary-like fa\u00e7ade around the configured persistence backend.\"\"\"\n\n    backend_type: Optional[str] = 'auto'\n    base_class: Optional[Type['BackendT']] = None\n\n    def __init__(\n        self,\n        name: Optional[str] = None,\n        serializer: Optional[str] = None,\n        serializer_kwargs: Optional[Dict[str, Any]] = None,\n        base_key: Optional[str] = None,\n        async_enabled: Optional[bool] = False,\n        settings: Optional['BaseSettings'] = None,\n        backend: Optional['BackendT'] = None,\n        backend_type: Optional[str] = None,\n        metric_types: Optional[Dict[str, Union[str, Type['MetricT']]]] = None,\n        **kwargs,\n    ):\n        \"\"\"Initialise a new persistent dictionary instance.\"\"\"\n        if 'new_base' in kwargs:\n            self._child_init(**kwargs)\n        else:\n            self._new_init_(\n                name = name,\n                serializer = serializer,\n                serializer_kwargs = serializer_kwargs,\n                base_key = base_key,\n                async_enabled = async_enabled,\n                settings = settings,\n                backend = backend,\n                backend_type = backend_type,\n                metric_types = metric_types,\n                **kwargs,\n            )\n\n\n    def _new_init_(\n        self,\n        name: Optional[str] = None,\n        serializer: Optional[str] = None,\n        serializer_kwargs: Optional[Dict[str, Any]] = None,\n        base_key: Optional[str] = None,\n        async_enabled: Optional[bool] = False,\n        settings: Optional['BaseSettings'] = None,\n        backend: Optional['BackendT'] = None,\n        backend_type: Optional[str] = None,\n        metric_types: Optional[Dict[str, Union[str, Type['MetricT']]]] = None,\n        **kwargs,\n    ):\n        \"\"\"Perform the default initialisation path for the dictionary.\"\"\"\n        if backend_type is not None: self.backend_type = backend_type\n        if backend is not None:\n            self.base_class = lazy_import(backend) if isinstance(backend, str) else backend\n        if self.base_class is None:\n            self.base_class = self.get_backend_class(base_key = base_key, **kwargs)\n        self.name = name\n        self.base_key = base_key\n        self.settings = settings\n\n        # Allow for handling of parent/child keys\n        # Maybe do something for deeply nested keys\n        self.parent_base_key = kwargs.pop('parent_base_key', None)\n        self.child_base_key = kwargs.pop('child_base_key', None)\n        self.is_child_cache = self.child_base_key is not None\n\n        self._kwargs = kwargs\n        self._kwargs['serializer'] = serializer\n        self._kwargs['serializer_kwargs'] = serializer_kwargs\n        self.base = self.base_class(\n            name = self.name,\n            base_key = self.base_key,\n            async_enabled = async_enabled,\n            settings = self.settings,\n            **self._kwargs,\n        )\n        self._metric_types: Dict[str, Type['MetricT']] = metric_types or {}\n        self._init_ctx_()\n\n    def _child_init(\n        self,\n        parent: 'PersistentDict',\n        new_base: 'BackendT',\n        **kwargs,\n    ):\n        \"\"\"Create a child dictionary linked to the provided ``parent``.\"\"\"\n        self.name = kwargs.get('name') or parent.name\n        self.base_key = kwargs.get('base_key') or parent.base_key\n        self.settings = kwargs.get('settings') or parent.settings\n        self.base_class = kwargs.get('base_class') or parent.base_class\n        self.parent_base_key = kwargs.get('parent_base_key') or parent.base_key\n        self.child_base_key = kwargs.get('child_base_key') or parent.base_key\n        self.is_child_cache = True\n        self._metric_types: Dict[str, Type['MetricT']] = kwargs.get('metric_types') or copy.deepcopy(parent._metric_types)\n        self.base = new_base\n\n        # self.async_enabled = kwargs.get('async_enabled', parent.async_enabled)\n        # self._kwargs = copy.deepcopy(parent._kwargs)\n        self._kwargs = parent._kwargs.copy()\n        self._kwargs.update(kwargs)\n        self._init_ctx_()\n\n\n    def _init_ctx_(self):\n        \"\"\"\n        Initializes the context\n        \"\"\"\n        self._mutation_tracker: Dict[KT, VT] = {}\n        self._mutation_hashes: Dict[str, str] = {}\n\n        # V2 Mutation Tracking with Context Manager  \n        self._in_context: bool = False\n        self._temporal_dict: Dict[KT, VT] = {}\n\n        if self._metric_types:\n            for k, v in self._metric_types.items():\n                if isinstance(v, str): v = lazy_import(v)\n                self._metric_types[k] = v\n\n        if is_in_async_loop():\n            from lzo.utils import aioexit\n            aioexit.register(self.aflush)\n        else:\n            atexit.register(self.flush)\n\n\n\n    @classmethod\n    def register_backend(cls, name: str, backend: Union[str, Type['BackendT']]):\n        \"\"\"\n        Registers a Backend\n        \"\"\"\n        global RegisteredBackends\n        RegisteredBackends[name] = backend\n\n    def get_backend_class(self, base_key: Optional[str] = None, **kwargs) -&gt; Type['BackendT']:\n        # sourcery skip: assign-if-exp, hoist-similar-statement-from-if, reintroduce-else, swap-nested-ifs\n        \"\"\"\n        Returns the Backend Class\n        \"\"\"\n        if self.backend_type in RegisteredBackends:\n            bt = RegisteredBackends[self.backend_type]\n            return lazy_import(bt) if isinstance(bt, str) else bt\n        # if self.backend_type == 'local':\n        #     return LocalStatefulBackend\n        # elif self.backend_type == 'redis':\n        #     return RedisStatefulBackend\n        if self.backend_type == 'auto':\n            if base_key is not None and '://' in base_key:\n                if base_key.startswith('sqlite://'):\n                    return SqliteStatefulBackend\n                return ObjStorageStatefulBackend\n\n            with contextlib.suppress(Exception):\n                import kvdb\n                if kvdb.is_available(url = kwargs.get('url')):\n                    from kvdb.components.persistence import KVDBStatefulBackend\n                    return KVDBStatefulBackend\n            with contextlib.suppress(Exception):\n                from lazyops.utils.lazy import get_keydb_enabled\n                if get_keydb_enabled():\n                    return RedisStatefulBackend\n            logger.warning('Defaulting to Local Stateful Backend')\n            return LocalStatefulBackend\n        raise NotImplementedError(f'Backend Type {self.backend_type} is not implemented')\n\n    def get_metric_class(self, kind: str, **kwargs) -&gt; Type['MetricT']:\n        \"\"\"\n        Metric Class\n        \"\"\"\n        return self._metric_types.get(kind, RegisteredMetricTypes[kind])\n\n\n    @property\n    def compression_level(self) -&gt; Optional[int]:\n        \"\"\"\n        Returns the Compression Level\n        \"\"\"\n        return self.base.serializer.compression_level\n\n    @property\n    def cache_save_key(self) -&gt; str:\n        \"\"\"\n        Returns the cache save key that can be used to save the cache file for globbing\n        \"\"\"\n        if not self.is_child_cache: return self.base_key\n        return f'p:{self.parent_base_key}:c:{self.child_base_key}'\n\n\n    def get_child_kwargs(self, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Returns the Child Kwargs\n        \"\"\"\n        base_kwargs = self._kwargs.copy()\n        if kwargs: base_kwargs.update(kwargs)\n        if 'settings' not in base_kwargs:\n            base_kwargs['settings'] = self.settings\n        if 'name' not in base_kwargs:\n            base_kwargs['name'] = self.name\n        if 'backend_type' not in base_kwargs and 'backend' not in base_kwargs:\n            base_kwargs['backend'] = self.base_class\n        if 'async_enabled' not in base_kwargs:\n            base_kwargs['async_enabled'] = self.base.async_enabled\n        return base_kwargs\n\n    def get_child(self, key: KT, **kwargs) -&gt; 'PersistentDict':\n        \"\"\"Return a scoped child :class:`PersistentDict` rooted under ``key``.\"\"\"\n        if hasattr(self.base, 'get_child'):\n            new_base = self.base.get_child(key, **kwargs)\n            return self.__class__(\n                parent = self,\n                new_base = new_base,\n                **kwargs,\n            )\n\n        base_key = f'{self.base_key}:{key}' if self.base_key else key\n        base_kwargs = self.get_child_kwargs(**kwargs)\n        return self.__class__(base_key = base_key, parent_base_key = self.base_key, child_base_key = key, **base_kwargs)\n\n    def get_key(self, key: str) -&gt; str:\n        \"\"\"\n        Gets a Key\n        \"\"\"\n        return self.base.get_key(key)\n\n    def get(self, key: KT, default: Optional[VT] = None, _raw: Optional[bool] = None, **kwargs) -&gt; Optional[VT]:\n        \"\"\"Return the value stored for ``key`` or ``default`` when missing.\"\"\"\n        self._save_mutation_objects(key)\n        return self.base.get(key, default = default, _raw = _raw, **kwargs)\n\n    def get_values(self, keys: Iterable[str], **kwargs) -&gt; List[VT]:\n        \"\"\"Bulk fetch helpers mirroring :meth:`get` for multiple keys.\"\"\"\n        self._save_mutation_objects(*keys)\n        return self.base.get_values(keys, **kwargs)\n\n    def fetch(self, key: KT, _raw: Optional[bool] = None, **kwargs) -&gt; Optional[VT]:\n        \"\"\"Return ``None`` for missing keys instead of raising errors.\"\"\"\n        return self.get(key, _raw = _raw, **kwargs) if self.contains(key) else None\n\n    def set(self, key: KT, value: Any, ex: Optional[Union[float, int]] = None, _raw: Optional[bool] = None, **kwargs) -&gt; Optional[KT]:\n        \"\"\"Persist ``value`` under ``key`` optionally expiring after ``ex`` seconds.\"\"\"\n        if self.base.async_enabled and is_in_async_loop():\n            ThreadPool.create_background_task(self.base.aset(key, value, ex = ex, _raw = _raw, **kwargs))\n        else:\n            return self.base.set(key, value, ex = ex, _raw = _raw, **kwargs)\n\n    def set_batch(self, data: Dict[str, Any], **kwargs) -&gt; None:\n        \"\"\"Store a mapping of key/value pairs in a single backend call.\"\"\"\n        if self.base.async_enabled:\n            ThreadPool.create_background_task(self.base.aset_batch(data, **kwargs))\n        else:\n            self.base.set_batch(data, **kwargs)\n\n    def delete(self, key: KT, **kwargs) -&gt; None:\n        \"\"\"Remove ``key`` from the persistence backend.\"\"\"\n        if self.base.async_enabled and is_in_async_loop():\n            ThreadPool.create_background_task(self.base.adelete(key, **kwargs))\n        else:\n            self.base.delete(key, **kwargs)\n\n    def contains(self, key: KT, **kwargs) -&gt; bool:\n        \"\"\"Return ``True`` when the backend currently stores ``key``.\"\"\"\n        return self.base.contains(key, **kwargs)\n\n    def clear(self, *keys, **kwargs) -&gt; None:\n        \"\"\"Clear all stored items or only the provided ``keys`` when supplied.\"\"\"\n        if self.base.async_enabled and is_in_async_loop():\n            ThreadPool.create_background_task(self.base.clear(*keys, **kwargs))\n        else:\n            self.base.clear(*keys, **kwargs)\n\n    async def aget(self, key: KT, default: Optional[VT] = None, _raw: Optional[bool] = None, **kwargs) -&gt; Optional[VT]:\n        \"\"\"Async equivalent of :meth:`get` for coroutine contexts.\"\"\"\n        await self._asave_mutation_objects(key)\n        return await self.base.aget(key, default = default, _raw = _raw, **kwargs)\n\n    async def aget_values(self, keys: Iterable[KT], **kwargs) -&gt; List[VT]:\n        \"\"\"Async variant of :meth:`get_values`.\"\"\"\n        await self._asave_mutation_objects(*keys)\n        return await self.base.aget_values(keys,  **kwargs)\n\n    async def afetch(self, key: KT, _raw: Optional[bool] = None, **kwargs) -&gt; Optional[VT]:\n        \"\"\"Async variant of :meth:`fetch`.\"\"\"\n        return await self.aget(key, _raw = _raw, **kwargs) if await self.acontains(key) else None\n\n    async def aset(self, key: KT, value: VT, ex: Optional[Union[float, int]] = None, _raw: Optional[bool] = None, **kwargs) -&gt; Optional[KT]:\n        \"\"\"\n        Saves a Value to the DB\n        \"\"\"\n        return await self.base.aset(key, value, ex = ex, _raw = _raw, **kwargs)\n\n    async def aset_batch(self, data: Dict[KT, VT], **kwargs) -&gt; None:\n        \"\"\"\n        Saves a Value to the DB\n        \"\"\"\n        await self.base.aset_batch(data, **kwargs)\n\n    async def adelete(self, key: KT, **kwargs) -&gt; None:\n        \"\"\"\n        Deletes a Value from the DB\n        \"\"\"\n        await self.base.adelete(key, **kwargs)\n\n    async def acontains(self, key: KT, **kwargs) -&gt; bool:\n        \"\"\"\n        Returns True if the Cache contains the Key\n        \"\"\"\n        return await self.base.acontains(key, **kwargs)\n\n    async def aclear(self, *keys: KT, **kwargs) -&gt; None:\n        \"\"\"\n        Clears the Cache\n        \"\"\"\n        await self.base.aclear(*keys, **kwargs)\n\n    def get_all_data(self, **kwargs) -&gt; Dict[KT, VT]:\n        \"\"\"\n        Loads all the Data\n        \"\"\"\n        self._save_mutation_objects()\n        return self.base.get_all_data(**kwargs)\n\n    def get_all_keys(self, **kwargs) -&gt; Iterable[KT]:\n        \"\"\"\n        Returns all the Keys\n        \"\"\"\n        return self.base.get_all_keys(**kwargs)\n\n    def get_keys(self, pattern: str, exclude_base_key: Optional[bool] = None, **kwargs) -&gt; List[KT]:\n        \"\"\"\n        Returns all the Keys\n        \"\"\"\n        return self.base.get_keys(pattern, exclude_base_key = exclude_base_key, **kwargs)\n\n    def get_all_values(self, **kwargs) -&gt; Iterable[VT]:\n        \"\"\"\n        Returns all the Values\n        \"\"\"\n        self._save_mutation_objects()\n        return self.base.get_all_values(**kwargs)\n\n    async def aget_all_data(self, **kwargs) -&gt; Dict[KT, VT]:\n        \"\"\"\n        Loads all the Data\n        \"\"\"\n        await self._asave_mutation_objects()\n        return await self.base.aget_all_data(**kwargs)\n\n    async def aget_all_keys(self, **kwargs) -&gt; Iterable[KT]:\n        \"\"\"\n        Returns all the Keys\n        \"\"\"\n        return await self.base.aget_all_keys(**kwargs)\n\n    async def aget_keys(self, pattern: str, exclude_base_key: Optional[bool] = None, **kwargs) -&gt; List[KT]:\n        \"\"\"\n        Returns all the Keys\n        \"\"\"\n        return await self.base.aget_keys(pattern, exclude_base_key = exclude_base_key, **kwargs)\n\n    async def aget_all_values(self, **kwargs) -&gt; Iterable[VT]:\n        \"\"\"\n        Returns all the Values\n        \"\"\"\n        await self._asave_mutation_objects()\n        return await self.base.aget_all_values(**kwargs)\n\n    def keys(self, **kwargs) -&gt; Iterable[KT]:\n        \"\"\"\n        Returns the Keys\n        \"\"\"\n        return self.base.keys(**kwargs)\n\n    def values(self, **kwargs) -&gt; Iterable[VT]:\n        \"\"\"\n        Returns the Values\n        \"\"\"\n        self._save_mutation_objects()\n        return self.base.values(**kwargs)\n\n    def items(self, iterable: Optional[bool] = True, **kwargs) -&gt; Dict[KT, VT]:\n        \"\"\"\n        Returns the Items\n        \"\"\"\n        self._save_mutation_objects()\n        return self.base.items(iterable = iterable, **kwargs)\n\n    async def akeys(self, **kwargs) -&gt; Iterable[KT]:\n        \"\"\"\n        Returns the Keys\n        \"\"\"\n        return await self.base.akeys(**kwargs)\n\n    async def avalues(self, **kwargs) -&gt; Iterable[VT]:\n        \"\"\"\n        Returns the Values\n        \"\"\"\n        await self._asave_mutation_objects()\n        return await self.base.avalues(**kwargs)\n\n    @overload\n    async def aitems(self, iterable: None = None, **kwargs) -&gt; Iterable[Tuple[KT, VT]]: \n        \"\"\"\n        Returns the Items\n        \"\"\"\n        ...\n\n    @overload\n    async def aitems(self, iterable: bool = False, **kwargs) -&gt; Dict[KT, VT]:\n        \"\"\"\n        Returns the Items\n        \"\"\"\n        ...\n\n\n    async def aitems(self, iterable: Optional[bool] = True, **kwargs) -&gt; Union[Iterable[Tuple[KT, VT]], Dict[KT, VT]]:\n        \"\"\"\n        Returns the Items\n        \"\"\"\n        await self._asave_mutation_objects()\n        return await self.base.aitems(iterable = iterable, **kwargs)\n\n    def expire(self, key: KT, timeout: Optional[int] = None, expiration: Optional[int] = None, **kwargs) -&gt; None:\n        \"\"\"\n        Expires a Key\n        \"\"\"\n        # Add a check to see if expiration or timeout is set\n        if 'ex' in kwargs:\n            expiration = kwargs.pop('ex')\n        ex = expiration if expiration is not None else timeout\n        self.base.expire(key, ex = ex, **kwargs)\n\n    async def aexpire(self, key: KT, timeout: Optional[int] = None, expiration: Optional[int] = None, **kwargs) -&gt; None:\n        \"\"\"\n        Expires a Key\n        \"\"\"\n        if 'ex' in kwargs:\n            expiration = kwargs.pop('ex')\n        ex = expiration if expiration is not None else timeout\n        await self.base.aexpire(key, ex = ex, **kwargs)\n\n    @contextlib.contextmanager\n    def track_changes(self, key: KT, func: str, *args, **kwargs):\n        \"\"\"\n        Tracks Changes\n        \"\"\"\n        try:\n            value = None\n            if key in self._mutation_tracker:\n                autologger.info(f'tracked {func} {key} (cached) {self._mutation_tracker[key]}')\n                if self.base.create_hash(self._mutation_tracker[key]) == self._mutation_hashes[key]:\n                    value = self._mutation_tracker[key]\n                else:\n                    autologger.info(f'tracked {func} {key} (changed). Saving')\n                    self.base.set(key, self._mutation_tracker[key])\n                    value = self._mutation_tracker.pop(key)\n                    self._mutation_hashes.pop(key)\n\n            if value is None:\n                autologger.info(f'tracked {func} {key}')\n                value = getattr(self.base, func)(key, *args, **kwargs)\n            yield value\n        finally:\n            if key not in self._mutation_hashes:\n                self._mutation_hashes[key] = self.base.create_hash(value)\n                self._mutation_tracker[key] = value\n            if self.base.create_hash(value) != self._mutation_hashes[key]:\n                autologger.info(f'tracked {func} {key} (post-changed). Saving')\n                self._save_mutation_objects(key)\n\n\n    @contextlib.asynccontextmanager\n    async def atrack_changes(self, key: KT, func: str, *args, **kwargs):\n        \"\"\"\n        Tracks Changes\n        \"\"\"\n        try:\n            value = None\n            if key in self._mutation_tracker:\n                autologger.info(f'tracked {func} {key} (cached): {self._mutation_tracker[key]}')\n                if self.base.create_hash(self._mutation_tracker[key]) == self._mutation_hashes[key]:\n                    value = self._mutation_tracker[key]\n                else:\n                    autologger.info(f'tracked {func} {key} (changed). Saving')\n                    await self.base.aset(key, self._mutation_tracker[key])\n                    value = self._mutation_tracker.pop(key)\n                    self._mutation_hashes.pop(key)\n            if value is None:\n                autologger.info(f'tracked {func} {key}')\n                value = await getattr(self.base, func)(key, *args, **kwargs)\n            yield value\n        finally:\n            if key not in self._mutation_hashes:\n                self._mutation_hashes[key] = self.base.create_hash(value)\n                self._mutation_tracker[key] = value\n            if self.base.create_hash(value) != self._mutation_hashes[key]:\n                autologger.info(f'tracked {func} {key} (post-changed). Saving')\n                await self._asave_mutation_objects(key)\n\n    def setdefault(self, key: KT, default: Any = None, update_values: Optional[bool] = False, enforce_type: Optional[bool] = False) -&gt; Any:\n        \"\"\"\n        Sets a Default Value\n        \"\"\"\n        with self.track_changes(key, 'setdefault', default, update_values = update_values, enforce_type = enforce_type) as result:\n            return result\n\n    async def asetdefault(self, key: KT, default: Any = None, update_values: Optional[bool] = False, enforce_type: Optional[bool] = False) -&gt; Any:\n        \"\"\"\n        Sets a Default Value\n        \"\"\"\n        async with self.atrack_changes(key, 'asetdefault', default, update_values = update_values, enforce_type = enforce_type) as result:\n            return result\n\n\n    def update(self, data: Dict[str, Any], **kwargs) -&gt; None:\n        \"\"\"\n        Updates the Cache\n        \"\"\"\n        self._save_mutation_objects()\n        self.base.update(data, **kwargs)\n\n    async def aupdate(self, data: Dict[str, Any], **kwargs) -&gt; None:\n        \"\"\"\n        Updates the Cache\n        \"\"\"\n        await self._asave_mutation_objects()\n        await self.base.aupdate(data, **kwargs)\n\n\n    def update_key(self, key: str, data: Dict[str, Any], deep: Optional[bool] = True,  exclude_none: Optional[bool] = True, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Updates the Dict at the Key\n        \"\"\"\n        return self.base.update_key(key, data, deep = deep, exclude_none = exclude_none, **kwargs)\n\n    async def aupdate_key(self, key: str, data: Dict[str, Any], deep: Optional[bool] = True,  exclude_none: Optional[bool] = True, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        [Async] Updates the Dict at the Key\n        \"\"\"\n        return await self.base.aupdate_key(key, data, deep = deep, exclude_none = exclude_none, **kwargs)\n\n    def popitem(self, **kwargs) -&gt; Any:\n        \"\"\"\n        Pops an Item from the Cache\n        \"\"\"\n        return self.base.popitem(**kwargs)\n\n    async def apopitem(self, **kwargs) -&gt; Any:\n        \"\"\"\n        Pops an Item from the Cache\n        \"\"\"\n        return await self.base.apopitem(**kwargs)\n\n    def pop(self, key: KT, default: Optional[VT] = None, **kwargs) -&gt; VT:\n        \"\"\"\n        Pops an Item from the Cache\n        \"\"\"\n        return self.base.pop(key, default, **kwargs)\n\n    async def apop(self, key: KT, default: Optional[VT] = None, **kwargs) -&gt; VT:\n        \"\"\"\n        Pops an Item from the Cache\n        \"\"\"\n        return await self.base.apop(key, default, **kwargs)\n\n    # def __repr__(self):\n    #     \"\"\"\n    #     Returns the Representation of the Cache\n    #     \"\"\"\n    #     return repr(self.base)\n\n    def __repr__(self):\n        \"\"\"\n        Returns the Representation of the Cache\n        \"\"\"\n        if hasattr(self.base, '__repr__'):\n            return self.base.__repr__()\n        return f'{self.base_key}: {dict(self.items())}'\n\n    def _clear_from_mutation_tracker(self, key: KT):\n        \"\"\"\n        Clears the Mutation Tracker\n        \"\"\"\n        _ = self._mutation_tracker.pop(key, None)\n        _ = self._mutation_hashes.pop(key, None)\n\n    def _save_mutation_objects(self, *keys: str):\n        \"\"\"\n        Saves the Mutation Objects\n        \"\"\"\n        if not self._mutation_tracker: return\n        if keys:\n            for key in keys:\n                if key in self._mutation_tracker:\n                    self.base.set(key, self._mutation_tracker[key])\n                    self._clear_from_mutation_tracker(key)\n\n        else:\n            autologger.info(f'_save_mutation_objects: {list(self._mutation_tracker.keys())}')\n            try:\n                self.base.set_batch(self._mutation_tracker)\n                self._mutation_tracker = {}\n                self._mutation_hashes = {}\n            except RuntimeError as e:\n                logger.warning(f'Unable to Save {len(self._mutation_tracker)} Mutation Objects: {e}')\n            except Exception as e:\n                logger.trace(f'Error Saving {len(self._mutation_tracker)} Mutation Objects:', e)\n                raise e\n        gc.collect()\n\n    async def _asave_mutation_objects(self, *keys: str):\n        \"\"\"\n        Saves the Mutation Objects\n        \"\"\"\n        if not self._mutation_tracker: return\n        if keys:\n            for key in keys:\n                if key in self._mutation_tracker:\n                    await self.base.aset(key, self._mutation_tracker[key])\n                    self._clear_from_mutation_tracker(key)\n        else:\n            autologger.info(f'_save_mutation_objects: {list(self._mutation_tracker.keys())}')\n            await self.base.aset_batch(self._mutation_tracker)\n            self._mutation_tracker = {}\n            self._mutation_hashes = {}\n        gc.collect()\n\n    \"\"\"\n    v2 Mutation Tracking\n    \"\"\"\n    # TODO: deal with atomicity across multiple threads/processes/workers\n\n    def _enter_context(self, timeout: Optional[float] = None, blocking: Optional[bool] = True, **kwargs) -&gt; bool:\n        \"\"\"\n        Enters the context\n        \"\"\"\n        if self.base.acquire_lock(timeout = timeout, blocking = blocking):\n            self._save_mutation_objects()\n            self._in_context = True\n            autologger.info(f'Entering Context: {self.name}/{self.base_key}')\n            return True\n        return False\n\n    def _exit_context(self):\n        \"\"\"\n        Exits the context\n        \"\"\"\n        autologger.info(f'Exiting Context: {self.name}/{self.base_key}')\n        autologger.info(self._temporal_dict, prefix = self.base_key, colored = True)\n        self.base.set_batch(self._temporal_dict)\n        self._temporal_dict.clear()\n        self.base.release_lock()\n        self._in_context = False\n\n    @contextlib.contextmanager\n    def acquire_context(self, timeout: Optional[float] = None, blocking: Optional[bool] = True, **kwargs):\n        \"\"\"\n        Acquires the context\n        \"\"\"\n        if self._enter_context(timeout = timeout, blocking = blocking, **kwargs):\n            try:\n                yield\n            finally:\n                self._exit_context()\n        else:\n            raise ContextError('Unable to acquire context due to concurrency')\n\n    async def _aenter_context(self, timeout: Optional[float] = None, blocking: Optional[bool] = True, **kwargs) -&gt; bool:\n        \"\"\"\n        Enters the context\n        \"\"\"\n        if await self.base.acquire_alock(timeout = timeout, blocking = blocking, **kwargs):\n            await self._asave_mutation_objects()\n            self._in_context = True\n            autologger.info(f'Entering Context: {self.name}/{self.base_key}')\n            return True\n        return False\n\n    async def _aexit_context(self):\n        \"\"\"\n        Exits the context\n        \"\"\"\n        autologger.info(f'Exiting Context: {self.name}/{self.base_key}')\n        autologger.info(self._temporal_dict, prefix = self.base_key, colored = True)\n        await self.base.aset_batch(self._temporal_dict)\n        self._temporal_dict.clear()\n        await self.base.release_alock()\n        self._in_context = False\n\n    async def acquire_acontext(self, timeout: Optional[float] = None, blocking: Optional[bool] = True, **kwargs):\n        \"\"\"\n        Acquires the context\n        \"\"\"\n        if await self._aenter_context(timeout = timeout, blocking = blocking, **kwargs):\n            try:\n                yield\n            finally:\n                await self._aexit_context()\n        else:\n            raise ContextError('Unable to acquire context due to concurrency')\n\n    def __getitem__(self, key: KT) -&gt; Union[VT, List[VT], Dict[KT, Union[List[VT], Dict[KT, VT]]]]:\n        \"\"\"\n        Gets an Item from the DB\n        \"\"\"\n        if self._in_context:\n            if key not in self._temporal_dict:\n                autologger.info(f'Loading {key}', prefix = f'{self.name}/{self.base_key}', colored = True)\n                self._temporal_dict[key] = self.base.get(key)\n            return self._temporal_dict[key]\n\n        with self.track_changes(key, '__getitem__') as result:\n            return result\n\n    def __setitem__(self, key: KT, value: VT):\n        \"\"\"\n        Sets an Item in the Cache\n        \"\"\"\n        if self._in_context:\n            autologger.info(f'Setting {key}: {value}', prefix = self.base_key, colored = True)\n            self._temporal_dict[key] = value\n            return\n\n        autologger.info(f'__setitem__ {key} {value}')\n        if key in self._mutation_tracker:\n            self._clear_from_mutation_tracker(key)\n        return self.base.__setitem__(key, value)\n\n    def __delitem__(self, key):\n        \"\"\"\n        Deletes an Item from the Cache\n        \"\"\"\n        if self._in_context:\n            autologger.info(f'Deleting {key}', prefix = self.base_key, colored = True)\n            del self._temporal_dict[key]\n            return\n\n        autologger.info(f'__delitem__ {key}')\n        if key in self._mutation_tracker:\n            self._clear_from_mutation_tracker(key)\n        return self.base.__delitem__(key)\n\n    def __contains__(self, key: KT):\n        \"\"\"\n        Returns True if the Cache contains the Key\n        \"\"\"\n        if self._in_context:\n            return key in self._temporal_dict\n        return self.base.contains(key)\n\n    def __iter__(self):\n        \"\"\"\n        Iterates over the Cache\n        \"\"\"\n        if self._in_context:\n            return iter(self._temporal_dict)\n        return iter(self.base.keys())\n\n    def __len__(self):\n        \"\"\"\n        Returns the Length of the Cache\n        \"\"\"\n        return len(self._temporal_dict) if self._in_context else len(self.base)\n\n    def __bool__(self):\n        \"\"\"\n        Returns True if the Cache is not Empty\n        \"\"\"\n        return bool(self.base.keys())\n\n    def __enter__(self):\n        \"\"\"\n        Enters the context\n        \"\"\"\n        if self._enter_context():\n            return self\n        raise ContextError('Unable to acquire context due to concurrency')\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"\n        Exits the context\n        \"\"\"\n        self._exit_context()\n\n    async def __aenter__(self):\n        \"\"\"\n        Enters the context\n        \"\"\"\n        if await self._aenter_context():\n            return self\n        raise ContextError('Unable to acquire context due to concurrency')\n\n    async def __aexit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"\n        Exits the context\n        \"\"\"\n        await self._aexit_context()\n\n    def length(self, **kwargs):\n        \"\"\"\n        Returns the Length of the Cache\n        \"\"\"\n        return self.base.length(**kwargs)\n\n    async def alength(self, **kwargs):\n        \"\"\"\n        Returns the Length of the Cache\n        \"\"\"\n        return await self.base.alength(**kwargs)\n\n    def migrate_compression(self, **kwargs):\n        \"\"\"\n        Migrates the compression\n        \"\"\"\n        return self.base.migrate_compression(**kwargs)\n\n    async def amigrate_compression(self, **kwargs):\n        \"\"\"\n        Migrates the compression\n        \"\"\"\n        return await self.base.amigrate_compression(**kwargs)\n\n    def flush(self, *keys: str):\n        \"\"\"\n        Finalize any in-memory objects\n        \"\"\"\n        if self.base.async_enabled and is_in_async_loop():\n            ThreadPool.create_background_task(self._asave_mutation_objects(*keys))\n        else:\n            self._save_mutation_objects(*keys)\n\n    async def aflush(self, *keys: str):\n        \"\"\"\n        Finalize any in-memory objects\n        \"\"\"\n        try:\n            import anyio\n            with anyio.move_on_after(2):\n                await self._asave_mutation_objects(*keys)\n        except ImportError:\n            await self._asave_mutation_objects(*keys)\n\n\n    def get_all_data_raw(self, exclude_base_key: Optional[bool] = False, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Loads all the Data\n        \"\"\"\n        return self.base.get_all_data_raw(exclude_base_key = exclude_base_key, **kwargs)\n\n    async def aget_all_data_raw(self, exclude_base_key: Optional[bool] = False, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Loads all the Data\n        \"\"\"\n        return await self.base.aget_all_data_raw(exclude_base_key = exclude_base_key, **kwargs)\n\n\n    def load_data_raw(self, data: Dict[str, Any], includes_base_key: Optional[bool] = False, **kwargs):\n        \"\"\"\n        Loads the Data\n        \"\"\"\n        self.base.load_data_raw(data, includes_base_key = includes_base_key, **kwargs)\n\n    async def aload_data_raw(self, data: Dict[str, Any], includes_base_key: Optional[bool] = False, **kwargs):\n        \"\"\"\n        Loads the Data\n        \"\"\"\n        await self.base.aload_data_raw(data, includes_base_key = includes_base_key, **kwargs)\n\n\n    def dump_data_raw(self, include_base_key: Optional[bool] = False, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Dumps the Data\n        \"\"\"\n        return self.base.dump_data_raw(include_base_key = include_base_key, **kwargs)\n\n    async def adump_data_raw(self, include_base_key: Optional[bool] = False, **kwargs) -&gt; Dict[str, Any]:\n        \"\"\"\n        Dumps the Data\n        \"\"\"\n        return await self.base.adump_data_raw(include_base_key = include_base_key, **kwargs)\n\n    def replicate_from(self, source: Any, **kwargs):\n        \"\"\"\n        Replicates the Data\n        \"\"\"\n        self.base.replicate_from(source, **kwargs)\n\n    async def areplicate_from(self, source: Any, **kwargs):\n        \"\"\"\n        Replicates the Data\n        \"\"\"\n        await self.base.areplicate_from(source, **kwargs)\n\n\n    \"\"\"\n    Math Related Methods\n    \"\"\"\n\n    def incr(self, key: KT, amount: Union[int, float] = 1, **kwargs) -&gt; Union[int, float]:\n        \"\"\"\n        Increments the value of the key by the given amount\n        \"\"\"\n        return self.base.incr(key, amount = amount, **kwargs)\n\n    async def aincr(self, key: KT, amount: Union[int, float] = 1, **kwargs) -&gt; Union[int, float]:\n        \"\"\"\n        Increments the value of the key by the given amount\n        \"\"\"\n        return await self.base.aincr(key, amount = amount, **kwargs)\n\n    def decr(self, key: KT, amount: Union[int, float] = 1, **kwargs) -&gt; Union[int, float]:\n        \"\"\"\n        Decrements the value of the key by the given amount\n        \"\"\"\n        return self.base.decr(key, amount = amount, **kwargs)\n\n    async def adecr(self, key: KT, amount: Union[int, float] = 1, **kwargs) -&gt; Union[int, float]:\n        \"\"\"\n        Decrements the value of the key by the given amount\n        \"\"\"\n        return await self.base.adecr(key, amount = amount, **kwargs)\n\n\n    \"\"\"\n    Set Operations\n    \"\"\"\n\n    def sadd(self, key: KT, *values: Any, **kwargs) -&gt; int:\n        \"\"\"\n        Adds the value to the set\n        \"\"\"\n        return self.base.sadd(key, *values, **kwargs)\n\n    async def asadd(self, key: KT, *value: Any, **kwargs) -&gt; int:\n        \"\"\"\n        Adds the value to the set\n        \"\"\"\n        return await self.base.asadd(key, *value, **kwargs)\n\n    def slength(self, key: KT, **kwargs) -&gt; int:\n        \"\"\"\n        Returns the length of the set\n        \"\"\"\n        return self.base.slength(key, **kwargs)\n\n    async def aslength(self, key: KT, **kwargs) -&gt; int:\n        \"\"\"\n        Returns the length of the set\n        \"\"\"\n        return await self.base.aslength(key, **kwargs)\n\n\n    def sismember(self, key: KT, value: Any, **kwargs) -&gt; bool:\n        \"\"\"\n        Returns whether the value is a member of the set\n        \"\"\"\n        return self.base.sismember(key, value, **kwargs)\n\n    async def asismember(self, key: KT, value: Any, **kwargs) -&gt; bool:\n        \"\"\"\n        Returns whether the value is a member of the set\n        \"\"\"\n        return await self.base.asismember(key, value, **kwargs)\n\n    def smembers(self, key: KT, **kwargs) -&gt; List[Any]:\n        \"\"\"\n        Returns the members of the set\n        \"\"\"\n        return self.base.smembers(key, **kwargs)\n\n    async def asembers(self, key: KT, **kwargs) -&gt; List[Any]:\n        \"\"\"\n        Returns the members of the set\n        \"\"\"\n        return await self.base.asembers(key, **kwargs)\n\n    def smismember(self, key: KT, *values: Any, **kwargs) -&gt; bool:\n        \"\"\"\n        Returns whether the values are members of the set\n        \"\"\"\n        return self.base.smismember(key, *values, **kwargs)\n\n    async def asmismember(self, key: KT, *values: Any, **kwargs) -&gt; bool:\n        \"\"\"\n        Returns whether the values are members of the set\n        \"\"\"\n        return await self.base.asmismember(key, *values, **kwargs)\n\n    def srem(self, key: KT, *values: Any, **kwargs) -&gt; int:\n        \"\"\"\n        Removes the value from the set\n        \"\"\"\n        return self.base.srem(key, *values, **kwargs)\n\n    async def asrem(self, key: KT, *values: Any, **kwargs) -&gt; int:\n        \"\"\"\n        Removes the value from the set\n        \"\"\"\n        return await self.base.asrem(key, *values, **kwargs)\n\n    def spop(self, key: KT, **kwargs) -&gt; Any:\n        \"\"\"\n        Removes and returns a random member of the set\n        \"\"\"\n        return self.base.spop(key, **kwargs)\n\n    async def aspop(self, key: KT, **kwargs) -&gt; Any:\n        \"\"\"\n        Removes and returns a random member of the set\n        \"\"\"\n        return await self.base.aspop(key, **kwargs) \n\n    \"\"\"\n    Copy Methods\n    \"\"\"\n\n    def copy(\n        self,\n        exclude: Optional[Set[str]] = None,\n        exclude_none: Optional[bool] = False,\n        **kwargs\n    ) -&gt; Dict[KT, VT]:\n        \"\"\"\n        Copies the current data and returns a Dict\n        \"\"\"\n        data = self.items()\n        if exclude is not None: data = {k: v for k, v in data.items() if k not in exclude}\n        if exclude_none: data = {k: v for k, v in data.items() if v is not None}\n        return data\n\n    async def acopy(\n        self,\n        exclude: Optional[Set[str]] = None,\n        exclude_none: Optional[bool] = False,\n        **kwargs\n    ) -&gt; Dict[KT, VT]:\n        \"\"\"\n        Copies the current data and returns a Dict\n        \"\"\"\n        data = await self.aitems()\n        if exclude is not None: data = {k: v for k, v in data.items() if k not in exclude}\n        if exclude_none: data = {k: v for k, v in data.items() if v is not None}\n        return data\n\n\n    \"\"\"\n    Schema Modification Methods\n    \"\"\"\n\n    def migrate_schema(self, schema_map: Dict[str, Any], overwrite: Optional[bool] = None, **kwargs) -&gt; None:\n        \"\"\"\n        Migrates the schema\n        \"\"\"\n        self.base.migrate_schema(schema_map, overwrite = overwrite, **kwargs)\n\n\n    async def amigrate_schema(self, schema_map: Dict[str, Any], overwrite: Optional[bool] = None, **kwargs) -&gt; None:\n        \"\"\"\n        Migrates the schema\n        \"\"\"\n        await self.base.amigrate_schema(schema_map, overwrite = overwrite, **kwargs)\n\n\n    def clone(\n        self, \n        target: Optional[Any], \n        target_base_key: Optional[str] = None,\n        schema_map: Optional[Dict[str, str]] = None,\n        overwrite: Optional[bool] = None, \n        **kwargs\n    ):\n        \"\"\"\n        Clones the data from the current PersistentDict to a new PersistentDict\n        \"\"\"\n        return self.base.clone(target = target, target_base_key = target_base_key, schema_map = schema_map, overwrite = overwrite, **kwargs)\n\n    @overload\n    async def aclone(\n        self,\n        target: str, \n        target_base_key: Optional[str] = None,\n        target_db_id: Optional[int] = None,\n        source_url: Optional[str] = None,\n        source_base_key: Optional[str] = None,\n        schema_map: Optional[Dict[str, str]] = None,\n        overwrite: Optional[bool] = None, \n        excluded: Optional[Union[str, List[str]]] = None,\n        filter_function: Optional[Callable[[str], bool]] = None,\n        raise_errors: Optional[bool] = True,\n        verbose: Optional[bool] = True,\n        **kwargs\n    ) -&gt; Dict[str, Union[List[str], int, float]]:\n        \"\"\"\n        Clones the data from the current PersistentDict to a new PersistentDict\n        \"\"\"\n        ...\n\n    async def aclone(\n        self,\n        target: Optional[Any], \n        target_base_key: Optional[str] = None,\n        schema_map: Optional[Dict[str, str]] = None,\n        overwrite: Optional[bool] = None, \n        **kwargs\n    ):\n        \"\"\"\n        Clones the data from the current PersistentDict to a new PersistentDict\n        \"\"\"\n        return await self.base.aclone(target = target, target_base_key = target_base_key, schema_map = schema_map, overwrite = overwrite, **kwargs)\n\n    def clone_from(\n        self,\n        target: Any, \n        target_base_key: Optional[str] = None,\n        schema_map: Optional[Dict[str, str]] = None,\n        overwrite: Optional[bool] = None, \n        **kwargs\n    ):\n        \"\"\"\n        Clones the data from the target PersistentDict to a current PersistentDict\n        \"\"\"\n        return self.base.clone_from(target = target, target_base_key = target_base_key, schema_map = schema_map, overwrite = overwrite, **kwargs)\n\n    @overload\n    async def aclone_from(\n        self,\n        target: str, \n        target_base_key: Optional[str] = None,\n        target_db_id: Optional[int] = None,\n        source_url: Optional[str] = None,\n        source_base_key: Optional[str] = None,\n        schema_map: Optional[Dict[str, str]] = None,\n        overwrite: Optional[bool] = None, \n        excluded: Optional[Union[str, List[str]]] = None,\n        filter_function: Optional[Callable[[str], bool]] = None,\n        raise_errors: Optional[bool] = True,\n        verbose: Optional[bool] = True,\n        **kwargs\n    ) -&gt; Dict[str, Union[List[str], int, float]]:\n        \"\"\"\n        Clones the data from the target PersistentDict to a current PersistentDict\n        \"\"\"\n        ...\n\n    async def aclone_from(\n        self,\n        target: Any, \n        target_base_key: Optional[str] = None,\n        schema_map: Optional[Dict[str, str]] = None,\n        overwrite: Optional[bool] = None, \n        **kwargs\n    ):\n        \"\"\"\n        Clones the data from the target PersistentDict to a current PersistentDict\n        \"\"\"\n        return await self.base.aclone_from(target = target, target_base_key = target_base_key, schema_map = schema_map, overwrite = overwrite, **kwargs)\n\n\n    \"\"\"\n    Metrics\n    \"\"\"\n\n    def configure_metric(\n        self,\n        name: str,\n        kind: str,\n        reset: Optional[bool] = None,\n        metric_class: Optional[Union[Type['MetricT'], str]] = None,\n        verbose: Optional[bool] = False,\n        **kwargs,\n    ):\n        \"\"\"\n        Configures a Metric\n        \"\"\"\n        if 'metrics' not in self: self['metrics'] = {}\n        if reset or name not in self['metrics']:\n            if metric_class: metric_class = lazy_import(metric_class) if isinstance(metric_class, str) else metric_class\n            else: metric_class = self.get_metric_class(kind, **kwargs)\n            self['metrics'][name] = metric_class(name = name, **kwargs)\n        elif verbose:\n            autologger.info(f'Metric {kind} {name} already configured', prefix = self.name, colored = True)\n\n\n    @property\n    def metrics(self) -&gt; Dict[str, 'MetricT']:\n        \"\"\"\n        Returns the Metrics\n        \"\"\"\n        return self.__getitem__('metrics')\n\n\n    def __call__(\n        self,\n        method: str,\n        *args,\n        **kwargs\n    ) -&gt; Any:\n        \"\"\"\n        Calls the method\n        \"\"\"\n        return getattr(self.base, method)(*args, **kwargs)\n\n\n    # def __getattribute__(self, name: str) -&gt; Any:\n    #     \"\"\"\n    #     Gets the attribute\n    #     \"\"\"\n    #     if hasattr(self.base, name):\n    #         print(f'Getting Attribute: {name} from {self.base}')\n    #         return getattr(self.base, name)\n    #     return super().__getattribute__(name)\n\n    \"\"\"\n    Extra Methods\n    \"\"\"\n\n    def select(self, *args, **kwargs) -&gt; t.Union[t.Dict[str, t.Any], t.Tuple[t.Dict[str, t.Any], t.Dict[str, t.Any]]]:\n        \"\"\"\n        Select all items with the given tags\n        \"\"\"\n        return self.base.select(*args, **kwargs)\n\n    async def aselect(self, *args, **kwargs) -&gt; t.Union[t.Dict[str, t.Any], t.Tuple[t.Dict[str, t.Any], t.Dict[str, t.Any]]]:\n        \"\"\"\n        [Async] Select all items with the given tags\n        \"\"\"\n        return await self.base.aselect(*args, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.compression_level","title":"<code>compression_level</code>  <code>property</code>","text":"<p>Returns the Compression Level</p>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.cache_save_key","title":"<code>cache_save_key</code>  <code>property</code>","text":"<p>Returns the cache save key that can be used to save the cache file for globbing</p>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.metrics","title":"<code>metrics</code>  <code>property</code>","text":"<p>Returns the Metrics</p>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.register_backend","title":"<code>register_backend(name, backend)</code>  <code>classmethod</code>","text":"<p>Registers a Backend</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>@classmethod\ndef register_backend(cls, name: str, backend: Union[str, Type['BackendT']]):\n    \"\"\"\n    Registers a Backend\n    \"\"\"\n    global RegisteredBackends\n    RegisteredBackends[name] = backend\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.get_backend_class","title":"<code>get_backend_class(base_key=None, **kwargs)</code>","text":"<p>Returns the Backend Class</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def get_backend_class(self, base_key: Optional[str] = None, **kwargs) -&gt; Type['BackendT']:\n    # sourcery skip: assign-if-exp, hoist-similar-statement-from-if, reintroduce-else, swap-nested-ifs\n    \"\"\"\n    Returns the Backend Class\n    \"\"\"\n    if self.backend_type in RegisteredBackends:\n        bt = RegisteredBackends[self.backend_type]\n        return lazy_import(bt) if isinstance(bt, str) else bt\n    # if self.backend_type == 'local':\n    #     return LocalStatefulBackend\n    # elif self.backend_type == 'redis':\n    #     return RedisStatefulBackend\n    if self.backend_type == 'auto':\n        if base_key is not None and '://' in base_key:\n            if base_key.startswith('sqlite://'):\n                return SqliteStatefulBackend\n            return ObjStorageStatefulBackend\n\n        with contextlib.suppress(Exception):\n            import kvdb\n            if kvdb.is_available(url = kwargs.get('url')):\n                from kvdb.components.persistence import KVDBStatefulBackend\n                return KVDBStatefulBackend\n        with contextlib.suppress(Exception):\n            from lazyops.utils.lazy import get_keydb_enabled\n            if get_keydb_enabled():\n                return RedisStatefulBackend\n        logger.warning('Defaulting to Local Stateful Backend')\n        return LocalStatefulBackend\n    raise NotImplementedError(f'Backend Type {self.backend_type} is not implemented')\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.get_metric_class","title":"<code>get_metric_class(kind, **kwargs)</code>","text":"<p>Metric Class</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def get_metric_class(self, kind: str, **kwargs) -&gt; Type['MetricT']:\n    \"\"\"\n    Metric Class\n    \"\"\"\n    return self._metric_types.get(kind, RegisteredMetricTypes[kind])\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.get_child_kwargs","title":"<code>get_child_kwargs(**kwargs)</code>","text":"<p>Returns the Child Kwargs</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def get_child_kwargs(self, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Returns the Child Kwargs\n    \"\"\"\n    base_kwargs = self._kwargs.copy()\n    if kwargs: base_kwargs.update(kwargs)\n    if 'settings' not in base_kwargs:\n        base_kwargs['settings'] = self.settings\n    if 'name' not in base_kwargs:\n        base_kwargs['name'] = self.name\n    if 'backend_type' not in base_kwargs and 'backend' not in base_kwargs:\n        base_kwargs['backend'] = self.base_class\n    if 'async_enabled' not in base_kwargs:\n        base_kwargs['async_enabled'] = self.base.async_enabled\n    return base_kwargs\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.get_child","title":"<code>get_child(key, **kwargs)</code>","text":"<p>Return a scoped child :class:<code>PersistentDict</code> rooted under <code>key</code>.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def get_child(self, key: KT, **kwargs) -&gt; 'PersistentDict':\n    \"\"\"Return a scoped child :class:`PersistentDict` rooted under ``key``.\"\"\"\n    if hasattr(self.base, 'get_child'):\n        new_base = self.base.get_child(key, **kwargs)\n        return self.__class__(\n            parent = self,\n            new_base = new_base,\n            **kwargs,\n        )\n\n    base_key = f'{self.base_key}:{key}' if self.base_key else key\n    base_kwargs = self.get_child_kwargs(**kwargs)\n    return self.__class__(base_key = base_key, parent_base_key = self.base_key, child_base_key = key, **base_kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.get_key","title":"<code>get_key(key)</code>","text":"<p>Gets a Key</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def get_key(self, key: str) -&gt; str:\n    \"\"\"\n    Gets a Key\n    \"\"\"\n    return self.base.get_key(key)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.get","title":"<code>get(key, default=None, _raw=None, **kwargs)</code>","text":"<p>Return the value stored for <code>key</code> or <code>default</code> when missing.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def get(self, key: KT, default: Optional[VT] = None, _raw: Optional[bool] = None, **kwargs) -&gt; Optional[VT]:\n    \"\"\"Return the value stored for ``key`` or ``default`` when missing.\"\"\"\n    self._save_mutation_objects(key)\n    return self.base.get(key, default = default, _raw = _raw, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.get_values","title":"<code>get_values(keys, **kwargs)</code>","text":"<p>Bulk fetch helpers mirroring :meth:<code>get</code> for multiple keys.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def get_values(self, keys: Iterable[str], **kwargs) -&gt; List[VT]:\n    \"\"\"Bulk fetch helpers mirroring :meth:`get` for multiple keys.\"\"\"\n    self._save_mutation_objects(*keys)\n    return self.base.get_values(keys, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.fetch","title":"<code>fetch(key, _raw=None, **kwargs)</code>","text":"<p>Return <code>None</code> for missing keys instead of raising errors.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def fetch(self, key: KT, _raw: Optional[bool] = None, **kwargs) -&gt; Optional[VT]:\n    \"\"\"Return ``None`` for missing keys instead of raising errors.\"\"\"\n    return self.get(key, _raw = _raw, **kwargs) if self.contains(key) else None\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.set","title":"<code>set(key, value, ex=None, _raw=None, **kwargs)</code>","text":"<p>Persist <code>value</code> under <code>key</code> optionally expiring after <code>ex</code> seconds.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def set(self, key: KT, value: Any, ex: Optional[Union[float, int]] = None, _raw: Optional[bool] = None, **kwargs) -&gt; Optional[KT]:\n    \"\"\"Persist ``value`` under ``key`` optionally expiring after ``ex`` seconds.\"\"\"\n    if self.base.async_enabled and is_in_async_loop():\n        ThreadPool.create_background_task(self.base.aset(key, value, ex = ex, _raw = _raw, **kwargs))\n    else:\n        return self.base.set(key, value, ex = ex, _raw = _raw, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.set_batch","title":"<code>set_batch(data, **kwargs)</code>","text":"<p>Store a mapping of key/value pairs in a single backend call.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def set_batch(self, data: Dict[str, Any], **kwargs) -&gt; None:\n    \"\"\"Store a mapping of key/value pairs in a single backend call.\"\"\"\n    if self.base.async_enabled:\n        ThreadPool.create_background_task(self.base.aset_batch(data, **kwargs))\n    else:\n        self.base.set_batch(data, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.delete","title":"<code>delete(key, **kwargs)</code>","text":"<p>Remove <code>key</code> from the persistence backend.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def delete(self, key: KT, **kwargs) -&gt; None:\n    \"\"\"Remove ``key`` from the persistence backend.\"\"\"\n    if self.base.async_enabled and is_in_async_loop():\n        ThreadPool.create_background_task(self.base.adelete(key, **kwargs))\n    else:\n        self.base.delete(key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.contains","title":"<code>contains(key, **kwargs)</code>","text":"<p>Return <code>True</code> when the backend currently stores <code>key</code>.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def contains(self, key: KT, **kwargs) -&gt; bool:\n    \"\"\"Return ``True`` when the backend currently stores ``key``.\"\"\"\n    return self.base.contains(key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.clear","title":"<code>clear(*keys, **kwargs)</code>","text":"<p>Clear all stored items or only the provided <code>keys</code> when supplied.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def clear(self, *keys, **kwargs) -&gt; None:\n    \"\"\"Clear all stored items or only the provided ``keys`` when supplied.\"\"\"\n    if self.base.async_enabled and is_in_async_loop():\n        ThreadPool.create_background_task(self.base.clear(*keys, **kwargs))\n    else:\n        self.base.clear(*keys, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aget","title":"<code>aget(key, default=None, _raw=None, **kwargs)</code>  <code>async</code>","text":"<p>Async equivalent of :meth:<code>get</code> for coroutine contexts.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aget(self, key: KT, default: Optional[VT] = None, _raw: Optional[bool] = None, **kwargs) -&gt; Optional[VT]:\n    \"\"\"Async equivalent of :meth:`get` for coroutine contexts.\"\"\"\n    await self._asave_mutation_objects(key)\n    return await self.base.aget(key, default = default, _raw = _raw, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aget_values","title":"<code>aget_values(keys, **kwargs)</code>  <code>async</code>","text":"<p>Async variant of :meth:<code>get_values</code>.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aget_values(self, keys: Iterable[KT], **kwargs) -&gt; List[VT]:\n    \"\"\"Async variant of :meth:`get_values`.\"\"\"\n    await self._asave_mutation_objects(*keys)\n    return await self.base.aget_values(keys,  **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.afetch","title":"<code>afetch(key, _raw=None, **kwargs)</code>  <code>async</code>","text":"<p>Async variant of :meth:<code>fetch</code>.</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def afetch(self, key: KT, _raw: Optional[bool] = None, **kwargs) -&gt; Optional[VT]:\n    \"\"\"Async variant of :meth:`fetch`.\"\"\"\n    return await self.aget(key, _raw = _raw, **kwargs) if await self.acontains(key) else None\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aset","title":"<code>aset(key, value, ex=None, _raw=None, **kwargs)</code>  <code>async</code>","text":"<p>Saves a Value to the DB</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aset(self, key: KT, value: VT, ex: Optional[Union[float, int]] = None, _raw: Optional[bool] = None, **kwargs) -&gt; Optional[KT]:\n    \"\"\"\n    Saves a Value to the DB\n    \"\"\"\n    return await self.base.aset(key, value, ex = ex, _raw = _raw, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aset_batch","title":"<code>aset_batch(data, **kwargs)</code>  <code>async</code>","text":"<p>Saves a Value to the DB</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aset_batch(self, data: Dict[KT, VT], **kwargs) -&gt; None:\n    \"\"\"\n    Saves a Value to the DB\n    \"\"\"\n    await self.base.aset_batch(data, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.adelete","title":"<code>adelete(key, **kwargs)</code>  <code>async</code>","text":"<p>Deletes a Value from the DB</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def adelete(self, key: KT, **kwargs) -&gt; None:\n    \"\"\"\n    Deletes a Value from the DB\n    \"\"\"\n    await self.base.adelete(key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.acontains","title":"<code>acontains(key, **kwargs)</code>  <code>async</code>","text":"<p>Returns True if the Cache contains the Key</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def acontains(self, key: KT, **kwargs) -&gt; bool:\n    \"\"\"\n    Returns True if the Cache contains the Key\n    \"\"\"\n    return await self.base.acontains(key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aclear","title":"<code>aclear(*keys, **kwargs)</code>  <code>async</code>","text":"<p>Clears the Cache</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aclear(self, *keys: KT, **kwargs) -&gt; None:\n    \"\"\"\n    Clears the Cache\n    \"\"\"\n    await self.base.aclear(*keys, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.get_all_data","title":"<code>get_all_data(**kwargs)</code>","text":"<p>Loads all the Data</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def get_all_data(self, **kwargs) -&gt; Dict[KT, VT]:\n    \"\"\"\n    Loads all the Data\n    \"\"\"\n    self._save_mutation_objects()\n    return self.base.get_all_data(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.get_all_keys","title":"<code>get_all_keys(**kwargs)</code>","text":"<p>Returns all the Keys</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def get_all_keys(self, **kwargs) -&gt; Iterable[KT]:\n    \"\"\"\n    Returns all the Keys\n    \"\"\"\n    return self.base.get_all_keys(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.get_keys","title":"<code>get_keys(pattern, exclude_base_key=None, **kwargs)</code>","text":"<p>Returns all the Keys</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def get_keys(self, pattern: str, exclude_base_key: Optional[bool] = None, **kwargs) -&gt; List[KT]:\n    \"\"\"\n    Returns all the Keys\n    \"\"\"\n    return self.base.get_keys(pattern, exclude_base_key = exclude_base_key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.get_all_values","title":"<code>get_all_values(**kwargs)</code>","text":"<p>Returns all the Values</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def get_all_values(self, **kwargs) -&gt; Iterable[VT]:\n    \"\"\"\n    Returns all the Values\n    \"\"\"\n    self._save_mutation_objects()\n    return self.base.get_all_values(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aget_all_data","title":"<code>aget_all_data(**kwargs)</code>  <code>async</code>","text":"<p>Loads all the Data</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aget_all_data(self, **kwargs) -&gt; Dict[KT, VT]:\n    \"\"\"\n    Loads all the Data\n    \"\"\"\n    await self._asave_mutation_objects()\n    return await self.base.aget_all_data(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aget_all_keys","title":"<code>aget_all_keys(**kwargs)</code>  <code>async</code>","text":"<p>Returns all the Keys</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aget_all_keys(self, **kwargs) -&gt; Iterable[KT]:\n    \"\"\"\n    Returns all the Keys\n    \"\"\"\n    return await self.base.aget_all_keys(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aget_keys","title":"<code>aget_keys(pattern, exclude_base_key=None, **kwargs)</code>  <code>async</code>","text":"<p>Returns all the Keys</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aget_keys(self, pattern: str, exclude_base_key: Optional[bool] = None, **kwargs) -&gt; List[KT]:\n    \"\"\"\n    Returns all the Keys\n    \"\"\"\n    return await self.base.aget_keys(pattern, exclude_base_key = exclude_base_key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aget_all_values","title":"<code>aget_all_values(**kwargs)</code>  <code>async</code>","text":"<p>Returns all the Values</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aget_all_values(self, **kwargs) -&gt; Iterable[VT]:\n    \"\"\"\n    Returns all the Values\n    \"\"\"\n    await self._asave_mutation_objects()\n    return await self.base.aget_all_values(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.keys","title":"<code>keys(**kwargs)</code>","text":"<p>Returns the Keys</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def keys(self, **kwargs) -&gt; Iterable[KT]:\n    \"\"\"\n    Returns the Keys\n    \"\"\"\n    return self.base.keys(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.values","title":"<code>values(**kwargs)</code>","text":"<p>Returns the Values</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def values(self, **kwargs) -&gt; Iterable[VT]:\n    \"\"\"\n    Returns the Values\n    \"\"\"\n    self._save_mutation_objects()\n    return self.base.values(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.items","title":"<code>items(iterable=True, **kwargs)</code>","text":"<p>Returns the Items</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def items(self, iterable: Optional[bool] = True, **kwargs) -&gt; Dict[KT, VT]:\n    \"\"\"\n    Returns the Items\n    \"\"\"\n    self._save_mutation_objects()\n    return self.base.items(iterable = iterable, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.akeys","title":"<code>akeys(**kwargs)</code>  <code>async</code>","text":"<p>Returns the Keys</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def akeys(self, **kwargs) -&gt; Iterable[KT]:\n    \"\"\"\n    Returns the Keys\n    \"\"\"\n    return await self.base.akeys(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.avalues","title":"<code>avalues(**kwargs)</code>  <code>async</code>","text":"<p>Returns the Values</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def avalues(self, **kwargs) -&gt; Iterable[VT]:\n    \"\"\"\n    Returns the Values\n    \"\"\"\n    await self._asave_mutation_objects()\n    return await self.base.avalues(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aitems","title":"<code>aitems(iterable=True, **kwargs)</code>  <code>async</code>","text":"<pre><code>aitems(iterable: None = None, **kwargs) -&gt; Iterable[Tuple[KT, VT]]\n</code></pre><pre><code>aitems(iterable: bool = False, **kwargs) -&gt; Dict[KT, VT]\n</code></pre> <p>Returns the Items</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aitems(self, iterable: Optional[bool] = True, **kwargs) -&gt; Union[Iterable[Tuple[KT, VT]], Dict[KT, VT]]:\n    \"\"\"\n    Returns the Items\n    \"\"\"\n    await self._asave_mutation_objects()\n    return await self.base.aitems(iterable = iterable, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.expire","title":"<code>expire(key, timeout=None, expiration=None, **kwargs)</code>","text":"<p>Expires a Key</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def expire(self, key: KT, timeout: Optional[int] = None, expiration: Optional[int] = None, **kwargs) -&gt; None:\n    \"\"\"\n    Expires a Key\n    \"\"\"\n    # Add a check to see if expiration or timeout is set\n    if 'ex' in kwargs:\n        expiration = kwargs.pop('ex')\n    ex = expiration if expiration is not None else timeout\n    self.base.expire(key, ex = ex, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aexpire","title":"<code>aexpire(key, timeout=None, expiration=None, **kwargs)</code>  <code>async</code>","text":"<p>Expires a Key</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aexpire(self, key: KT, timeout: Optional[int] = None, expiration: Optional[int] = None, **kwargs) -&gt; None:\n    \"\"\"\n    Expires a Key\n    \"\"\"\n    if 'ex' in kwargs:\n        expiration = kwargs.pop('ex')\n    ex = expiration if expiration is not None else timeout\n    await self.base.aexpire(key, ex = ex, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.track_changes","title":"<code>track_changes(key, func, *args, **kwargs)</code>","text":"<p>Tracks Changes</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>@contextlib.contextmanager\ndef track_changes(self, key: KT, func: str, *args, **kwargs):\n    \"\"\"\n    Tracks Changes\n    \"\"\"\n    try:\n        value = None\n        if key in self._mutation_tracker:\n            autologger.info(f'tracked {func} {key} (cached) {self._mutation_tracker[key]}')\n            if self.base.create_hash(self._mutation_tracker[key]) == self._mutation_hashes[key]:\n                value = self._mutation_tracker[key]\n            else:\n                autologger.info(f'tracked {func} {key} (changed). Saving')\n                self.base.set(key, self._mutation_tracker[key])\n                value = self._mutation_tracker.pop(key)\n                self._mutation_hashes.pop(key)\n\n        if value is None:\n            autologger.info(f'tracked {func} {key}')\n            value = getattr(self.base, func)(key, *args, **kwargs)\n        yield value\n    finally:\n        if key not in self._mutation_hashes:\n            self._mutation_hashes[key] = self.base.create_hash(value)\n            self._mutation_tracker[key] = value\n        if self.base.create_hash(value) != self._mutation_hashes[key]:\n            autologger.info(f'tracked {func} {key} (post-changed). Saving')\n            self._save_mutation_objects(key)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.atrack_changes","title":"<code>atrack_changes(key, func, *args, **kwargs)</code>  <code>async</code>","text":"<p>Tracks Changes</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>@contextlib.asynccontextmanager\nasync def atrack_changes(self, key: KT, func: str, *args, **kwargs):\n    \"\"\"\n    Tracks Changes\n    \"\"\"\n    try:\n        value = None\n        if key in self._mutation_tracker:\n            autologger.info(f'tracked {func} {key} (cached): {self._mutation_tracker[key]}')\n            if self.base.create_hash(self._mutation_tracker[key]) == self._mutation_hashes[key]:\n                value = self._mutation_tracker[key]\n            else:\n                autologger.info(f'tracked {func} {key} (changed). Saving')\n                await self.base.aset(key, self._mutation_tracker[key])\n                value = self._mutation_tracker.pop(key)\n                self._mutation_hashes.pop(key)\n        if value is None:\n            autologger.info(f'tracked {func} {key}')\n            value = await getattr(self.base, func)(key, *args, **kwargs)\n        yield value\n    finally:\n        if key not in self._mutation_hashes:\n            self._mutation_hashes[key] = self.base.create_hash(value)\n            self._mutation_tracker[key] = value\n        if self.base.create_hash(value) != self._mutation_hashes[key]:\n            autologger.info(f'tracked {func} {key} (post-changed). Saving')\n            await self._asave_mutation_objects(key)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.setdefault","title":"<code>setdefault(key, default=None, update_values=False, enforce_type=False)</code>","text":"<p>Sets a Default Value</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def setdefault(self, key: KT, default: Any = None, update_values: Optional[bool] = False, enforce_type: Optional[bool] = False) -&gt; Any:\n    \"\"\"\n    Sets a Default Value\n    \"\"\"\n    with self.track_changes(key, 'setdefault', default, update_values = update_values, enforce_type = enforce_type) as result:\n        return result\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.asetdefault","title":"<code>asetdefault(key, default=None, update_values=False, enforce_type=False)</code>  <code>async</code>","text":"<p>Sets a Default Value</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def asetdefault(self, key: KT, default: Any = None, update_values: Optional[bool] = False, enforce_type: Optional[bool] = False) -&gt; Any:\n    \"\"\"\n    Sets a Default Value\n    \"\"\"\n    async with self.atrack_changes(key, 'asetdefault', default, update_values = update_values, enforce_type = enforce_type) as result:\n        return result\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.update","title":"<code>update(data, **kwargs)</code>","text":"<p>Updates the Cache</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def update(self, data: Dict[str, Any], **kwargs) -&gt; None:\n    \"\"\"\n    Updates the Cache\n    \"\"\"\n    self._save_mutation_objects()\n    self.base.update(data, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aupdate","title":"<code>aupdate(data, **kwargs)</code>  <code>async</code>","text":"<p>Updates the Cache</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aupdate(self, data: Dict[str, Any], **kwargs) -&gt; None:\n    \"\"\"\n    Updates the Cache\n    \"\"\"\n    await self._asave_mutation_objects()\n    await self.base.aupdate(data, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.update_key","title":"<code>update_key(key, data, deep=True, exclude_none=True, **kwargs)</code>","text":"<p>Updates the Dict at the Key</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def update_key(self, key: str, data: Dict[str, Any], deep: Optional[bool] = True,  exclude_none: Optional[bool] = True, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Updates the Dict at the Key\n    \"\"\"\n    return self.base.update_key(key, data, deep = deep, exclude_none = exclude_none, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aupdate_key","title":"<code>aupdate_key(key, data, deep=True, exclude_none=True, **kwargs)</code>  <code>async</code>","text":"<p>[Async] Updates the Dict at the Key</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aupdate_key(self, key: str, data: Dict[str, Any], deep: Optional[bool] = True,  exclude_none: Optional[bool] = True, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    [Async] Updates the Dict at the Key\n    \"\"\"\n    return await self.base.aupdate_key(key, data, deep = deep, exclude_none = exclude_none, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.popitem","title":"<code>popitem(**kwargs)</code>","text":"<p>Pops an Item from the Cache</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def popitem(self, **kwargs) -&gt; Any:\n    \"\"\"\n    Pops an Item from the Cache\n    \"\"\"\n    return self.base.popitem(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.apopitem","title":"<code>apopitem(**kwargs)</code>  <code>async</code>","text":"<p>Pops an Item from the Cache</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def apopitem(self, **kwargs) -&gt; Any:\n    \"\"\"\n    Pops an Item from the Cache\n    \"\"\"\n    return await self.base.apopitem(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.pop","title":"<code>pop(key, default=None, **kwargs)</code>","text":"<p>Pops an Item from the Cache</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def pop(self, key: KT, default: Optional[VT] = None, **kwargs) -&gt; VT:\n    \"\"\"\n    Pops an Item from the Cache\n    \"\"\"\n    return self.base.pop(key, default, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.apop","title":"<code>apop(key, default=None, **kwargs)</code>  <code>async</code>","text":"<p>Pops an Item from the Cache</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def apop(self, key: KT, default: Optional[VT] = None, **kwargs) -&gt; VT:\n    \"\"\"\n    Pops an Item from the Cache\n    \"\"\"\n    return await self.base.apop(key, default, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.acquire_context","title":"<code>acquire_context(timeout=None, blocking=True, **kwargs)</code>","text":"<p>Acquires the context</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>@contextlib.contextmanager\ndef acquire_context(self, timeout: Optional[float] = None, blocking: Optional[bool] = True, **kwargs):\n    \"\"\"\n    Acquires the context\n    \"\"\"\n    if self._enter_context(timeout = timeout, blocking = blocking, **kwargs):\n        try:\n            yield\n        finally:\n            self._exit_context()\n    else:\n        raise ContextError('Unable to acquire context due to concurrency')\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.acquire_acontext","title":"<code>acquire_acontext(timeout=None, blocking=True, **kwargs)</code>  <code>async</code>","text":"<p>Acquires the context</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def acquire_acontext(self, timeout: Optional[float] = None, blocking: Optional[bool] = True, **kwargs):\n    \"\"\"\n    Acquires the context\n    \"\"\"\n    if await self._aenter_context(timeout = timeout, blocking = blocking, **kwargs):\n        try:\n            yield\n        finally:\n            await self._aexit_context()\n    else:\n        raise ContextError('Unable to acquire context due to concurrency')\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.length","title":"<code>length(**kwargs)</code>","text":"<p>Returns the Length of the Cache</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def length(self, **kwargs):\n    \"\"\"\n    Returns the Length of the Cache\n    \"\"\"\n    return self.base.length(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.alength","title":"<code>alength(**kwargs)</code>  <code>async</code>","text":"<p>Returns the Length of the Cache</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def alength(self, **kwargs):\n    \"\"\"\n    Returns the Length of the Cache\n    \"\"\"\n    return await self.base.alength(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.migrate_compression","title":"<code>migrate_compression(**kwargs)</code>","text":"<p>Migrates the compression</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def migrate_compression(self, **kwargs):\n    \"\"\"\n    Migrates the compression\n    \"\"\"\n    return self.base.migrate_compression(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.amigrate_compression","title":"<code>amigrate_compression(**kwargs)</code>  <code>async</code>","text":"<p>Migrates the compression</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def amigrate_compression(self, **kwargs):\n    \"\"\"\n    Migrates the compression\n    \"\"\"\n    return await self.base.amigrate_compression(**kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.flush","title":"<code>flush(*keys)</code>","text":"<p>Finalize any in-memory objects</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def flush(self, *keys: str):\n    \"\"\"\n    Finalize any in-memory objects\n    \"\"\"\n    if self.base.async_enabled and is_in_async_loop():\n        ThreadPool.create_background_task(self._asave_mutation_objects(*keys))\n    else:\n        self._save_mutation_objects(*keys)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aflush","title":"<code>aflush(*keys)</code>  <code>async</code>","text":"<p>Finalize any in-memory objects</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aflush(self, *keys: str):\n    \"\"\"\n    Finalize any in-memory objects\n    \"\"\"\n    try:\n        import anyio\n        with anyio.move_on_after(2):\n            await self._asave_mutation_objects(*keys)\n    except ImportError:\n        await self._asave_mutation_objects(*keys)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.get_all_data_raw","title":"<code>get_all_data_raw(exclude_base_key=False, **kwargs)</code>","text":"<p>Loads all the Data</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def get_all_data_raw(self, exclude_base_key: Optional[bool] = False, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Loads all the Data\n    \"\"\"\n    return self.base.get_all_data_raw(exclude_base_key = exclude_base_key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aget_all_data_raw","title":"<code>aget_all_data_raw(exclude_base_key=False, **kwargs)</code>  <code>async</code>","text":"<p>Loads all the Data</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aget_all_data_raw(self, exclude_base_key: Optional[bool] = False, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Loads all the Data\n    \"\"\"\n    return await self.base.aget_all_data_raw(exclude_base_key = exclude_base_key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.load_data_raw","title":"<code>load_data_raw(data, includes_base_key=False, **kwargs)</code>","text":"<p>Loads the Data</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def load_data_raw(self, data: Dict[str, Any], includes_base_key: Optional[bool] = False, **kwargs):\n    \"\"\"\n    Loads the Data\n    \"\"\"\n    self.base.load_data_raw(data, includes_base_key = includes_base_key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aload_data_raw","title":"<code>aload_data_raw(data, includes_base_key=False, **kwargs)</code>  <code>async</code>","text":"<p>Loads the Data</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aload_data_raw(self, data: Dict[str, Any], includes_base_key: Optional[bool] = False, **kwargs):\n    \"\"\"\n    Loads the Data\n    \"\"\"\n    await self.base.aload_data_raw(data, includes_base_key = includes_base_key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.dump_data_raw","title":"<code>dump_data_raw(include_base_key=False, **kwargs)</code>","text":"<p>Dumps the Data</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def dump_data_raw(self, include_base_key: Optional[bool] = False, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Dumps the Data\n    \"\"\"\n    return self.base.dump_data_raw(include_base_key = include_base_key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.adump_data_raw","title":"<code>adump_data_raw(include_base_key=False, **kwargs)</code>  <code>async</code>","text":"<p>Dumps the Data</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def adump_data_raw(self, include_base_key: Optional[bool] = False, **kwargs) -&gt; Dict[str, Any]:\n    \"\"\"\n    Dumps the Data\n    \"\"\"\n    return await self.base.adump_data_raw(include_base_key = include_base_key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.replicate_from","title":"<code>replicate_from(source, **kwargs)</code>","text":"<p>Replicates the Data</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def replicate_from(self, source: Any, **kwargs):\n    \"\"\"\n    Replicates the Data\n    \"\"\"\n    self.base.replicate_from(source, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.areplicate_from","title":"<code>areplicate_from(source, **kwargs)</code>  <code>async</code>","text":"<p>Replicates the Data</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def areplicate_from(self, source: Any, **kwargs):\n    \"\"\"\n    Replicates the Data\n    \"\"\"\n    await self.base.areplicate_from(source, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.incr","title":"<code>incr(key, amount=1, **kwargs)</code>","text":"<p>Increments the value of the key by the given amount</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def incr(self, key: KT, amount: Union[int, float] = 1, **kwargs) -&gt; Union[int, float]:\n    \"\"\"\n    Increments the value of the key by the given amount\n    \"\"\"\n    return self.base.incr(key, amount = amount, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aincr","title":"<code>aincr(key, amount=1, **kwargs)</code>  <code>async</code>","text":"<p>Increments the value of the key by the given amount</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aincr(self, key: KT, amount: Union[int, float] = 1, **kwargs) -&gt; Union[int, float]:\n    \"\"\"\n    Increments the value of the key by the given amount\n    \"\"\"\n    return await self.base.aincr(key, amount = amount, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.decr","title":"<code>decr(key, amount=1, **kwargs)</code>","text":"<p>Decrements the value of the key by the given amount</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def decr(self, key: KT, amount: Union[int, float] = 1, **kwargs) -&gt; Union[int, float]:\n    \"\"\"\n    Decrements the value of the key by the given amount\n    \"\"\"\n    return self.base.decr(key, amount = amount, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.adecr","title":"<code>adecr(key, amount=1, **kwargs)</code>  <code>async</code>","text":"<p>Decrements the value of the key by the given amount</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def adecr(self, key: KT, amount: Union[int, float] = 1, **kwargs) -&gt; Union[int, float]:\n    \"\"\"\n    Decrements the value of the key by the given amount\n    \"\"\"\n    return await self.base.adecr(key, amount = amount, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.sadd","title":"<code>sadd(key, *values, **kwargs)</code>","text":"<p>Adds the value to the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def sadd(self, key: KT, *values: Any, **kwargs) -&gt; int:\n    \"\"\"\n    Adds the value to the set\n    \"\"\"\n    return self.base.sadd(key, *values, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.asadd","title":"<code>asadd(key, *value, **kwargs)</code>  <code>async</code>","text":"<p>Adds the value to the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def asadd(self, key: KT, *value: Any, **kwargs) -&gt; int:\n    \"\"\"\n    Adds the value to the set\n    \"\"\"\n    return await self.base.asadd(key, *value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.slength","title":"<code>slength(key, **kwargs)</code>","text":"<p>Returns the length of the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def slength(self, key: KT, **kwargs) -&gt; int:\n    \"\"\"\n    Returns the length of the set\n    \"\"\"\n    return self.base.slength(key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aslength","title":"<code>aslength(key, **kwargs)</code>  <code>async</code>","text":"<p>Returns the length of the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aslength(self, key: KT, **kwargs) -&gt; int:\n    \"\"\"\n    Returns the length of the set\n    \"\"\"\n    return await self.base.aslength(key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.sismember","title":"<code>sismember(key, value, **kwargs)</code>","text":"<p>Returns whether the value is a member of the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def sismember(self, key: KT, value: Any, **kwargs) -&gt; bool:\n    \"\"\"\n    Returns whether the value is a member of the set\n    \"\"\"\n    return self.base.sismember(key, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.asismember","title":"<code>asismember(key, value, **kwargs)</code>  <code>async</code>","text":"<p>Returns whether the value is a member of the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def asismember(self, key: KT, value: Any, **kwargs) -&gt; bool:\n    \"\"\"\n    Returns whether the value is a member of the set\n    \"\"\"\n    return await self.base.asismember(key, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.smembers","title":"<code>smembers(key, **kwargs)</code>","text":"<p>Returns the members of the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def smembers(self, key: KT, **kwargs) -&gt; List[Any]:\n    \"\"\"\n    Returns the members of the set\n    \"\"\"\n    return self.base.smembers(key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.asembers","title":"<code>asembers(key, **kwargs)</code>  <code>async</code>","text":"<p>Returns the members of the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def asembers(self, key: KT, **kwargs) -&gt; List[Any]:\n    \"\"\"\n    Returns the members of the set\n    \"\"\"\n    return await self.base.asembers(key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.smismember","title":"<code>smismember(key, *values, **kwargs)</code>","text":"<p>Returns whether the values are members of the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def smismember(self, key: KT, *values: Any, **kwargs) -&gt; bool:\n    \"\"\"\n    Returns whether the values are members of the set\n    \"\"\"\n    return self.base.smismember(key, *values, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.asmismember","title":"<code>asmismember(key, *values, **kwargs)</code>  <code>async</code>","text":"<p>Returns whether the values are members of the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def asmismember(self, key: KT, *values: Any, **kwargs) -&gt; bool:\n    \"\"\"\n    Returns whether the values are members of the set\n    \"\"\"\n    return await self.base.asmismember(key, *values, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.srem","title":"<code>srem(key, *values, **kwargs)</code>","text":"<p>Removes the value from the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def srem(self, key: KT, *values: Any, **kwargs) -&gt; int:\n    \"\"\"\n    Removes the value from the set\n    \"\"\"\n    return self.base.srem(key, *values, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.asrem","title":"<code>asrem(key, *values, **kwargs)</code>  <code>async</code>","text":"<p>Removes the value from the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def asrem(self, key: KT, *values: Any, **kwargs) -&gt; int:\n    \"\"\"\n    Removes the value from the set\n    \"\"\"\n    return await self.base.asrem(key, *values, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.spop","title":"<code>spop(key, **kwargs)</code>","text":"<p>Removes and returns a random member of the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def spop(self, key: KT, **kwargs) -&gt; Any:\n    \"\"\"\n    Removes and returns a random member of the set\n    \"\"\"\n    return self.base.spop(key, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aspop","title":"<code>aspop(key, **kwargs)</code>  <code>async</code>","text":"<p>Removes and returns a random member of the set</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aspop(self, key: KT, **kwargs) -&gt; Any:\n    \"\"\"\n    Removes and returns a random member of the set\n    \"\"\"\n    return await self.base.aspop(key, **kwargs) \n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.copy","title":"<code>copy(exclude=None, exclude_none=False, **kwargs)</code>","text":"<p>Copies the current data and returns a Dict</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def copy(\n    self,\n    exclude: Optional[Set[str]] = None,\n    exclude_none: Optional[bool] = False,\n    **kwargs\n) -&gt; Dict[KT, VT]:\n    \"\"\"\n    Copies the current data and returns a Dict\n    \"\"\"\n    data = self.items()\n    if exclude is not None: data = {k: v for k, v in data.items() if k not in exclude}\n    if exclude_none: data = {k: v for k, v in data.items() if v is not None}\n    return data\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.acopy","title":"<code>acopy(exclude=None, exclude_none=False, **kwargs)</code>  <code>async</code>","text":"<p>Copies the current data and returns a Dict</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def acopy(\n    self,\n    exclude: Optional[Set[str]] = None,\n    exclude_none: Optional[bool] = False,\n    **kwargs\n) -&gt; Dict[KT, VT]:\n    \"\"\"\n    Copies the current data and returns a Dict\n    \"\"\"\n    data = await self.aitems()\n    if exclude is not None: data = {k: v for k, v in data.items() if k not in exclude}\n    if exclude_none: data = {k: v for k, v in data.items() if v is not None}\n    return data\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.migrate_schema","title":"<code>migrate_schema(schema_map, overwrite=None, **kwargs)</code>","text":"<p>Migrates the schema</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def migrate_schema(self, schema_map: Dict[str, Any], overwrite: Optional[bool] = None, **kwargs) -&gt; None:\n    \"\"\"\n    Migrates the schema\n    \"\"\"\n    self.base.migrate_schema(schema_map, overwrite = overwrite, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.amigrate_schema","title":"<code>amigrate_schema(schema_map, overwrite=None, **kwargs)</code>  <code>async</code>","text":"<p>Migrates the schema</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def amigrate_schema(self, schema_map: Dict[str, Any], overwrite: Optional[bool] = None, **kwargs) -&gt; None:\n    \"\"\"\n    Migrates the schema\n    \"\"\"\n    await self.base.amigrate_schema(schema_map, overwrite = overwrite, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.clone","title":"<code>clone(target, target_base_key=None, schema_map=None, overwrite=None, **kwargs)</code>","text":"<p>Clones the data from the current PersistentDict to a new PersistentDict</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def clone(\n    self, \n    target: Optional[Any], \n    target_base_key: Optional[str] = None,\n    schema_map: Optional[Dict[str, str]] = None,\n    overwrite: Optional[bool] = None, \n    **kwargs\n):\n    \"\"\"\n    Clones the data from the current PersistentDict to a new PersistentDict\n    \"\"\"\n    return self.base.clone(target = target, target_base_key = target_base_key, schema_map = schema_map, overwrite = overwrite, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aclone","title":"<code>aclone(target, target_base_key=None, schema_map=None, overwrite=None, **kwargs)</code>  <code>async</code>","text":"<pre><code>aclone(target: str, target_base_key: Optional[str] = None, target_db_id: Optional[int] = None, source_url: Optional[str] = None, source_base_key: Optional[str] = None, schema_map: Optional[Dict[str, str]] = None, overwrite: Optional[bool] = None, excluded: Optional[Union[str, List[str]]] = None, filter_function: Optional[Callable[[str], bool]] = None, raise_errors: Optional[bool] = True, verbose: Optional[bool] = True, **kwargs) -&gt; Dict[str, Union[List[str], int, float]]\n</code></pre> <p>Clones the data from the current PersistentDict to a new PersistentDict</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aclone(\n    self,\n    target: Optional[Any], \n    target_base_key: Optional[str] = None,\n    schema_map: Optional[Dict[str, str]] = None,\n    overwrite: Optional[bool] = None, \n    **kwargs\n):\n    \"\"\"\n    Clones the data from the current PersistentDict to a new PersistentDict\n    \"\"\"\n    return await self.base.aclone(target = target, target_base_key = target_base_key, schema_map = schema_map, overwrite = overwrite, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.clone_from","title":"<code>clone_from(target, target_base_key=None, schema_map=None, overwrite=None, **kwargs)</code>","text":"<p>Clones the data from the target PersistentDict to a current PersistentDict</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def clone_from(\n    self,\n    target: Any, \n    target_base_key: Optional[str] = None,\n    schema_map: Optional[Dict[str, str]] = None,\n    overwrite: Optional[bool] = None, \n    **kwargs\n):\n    \"\"\"\n    Clones the data from the target PersistentDict to a current PersistentDict\n    \"\"\"\n    return self.base.clone_from(target = target, target_base_key = target_base_key, schema_map = schema_map, overwrite = overwrite, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aclone_from","title":"<code>aclone_from(target, target_base_key=None, schema_map=None, overwrite=None, **kwargs)</code>  <code>async</code>","text":"<pre><code>aclone_from(target: str, target_base_key: Optional[str] = None, target_db_id: Optional[int] = None, source_url: Optional[str] = None, source_base_key: Optional[str] = None, schema_map: Optional[Dict[str, str]] = None, overwrite: Optional[bool] = None, excluded: Optional[Union[str, List[str]]] = None, filter_function: Optional[Callable[[str], bool]] = None, raise_errors: Optional[bool] = True, verbose: Optional[bool] = True, **kwargs) -&gt; Dict[str, Union[List[str], int, float]]\n</code></pre> <p>Clones the data from the target PersistentDict to a current PersistentDict</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aclone_from(\n    self,\n    target: Any, \n    target_base_key: Optional[str] = None,\n    schema_map: Optional[Dict[str, str]] = None,\n    overwrite: Optional[bool] = None, \n    **kwargs\n):\n    \"\"\"\n    Clones the data from the target PersistentDict to a current PersistentDict\n    \"\"\"\n    return await self.base.aclone_from(target = target, target_base_key = target_base_key, schema_map = schema_map, overwrite = overwrite, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.configure_metric","title":"<code>configure_metric(name, kind, reset=None, metric_class=None, verbose=False, **kwargs)</code>","text":"<p>Configures a Metric</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def configure_metric(\n    self,\n    name: str,\n    kind: str,\n    reset: Optional[bool] = None,\n    metric_class: Optional[Union[Type['MetricT'], str]] = None,\n    verbose: Optional[bool] = False,\n    **kwargs,\n):\n    \"\"\"\n    Configures a Metric\n    \"\"\"\n    if 'metrics' not in self: self['metrics'] = {}\n    if reset or name not in self['metrics']:\n        if metric_class: metric_class = lazy_import(metric_class) if isinstance(metric_class, str) else metric_class\n        else: metric_class = self.get_metric_class(kind, **kwargs)\n        self['metrics'][name] = metric_class(name = name, **kwargs)\n    elif verbose:\n        autologger.info(f'Metric {kind} {name} already configured', prefix = self.name, colored = True)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.select","title":"<code>select(*args, **kwargs)</code>","text":"<p>Select all items with the given tags</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>def select(self, *args, **kwargs) -&gt; t.Union[t.Dict[str, t.Any], t.Tuple[t.Dict[str, t.Any], t.Dict[str, t.Any]]]:\n    \"\"\"\n    Select all items with the given tags\n    \"\"\"\n    return self.base.select(*args, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.main.PersistentDict.aselect","title":"<code>aselect(*args, **kwargs)</code>  <code>async</code>","text":"<p>[Async] Select all items with the given tags</p> Source code in <code>src/lzl/io/persistence/main.py</code> <pre><code>async def aselect(self, *args, **kwargs) -&gt; t.Union[t.Dict[str, t.Any], t.Tuple[t.Dict[str, t.Any], t.Dict[str, t.Any]]]:\n    \"\"\"\n    [Async] Select all items with the given tags\n    \"\"\"\n    return await self.base.aselect(*args, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/persistence/#initialization","title":"Initialization","text":"<pre><code>from lzl.io.persistence import PersistentDict\n\n# Local SQLite backend (default if no scheme provided)\ncache = PersistentDict(\"my_app_cache\", serializer=\"json\")\n\n# Redis backend\nredis_cache = PersistentDict(\n    \"my_redis_cache\", \n    backend=\"redis\", \n    base_key=\"app:v1\",\n    expiration=3600\n)\n\n# Object Storage backend (S3)\ns3_cache = PersistentDict(\n    \"s3_cache\",\n    base_key=\"s3://my-bucket/cache/prefix\",\n    serializer=\"pickle\"\n)\n</code></pre>"},{"location":"api/lzl/io/persistence/#features","title":"Features","text":""},{"location":"api/lzl/io/persistence/#async-support","title":"Async Support","text":"<p>Most methods have an <code>async</code> equivalent prefixed with <code>a</code> (e.g., <code>aget</code>, <code>aset</code>, <code>adelete</code>).</p> <pre><code>await cache.aset(\"key\", \"value\")\nvalue = await cache.aget(\"key\")\n</code></pre>"},{"location":"api/lzl/io/persistence/#context-managers-locking","title":"Context Managers &amp; Locking","text":"<p>Ensure data consistency with context managers that handle locking.</p> <pre><code># Sync context\nwith cache.acquire_context():\n    cache[\"key\"] = \"new_value\"\n    # Changes are flushed on exit\n\n# Async context\nasync with cache.acquire_acontext():\n    await cache.aset(\"key\", \"async_value\")\n</code></pre>"},{"location":"api/lzl/io/persistence/#mutation-tracking","title":"Mutation Tracking","text":"<p><code>PersistentDict</code> tracks changes to mutable objects (like lists or dicts) retrieved from the cache and saves them back if they are modified within a tracking context.</p> <pre><code>with cache.track_changes(\"user:123\", \"get\") as user_data:\n    user_data[\"login_count\"] += 1\n# user_data is automatically saved back to the backend if it changed\n</code></pre>"},{"location":"api/lzl/io/persistence/#math-set-operations","title":"Math &amp; Set Operations","text":"<p>Native support for atomic increments and set operations (especially useful with Redis).</p> <pre><code># Increment\ncache.incr(\"counter\", 1)\n\n# Set operations\ncache.sadd(\"users\", \"alice\", \"bob\")\nmembers = cache.smembers(\"users\")\n</code></pre>"},{"location":"api/lzl/io/persistence/#backends","title":"Backends","text":"<p>Supported backends implementations.</p> <ul> <li>Local: Stores data in local files.</li> <li>SQLite: High-performance, single-file database (Recommended for local persistence).</li> <li>Redis: Distributed in-memory store.</li> <li>Object Storage: S3, MinIO, R2 for cloud persistence.</li> </ul>"},{"location":"api/lzl/io/persistence/#lzl.io.persistence.backends","title":"<code>lzl.io.persistence.backends</code>","text":""},{"location":"api/lzl/io/persistence/#serialization","title":"Serialization","text":"<p>Data is serialized before storage. Supported formats: - <code>json</code>: Human-readable, widely supported. - <code>pickle</code>: Python-specific, supports complex objects. - <code>msgpack</code>: Binary, efficient.</p> <p>You can configure compression (gzip, zstd) alongside serialization.</p>"},{"location":"api/lzl/io/persistence/#metrics","title":"Metrics","text":"<p>Attach metrics to track usage or values within the dictionary.</p> <pre><code>from lzl.io.persistence.addons import CountMetric\n\ncache.configure_metric(\"hits\", kind=\"count\")\ncache.metrics[\"hits\"].incr()\n</code></pre>"},{"location":"api/lzl/io/ser/","title":"lzl.io.ser - Serialization","text":"<p>High-performance serialization utilities supporting JSON, Pickle, MsgPack, and compression.</p>"},{"location":"api/lzl/io/ser/#main-interface","title":"Main Interface","text":""},{"location":"api/lzl/io/ser/#lzl.io.ser.base","title":"<code>lzl.io.ser.base</code>","text":""},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer","title":"<code>BaseSerializer</code>","text":"<p>               Bases: <code>ABC</code></p> <p>The Base Serializer Class</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>class BaseSerializer(abc.ABC):\n    \"\"\"\n    The Base Serializer Class\n    \"\"\"\n    name: Optional[str] = None\n    encoding: Optional[str] = None\n    binary: Optional[bool] = False\n    compressor: Optional['CompressionT'] = None\n    previous_compressor: Optional['CompressionT'] = None\n    enforce_string_value: Optional[bool] = False\n    enforce_byte_value: Optional[bool] = False\n    ser_mode: Optional[SerMode] = 'auto'\n    _is_ser: Optional[bool] = True\n\n    def __init__(\n        self,\n        compression: Optional[str] = None,\n        compression_level: Optional[int] = None,\n        encoding: Optional[str] = None,\n        raise_errors: bool = False,\n        enforce_string_value: Optional[bool] = None,\n        enforce_byte_value: Optional[bool] = None,\n        ser_mode: Optional[SerMode] = None,\n        deprecated_compression: Optional[str] = None,\n        schema_map: Optional[Dict[str, str]] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Initializes the serializer\n        \"\"\"\n        if compression is not None or compression_level is not None:\n            from ..compression import get_compression\n            compression_kwargs = kwargs.pop(\"compression_kwargs\", None)\n            decompression_kwargs = kwargs.pop(\"decompression_kwargs\", None)\n            deprecated_compression = kwargs.pop(\"deprecated_compression\", None)\n            self.compressor = get_compression(\n                compression, \n                compression_level = compression_level, \n                compression_kwargs = compression_kwargs, \n                decompression_kwargs = decompression_kwargs,\n            )\n            if deprecated_compression is not None and deprecated_compression != compression:\n                self.previous_compressor = get_compression(deprecated_compression)\n        if encoding is not None: self.encoding = encoding\n        if enforce_string_value is not None: self.enforce_string_value = enforce_string_value\n        if enforce_byte_value is not None: self.enforce_byte_value = enforce_byte_value\n        if ser_mode is not None: self.ser_mode = ser_mode\n        self.schema_map = schema_map\n        self.raise_errors = raise_errors\n        self._kwargs = kwargs\n\n    @property\n    def compression_enabled(self) -&gt; bool:\n        \"\"\"\n        Returns if compression is enabled\n        \"\"\"\n        return self.compressor is not None\n\n    @property\n    def compression_level(self) -&gt; Optional[int]:\n        \"\"\"\n        Returns the compression level\n        \"\"\"\n        return self.compressor.compression_level if self.compressor is not None else None\n\n    @property\n    def is_binary(self) -&gt; bool:\n        \"\"\"\n        Returns whether the serializer output is binary\n        \"\"\"\n        if self.enforce_byte_value: return True\n        if self.enforce_string_value: return False\n        return self.binary or self.compression_enabled\n\n    @staticmethod\n    def fetch_object_classname(obj: ObjectValue, is_type: Optional[bool] = False) -&gt; str:\n        \"\"\"\n        Fetches the object classname\n        \"\"\"\n        return get_object_classname(obj, is_type = is_type)\n\n    @staticmethod\n    def fetch_object_class(name: str) -&gt; Type[SerializableObject]:\n        \"\"\"\n        Gets the object class\n        \"\"\"\n        return get_object_class(name)\n\n    @staticmethod\n    def register_schema(schema: Dict[str, str]) -&gt; None:\n        \"\"\"\n        Registers the schema\n        \"\"\"\n        register_schema_mapping(schema)\n\n    @staticmethod\n    def register_object_class(obj: SerializableObject, is_type: Optional[bool] = False) -&gt; str:\n        \"\"\"\n        Registers the object class\n        \"\"\"\n        return register_object_class(obj, is_type = is_type)\n\n    def create_hash(self, obj: ObjectValue) -&gt; str:\n        \"\"\"\n        Creates a hash for the object\n        \"\"\"\n        return create_object_hash(obj)\n\n    async def acreate_hash(self, obj: ObjectValue) -&gt; str:\n        \"\"\"\n        Creates a hash for the object asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.create_hash, obj)\n\n    def coerce_output_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Coerces the output value\n        \"\"\"\n        if self.enforce_string_value and isinstance(value, bytes): value = value.decode(self.encoding)\n        elif self.enforce_byte_value and not isinstance(value, bytes): value = value.encode(self.encoding)\n        return value\n\n    def compress_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Compresses the value\n        \"\"\"\n        if self.compression_enabled:\n            if isinstance(value, str): value = value.encode(self.encoding)\n            return self.coerce_output_value(self.compressor.compress(value))\n        return self.coerce_output_value(value)\n\n    def deprecated_decompress_value(self, value: Union[str, bytes], **kwargs) -&gt; Optional[Union[str, bytes]]:\n        \"\"\"\n        Attempts to decompress the value using the deprecated compressor\n        \"\"\"\n        e = None\n        attempt_msg = f\"{self.name}\"\n        if self.previous_compressor is not None:\n            try:\n                return self.previous_compressor.decompress(value)\n            except Exception as e:\n                attempt_msg += f\"-&gt; {self.previous_compressor.name}\"\n        try:\n            return zlib.decompress(value)\n        except Exception as e:\n            attempt_msg += \" -&gt; ZLib\"\n            logger.trace(f'[{attempt_msg}] Error in Decompression: {str(value)[:100]}', e)\n            if self.raise_errors: raise e\n            return None\n\n\n    def decompress_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n        # sourcery skip: extract-duplicate-method\n        \"\"\"\n        Decompresses the value\n        \"\"\"\n        if not self.compression_enabled: return value\n        try:\n            value = self.compressor.decompress(value, **kwargs)\n        except Exception as e:\n            if self.previous_compressor is not None:\n                value = self.deprecated_decompress_value(value, **kwargs)\n        if value is not None and not self.binary: value = value.decode(self.encoding)\n        return value\n\n    def encode_value(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Encodes the value\n        \"\"\"\n        raise NotImplementedError\n\n    def encode(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Encodes the value\n        \"\"\"\n        return self.compress_value(self.encode_value(value, **kwargs))\n\n    async def aencode(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Encodes the value asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.encode, value, **kwargs)\n\n    def decode_value(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value\n        \"\"\"\n        raise NotImplementedError\n\n    def decode(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value\n        \"\"\"\n        return self.decode_value(self.decompress_value(value, **kwargs), **kwargs)\n\n    async def adecode(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.decode, value, **kwargs)\n\n    def dumps(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        # sourcery skip: class-extract-method\n        \"\"\"\n        Dumps the value\n        \"\"\"\n        try:\n            return self.encode(value, **kwargs)\n        except Exception as e:\n            logger.trace(f'[{self.name}] Error in Encoding: {str(value)[:500]}', e)\n            if self.raise_errors: raise e\n            return None\n\n    async def adumps(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Dumps the value asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.dumps, value, **kwargs)\n\n    def loads(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Loads the value\n        \"\"\"\n        try:\n            return self.decode(value, **kwargs)\n        except Exception as e:\n            logger.trace(f'[{self.name}] Error in Decoding: {str(value)[:500]}', e)\n            if self.raise_errors: raise e\n            return None\n\n    async def aloads(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Loads the value asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.loads, value, **kwargs)\n\n\n    def serialize_obj(self, obj: SerializableObject, mode: Optional[SerMode] = None, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Serializes the object\n        \"\"\"\n        mode = mode or self.ser_mode\n        return serialize_object(obj, mode = mode, **kwargs)\n\n    def deserialize_obj(\n        self, \n        obj: Union[Dict[str, Any], List[Dict[str, Any]], Any], \n        schema_map: Optional[Dict[str, str]] = None, \n        allow_failed_import: Optional[bool] = False,\n        **kwargs\n    ) -&gt; SerializableObject:\n        \"\"\"\n        Deserializes the object\n        \"\"\"\n        return deserialize_object(obj, schema_map = schema_map or self.schema_map, allow_failed_import = allow_failed_import, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.compression_enabled","title":"<code>compression_enabled</code>  <code>property</code>","text":"<p>Returns if compression is enabled</p>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.compression_level","title":"<code>compression_level</code>  <code>property</code>","text":"<p>Returns the compression level</p>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.is_binary","title":"<code>is_binary</code>  <code>property</code>","text":"<p>Returns whether the serializer output is binary</p>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.fetch_object_classname","title":"<code>fetch_object_classname(obj, is_type=False)</code>  <code>staticmethod</code>","text":"<p>Fetches the object classname</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>@staticmethod\ndef fetch_object_classname(obj: ObjectValue, is_type: Optional[bool] = False) -&gt; str:\n    \"\"\"\n    Fetches the object classname\n    \"\"\"\n    return get_object_classname(obj, is_type = is_type)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.fetch_object_class","title":"<code>fetch_object_class(name)</code>  <code>staticmethod</code>","text":"<p>Gets the object class</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>@staticmethod\ndef fetch_object_class(name: str) -&gt; Type[SerializableObject]:\n    \"\"\"\n    Gets the object class\n    \"\"\"\n    return get_object_class(name)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.register_schema","title":"<code>register_schema(schema)</code>  <code>staticmethod</code>","text":"<p>Registers the schema</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>@staticmethod\ndef register_schema(schema: Dict[str, str]) -&gt; None:\n    \"\"\"\n    Registers the schema\n    \"\"\"\n    register_schema_mapping(schema)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.register_object_class","title":"<code>register_object_class(obj, is_type=False)</code>  <code>staticmethod</code>","text":"<p>Registers the object class</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>@staticmethod\ndef register_object_class(obj: SerializableObject, is_type: Optional[bool] = False) -&gt; str:\n    \"\"\"\n    Registers the object class\n    \"\"\"\n    return register_object_class(obj, is_type = is_type)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.create_hash","title":"<code>create_hash(obj)</code>","text":"<p>Creates a hash for the object</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def create_hash(self, obj: ObjectValue) -&gt; str:\n    \"\"\"\n    Creates a hash for the object\n    \"\"\"\n    return create_object_hash(obj)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.acreate_hash","title":"<code>acreate_hash(obj)</code>  <code>async</code>","text":"<p>Creates a hash for the object asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def acreate_hash(self, obj: ObjectValue) -&gt; str:\n    \"\"\"\n    Creates a hash for the object asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.create_hash, obj)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.coerce_output_value","title":"<code>coerce_output_value(value, **kwargs)</code>","text":"<p>Coerces the output value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def coerce_output_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Coerces the output value\n    \"\"\"\n    if self.enforce_string_value and isinstance(value, bytes): value = value.decode(self.encoding)\n    elif self.enforce_byte_value and not isinstance(value, bytes): value = value.encode(self.encoding)\n    return value\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.compress_value","title":"<code>compress_value(value, **kwargs)</code>","text":"<p>Compresses the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def compress_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Compresses the value\n    \"\"\"\n    if self.compression_enabled:\n        if isinstance(value, str): value = value.encode(self.encoding)\n        return self.coerce_output_value(self.compressor.compress(value))\n    return self.coerce_output_value(value)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.deprecated_decompress_value","title":"<code>deprecated_decompress_value(value, **kwargs)</code>","text":"<p>Attempts to decompress the value using the deprecated compressor</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def deprecated_decompress_value(self, value: Union[str, bytes], **kwargs) -&gt; Optional[Union[str, bytes]]:\n    \"\"\"\n    Attempts to decompress the value using the deprecated compressor\n    \"\"\"\n    e = None\n    attempt_msg = f\"{self.name}\"\n    if self.previous_compressor is not None:\n        try:\n            return self.previous_compressor.decompress(value)\n        except Exception as e:\n            attempt_msg += f\"-&gt; {self.previous_compressor.name}\"\n    try:\n        return zlib.decompress(value)\n    except Exception as e:\n        attempt_msg += \" -&gt; ZLib\"\n        logger.trace(f'[{attempt_msg}] Error in Decompression: {str(value)[:100]}', e)\n        if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.decompress_value","title":"<code>decompress_value(value, **kwargs)</code>","text":"<p>Decompresses the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def decompress_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n    # sourcery skip: extract-duplicate-method\n    \"\"\"\n    Decompresses the value\n    \"\"\"\n    if not self.compression_enabled: return value\n    try:\n        value = self.compressor.decompress(value, **kwargs)\n    except Exception as e:\n        if self.previous_compressor is not None:\n            value = self.deprecated_decompress_value(value, **kwargs)\n    if value is not None and not self.binary: value = value.decode(self.encoding)\n    return value\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.encode_value","title":"<code>encode_value(value, **kwargs)</code>","text":"<p>Encodes the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def encode_value(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Encodes the value\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.encode","title":"<code>encode(value, **kwargs)</code>","text":"<p>Encodes the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def encode(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Encodes the value\n    \"\"\"\n    return self.compress_value(self.encode_value(value, **kwargs))\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.aencode","title":"<code>aencode(value, **kwargs)</code>  <code>async</code>","text":"<p>Encodes the value asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def aencode(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Encodes the value asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.encode, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.decode_value","title":"<code>decode_value(value, **kwargs)</code>","text":"<p>Decodes the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def decode_value(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.decode","title":"<code>decode(value, **kwargs)</code>","text":"<p>Decodes the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def decode(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value\n    \"\"\"\n    return self.decode_value(self.decompress_value(value, **kwargs), **kwargs)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.adecode","title":"<code>adecode(value, **kwargs)</code>  <code>async</code>","text":"<p>Decodes the value asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def adecode(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.decode, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.dumps","title":"<code>dumps(value, **kwargs)</code>","text":"<p>Dumps the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def dumps(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    # sourcery skip: class-extract-method\n    \"\"\"\n    Dumps the value\n    \"\"\"\n    try:\n        return self.encode(value, **kwargs)\n    except Exception as e:\n        logger.trace(f'[{self.name}] Error in Encoding: {str(value)[:500]}', e)\n        if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.adumps","title":"<code>adumps(value, **kwargs)</code>  <code>async</code>","text":"<p>Dumps the value asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def adumps(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Dumps the value asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.dumps, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.loads","title":"<code>loads(value, **kwargs)</code>","text":"<p>Loads the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def loads(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Loads the value\n    \"\"\"\n    try:\n        return self.decode(value, **kwargs)\n    except Exception as e:\n        logger.trace(f'[{self.name}] Error in Decoding: {str(value)[:500]}', e)\n        if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.aloads","title":"<code>aloads(value, **kwargs)</code>  <code>async</code>","text":"<p>Loads the value asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def aloads(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Loads the value asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.loads, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.serialize_obj","title":"<code>serialize_obj(obj, mode=None, **kwargs)</code>","text":"<p>Serializes the object</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def serialize_obj(self, obj: SerializableObject, mode: Optional[SerMode] = None, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Serializes the object\n    \"\"\"\n    mode = mode or self.ser_mode\n    return serialize_object(obj, mode = mode, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser.base.BaseSerializer.deserialize_obj","title":"<code>deserialize_obj(obj, schema_map=None, allow_failed_import=False, **kwargs)</code>","text":"<p>Deserializes the object</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def deserialize_obj(\n    self, \n    obj: Union[Dict[str, Any], List[Dict[str, Any]], Any], \n    schema_map: Optional[Dict[str, str]] = None, \n    allow_failed_import: Optional[bool] = False,\n    **kwargs\n) -&gt; SerializableObject:\n    \"\"\"\n    Deserializes the object\n    \"\"\"\n    return deserialize_object(obj, schema_map = schema_map or self.schema_map, allow_failed_import = allow_failed_import, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/ser/#formatters","title":"Formatters","text":""},{"location":"api/lzl/io/ser/#lzl.io.ser._json","title":"<code>lzl.io.ser._json</code>","text":""},{"location":"api/lzl/io/ser/#lzl.io.ser._json.JsonSerializer","title":"<code>JsonSerializer</code>","text":"<p>               Bases: <code>BaseSerializer</code></p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>class JsonSerializer(BaseSerializer):\n\n    name: Optional[str] = \"json\"\n    encoding: Optional[str] = \"utf-8\"\n    jsonlib: JsonLibT = default_json\n    disable_object_serialization: Optional[bool] = False\n    disable_nested_values: Optional[bool] = None\n    allow_failed_import: Optional[bool] = False\n\n    def __init__(\n        self, \n        jsonlib: Optional[Union[str, Any]] = None,\n        compression: Optional[str] = None,\n        compression_level: int | None = None, \n        encoding: str | None = None, \n        serialization_obj: Optional[Type[BaseModel]] = None,\n        serialization_obj_kwargs: Optional[Dict[str, Any]] = None,\n        disable_object_serialization: Optional[bool] = None,\n        disable_nested_values: Optional[bool] = None,\n        verbosity: Optional[int] = None,\n        **kwargs\n    ):\n        super().__init__(compression = compression, compression_level = compression_level, encoding = encoding, **kwargs)\n        self.serialization_obj = serialization_obj\n        self.serialization_obj_kwargs = serialization_obj_kwargs or {}\n        self.serialization_schemas: Dict[str, Type[BaseModel]] = {}\n        if disable_object_serialization is not None:\n            self.disable_object_serialization = disable_object_serialization\n        if disable_nested_values is not None:\n            self.disable_nested_values = disable_nested_values\n        if jsonlib is not None:\n            if isinstance(jsonlib, str):\n                jsonlib = lazy_import(jsonlib, is_module=True)\n            assert hasattr(jsonlib, \"dumps\") and hasattr(jsonlib, \"loads\"), f\"Invalid JSON Library: {jsonlib}\"\n            self.jsonlib = jsonlib\n        self.verbosity = verbosity\n        self.jsonlib_name: str = self.jsonlib.__name__\n        if 'bindings' in self.jsonlib_name.lower():\n            self.jsonlib_name = self.jsonlib_name.rsplit('_', 1)[-1]\n\n    @classmethod\n    def set_default_lib(cls, lib: Union[str, JsonLibT, ModuleType]) -&gt; None:\n        \"\"\"\n        Sets the default JSON library\n        \"\"\"\n        global default_json\n        if isinstance(lib, str):\n            lib = lazy_import(lib, is_module=True)\n        assert hasattr(lib, \"dumps\") and hasattr(lib, \"loads\"), f\"Invalid JSON Library: {lib}\"\n        cls.jsonlib = lib\n        default_json = lib\n\n    @property\n    def _is_verbose(self) -&gt; bool:\n        \"\"\"\n        Returns whether the serializer is verbose\n        \"\"\"\n        return self.verbosity is None or self.verbosity &gt;= 1\n\n    @property\n    def _is_silenced(self) -&gt; bool:\n        \"\"\"\n        Returns whether the serializer is verbose\n        \"\"\"\n        return self.verbosity and self.verbosity &lt; 0\n\n    def serialize_obj(self, obj: SerializableObject, mode: Optional[SerMode] = None, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Serializes the object\n        \"\"\"\n        mode = mode or self.ser_mode\n        if 'disable_nested_values' not in kwargs and self.disable_nested_values is not None:\n            kwargs['disable_nested_values'] = self.disable_nested_values\n        if 'disable_object_serialization' in kwargs:\n            disable_object_serialization = kwargs.pop('disable_object_serialization')\n            mode = 'raw' if disable_object_serialization else mode\n        elif self.disable_object_serialization:\n            mode = 'raw'\n        return serialize_object(obj, mode = mode, **kwargs)\n\n    def encode_value(self, value: Union[Any, SchemaType], mode: Optional[SerMode] = None, **kwargs) -&gt; str:\n        \"\"\"\n        Encode the value with the JSON Library\n        \"\"\"\n        try:\n            value_dict = self.serialize_obj(value, mode = mode, **kwargs, **self.serialization_obj_kwargs)\n            encoded = self.jsonlib.dumps(value_dict, **kwargs)\n            return self.coerce_output_value(encoded)\n\n        except Exception as e:\n            if not self._is_silenced: logger.trace(f'Error Encoding Value: |r|({type(value)})|e| {str(value)[:1000]}', e, colored = True)\n        try:\n            encoded = self.jsonlib.dumps(value, **kwargs)\n            return self.coerce_output_value(encoded)\n        except Exception as e:\n            if not self._is_silenced: logger.info(f'Error Encoding Value: |r|({type(value)}) {e}|e| {str(value)[:1000]}', colored = True, prefix = self.jsonlib_name)\n            if self.raise_errors: raise e\n        return None\n\n\n    def decode(self, value: Union[str, bytes], schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value\n        \"\"\"\n        try:\n            decompressed_value = self.decompress_value(value, **kwargs)\n            if decompressed_value is not None:\n                value = decompressed_value\n        except Exception as e:\n            if not self._is_silenced: logger.info(f'Error Decompressing Value: |r|({type(value)}) {e}|e| {str(value)[:100]}', colored = True, prefix = self.jsonlib_name)\n            if raise_errors or self.raise_errors: raise ValueError(f\"[{self.name}] Error in Decompression: {str(value)[:100]}\") from e\n            # return self.decode_value(value, **kwargs)\n        return self.decode_value(value, schema_map = schema_map, raise_errors = raise_errors, **kwargs)\n\n\n    def decode_value(self, value: str, schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n        \"\"\"\n        Decode the value with the JSON Library\n        \"\"\"\n        if value is None: return None\n        if isinstance(value, (str, bytes)):\n            try:\n                # value = self.check_encoded_value(value)\n                value = self.jsonlib.loads(value, **kwargs)\n            except Exception as e:\n                if isinstance(value, str) and 'Exception' in value or 'Traceback (most recent call last):' in value:\n                    return value\n                str_value = str(value)\n                if not schema_map: str_value = str_value[:1000]\n                if self._is_verbose: logger.info(f'Error JSON Decoding Value: |r|({type(value)}) {e}|e| {str_value}', colored = True, prefix = self.jsonlib_name)\n                if raise_errors or self.raise_errors: raise e\n        try:\n            return self.deserialize_obj(value, schema_map = schema_map, allow_failed_import = self.allow_failed_import)\n        except Exception as e:\n            str_value = str(value)\n            if not schema_map: str_value = str_value[:1000]\n            if not self._is_silenced: logger.trace(f'Error Deserializing Object: ({type(value)}) {str_value}', e, prefix = self.jsonlib_name)\n            if raise_errors or self.raise_errors: raise e\n        return None\n\n\n    async def adecode(self, value: Union[str, bytes], schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value asynchronously\n        \"\"\"\n        return await ThreadPool.arun(self.decode, value, schema_map = schema_map, raise_errors = raise_errors, **kwargs)\n\n\n    if TYPE_CHECKING:\n        def dumps(\n            self, \n            value: ObjectValue, \n            skipkeys: bool = False, \n            ensure_ascii: bool = True, \n            check_circular: bool = True,\n            allow_nan: bool = True, \n            cls: Optional[Any] = None, \n            indent: Optional[int] = None, \n            separators: Optional[Tuple[str, str]] = None,\n            default: Optional[Any] = None, \n            sort_keys: bool = False,\n            mode: Optional[SerMode] = None,\n            **kwargs\n        ) -&gt; Union[str, bytes]:\n            \"\"\"Serialize ``obj`` to a JSON formatted ``str``.\n\n            If ``skipkeys`` is true then ``dict`` keys that are not basic types\n            (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n            instead of raising a ``TypeError``.\n\n            If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n            characters if they appear in strings contained in ``obj``. Otherwise, all\n            such characters are escaped in JSON strings.\n\n            If ``check_circular`` is false, then the circular reference check\n            for container types will be skipped and a circular reference will\n            result in an ``RecursionError`` (or worse).\n\n            If ``allow_nan`` is false, then it will be a ``ValueError`` to\n            serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n            strict compliance of the JSON specification, instead of using the\n            JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n\n            If ``indent`` is a non-negative integer, then JSON array elements and\n            object members will be pretty-printed with that indent level. An indent\n            level of 0 will only insert newlines. ``None`` is the most compact\n            representation.\n\n            If specified, ``separators`` should be an ``(item_separator, key_separator)``\n            tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n            ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n            you should specify ``(',', ':')`` to eliminate whitespace.\n\n            ``default(obj)`` is a function that should return a serializable version\n            of obj or raise TypeError. The default simply raises TypeError.\n\n            If *sort_keys* is true (default: ``False``), then the output of\n            dictionaries will be sorted by key.\n\n            To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n            ``.default()`` method to serialize additional types), specify it with\n            the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n\n            \"\"\"\n            ...\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._json.JsonSerializer.set_default_lib","title":"<code>set_default_lib(lib)</code>  <code>classmethod</code>","text":"<p>Sets the default JSON library</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>@classmethod\ndef set_default_lib(cls, lib: Union[str, JsonLibT, ModuleType]) -&gt; None:\n    \"\"\"\n    Sets the default JSON library\n    \"\"\"\n    global default_json\n    if isinstance(lib, str):\n        lib = lazy_import(lib, is_module=True)\n    assert hasattr(lib, \"dumps\") and hasattr(lib, \"loads\"), f\"Invalid JSON Library: {lib}\"\n    cls.jsonlib = lib\n    default_json = lib\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._json.JsonSerializer.serialize_obj","title":"<code>serialize_obj(obj, mode=None, **kwargs)</code>","text":"<p>Serializes the object</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def serialize_obj(self, obj: SerializableObject, mode: Optional[SerMode] = None, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Serializes the object\n    \"\"\"\n    mode = mode or self.ser_mode\n    if 'disable_nested_values' not in kwargs and self.disable_nested_values is not None:\n        kwargs['disable_nested_values'] = self.disable_nested_values\n    if 'disable_object_serialization' in kwargs:\n        disable_object_serialization = kwargs.pop('disable_object_serialization')\n        mode = 'raw' if disable_object_serialization else mode\n    elif self.disable_object_serialization:\n        mode = 'raw'\n    return serialize_object(obj, mode = mode, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._json.JsonSerializer.encode_value","title":"<code>encode_value(value, mode=None, **kwargs)</code>","text":"<p>Encode the value with the JSON Library</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def encode_value(self, value: Union[Any, SchemaType], mode: Optional[SerMode] = None, **kwargs) -&gt; str:\n    \"\"\"\n    Encode the value with the JSON Library\n    \"\"\"\n    try:\n        value_dict = self.serialize_obj(value, mode = mode, **kwargs, **self.serialization_obj_kwargs)\n        encoded = self.jsonlib.dumps(value_dict, **kwargs)\n        return self.coerce_output_value(encoded)\n\n    except Exception as e:\n        if not self._is_silenced: logger.trace(f'Error Encoding Value: |r|({type(value)})|e| {str(value)[:1000]}', e, colored = True)\n    try:\n        encoded = self.jsonlib.dumps(value, **kwargs)\n        return self.coerce_output_value(encoded)\n    except Exception as e:\n        if not self._is_silenced: logger.info(f'Error Encoding Value: |r|({type(value)}) {e}|e| {str(value)[:1000]}', colored = True, prefix = self.jsonlib_name)\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._json.JsonSerializer.decode","title":"<code>decode(value, schema_map=None, raise_errors=None, **kwargs)</code>","text":"<p>Decodes the value</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def decode(self, value: Union[str, bytes], schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value\n    \"\"\"\n    try:\n        decompressed_value = self.decompress_value(value, **kwargs)\n        if decompressed_value is not None:\n            value = decompressed_value\n    except Exception as e:\n        if not self._is_silenced: logger.info(f'Error Decompressing Value: |r|({type(value)}) {e}|e| {str(value)[:100]}', colored = True, prefix = self.jsonlib_name)\n        if raise_errors or self.raise_errors: raise ValueError(f\"[{self.name}] Error in Decompression: {str(value)[:100]}\") from e\n        # return self.decode_value(value, **kwargs)\n    return self.decode_value(value, schema_map = schema_map, raise_errors = raise_errors, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._json.JsonSerializer.decode_value","title":"<code>decode_value(value, schema_map=None, raise_errors=None, **kwargs)</code>","text":"<p>Decode the value with the JSON Library</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def decode_value(self, value: str, schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n    \"\"\"\n    Decode the value with the JSON Library\n    \"\"\"\n    if value is None: return None\n    if isinstance(value, (str, bytes)):\n        try:\n            # value = self.check_encoded_value(value)\n            value = self.jsonlib.loads(value, **kwargs)\n        except Exception as e:\n            if isinstance(value, str) and 'Exception' in value or 'Traceback (most recent call last):' in value:\n                return value\n            str_value = str(value)\n            if not schema_map: str_value = str_value[:1000]\n            if self._is_verbose: logger.info(f'Error JSON Decoding Value: |r|({type(value)}) {e}|e| {str_value}', colored = True, prefix = self.jsonlib_name)\n            if raise_errors or self.raise_errors: raise e\n    try:\n        return self.deserialize_obj(value, schema_map = schema_map, allow_failed_import = self.allow_failed_import)\n    except Exception as e:\n        str_value = str(value)\n        if not schema_map: str_value = str_value[:1000]\n        if not self._is_silenced: logger.trace(f'Error Deserializing Object: ({type(value)}) {str_value}', e, prefix = self.jsonlib_name)\n        if raise_errors or self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._json.JsonSerializer.adecode","title":"<code>adecode(value, schema_map=None, raise_errors=None, **kwargs)</code>  <code>async</code>","text":"<p>Decodes the value asynchronously</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>async def adecode(self, value: Union[str, bytes], schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value asynchronously\n    \"\"\"\n    return await ThreadPool.arun(self.decode, value, schema_map = schema_map, raise_errors = raise_errors, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._json.JsonSerializer.dumps","title":"<code>dumps(value, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, mode=None, **kwargs)</code>","text":"<p>Serialize <code>obj</code> to a JSON formatted <code>str</code>.</p> <p>If <code>skipkeys</code> is true then <code>dict</code> keys that are not basic types (<code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>None</code>) will be skipped instead of raising a <code>TypeError</code>.</p> <p>If <code>ensure_ascii</code> is false, then the return value can contain non-ASCII characters if they appear in strings contained in <code>obj</code>. Otherwise, all such characters are escaped in JSON strings.</p> <p>If <code>check_circular</code> is false, then the circular reference check for container types will be skipped and a circular reference will result in an <code>RecursionError</code> (or worse).</p> <p>If <code>allow_nan</code> is false, then it will be a <code>ValueError</code> to serialize out of range <code>float</code> values (<code>nan</code>, <code>inf</code>, <code>-inf</code>) in strict compliance of the JSON specification, instead of using the JavaScript equivalents (<code>NaN</code>, <code>Infinity</code>, <code>-Infinity</code>).</p> <p>If <code>indent</code> is a non-negative integer, then JSON array elements and object members will be pretty-printed with that indent level. An indent level of 0 will only insert newlines. <code>None</code> is the most compact representation.</p> <p>If specified, <code>separators</code> should be an <code>(item_separator, key_separator)</code> tuple.  The default is <code>(', ', ': ')</code> if indent is <code>None</code> and <code>(',', ': ')</code> otherwise.  To get the most compact JSON representation, you should specify <code>(',', ':')</code> to eliminate whitespace.</p> <p><code>default(obj)</code> is a function that should return a serializable version of obj or raise TypeError. The default simply raises TypeError.</p> <p>If sort_keys is true (default: <code>False</code>), then the output of dictionaries will be sorted by key.</p> <p>To use a custom <code>JSONEncoder</code> subclass (e.g. one that overrides the <code>.default()</code> method to serialize additional types), specify it with the <code>cls</code> kwarg; otherwise <code>JSONEncoder</code> is used.</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def dumps(\n    self, \n    value: ObjectValue, \n    skipkeys: bool = False, \n    ensure_ascii: bool = True, \n    check_circular: bool = True,\n    allow_nan: bool = True, \n    cls: Optional[Any] = None, \n    indent: Optional[int] = None, \n    separators: Optional[Tuple[str, str]] = None,\n    default: Optional[Any] = None, \n    sort_keys: bool = False,\n    mode: Optional[SerMode] = None,\n    **kwargs\n) -&gt; Union[str, bytes]:\n    \"\"\"Serialize ``obj`` to a JSON formatted ``str``.\n\n    If ``skipkeys`` is true then ``dict`` keys that are not basic types\n    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n    instead of raising a ``TypeError``.\n\n    If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n    characters if they appear in strings contained in ``obj``. Otherwise, all\n    such characters are escaped in JSON strings.\n\n    If ``check_circular`` is false, then the circular reference check\n    for container types will be skipped and a circular reference will\n    result in an ``RecursionError`` (or worse).\n\n    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n    strict compliance of the JSON specification, instead of using the\n    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n\n    If ``indent`` is a non-negative integer, then JSON array elements and\n    object members will be pretty-printed with that indent level. An indent\n    level of 0 will only insert newlines. ``None`` is the most compact\n    representation.\n\n    If specified, ``separators`` should be an ``(item_separator, key_separator)``\n    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n    you should specify ``(',', ':')`` to eliminate whitespace.\n\n    ``default(obj)`` is a function that should return a serializable version\n    of obj or raise TypeError. The default simply raises TypeError.\n\n    If *sort_keys* is true (default: ``False``), then the output of\n    dictionaries will be sorted by key.\n\n    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n    ``.default()`` method to serialize additional types), specify it with\n    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._pickle","title":"<code>lzl.io.ser._pickle</code>","text":""},{"location":"api/lzl/io/ser/#lzl.io.ser._pickle.PickleSerializer","title":"<code>PickleSerializer</code>","text":"<p>               Bases: <code>BinaryBaseSerializer</code></p> Source code in <code>src/lzl/io/ser/_pickle.py</code> <pre><code>class PickleSerializer(BinaryBaseSerializer):\n    name: Optional[str] = \"pickle\"\n    encoding: Optional[str] = \"utf-8\"\n    picklelib: PickleLibT = default_pickle\n\n    def __init__(\n        self, \n        picklelib: Optional[Union[str, Any]] = None,\n        compression: Optional[str] = None,\n        compression_level: int | None = None, \n        encoding: str | None = None, \n        **kwargs\n    ):\n        super().__init__(compression = compression, compression_level = compression_level, encoding = encoding, **kwargs)\n        if picklelib is not None:\n            if isinstance(picklelib, str):\n                picklelib = lazy_import(picklelib, is_module=True)\n            assert hasattr(picklelib, \"dumps\") and hasattr(picklelib, \"loads\"), f\"Invalid Pickle Library: {picklelib}\"\n            self.picklelib = picklelib\n        self.picklelib_name = self.picklelib.__name__\n\n    @classmethod\n    def set_default_lib(cls, lib: Union[str, PickleLibT, ModuleType]) -&gt; None:\n        \"\"\"\n        Sets the default Pickle library\n        \"\"\"\n        global default_pickle\n        if isinstance(lib, str):\n            lib = lazy_import(lib, is_module=True)\n        assert hasattr(lib, \"loads\") and hasattr(lib, \"dumps\"), f\"Invalid Pickle Library: `{lib}`\"\n        cls.picklelib = lib\n        default_pickle = lib\n\n    def encode_value(self, value: Union[Any, SchemaType], **kwargs) -&gt; bytes:\n        \"\"\"\n        Encode the value with the Pickle Library\n        \"\"\"\n        try:\n            return self.picklelib.dumps(value, **kwargs)\n        except Exception as e:\n            logger.trace(f'Error Encoding Object: ({type(value)}) {str(value)[:1000]}', e, prefix = self.picklelib_name)\n            if self.raise_errors: raise e\n        return None\n\n    def decode_value(self, value: bytes, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n        \"\"\"\n        Decode the value with the Pickle Library\n        \"\"\"\n        try:\n            if self.picklelib_name == 'cloudpickle':\n                if 'encoding' not in kwargs:\n                    kwargs['encoding'] = self.encoding\n                if 'fix_imports' not in kwargs:\n                    kwargs['fix_imports'] = False\n            return self.picklelib.loads(value, **kwargs)\n        except Exception as e:\n            logger.trace(f'Error Deserializing Object: ({type(value)}) {str(value)[:1000]}', e, prefix = self.picklelib_name)\n            if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._pickle.PickleSerializer.set_default_lib","title":"<code>set_default_lib(lib)</code>  <code>classmethod</code>","text":"<p>Sets the default Pickle library</p> Source code in <code>src/lzl/io/ser/_pickle.py</code> <pre><code>@classmethod\ndef set_default_lib(cls, lib: Union[str, PickleLibT, ModuleType]) -&gt; None:\n    \"\"\"\n    Sets the default Pickle library\n    \"\"\"\n    global default_pickle\n    if isinstance(lib, str):\n        lib = lazy_import(lib, is_module=True)\n    assert hasattr(lib, \"loads\") and hasattr(lib, \"dumps\"), f\"Invalid Pickle Library: `{lib}`\"\n    cls.picklelib = lib\n    default_pickle = lib\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._pickle.PickleSerializer.encode_value","title":"<code>encode_value(value, **kwargs)</code>","text":"<p>Encode the value with the Pickle Library</p> Source code in <code>src/lzl/io/ser/_pickle.py</code> <pre><code>def encode_value(self, value: Union[Any, SchemaType], **kwargs) -&gt; bytes:\n    \"\"\"\n    Encode the value with the Pickle Library\n    \"\"\"\n    try:\n        return self.picklelib.dumps(value, **kwargs)\n    except Exception as e:\n        logger.trace(f'Error Encoding Object: ({type(value)}) {str(value)[:1000]}', e, prefix = self.picklelib_name)\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._pickle.PickleSerializer.decode_value","title":"<code>decode_value(value, **kwargs)</code>","text":"<p>Decode the value with the Pickle Library</p> Source code in <code>src/lzl/io/ser/_pickle.py</code> <pre><code>def decode_value(self, value: bytes, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n    \"\"\"\n    Decode the value with the Pickle Library\n    \"\"\"\n    try:\n        if self.picklelib_name == 'cloudpickle':\n            if 'encoding' not in kwargs:\n                kwargs['encoding'] = self.encoding\n            if 'fix_imports' not in kwargs:\n                kwargs['fix_imports'] = False\n        return self.picklelib.loads(value, **kwargs)\n    except Exception as e:\n        logger.trace(f'Error Deserializing Object: ({type(value)}) {str(value)[:1000]}', e, prefix = self.picklelib_name)\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._msgpack","title":"<code>lzl.io.ser._msgpack</code>","text":""},{"location":"api/lzl/io/ser/#lzl.io.ser._msgpack.MsgPackSerializer","title":"<code>MsgPackSerializer</code>","text":"<p>               Bases: <code>BinaryBaseSerializer</code></p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>class MsgPackSerializer(BinaryBaseSerializer):\n    name: Optional[str] = \"msgpack\"\n    encoding: Optional[str] = \"utf-8\"\n    disable_object_serialization: Optional[bool] = False\n    jsonlib: JsonLibT = default_json\n    msgpacklib: MsgPackLibT = default_msgpack\n\n    def __init__(\n        self, \n        msgpacklib: Optional[Union[str, Any]] = None,\n        compression: Optional[str] = None,\n        compression_level: int | None = None, \n        encoding: str | None = None, \n        serialization_obj: Optional[Type[BaseModel]] = None,\n        serialization_obj_kwargs: Optional[Dict[str, Any]] = None,\n        disable_object_serialization: Optional[bool] = None,\n        jsonlib: Optional[Union[str, Any]] = None,\n        **kwargs\n    ):\n        if not default_msgpack:\n            raise ImportError(\"MsgPack Serializer is not available. Please install `msgpack`\")\n        super().__init__(compression = compression, compression_level = compression_level, encoding = encoding, **kwargs)\n        self.serialization_obj = serialization_obj\n        self.serialization_obj_kwargs = serialization_obj_kwargs or {}\n        self.serialization_schemas: Dict[str, Type[BaseModel]] = {}\n        if disable_object_serialization is not None:\n            self.disable_object_serialization = disable_object_serialization\n\n        if msgpacklib is not None:\n            if isinstance(msgpacklib, str):\n                msgpacklib = lazy_import(msgpacklib, is_module=True)\n            assert hasattr(msgpacklib, \"packb\") and hasattr(msgpacklib, \"unpackb\"), f\"Invalid MsgPack Library: {msgpacklib}\"\n            self.msgpacklib = msgpacklib\n        self.msgpacklib_name = self.msgpacklib.__name__\n        if jsonlib is not None:\n            if isinstance(jsonlib, str):\n                jsonlib = lazy_import(jsonlib, is_module=True)\n            assert hasattr(jsonlib, \"dumps\") and hasattr(jsonlib, \"loads\"), f\"Invalid JSON Library: {jsonlib}\"\n            self.jsonlib = jsonlib\n        self.jsonlib_name = self.jsonlib.__name__\n\n\n    @classmethod\n    def set_default_lib(cls, lib: Union[str, MsgPackLibT, ModuleType]) -&gt; None:\n        \"\"\"\n        Sets the default MsgPack library\n        \"\"\"\n        global default_msgpack\n        if isinstance(lib, str):\n            lib = lazy_import(lib, is_module=True)\n        assert hasattr(lib, \"packb\") and hasattr(lib, \"unpackb\"), f\"Invalid Msgpack Library: `{lib}`\"\n        cls.msgpacklib = lib\n        default_msgpack = lib\n\n    def default_serialization_hook(self, obj: ObjectValue):\n        \"\"\"\n        Default Serialization Hook\n        \"\"\"\n        if not isinstance(obj, BaseModel) and not hasattr(obj, 'model_dump'):\n            logger.info(f'Invalid Object Type: |r|{type(obj)}|e| {obj}', colored = True, prefix = \"msgpack\")\n            return obj\n\n        if self.disable_object_serialization: \n            return obj.model_dump_json(**self.serialization_obj_kwargs)\n\n        obj_class_name = self.fetch_object_classname(obj)\n        if obj_class_name not in self.serialization_schemas:\n            self.serialization_schemas[obj_class_name] = obj.__class__\n        data = obj.model_dump(mode = 'json', **self.serialization_obj_kwargs)\n        data['__class__'] = obj_class_name\n        return self.msgpacklib.ExtType(2, self.jsonlib.dumps(data).encode(self.encoding))\n\n    def default_deserialization_hook(self, code: int, data: Union[str, bytes]) -&gt; ObjectValue:\n        \"\"\"\n        Default Deserialization Hook\n        \"\"\"\n        if code != 2: return data\n        if isinstance(data, bytes): data = data.decode(self.encoding)\n        try:\n            data = self.jsonlib.loads(data)\n        except Exception as e:\n            logger.info(f'Error Decoding Value: |r|({type(data)}) {e}|e| {str(data)[:500]}', colored = True, prefix = \"msgpack\")\n            if self.raise_errors: raise e\n            return data\n        if not self.disable_object_serialization:\n            _class = data.pop('__class__', None)\n            if _class is not None:\n                if _class not in self.serialization_schemas:\n                    self.serialization_schemas[_class] = lazy_import(_class)\n                _class = self.serialization_schemas[_class]\n                return _class.model_validate(data, **self.serialization_obj_kwargs)\n        elif self.serialization_obj is not None:\n            return self.serialization_obj.model_validate(data, **self.serialization_obj_kwargs)\n        return data\n\n    def encode_value(self, value: Union[Any, SchemaType], **kwargs) -&gt; bytes:\n        \"\"\"\n        Encode the value with the Pickle Library\n        \"\"\"\n        if 'use_bin_type' not in kwargs: kwargs['use_bin_type'] = True\n        if 'default' not in kwargs: kwargs['default'] = self.default_serialization_hook\n        try:\n            return self.msgpacklib.packb(value, **kwargs)\n        except Exception as e:\n            logger.info(f'Error Encoding Value: |r|({type(value)}) {e}|e| {str(value)[:500]}', colored = True, prefix = \"msgpack\")\n            if self.raise_errors: raise e\n        return None\n\n    def decode_value(self, value: bytes, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n        \"\"\"\n        Decode the value with the Pickle Library\n        \"\"\"\n        try:\n            if 'raw' not in kwargs: kwargs['raw'] = False\n            if 'ext_hook' not in kwargs: kwargs['ext_hook'] = self.default_deserialization_hook\n            return self.msgpacklib.unpackb(value, **kwargs)\n        except Exception as e:\n            logger.info(f'Error Decoding Value: |r|({type(value)}) {e}|e| {str(value)[:500]}', colored = True, prefix = \"msgpack\")\n            if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._msgpack.MsgPackSerializer.set_default_lib","title":"<code>set_default_lib(lib)</code>  <code>classmethod</code>","text":"<p>Sets the default MsgPack library</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>@classmethod\ndef set_default_lib(cls, lib: Union[str, MsgPackLibT, ModuleType]) -&gt; None:\n    \"\"\"\n    Sets the default MsgPack library\n    \"\"\"\n    global default_msgpack\n    if isinstance(lib, str):\n        lib = lazy_import(lib, is_module=True)\n    assert hasattr(lib, \"packb\") and hasattr(lib, \"unpackb\"), f\"Invalid Msgpack Library: `{lib}`\"\n    cls.msgpacklib = lib\n    default_msgpack = lib\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._msgpack.MsgPackSerializer.default_serialization_hook","title":"<code>default_serialization_hook(obj)</code>","text":"<p>Default Serialization Hook</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>def default_serialization_hook(self, obj: ObjectValue):\n    \"\"\"\n    Default Serialization Hook\n    \"\"\"\n    if not isinstance(obj, BaseModel) and not hasattr(obj, 'model_dump'):\n        logger.info(f'Invalid Object Type: |r|{type(obj)}|e| {obj}', colored = True, prefix = \"msgpack\")\n        return obj\n\n    if self.disable_object_serialization: \n        return obj.model_dump_json(**self.serialization_obj_kwargs)\n\n    obj_class_name = self.fetch_object_classname(obj)\n    if obj_class_name not in self.serialization_schemas:\n        self.serialization_schemas[obj_class_name] = obj.__class__\n    data = obj.model_dump(mode = 'json', **self.serialization_obj_kwargs)\n    data['__class__'] = obj_class_name\n    return self.msgpacklib.ExtType(2, self.jsonlib.dumps(data).encode(self.encoding))\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._msgpack.MsgPackSerializer.default_deserialization_hook","title":"<code>default_deserialization_hook(code, data)</code>","text":"<p>Default Deserialization Hook</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>def default_deserialization_hook(self, code: int, data: Union[str, bytes]) -&gt; ObjectValue:\n    \"\"\"\n    Default Deserialization Hook\n    \"\"\"\n    if code != 2: return data\n    if isinstance(data, bytes): data = data.decode(self.encoding)\n    try:\n        data = self.jsonlib.loads(data)\n    except Exception as e:\n        logger.info(f'Error Decoding Value: |r|({type(data)}) {e}|e| {str(data)[:500]}', colored = True, prefix = \"msgpack\")\n        if self.raise_errors: raise e\n        return data\n    if not self.disable_object_serialization:\n        _class = data.pop('__class__', None)\n        if _class is not None:\n            if _class not in self.serialization_schemas:\n                self.serialization_schemas[_class] = lazy_import(_class)\n            _class = self.serialization_schemas[_class]\n            return _class.model_validate(data, **self.serialization_obj_kwargs)\n    elif self.serialization_obj is not None:\n        return self.serialization_obj.model_validate(data, **self.serialization_obj_kwargs)\n    return data\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._msgpack.MsgPackSerializer.encode_value","title":"<code>encode_value(value, **kwargs)</code>","text":"<p>Encode the value with the Pickle Library</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>def encode_value(self, value: Union[Any, SchemaType], **kwargs) -&gt; bytes:\n    \"\"\"\n    Encode the value with the Pickle Library\n    \"\"\"\n    if 'use_bin_type' not in kwargs: kwargs['use_bin_type'] = True\n    if 'default' not in kwargs: kwargs['default'] = self.default_serialization_hook\n    try:\n        return self.msgpacklib.packb(value, **kwargs)\n    except Exception as e:\n        logger.info(f'Error Encoding Value: |r|({type(value)}) {e}|e| {str(value)[:500]}', colored = True, prefix = \"msgpack\")\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/ser/#lzl.io.ser._msgpack.MsgPackSerializer.decode_value","title":"<code>decode_value(value, **kwargs)</code>","text":"<p>Decode the value with the Pickle Library</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>def decode_value(self, value: bytes, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n    \"\"\"\n    Decode the value with the Pickle Library\n    \"\"\"\n    try:\n        if 'raw' not in kwargs: kwargs['raw'] = False\n        if 'ext_hook' not in kwargs: kwargs['ext_hook'] = self.default_deserialization_hook\n        return self.msgpacklib.unpackb(value, **kwargs)\n    except Exception as e:\n        logger.info(f'Error Decoding Value: |r|({type(value)}) {e}|e| {str(value)[:500]}', colored = True, prefix = \"msgpack\")\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/ser/#usage","title":"Usage","text":"<pre><code>from lzl.io.ser import serialize, deserialize\n\ndata = {\"complex\": \"object\"}\n\n# Auto-detect format based on context or configuration\ns = serialize(data, format=\"json\")\nd = deserialize(s, format=\"json\")\n</code></pre>"},{"location":"api/lzo/","title":"lzo - Lazy Objects/Registry","text":"<p>The <code>lzo</code> namespace provides object registry patterns, state management, settings configuration, and related functionalities.</p>"},{"location":"api/lzo/#key-modules","title":"Key Modules","text":"<ul> <li>Registry: Object registry with lifecycle hooks and dependency injection</li> <li>Types: Pydantic-based configuration and settings management</li> <li>Utils: Lightweight utility helpers for common operations</li> </ul>"},{"location":"api/lzo/#overview","title":"Overview","text":"<p>The <code>lzo</code> toolkit focuses on object lifecycle management, configuration handling, and reusable patterns for building robust applications. It provides a clean, type-safe way to manage application state and dependencies.</p>"},{"location":"api/lzo/#installation","title":"Installation","text":"<p>The <code>lzo</code> module is included with the base <code>lazyops</code> installation:</p> <pre><code>pip install lazyops\n</code></pre>"},{"location":"api/lzo/#quick-example","title":"Quick Example","text":"<pre><code>import lzo\nfrom lzo.registry import MRegistry\nfrom lzo.types import BaseSettings\n\n# Define configuration\nclass AppConfig(BaseSettings):\n    app_name: str\n    debug: bool = False\n\n# Register and retrieve\nregistry = MRegistry()\nregistry.register('config', AppConfig(app_name=\"MyApp\"))\nconfig = registry.get('config')\n</code></pre>"},{"location":"api/lzo/#core-concepts","title":"Core Concepts","text":""},{"location":"api/lzo/#registry-pattern","title":"Registry Pattern","text":"<p>The registry pattern provides a centralized way to manage objects throughout your application's lifecycle. It supports:</p> <ul> <li>Lifecycle Hooks: Pre/post instantiation callbacks</li> <li>Dependency Injection: Automatic resolution of dependencies</li> <li>Singleton Management: Control object creation and reuse</li> <li>Type Safety: Full typing support with Pydantic</li> </ul>"},{"location":"api/lzo/#settings-management","title":"Settings Management","text":"<p>The types module extends Pydantic's settings management with:</p> <ul> <li>Environment Integration: Automatic environment variable loading</li> <li>Validation: Type-safe configuration validation</li> <li>Serialization: Easy conversion to/from various formats</li> <li>Nested Configuration: Support for complex configuration structures</li> </ul>"},{"location":"api/lzo/#utility-helpers","title":"Utility Helpers","text":"<p>The utils module provides lightweight helpers that avoid heavy dependencies:</p> <ul> <li>Retry Decorators: Automatic retry with exponential backoff</li> <li>Key Generators: Consistent key generation for caching</li> <li>Formatting: String and data formatting utilities</li> <li>Batching: Efficient batch processing helpers</li> </ul>"},{"location":"api/lzo/#architecture","title":"Architecture","text":"<p>The <code>lzo</code> namespace follows these design principles:</p> <ol> <li>Type Safety: Extensive use of type hints and Pydantic models</li> <li>Minimal Dependencies: Keep the core lightweight</li> <li>Extensibility: Easy to extend with custom patterns</li> <li>Documentation: Well-documented with clear examples</li> </ol> <p>Browse the sidebar to explore specific modules and their documentation.</p>"},{"location":"api/lzo/cmd/","title":"lzo.cmd - Command Line Utilities","text":"<p>The <code>lzo.cmd</code> module contains command-line interface tools and scripts.</p>"},{"location":"api/lzo/cmd/#key-generation","title":"Key Generation","text":""},{"location":"api/lzo/cmd/#lzo.cmd.keygen","title":"<code>lzo.cmd.keygen</code>","text":""},{"location":"api/lzo/cmd/#lzo.cmd.keygen.create_secret_key","title":"<code>create_secret_key(length=Argument(32, help='Length of Secret Key'), repeat=Option(1, '-r', '-n', '--repeat', help='Number of Secret Keys to Generate'), alpha_only=Option(False, help='Use only Alpha Characters'), hash=Option(None, help='Hash the Secret Key. Ex: sha256'), lower=Option(False, help='Lowercase the Secret Key'), prefix=Option(None, '-p', help='Prefix for the Secret Key'), from_string=Option(None, '-s', '--string', help='Generate from a length string'), from_file=Option(None, '-f', '--file', help='Generate and replace secrets within a file'), file_key=Option('&lt;key&gt;', '-k', '--key', help='Key to replace in the file'))</code>","text":"<p>Generate a random alphanumeric secret key.</p> <p>lzo kg secret</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('secret', help = \"Create an alphanmeric secret\")\ndef create_secret_key(\n    length: int = Argument(32, help = \"Length of Secret Key\"),\n    repeat: int = Option(1, '-r', '-n', '--repeat', help = \"Number of Secret Keys to Generate\"),\n    alpha_only: bool = Option(False, help = \"Use only Alpha Characters\"),\n    hash: t.Optional[str] = Option(None, help = \"Hash the Secret Key. Ex: sha256\"),\n    lower: bool = Option(False, help = \"Lowercase the Secret Key\"),\n    prefix: t.Optional[str] = Option(None, '-p', help = \"Prefix for the Secret Key\"),\n    from_string: t.Optional[str] = Option(None, '-s', '--string', help = \"Generate from a length string\"),\n    from_file: t.Optional[pathlib.Path] = Option(None, '-f', '--file', help = \"Generate and replace secrets within a file\"),\n    file_key: t.Optional[str] = Option('&lt;key&gt;', '-k', '--key', help = \"Key to replace in the file\"),\n):\n    \"\"\"\n    Generate a random alphanumeric secret key.\n\n    &gt;&gt;&gt; lzo kg secret\n    \"\"\"\n    if from_string: length = len(from_string)\n    existing = None\n    if from_file:\n        existing = from_file.read_text()\n        if file_key not in existing:\n            raise ValueError(f\"Key '{file_key}' not found in file '{from_file}'\")\n        # Find the number of times the key appears in the file\n        repeat = existing.count(file_key)\n    for _ in range(repeat):\n        value = Generate.alphanumeric_passcode(length, alpha_only)\n        if lower: value = value.lower()\n        if prefix: value = f'{prefix}{value}'\n        echo(value)\n        if existing and not hash: existing = existing.replace(file_key, value, 1)\n        if hash:\n            hashed_value = getattr(hashlib, hash)(value.encode()).hexdigest()\n            if lower: hashed_value = hashed_value.lower()\n            echo(hashed_value)\n            if existing: existing = existing.replace(file_key, hashed_value, 1)\n    if from_file: \n        from_file.write_text(existing)\n        echo(f\"Replaced '{file_key}' x {repeat}\")\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.create_uuid_key","title":"<code>create_uuid_key(length=Argument(None, help='Length of UUID Key'), clean=Option(True, help=\"Strip '-' from UUID\"), repeat=Option(1, help='Number of Secret Keys to Generate'), raw=Option(False, help='Return Raw UUID Key'))</code>","text":"<p>Generate a UUID key.</p> <p>lzo kg uuid</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('uuid', help = \"Generate UUID Key\")\ndef create_uuid_key(\n    length: int = Argument(None, help = \"Length of UUID Key\"),\n    clean: bool = Option(True, help = \"Strip '-' from UUID\"),\n    repeat: int = Option(1, help = \"Number of Secret Keys to Generate\"),\n    raw: bool = Option(False, help = \"Return Raw UUID Key\"),\n):\n    \"\"\"\n    Generate a UUID key.\n\n    &gt;&gt;&gt; lzo kg uuid\n    \"\"\"\n    for _ in range(repeat):\n        value = Generate.uuid_passcode(length = length, clean = clean, raw = raw)\n        echo(value)\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.generate_htpasswd","title":"<code>generate_htpasswd(secret=Argument(..., help='Secret Key to Hash'), salt=Option(None, '-s', '--salt', help='Salt for the Hash'), rounds=Option(10, '-r', '--rounds', help='Number of Rounds for the Hash'), repeat=Option(1, '-n', '--num', help='Number of Secret Keys to Generate'))</code>","text":"<p>Generate a bcrypt hashed password for use in htpasswd files.</p> <p>lzo kg htpass mysecret</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('htpass', help = \"Generate htpasswd Key using bcrypt\")\ndef generate_htpasswd(\n    secret: str = Argument(..., help = \"Secret Key to Hash\"),\n    salt: t.Optional[str] = Option(None,  \"-s\", \"--salt\", help = \"Salt for the Hash\"),\n    rounds: int = Option(10, \"-r\", \"--rounds\", help = \"Number of Rounds for the Hash\"),\n    repeat: int = Option(1, \"-n\", \"--num\",  help = \"Number of Secret Keys to Generate\"),\n):\n    \"\"\"\n    Generate a bcrypt hashed password for use in htpasswd files.\n\n    &gt;&gt;&gt; lzo kg htpass mysecret\n    \"\"\"\n    for hashed in generate_htpasswd_key(secret, salt=salt, rounds=rounds, repeat=repeat):\n        echo(hashed)\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.validate_htpasswd","title":"<code>validate_htpasswd(secret=Argument(..., help='Secret Key to Validate'), hashed=Argument(..., help='Hashed Key to Validate Against'))</code>","text":"<p>Validate a bcrypt hashed password against a plain text password.</p> <p>lzo kg htpass-validate mysecret $2b$12$eImiTMZG4ELQ2Z8K1z3uOe</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('htpass-validate', help = \"Validate a bcrypt hashed password\")\ndef validate_htpasswd(\n    secret: str = Argument(..., help = \"Secret Key to Validate\"),\n    hashed: str = Argument(..., help = \"Hashed Key to Validate Against\"),\n):\n    \"\"\"\n    Validate a bcrypt hashed password against a plain text password.\n\n    &gt;&gt;&gt; lzo kg htpass-validate mysecret $2b$12$eImiTMZG4ELQ2Z8K1z3uOe\n    \"\"\"\n    echo(validate_htpasswd_key(secret, hashed))\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.create_keypair","title":"<code>create_keypair(key_length=Argument(16, help='Length of Key'), secret_length=Argument(32, help='Length of Secret'), repeat=Option(1, help='Number of Secret Keys to Generate'))</code>","text":"<p>Create a Key Pair.</p> <p>lzo kg keypair</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('keypair', help = \"Create Key Pair\")\ndef create_keypair(\n    key_length: int = Argument(16, help = \"Length of Key\"),\n    secret_length: int = Argument(32, help = \"Length of Secret\"),\n    repeat: int = Option(1, help = \"Number of Secret Keys to Generate\"),\n):\n    \"\"\"\n    Create a Key Pair.\n\n    &gt;&gt;&gt; lzo kg keypair\n    \"\"\"\n    for _ in range(repeat):\n        value = Generate.keypair(key_length = key_length, secret_length = secret_length)\n        echo(f'{value[\"key\"]}:{value[\"secret\"]}')\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.create_token","title":"<code>create_token(length=Argument(32, help='Length of Token'), safe=Option(False, help='Use URL Safe Token'), clean=Option(True, help='Remove non-alphanumeric from Token'), repeat=Option(1, help='Number of Tokens to Generate'))</code>","text":"<p>Create a Token.</p> <p>lzo kg token</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('token', help = \"Create a Token\")\ndef create_token(\n    length: int = Argument(32, help = \"Length of Token\"),\n    safe: bool = Option(False, help = \"Use URL Safe Token\"),\n    clean: bool = Option(True, help = \"Remove non-alphanumeric from Token\"),\n    repeat: bool = Option(1, help = \"Number of Tokens to Generate\"),\n):\n    \"\"\"\n    Create a Token.\n\n    &gt;&gt;&gt; lzo kg token\n    \"\"\"\n    for _ in range(repeat):\n        value = Generate.token(length = length, safe = safe, clean = clean)\n        echo(value)\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.create_ssl_token","title":"<code>create_ssl_token(length=Argument(64, help='Length of Token'), base_encode=Option(False, help='Base64 Encode the Token'), repeat=Option(1, help='Number of Secret Keys to Generate'))</code>","text":"<p>Create a Token using OpenSSL.</p> <p>lzo kg ssl</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('ssl', help = \"Create a Token using OpenSSL\")\ndef create_ssl_token(\n    length: int = Argument(64, help = \"Length of Token\"),\n    base_encode: bool = Option(False, help = \"Base64 Encode the Token\"),\n    repeat: int = Option(1, help = \"Number of Secret Keys to Generate\"),\n):\n    \"\"\"\n    Create a Token using OpenSSL.\n\n    &gt;&gt;&gt; lzo kg ssl\n    \"\"\"\n    for _ in range(repeat):\n        value = Generate.openssl_random_key(length = length, base = base_encode)\n        echo(value)\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.create_key","title":"<code>create_key(method=Option(SecretMethod.secret, help='Method to generate Key'), length=Option(32, help='Length of Key'), secret_length=Option(32, help='[Optional] Length of Secret'), clean=Option(True, help='[Optional] Remove non-alphanumeric from Key'), safe=Option(False, help='[Optional] Use URL Safe Token'), base_encode=Option(True, help='[Optional] Base64 Encode the Token'), repeat=Option(1, help='[Optional] Number of Tokens to Generate'))</code>","text":"<p>Generate a Unique Key.</p> <p>lzo kg create secret</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('create', help = \"Generate a Unique Key\")\ndef create_key(\n    method: SecretMethod = Option(SecretMethod.secret, help = \"Method to generate Key\"),\n    length: int = Option(32, help = \"Length of Key\"),\n    secret_length: int = Option(32, help = \"[Optional] Length of Secret\"),\n    clean: bool = Option(True, help = \"[Optional] Remove non-alphanumeric from Key\"),\n    safe: bool = Option(False, help = \"[Optional] Use URL Safe Token\"),\n    base_encode: bool = Option(True, help = \"[Optional] Base64 Encode the Token\"),\n    repeat: bool = Option(1, help = \"[Optional] Number of Tokens to Generate\"),\n):\n    \"\"\"\n    Generate a Unique Key.\n\n    &gt;&gt;&gt; lzo kg create secret\n    \"\"\"\n    for _ in range(repeat):\n        if method == SecretMethod.secret:\n            value = Generate.alphanumeric_passcode(length = length)\n        elif method == SecretMethod.uuid:\n            value = Generate.uuid_passcode(length = length, clean = clean)\n        elif method == SecretMethod.keypair:\n            value = Generate.keypair(key_length = length, secret_length = secret_length)\n        elif method == SecretMethod.token:\n            value = Generate.token(length = length, clean = clean, safe = safe)\n        elif method == SecretMethod.ssl:\n            value = Generate.openssl_random_key(length = length, base = base_encode)\n        if isinstance(value, dict):\n            echo(f'{value[\"key\"]}:{value[\"secret\"]}')\n        else:\n            echo(value)\n</code></pre>"},{"location":"api/lzo/cmd/#s3-operations","title":"S3 Operations","text":""},{"location":"api/lzo/cmd/#lzo.cmd.s3","title":"<code>lzo.cmd.s3</code>","text":""},{"location":"api/lzo/io/","title":"lzo.io - Input/Output Operations","text":"<p>The <code>lzo.io</code> module handles data downloading and resource resolution.</p>"},{"location":"api/lzo/io/#download","title":"Download","text":""},{"location":"api/lzo/io/#lzo.io.download","title":"<code>lzo.io.download</code>","text":""},{"location":"api/lzo/io/#lzo.io.download.download_url_to_bytes","title":"<code>download_url_to_bytes(url, follow_redirects=True, verbose=True, return_response=False, **kwargs)</code>","text":"<p>Synchronously downloads content from a URL into bytes.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to download from.</p> required <code>follow_redirects</code> <code>Optional[bool]</code> <p>Whether to follow HTTP redirects.</p> <code>True</code> <code>verbose</code> <code>Optional[bool]</code> <p>If True, logs errors.</p> <code>True</code> <code>return_response</code> <code>Optional[bool]</code> <p>If True, returns a tuple of (content, response_object).</p> <code>False</code> <code>**kwargs</code> <p>Additional arguments passed to <code>aiohttpx.Client.get</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[Union[bytes, Tuple[bytes, 'Response']]]</code> <p>The file content as bytes, or (bytes, Response) if return_response is True.</p> <code>Optional[Union[bytes, Tuple[bytes, 'Response']]]</code> <p>Returns None if the request fails.</p> Source code in <code>src/lzo/io/download.py</code> <pre><code>def download_url_to_bytes(\n    url: str,\n    follow_redirects: Optional[bool] = True,\n    verbose: Optional[bool] = True,\n    return_response: Optional[bool] = False,\n    **kwargs,\n) -&gt; Optional[Union[bytes, Tuple[bytes, 'Response']]]:\n    \"\"\"\n    Synchronously downloads content from a URL into bytes.\n\n    Args:\n        url: The URL to download from.\n        follow_redirects: Whether to follow HTTP redirects.\n        verbose: If True, logs errors.\n        return_response: If True, returns a tuple of (content, response_object).\n        **kwargs: Additional arguments passed to `aiohttpx.Client.get`.\n\n    Returns:\n        The file content as bytes, or (bytes, Response) if return_response is True.\n        Returns None if the request fails.\n    \"\"\"\n    from lzo.utils import logger\n    url = normalize_url(url)\n    with contextlib.suppress(Exception):\n        with aiohttpx.Client() as client:\n            response = client.get(url, follow_redirects = follow_redirects, **kwargs)\n            if response.status_code &gt; 400:\n                if verbose: logger.error(f\"[{response.status_code}] Error fetching url {url}\\n{response.text[:1000]}...\")\n                if return_response: return (None, response)\n                return\n            return (response.read(), response) if return_response else response.read()\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.download.adownload_url_to_bytes","title":"<code>adownload_url_to_bytes(url, follow_redirects=True, verbose=True, return_response=False, **kwargs)</code>  <code>async</code>","text":"<p>Asynchronously downloads content from a URL into bytes.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to download from.</p> required <code>follow_redirects</code> <code>Optional[bool]</code> <p>Whether to follow HTTP redirects.</p> <code>True</code> <code>verbose</code> <code>Optional[bool]</code> <p>If True, logs errors.</p> <code>True</code> <code>return_response</code> <code>Optional[bool]</code> <p>If True, returns a tuple of (content, response_object).</p> <code>False</code> <code>**kwargs</code> <p>Additional arguments passed to <code>aiohttpx.Client.async_get</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[Union[bytes, Tuple[bytes, 'Response']]]</code> <p>The file content as bytes, or (bytes, Response) if return_response is True.</p> <code>Optional[Union[bytes, Tuple[bytes, 'Response']]]</code> <p>Returns None if the request fails.</p> Source code in <code>src/lzo/io/download.py</code> <pre><code>async def adownload_url_to_bytes(\n    url: str,\n    follow_redirects: Optional[bool] = True,\n    verbose: Optional[bool] = True,\n    return_response: Optional[bool] = False,\n    **kwargs,\n) -&gt; Optional[Union[bytes, Tuple[bytes, 'Response']]]:\n    \"\"\"\n    Asynchronously downloads content from a URL into bytes.\n\n    Args:\n        url: The URL to download from.\n        follow_redirects: Whether to follow HTTP redirects.\n        verbose: If True, logs errors.\n        return_response: If True, returns a tuple of (content, response_object).\n        **kwargs: Additional arguments passed to `aiohttpx.Client.async_get`.\n\n    Returns:\n        The file content as bytes, or (bytes, Response) if return_response is True.\n        Returns None if the request fails.\n    \"\"\"\n    from lzo.utils import logger\n    url = normalize_url(url)\n    with contextlib.suppress(Exception):\n        async with aiohttpx.Client() as client:\n            response = await client.async_get(url, follow_redirects = follow_redirects, **kwargs)\n            if response.status_code &gt; 400:\n                if verbose: logger.error(f\"[{response.status_code}] Error fetching url {url}\\n{response.text[:1000]}...\")\n                if return_response: return (None, response)\n                return\n            return (response.read(), response) if return_response else response.read()\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.download.download_url_to_tempfile","title":"<code>download_url_to_tempfile(url, follow_redirects=True, verbose=True, **kwargs)</code>","text":"<p>Synchronously downloads a URL and saves it to a temporary file.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to download.</p> required <code>follow_redirects</code> <code>Optional[bool]</code> <p>Whether to follow redirects.</p> <code>True</code> <code>verbose</code> <code>Optional[bool]</code> <p>If True, logs success/failure messages.</p> <code>True</code> <code>**kwargs</code> <p>Additional arguments passed to the download function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The absolute path to the temporary file, or None if download failed.</p> Source code in <code>src/lzo/io/download.py</code> <pre><code>def download_url_to_tempfile(\n    url: str,\n    follow_redirects: Optional[bool] = True,\n    verbose: Optional[bool] = True,\n    **kwargs,\n) -&gt; Optional[str]:\n    \"\"\"\n    Synchronously downloads a URL and saves it to a temporary file.\n\n    Args:\n        url: The URL to download.\n        follow_redirects: Whether to follow redirects.\n        verbose: If True, logs success/failure messages.\n        **kwargs: Additional arguments passed to the download function.\n\n    Returns:\n        The absolute path to the temporary file, or None if download failed.\n    \"\"\"\n    # from lzo.utils import logger\n    from lazyops.utils import Timer, logger\n    t = Timer()\n    tmp_file = None\n    headers = kwargs.pop('headers', None)\n    headers = headers or get_http_download_headers()\n    file_bytes, response = download_url_to_bytes(url, follow_redirects = follow_redirects, headers = headers, return_response = True, **kwargs)\n    if not file_bytes: return None\n    with contextlib.suppress(Exception):\n        with tempfile.NamedTemporaryFile(delete=False) as f:\n            tmp_file = f.name\n            f.write(file_bytes)\n            f.flush()\n            if verbose: logger.info(f\"[{response.status_code}] Saved {url} to {tmp_file} in {t.duration_s}\", colored = True)\n            return tmp_file\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.download.adownload_url_to_tempfile","title":"<code>adownload_url_to_tempfile(url, follow_redirects=True, verbose=True, **kwargs)</code>  <code>async</code>","text":"<p>Asynchronously downloads a URL and saves it to a temporary file.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to download.</p> required <code>follow_redirects</code> <code>Optional[bool]</code> <p>Whether to follow redirects.</p> <code>True</code> <code>verbose</code> <code>Optional[bool]</code> <p>If True, logs success/failure messages.</p> <code>True</code> <code>**kwargs</code> <p>Additional arguments passed to the download function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The absolute path to the temporary file, or None if download failed.</p> Source code in <code>src/lzo/io/download.py</code> <pre><code>async def adownload_url_to_tempfile(\n    url: str,\n    follow_redirects: Optional[bool] = True,\n    verbose: Optional[bool] = True,\n    **kwargs,\n) -&gt; Optional[str]:\n    \"\"\"\n    Asynchronously downloads a URL and saves it to a temporary file.\n\n    Args:\n        url: The URL to download.\n        follow_redirects: Whether to follow redirects.\n        verbose: If True, logs success/failure messages.\n        **kwargs: Additional arguments passed to the download function.\n\n    Returns:\n        The absolute path to the temporary file, or None if download failed.\n    \"\"\"\n    # from lzo.utils import logger\n    from lazyops.utils import Timer, logger\n    t = Timer()\n    tmp_file = None\n    headers = kwargs.pop('headers', None)\n    headers = headers or get_http_download_headers()\n    file_bytes, response = await adownload_url_to_bytes(url, follow_redirects = follow_redirects, headers = headers, return_response = True, **kwargs)\n    if not file_bytes: return None\n    async with aiofiles.tempfile.NamedTemporaryFile(delete=False) as f:\n        tmp_file = f.name\n        await f.write(file_bytes)\n        await f.flush()\n        if verbose: logger.info(f\"[{response.status_code}] Saved {url} to {tmp_file} in {t.duration_s}\", colored = True)\n        return tmp_file\n</code></pre>"},{"location":"api/lzo/io/#resolver","title":"Resolver","text":""},{"location":"api/lzo/io/#lzo.io.resolver","title":"<code>lzo.io.resolver</code>","text":""},{"location":"api/lzo/io/#lzo.io.resolver.normalize_url","title":"<code>normalize_url(url)</code>","text":"<p>Normalizes a URL string to a standard HTTPS format.</p> <p>Handles various edge cases like missing schemes, 'www://', and malformed prefixes.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL string to normalize.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The normalized URL starting with 'https://'.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def normalize_url(url: str) -&gt; str:\n    \"\"\"\n    Normalizes a URL string to a standard HTTPS format.\n\n    Handles various edge cases like missing schemes, 'www://', and malformed prefixes.\n\n    Args:\n        url: The URL string to normalize.\n\n    Returns:\n        The normalized URL starting with 'https://'.\n    \"\"\"\n    url = url.lower()\n    url = url.replace('http//', '').replace('https//', '').replace('htpps://', '').replace('htp://', '')\n    if '@' in url: url = url.split('@')[-1]\n    if url.startswith('www://'): url = url.replace('www://', 'www.')\n    if not url.startswith('http://') and not url.startswith('https://'): url = f'https://{url}'\n    return url.replace('http://', 'https://').rstrip('/')\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.extract_registered_domain","title":"<code>extract_registered_domain(url)</code>  <code>cached</code>","text":"<p>Extracts the registered domain (e.g., 'google.com' from 'sub.google.com') using tldextract.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to extract the domain from.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The registered domain string.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>@functools.lru_cache(500)\ndef extract_registered_domain(url: str) -&gt; str:\n    \"\"\"\n    Extracts the registered domain (e.g., 'google.com' from 'sub.google.com') using tldextract.\n\n    Args:\n        url: The URL to extract the domain from.\n\n    Returns:\n        The registered domain string.\n    \"\"\"\n    return tldextract.extract(url).registered_domain\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.extract_clean_domain","title":"<code>extract_clean_domain(url)</code>","text":"<p>Extracts the registered domain and removes any leading 'www.'.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to process.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The cleaned domain string.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def extract_clean_domain(\n    url: str\n) -&gt; str:\n    \"\"\"\n    Extracts the registered domain and removes any leading 'www.'.\n\n    Args:\n        url: The URL to process.\n\n    Returns:\n        The cleaned domain string.\n    \"\"\"\n    domain = extract_registered_domain(url.lower())\n    if domain.startswith('www.'): domain = domain.replace('www.', '')\n    return domain.lower()\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.get_http_download_headers","title":"<code>get_http_download_headers()</code>","text":"<p>Retrieves HTTP headers suitable for mimicking a real browser.</p> <p>Uses <code>browserforge</code> if available; otherwise falls back to a hardcoded Chrome-like user agent.</p> <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>A dictionary of HTTP headers.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def get_http_download_headers() -&gt; Dict[str, str]:\n    \"\"\"\n    Retrieves HTTP headers suitable for mimicking a real browser.\n\n    Uses `browserforge` if available; otherwise falls back to a hardcoded Chrome-like user agent.\n\n    Returns:\n        A dictionary of HTTP headers.\n    \"\"\"\n    global _http_download_headers\n    if _http_download_headers is None:\n        try:\n            from browserforge.headers import HeaderGenerator\n            _http_download_headers = HeaderGenerator().generate(browser='chrome')\n        except ImportError:\n            _http_download_headers = {\n                'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',\n                'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n                'accept-language': 'en-US,en;q=0.9',\n                'accept-encoding': 'gzip, deflate, br',\n                'cache-control': 'no-cache',\n            }\n    return _http_download_headers\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.validate_website_with_ping","title":"<code>validate_website_with_ping(url, timeout=2, count=4)</code>","text":"<p>Validates a website's reachability using ICMP ping.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL or hostname to ping.</p> required <code>timeout</code> <code>Optional[int]</code> <p>Timeout in seconds for each ping.</p> <code>2</code> <code>count</code> <code>Optional[int]</code> <p>Number of ping attempts.</p> <code>4</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the host is reachable (success count &gt;= 3), False otherwise.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def validate_website_with_ping(\n    url: str,\n    timeout: Optional[int] = 2,\n    count: Optional[int] = 4,\n) -&gt; bool:\n    \"\"\"\n    Validates a website's reachability using ICMP ping.\n\n    Args:\n        url: The URL or hostname to ping.\n        timeout: Timeout in seconds for each ping.\n        count: Number of ping attempts.\n\n    Returns:\n        True if the host is reachable (success count &gt;= 3), False otherwise.\n    \"\"\"\n    url = normalize_url(url)\n    ping_results = pythonping.ping(url, count = count, timeout = timeout)\n    return ping_results.success(3)\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.validate_website_with_socket","title":"<code>validate_website_with_socket(url)</code>","text":"<p>Validates a website's reachability by resolving its hostname via DNS.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to validate.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if DNS resolution succeeds, False otherwise.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def validate_website_with_socket(\n    url: str,\n) -&gt; bool:\n    \"\"\"\n    Validates a website's reachability by resolving its hostname via DNS.\n\n    Args:\n        url: The URL to validate.\n\n    Returns:\n        True if DNS resolution succeeds, False otherwise.\n    \"\"\"\n    url = extract_clean_domain(url)\n    with contextlib.suppress(Exception):\n        socket.gethostbyname(url)\n        return True\n    return False\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.validate_website_with_httpx","title":"<code>validate_website_with_httpx(url, timeout=15, headers=None, **kwargs)</code>","text":"<p>Validates a website by sending an HTTP HEAD (or GET) request.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to validate.</p> required <code>timeout</code> <code>Optional[int]</code> <p>Connection timeout in seconds.</p> <code>15</code> <code>headers</code> <code>Optional[Dict[str, str]]</code> <p>Optional HTTP headers.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the client.</p> <code>{}</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the server responds with a 2xx-4xx status (excluding 405 which triggers a GET retry), False on connection error.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def validate_website_with_httpx(\n    url: str,\n    timeout: Optional[int] = 15,\n    headers: Optional[Dict[str, str]] = None,\n    **kwargs,\n) -&gt; bool:\n    \"\"\"\n    Validates a website by sending an HTTP HEAD (or GET) request.\n\n    Args:\n        url: The URL to validate.\n        timeout: Connection timeout in seconds.\n        headers: Optional HTTP headers.\n        **kwargs: Additional arguments passed to the client.\n\n    Returns:\n        True if the server responds with a 2xx-4xx status (excluding 405 which triggers a GET retry), False on connection error.\n    \"\"\"\n    url = normalize_url(url)\n    try:\n        # Try with head first\n        headers = headers or get_http_download_headers()\n        response = aiohttpx.head(url, timeout = timeout, headers = headers,follow_redirects = True)\n        if response.status_code == 405:\n            response = aiohttpx.get(url, timeout = timeout, headers = headers, follow_redirects = True)\n        response.raise_for_status()\n        return True\n    except (aiohttpx.ConnectTimeout, aiohttpx.ReadTimeout) as e:\n        return False\n    except aiohttpx.HTTPStatusError as e:\n        return e.response.status_code &lt; 500\n    except Exception as e:\n        return False\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.avalidate_website_with_httpx","title":"<code>avalidate_website_with_httpx(url, timeout=15, headers=None, **kwargs)</code>  <code>async</code>","text":"<p>Asynchronously validates a website by sending an HTTP HEAD (or GET) request.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to validate.</p> required <code>timeout</code> <code>Optional[int]</code> <p>Connection timeout in seconds.</p> <code>15</code> <code>headers</code> <code>Optional[Dict[str, str]]</code> <p>Optional HTTP headers.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the client.</p> <code>{}</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the server responds with a 2xx-4xx status, False on connection error.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>async def avalidate_website_with_httpx(\n    url: str,\n    timeout: Optional[int] = 15,\n    headers: Optional[Dict[str, str]] = None,\n    **kwargs,\n) -&gt; bool:\n    \"\"\"\n    Asynchronously validates a website by sending an HTTP HEAD (or GET) request.\n\n    Args:\n        url: The URL to validate.\n        timeout: Connection timeout in seconds.\n        headers: Optional HTTP headers.\n        **kwargs: Additional arguments passed to the client.\n\n    Returns:\n        True if the server responds with a 2xx-4xx status, False on connection error.\n    \"\"\"\n    url = normalize_url(url)\n    try:\n        # Try with head first\n        headers = headers or get_http_download_headers()\n        response = await aiohttpx.async_head(url, timeout = timeout, headers = headers, follow_redirects = True)\n        if response.status_code == 405:\n            response = await aiohttpx.async_get(url, headers = headers, timeout = timeout, follow_redirects = True)\n        response.raise_for_status()\n        return True\n    except (aiohttpx.ConnectTimeout, aiohttpx.ReadTimeout) as e:\n        return False\n    except aiohttpx.HTTPStatusError as e:\n        return e.response.status_code &lt; 500\n    except Exception as e:\n        return False\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.validate_hostname","title":"<code>validate_hostname(url)</code>  <code>cached</code>","text":"<p>Validates that a hostname resolves to an IP address.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL or hostname.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if resolvable, False otherwise. Retries up to 5 times.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>@functools.lru_cache(maxsize=1200)\ndef validate_hostname(url: str) -&gt; bool:\n    \"\"\"\n    Validates that a hostname resolves to an IP address.\n\n    Args:\n        url: The URL or hostname.\n\n    Returns:\n        True if resolvable, False otherwise. Retries up to 5 times.\n    \"\"\"    \n    hostname = urlparse(url).hostname if '://' in url else url\n    for _attempts in range(5):\n        with contextlib.suppress(Exception):\n            socket.gethostbyname(hostname)\n            return True\n        time.sleep(1.5)\n    return False\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.validate_website_exists","title":"<code>validate_website_exists(url, timeout=15, headers=None, soft_validate=False)</code>","text":"<p>Comprehensive website validation checking ping first, then HTTP accessibility.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to check.</p> required <code>timeout</code> <code>Optional[int]</code> <p>Timeout for requests.</p> <code>15</code> <code>headers</code> <code>Optional[Dict[str, str]]</code> <p>Optional HTTP headers.</p> <code>None</code> <code>soft_validate</code> <code>Optional[bool]</code> <p>If True, only checks ping/DNS, skips HTTP check if ping succeeds.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the website appears to exist and be reachable.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def validate_website_exists(\n    url: str,\n    timeout: Optional[int] = 15,\n    headers: Optional[Dict[str, str]] = None,\n    soft_validate: Optional[bool] = False,\n) -&gt; bool:\n    \"\"\"\n    Comprehensive website validation checking ping first, then HTTP accessibility.\n\n    Args:\n        url: The URL to check.\n        timeout: Timeout for requests.\n        headers: Optional HTTP headers.\n        soft_validate: If True, only checks ping/DNS, skips HTTP check if ping succeeds.\n\n    Returns:\n        True if the website appears to exist and be reachable.\n    \"\"\"\n    url = normalize_url(url)\n    hn_valid = validate_website_with_ping(url)\n    if soft_validate or not hn_valid: return hn_valid\n    return validate_website_with_httpx(url, headers = headers, timeout = timeout)\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.avalidate_website_exists","title":"<code>avalidate_website_exists(url, timeout=15, headers=None, soft_validate=False)</code>  <code>async</code>","text":"<p>Async version of comprehensive website validation.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to check.</p> required <code>timeout</code> <code>Optional[int]</code> <p>Timeout for requests.</p> <code>15</code> <code>headers</code> <code>Optional[Dict[str, str]]</code> <p>Optional HTTP headers.</p> <code>None</code> <code>soft_validate</code> <code>Optional[bool]</code> <p>If True, only checks ping/DNS, skips HTTP check if ping succeeds.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the website appears to exist and be reachable.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>async def avalidate_website_exists(\n    url: str,\n    timeout: Optional[int] = 15,\n    headers: Optional[Dict[str, str]] = None,\n    soft_validate: Optional[bool] = False,\n) -&gt; bool:\n    \"\"\"\n    Async version of comprehensive website validation.\n\n    Args:\n        url: The URL to check.\n        timeout: Timeout for requests.\n        headers: Optional HTTP headers.\n        soft_validate: If True, only checks ping/DNS, skips HTTP check if ping succeeds.\n\n    Returns:\n        True if the website appears to exist and be reachable.\n    \"\"\"\n    url = normalize_url(url)\n    hn_valid = validate_website_with_ping(url)\n    if soft_validate or not hn_valid: return hn_valid\n    return await avalidate_website_with_httpx(url, headers = headers, timeout = timeout)\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.resolve_domain","title":"<code>resolve_domain(url, attempts=None)</code>  <code>cached</code>","text":"<p>Resolves the final root URL of a website after following redirects.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The starting URL.</p> required <code>attempts</code> <code>Optional[int]</code> <p>Recursion counter for retries (internal use).</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The final resolved URL, or the original if resolution fails.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>@functools.lru_cache()\ndef resolve_domain(url: str, attempts: Optional[int] = None) -&gt; str:\n    \"\"\"\n    Resolves the final root URL of a website after following redirects.\n\n    Args:\n        url: The starting URL.\n        attempts: Recursion counter for retries (internal use).\n\n    Returns:\n        The final resolved URL, or the original if resolution fails.\n    \"\"\"\n    if url.startswith('www://'): url = url.replace('www://', '')\n    if not url.startswith('http'): url = f'https://{url}'\n    try:\n        with aiohttpx.Client(follow_redirects = True, verify = False) as client:\n            r = client.get(url, timeout = 5)\n        r.raise_for_status()\n        return str(r.url).rstrip('/')\n    except (aiohttpx.ConnectTimeout, aiohttpx.ReadTimeout) as e:\n        return url\n    except aiohttpx.HTTPStatusError as e:\n        return str(e.response.url).rstrip('/') if e.response.status_code &lt; 500 else url\n    except Exception as e:\n        attempts = attempts + 1 if attempts else 1\n        if attempts &gt; 2:\n            return None\n        new_url = f'https://{extract_registered_domain(url)}'\n        return resolve_domain(new_url, attempts = attempts)\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.aresolve_domain","title":"<code>aresolve_domain(url, attempts=None)</code>  <code>async</code>","text":"<p>Asynchronously resolves the final root URL of a website after following redirects.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The starting URL.</p> required <code>attempts</code> <code>Optional[int]</code> <p>Recursion counter for retries (internal use).</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The final resolved URL, or the original if resolution fails.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>@async_lru.alru_cache(maxsize=1200)\nasync def aresolve_domain(url: str, attempts: Optional[int] = None) -&gt; str:\n    \"\"\"\n    Asynchronously resolves the final root URL of a website after following redirects.\n\n    Args:\n        url: The starting URL.\n        attempts: Recursion counter for retries (internal use).\n\n    Returns:\n        The final resolved URL, or the original if resolution fails.\n    \"\"\"\n    if url.startswith('www://'): url = url.replace('www://', '')\n    if not url.startswith('http'): url = f'https://{url}'\n    try:\n        async with aiohttpx.Client(follow_redirects = True, verify = False) as client:\n            r = await client.async_get(url, timeout = 5)\n        r.raise_for_status()\n        return str(r.url).rstrip('/')\n    except (aiohttpx.ConnectTimeout, aiohttpx.ReadTimeout) as e:\n        return url\n    except aiohttpx.HTTPStatusError as e:\n        return str(e.response.url).rstrip('/') if e.response.status_code &lt; 500 else url\n    except Exception as e:\n        attempts = attempts + 1 if attempts else 1\n        if attempts &gt; 2:\n            return None\n        new_url = f'https://{extract_registered_domain(url)}'\n        return await aresolve_domain(new_url, attempts = attempts)\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.determine_invalid_domains","title":"<code>determine_invalid_domains(urls, timeout=4)</code>","text":"<p>Filters a list of URLs and returns those that are unreachable.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>List[str]</code> <p>List of URLs to check.</p> required <code>timeout</code> <code>Optional[int]</code> <p>Timeout for each check.</p> <code>4</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of invalid/unreachable URLs.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def determine_invalid_domains(\n    urls: List[str],\n    timeout: Optional[int] = 4,\n) -&gt; List[str]:\n    \"\"\"\n    Filters a list of URLs and returns those that are unreachable.\n\n    Args:\n        urls: List of URLs to check.\n        timeout: Timeout for each check.\n\n    Returns:\n        List of invalid/unreachable URLs.\n    \"\"\"\n    if not urls: return []\n    return [\n        url\n        for url in urls\n        if not validate_website_with_ping(url, timeout=timeout)\n    ]\n</code></pre>"},{"location":"api/lzo/registry/","title":"lzo.registry - Object Registries","text":"<p>The <code>lzo.registry</code> module provides patterns for managing global object registries, plugins, and configuration settings. It supports lazy instantiation, hook injection, and string-based import resolution.</p>"},{"location":"api/lzo/registry/#mregistry","title":"MRegistry","text":"<p>The <code>MRegistry</code> (Mutable Registry) is the core class. It manages three internal maps: 1.  mregistry: Classes/Functions registered directly. 2.  uninit_registry: String import paths for lazy loading. 3.  init_registry: Cached, instantiated objects.</p>"},{"location":"api/lzo/registry/#lzo.registry.base","title":"<code>lzo.registry.base</code>","text":""},{"location":"api/lzo/registry/#lzo.registry.base.MRegistry","title":"<code>MRegistry</code>","text":"<p>               Bases: <code>Generic[RT]</code></p> <p>Mutable registry that lazily initialises and caches objects.</p> <p>The registry stores three parallel maps:</p> <ul> <li><code>mregistry</code> for classes/functions registered ahead of time.</li> <li><code>uninit_registry</code> for dotted import paths that are resolved on demand.</li> <li><code>init_registry</code> for concrete instances that have been constructed.</li> </ul> <p>Hooks can be attached to modify kwargs before instantiation (<code>prehooks</code>) or the resulting object after instantiation (<code>posthooks</code>).</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>class MRegistry(t.Generic[RT]):\n    \"\"\"Mutable registry that lazily initialises and caches objects.\n\n    The registry stores three parallel maps:\n\n    - ``mregistry`` for classes/functions registered ahead of time.\n    - ``uninit_registry`` for dotted import paths that are resolved on demand.\n    - ``init_registry`` for concrete instances that have been constructed.\n\n    Hooks can be attached to modify kwargs before instantiation (``prehooks``)\n    or the resulting object after instantiation (``posthooks``).\n    \"\"\"\n\n    mregistry: t.ClassVar[t.Dict[str, t.Type[RT]]] = {}\n    uninit_registry: t.ClassVar[t.Dict[str, str]] = {}\n    init_registry: t.ClassVar[t.Dict[str, RT]] = {}\n\n    prehooks: t.ClassVar[t.Dict[str, t.Callable[..., t.Any]]] = {}\n    posthooks: t.ClassVar[t.Dict[str, t.Callable[..., t.Any]]] = {}\n\n    def __init__(\n        self,\n        name: str,\n        verbose: t.Optional[bool] = False,\n        **kwargs: t.Any,\n    ) -&gt; None:\n        \"\"\"Initialise the registry with a display name and verbosity flag.\n\n        Args:\n            name: Friendly name used when logging registration activity.\n            verbose: Enables additional logging when objects are created.\n            **kwargs: Forwarded for compatibility; unused presently.\n        \"\"\"\n\n        from lzl.io.ser import get_object_classname\n        from lzl.load import lazy_import\n        from lzl.logging import logger\n\n        self.name = name\n        self.logger = logger\n        self.get_classname = get_object_classname\n        self.lazy_import = lazy_import\n        self.verbose = verbose\n        self.idx: t.Dict[str, RT] = {}\n        self._extra: t.Dict[str, t.Any] = {}\n\n    def _register(self, key: str, value: RT) -&gt; None:\n        \"\"\"Store a class/constructor in the registry, replacing existing values.\"\"\"\n\n        self.mregistry[key] = value\n        if key in self.uninit_registry:\n            self.uninit_registry.pop(key)\n        if os.getenv('MUTE_LZ_REGISTRY', 'false').lower() in {'true', '1'}:\n            return\n        if not isinstance(value, str) and getattr(value, '_rverbose', self.verbose):\n            if not TempData.has_logged(f'lzo.registry.register:{key}'):\n                self.logger.info(\n                    f'Registered: {key}',\n                    colored=True,\n                    prefix=self.name,\n                )\n\n    def __setitem__(self, key: str, value: RT) -&gt; None:\n        \"\"\"Alias for :meth:`_register` so the registry mimics a mapping.\"\"\"\n\n        self._register(key, value)\n\n    def register_prehook(self, key: str, func: t.Union[t.Callable[..., t.Any], str]) -&gt; None:\n        \"\"\"Attach a callable executed before an object is instantiated.\"\"\"\n\n        self.prehooks[key] = func\n\n    def register_posthook(self, key: str, func: t.Union[t.Callable[..., t.Any], str]) -&gt; None:\n        \"\"\"Attach a callable executed after an object is instantiated.\"\"\"\n\n        self.posthooks[key] = func\n\n    def register_hook(\n        self,\n        key: str,\n        func: t.Union[t.Callable[..., t.Any], str],\n        kind: t.Literal['pre', 'post'] = 'pre',\n    ) -&gt; None:\n        \"\"\"Convenience wrapper for registering pre- or post-hooks.\"\"\"\n\n        if kind == 'pre':\n            self.register_prehook(key, func)\n        elif kind == 'post':\n            self.register_posthook(key, func)\n\n    def run_obj_init(\n        self,\n        key: str,\n        obj: t.Union[t.Type[RT], RT],\n        **kwargs: t.Any,\n    ) -&gt; RT:\n        \"\"\"\n        Instantiates an object (or invokes a callable) and executes configured hooks.\n\n        If a 'prehook' is registered for the key, it modifies the `kwargs` before instantiation.\n        If a 'posthook' is registered, it receives the instantiated object and can modify or replace it.\n\n        Args:\n            key: The registry key associated with the object.\n            obj: The callable/class to instantiate, or an existing instance.\n            **kwargs: Arguments to pass to the object constructor/callable.\n\n        Returns:\n            The initialized (and potentially modified) object.\n        \"\"\"\n\n        if key in self.prehooks:\n            if isinstance(self.prehooks[key], str):\n                self.prehooks[key] = self.lazy_import(self.prehooks[key])\n            kwargs = self.prehooks[key](**kwargs)\n\n        if isinstance(obj, ProxyObject):\n            if self.verbose:\n                self.logger.info(\n                    f'Skipping Initialization for Proxy Object: {key}',\n                    colored=True,\n                    prefix=self.name,\n                )\n        else:\n            obj = obj(**kwargs)\n\n        if key in self.posthooks:\n            if isinstance(self.posthooks[key], str):\n                self.posthooks[key] = self.lazy_import(self.posthooks[key])\n            obj = self.posthooks[key](obj)\n        return obj\n\n    def _register_initialized(self, key: str, value: RT) -&gt; None:\n        \"\"\"Cache an already-instantiated object for repeated retrieval.\"\"\"\n\n        self.init_registry[key] = value\n\n    def _get(\n        self,\n        key: str,\n        _raise_error: bool = True,\n        **kwargs: t.Any,\n    ) -&gt; RT:\n        \"\"\"Resolve the concrete object backing ``key`` without memoisation.\"\"\"\n\n        if key in self.init_registry:\n            return self.init_registry[key]\n\n        if key in self.uninit_registry:\n            _path = self.uninit_registry[key]\n            _obj = self.lazy_import(_path)\n            self.init_registry[key] = self.run_obj_init(key, _obj, **kwargs)\n            self.uninit_registry.pop(key, None)\n            return self.init_registry[key]\n\n        if key in self.mregistry:\n            _obj = self.mregistry[key]\n            self.init_registry[key] = self.run_obj_init(key, _obj, **kwargs)\n            return self.init_registry[key]\n\n        if not _raise_error:\n            return None\n        raise KeyError(f'Key {key} not found in {self.name}')\n\n    def get(self, key: str, **kwargs: t.Any) -&gt; RT:\n        \"\"\"Public accessor that memoises lookups for repeat calls.\"\"\"\n\n        if key in self.idx:\n            return self.idx[key]\n        if (item := self._get(key, _raise_error=False, **kwargs)) is not None:\n            self.idx[key] = item\n            return item\n        if possible_key := self.search_for_parent(key, raise_error=False):\n            if possible_key in self.idx:\n                self.idx[key] = self.idx[possible_key]\n                return self.idx[key]\n            if (item := self._get(possible_key, _raise_error=False, **kwargs)) is not None:\n                self.idx[key] = item\n                return item\n        raise KeyError(\n            f'Key {key} not found in {self.name}: '\n            f'init: `{list(self.init_registry.keys())}`, '\n            f'idx: `{list(self.idx.keys())}`'\n        )\n\n    def get_module_path(self, obj: t.Type[RT]) -&gt; Path:\n        \"\"\"Return the filesystem path where ``obj`` is defined.\"\"\"\n\n        return Path(inspect.getfile(obj)).parent\n\n    def search_for_parent(self, key: str, raise_error: bool = True) -&gt; t.Optional[str]:\n        \"\"\"Find a registry key that ends with ``key`` (supports partial lookups).\"\"\"\n\n        if self.init_registry:\n            for k in self.init_registry:\n                if k.endswith(key):\n                    return k\n\n        if self.uninit_registry:\n            for k in self.uninit_registry:\n                if k.endswith(key):\n                    return k\n\n        if self.mregistry:\n            for k in self.mregistry:\n                if k.endswith(key):\n                    return k\n\n        if not raise_error:\n            return None\n        raise KeyError(f'Key {key} not found in {self.name}')\n\n    def __getitem__(self, key: str) -&gt; RT:\n        \"\"\"Allow bracket-notation access (``registry[key]``).\"\"\"\n\n        return self.get(key)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.base.MRegistry.register_prehook","title":"<code>register_prehook(key, func)</code>","text":"<p>Attach a callable executed before an object is instantiated.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def register_prehook(self, key: str, func: t.Union[t.Callable[..., t.Any], str]) -&gt; None:\n    \"\"\"Attach a callable executed before an object is instantiated.\"\"\"\n\n    self.prehooks[key] = func\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.base.MRegistry.register_posthook","title":"<code>register_posthook(key, func)</code>","text":"<p>Attach a callable executed after an object is instantiated.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def register_posthook(self, key: str, func: t.Union[t.Callable[..., t.Any], str]) -&gt; None:\n    \"\"\"Attach a callable executed after an object is instantiated.\"\"\"\n\n    self.posthooks[key] = func\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.base.MRegistry.register_hook","title":"<code>register_hook(key, func, kind='pre')</code>","text":"<p>Convenience wrapper for registering pre- or post-hooks.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def register_hook(\n    self,\n    key: str,\n    func: t.Union[t.Callable[..., t.Any], str],\n    kind: t.Literal['pre', 'post'] = 'pre',\n) -&gt; None:\n    \"\"\"Convenience wrapper for registering pre- or post-hooks.\"\"\"\n\n    if kind == 'pre':\n        self.register_prehook(key, func)\n    elif kind == 'post':\n        self.register_posthook(key, func)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.base.MRegistry.run_obj_init","title":"<code>run_obj_init(key, obj, **kwargs)</code>","text":"<p>Instantiates an object (or invokes a callable) and executes configured hooks.</p> <p>If a 'prehook' is registered for the key, it modifies the <code>kwargs</code> before instantiation. If a 'posthook' is registered, it receives the instantiated object and can modify or replace it.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The registry key associated with the object.</p> required <code>obj</code> <code>Union[Type[RT], RT]</code> <p>The callable/class to instantiate, or an existing instance.</p> required <code>**kwargs</code> <code>Any</code> <p>Arguments to pass to the object constructor/callable.</p> <code>{}</code> <p>Returns:</p> Type Description <code>RT</code> <p>The initialized (and potentially modified) object.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def run_obj_init(\n    self,\n    key: str,\n    obj: t.Union[t.Type[RT], RT],\n    **kwargs: t.Any,\n) -&gt; RT:\n    \"\"\"\n    Instantiates an object (or invokes a callable) and executes configured hooks.\n\n    If a 'prehook' is registered for the key, it modifies the `kwargs` before instantiation.\n    If a 'posthook' is registered, it receives the instantiated object and can modify or replace it.\n\n    Args:\n        key: The registry key associated with the object.\n        obj: The callable/class to instantiate, or an existing instance.\n        **kwargs: Arguments to pass to the object constructor/callable.\n\n    Returns:\n        The initialized (and potentially modified) object.\n    \"\"\"\n\n    if key in self.prehooks:\n        if isinstance(self.prehooks[key], str):\n            self.prehooks[key] = self.lazy_import(self.prehooks[key])\n        kwargs = self.prehooks[key](**kwargs)\n\n    if isinstance(obj, ProxyObject):\n        if self.verbose:\n            self.logger.info(\n                f'Skipping Initialization for Proxy Object: {key}',\n                colored=True,\n                prefix=self.name,\n            )\n    else:\n        obj = obj(**kwargs)\n\n    if key in self.posthooks:\n        if isinstance(self.posthooks[key], str):\n            self.posthooks[key] = self.lazy_import(self.posthooks[key])\n        obj = self.posthooks[key](obj)\n    return obj\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.base.MRegistry.get","title":"<code>get(key, **kwargs)</code>","text":"<p>Public accessor that memoises lookups for repeat calls.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def get(self, key: str, **kwargs: t.Any) -&gt; RT:\n    \"\"\"Public accessor that memoises lookups for repeat calls.\"\"\"\n\n    if key in self.idx:\n        return self.idx[key]\n    if (item := self._get(key, _raise_error=False, **kwargs)) is not None:\n        self.idx[key] = item\n        return item\n    if possible_key := self.search_for_parent(key, raise_error=False):\n        if possible_key in self.idx:\n            self.idx[key] = self.idx[possible_key]\n            return self.idx[key]\n        if (item := self._get(possible_key, _raise_error=False, **kwargs)) is not None:\n            self.idx[key] = item\n            return item\n    raise KeyError(\n        f'Key {key} not found in {self.name}: '\n        f'init: `{list(self.init_registry.keys())}`, '\n        f'idx: `{list(self.idx.keys())}`'\n    )\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.base.MRegistry.get_module_path","title":"<code>get_module_path(obj)</code>","text":"<p>Return the filesystem path where <code>obj</code> is defined.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def get_module_path(self, obj: t.Type[RT]) -&gt; Path:\n    \"\"\"Return the filesystem path where ``obj`` is defined.\"\"\"\n\n    return Path(inspect.getfile(obj)).parent\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.base.MRegistry.search_for_parent","title":"<code>search_for_parent(key, raise_error=True)</code>","text":"<p>Find a registry key that ends with <code>key</code> (supports partial lookups).</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def search_for_parent(self, key: str, raise_error: bool = True) -&gt; t.Optional[str]:\n    \"\"\"Find a registry key that ends with ``key`` (supports partial lookups).\"\"\"\n\n    if self.init_registry:\n        for k in self.init_registry:\n            if k.endswith(key):\n                return k\n\n    if self.uninit_registry:\n        for k in self.uninit_registry:\n            if k.endswith(key):\n                return k\n\n    if self.mregistry:\n        for k in self.mregistry:\n            if k.endswith(key):\n                return k\n\n    if not raise_error:\n        return None\n    raise KeyError(f'Key {key} not found in {self.name}')\n</code></pre>"},{"location":"api/lzo/registry/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzo/registry/#basic-registration","title":"Basic Registration","text":"<pre><code>from lzo.registry import MRegistry\n\n# Create a named registry\nServices = MRegistry(\"services\")\n\n# Register a class\n@Services.register(\"email_sender\")\nclass EmailService:\n    def send(self, msg): ...\n\n# Lazy instantiation (created on first access)\nsender = Services.get(\"email_sender\")\n</code></pre>"},{"location":"api/lzo/registry/#lazy-import-paths","title":"Lazy Import Paths","text":"<p>Register objects without importing them at the top level.</p> <pre><code># Registers the string path; import happens only when 'db' is requested\nServices.register(\"db\", \"my_app.database.PostgresConnection\")\n\n# Triggers import and instantiation\ndb = Services.get(\"db\") \n</code></pre>"},{"location":"api/lzo/registry/#lifecycle-hooks","title":"Lifecycle Hooks","text":"<p>Inject logic before or after object instantiation.</p> <pre><code>def configure_db(db_instance):\n    db_instance.connect()\n    return db_instance\n\n# Post-hook: runs after instantiation\nServices.register_posthook(\"db\", configure_db)\n\n# Pre-hook: modifies kwargs before instantiation\ndef inject_credentials(**kwargs):\n    kwargs['password'] = 'secret'\n    return kwargs\n\nServices.register_prehook(\"db\", inject_credentials)\n</code></pre>"},{"location":"api/lzo/registry/#settings-registry","title":"Settings Registry","text":"<p>A specialized registry for application settings, often used with Pydantic <code>BaseSettings</code>.</p>"},{"location":"api/lzo/registry/#lzo.registry.settings","title":"<code>lzo.registry.settings</code>","text":""},{"location":"api/lzo/registry/#lzo.registry.settings.register_settings","title":"<code>register_settings(settings)</code>","text":"<p>Register settings for lazy instantiation and discovery.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Union[Type['RSettingT'], 'RSettingT']</code> <p>Settings class or instance to register. Classes are stored for lazy creation; instances are cached immediately.</p> required Source code in <code>src/lzo/registry/settings.py</code> <pre><code>def register_settings(settings: t.Union[t.Type['RSettingT'], 'RSettingT']) -&gt; None:\n    \"\"\"Register settings for lazy instantiation and discovery.\n\n    Args:\n        settings: Settings class or instance to register. Classes are stored for\n            lazy creation; instances are cached immediately.\n    \"\"\"\n\n    if not isinstance(settings, type):\n        register_initialized_settings(settings)\n        return\n    cls_name = _sregistry.get_classname(settings, is_type=True)\n    cls_module = (\n        settings._rmodule\n        if getattr(settings, '_rmodule', None) is not None\n        else settings.__module__.split('.')[0]\n    )\n    cls_submodule = settings._rsubmodule\n    registry_name = combine_parts(cls_module, cls_submodule)\n    if registry_name in _sregistry.mregistry:\n        _sregistry.logger.warning(\n            f'Settings {registry_name} already registered with {cls_module}'\n        )\n        return\n\n    module_config_path = Path(inspect.getfile(settings)).parent\n    settings._rxtra['module'] = cls_module\n    settings._rxtra['submodule'] = cls_submodule\n    settings._rxtra['cls_name'] = cls_name\n    settings._rxtra['module_config_path'] = module_config_path\n    settings._rxtra['registry_name'] = registry_name\n    settings._rxtra['registered'] = True\n\n    if '__main__' not in cls_module:\n        p = module_config_path\n        m_path, iters = None, 0\n        while p.name != cls_module and iters &lt; 4:\n            p = p.parent\n            iters += 1\n            if p.name == cls_module:\n                m_path = p\n                break\n        if m_path is not None:\n            settings._rxtra['module_path'] = m_path\n\n    _sregistry[cls_module] = settings\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.settings.get_app_settings","title":"<code>get_app_settings(module, submodule=None, **kwargs)</code>","text":"<p>Fetch settings for <code>module</code> (and optional <code>submodule</code>).</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>Top-level package name used during registration.</p> required <code>submodule</code> <code>Optional[str]</code> <p>Optional namespace component for nested settings.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Forwarded to the <code>RegisteredSettings</code> constructor when instantiation is required.</p> <code>{}</code> <p>Returns:</p> Type Description <code>'RegisteredSettings'</code> <p>Lazily constructed settings instance, cached for future retrievals.</p> Source code in <code>src/lzo/registry/settings.py</code> <pre><code>def get_app_settings(\n    module: str,\n    submodule: t.Optional[str] = None,\n    **kwargs: t.Any,\n) -&gt; 'RegisteredSettings':\n    \"\"\"Fetch settings for ``module`` (and optional ``submodule``).\n\n    Args:\n        module: Top-level package name used during registration.\n        submodule: Optional namespace component for nested settings.\n        **kwargs: Forwarded to the ``RegisteredSettings`` constructor when\n            instantiation is required.\n\n    Returns:\n        Lazily constructed settings instance, cached for future retrievals.\n    \"\"\"\n\n    registry_name = combine_parts(module, submodule)\n    return _sregistry.get(registry_name, **kwargs)\n</code></pre>"},{"location":"api/lzo/registry/#usage","title":"Usage","text":"<pre><code>from lzo.registry import register_settings, get_app_settings\nfrom lzo.types import BaseSettings\n\n# Define your settings\nclass AppConfig(BaseSettings):\n    app_name: str = \"MyApp\"\n\n    class Config:\n        # Special attributes for registry\n        _rmodule = \"my_app\"\n\n# Register them\nregister_settings(AppConfig)\n\n# Retrieve globally\nconfig = get_app_settings(\"my_app\")\nprint(config.app_name)\n</code></pre>"},{"location":"api/lzo/registry/#client-registry","title":"Client Registry","text":"<p>Registry for managing API clients and services.</p>"},{"location":"api/lzo/registry/#lzo.registry.clients","title":"<code>lzo.registry.clients</code>","text":""},{"location":"api/lzo/registry/#lzo.registry.clients.register_initialized_client","title":"<code>register_initialized_client(client, **kwargs)</code>","text":"<p>Record an already instantiated client in the registry.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>'RClientT'</code> <p>Concrete instance created by the caller.</p> required <code>**kwargs</code> <code>Any</code> <p>Currently unused; retained for API compatibility.</p> <code>{}</code> Source code in <code>src/lzo/registry/clients.py</code> <pre><code>def register_initialized_client(client: 'RClientT', **kwargs: t.Any) -&gt; None:\n    \"\"\"Record an already instantiated client in the registry.\n\n    Args:\n        client: Concrete instance created by the caller.\n        **kwargs: Currently unused; retained for API compatibility.\n    \"\"\"\n\n    if hasattr(client, '_rxtra'):\n        _cregistry._register_initialized(client._rxtra['registry_name'], client)\n        return\n    cls_name = _cregistry.get_classname(client, is_type=False)\n    cls_module = (\n        client._rmodule\n        if getattr(client, '_rmodule', None) is not None\n        else client.__class__.__module__.split('.')[0]\n    )\n    cls_submodule = (\n        client._rsubmodule if getattr(client, '_rsubmodule', None) is not None else None\n    )\n    client_name = client.name if getattr(client, 'name', None) is not None else cls_name\n\n    registry_name = combine_parts(cls_module, cls_submodule, client_name)\n    if registry_name in _cregistry.init_registry:\n        return\n    _cregistry._register_initialized(registry_name, client)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.clients.register_client","title":"<code>register_client(client, **kwargs)</code>","text":"<p>Register a client class or instance for lazy lookup.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>Union[Type['RClientT'], 'RClientT']</code> <p>Client type or pre-instantiated object to register.</p> required <code>**kwargs</code> <code>Any</code> <p>Ignored but accepted for compatibility.</p> <code>{}</code> Source code in <code>src/lzo/registry/clients.py</code> <pre><code>def register_client(client: t.Union[t.Type['RClientT'], 'RClientT'], **kwargs: t.Any) -&gt; None:\n    \"\"\"Register a client class or instance for lazy lookup.\n\n    Args:\n        client: Client type or pre-instantiated object to register.\n        **kwargs: Ignored but accepted for compatibility.\n    \"\"\"\n\n    if not isinstance(client, type):\n        register_initialized_client(client, **kwargs)\n        return\n    cls_name = _cregistry.get_classname(client, is_type=True)\n    client_name = client.name if getattr(client, 'name', None) is not None else cls_name\n    cls_module = (\n        client._rmodule\n        if getattr(client, '_rmodule', None) is not None\n        else client.__module__.split('.')[0]\n    )\n    cls_submodule = client._rsubmodule if getattr(client, '_rsubmodule', None) is not None else None\n    registry_name = combine_parts(cls_module, cls_submodule, client_name)\n    if registry_name in _cregistry.mregistry:\n        _cregistry.logger.warning(\n            f'Client {client_name} already registered with `{registry_name}`'\n        )\n        return\n    client._rxtra['module'] = cls_module\n    client._rxtra['submodule'] = cls_submodule\n    client._rxtra['cls_name'] = cls_name\n    client._rxtra['client_name'] = client_name\n    client._rxtra['registry_name'] = registry_name\n    client._rxtra['module_path'] = _cregistry.get_module_path(client)\n    client._rxtra['registered'] = True\n    _cregistry[registry_name] = client\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.clients.register_app_client","title":"<code>register_app_client(client_name, client_path, module=None, submodule=None)</code>","text":"<p>Register a lazily importable client path.</p> <p>Parameters:</p> Name Type Description Default <code>client_name</code> <code>str</code> <p>Friendly name used for lookup.</p> required <code>client_path</code> <code>str</code> <p>Dotted import path to the client class.</p> required <code>module</code> <code>Optional[str]</code> <p>Optional module prefix used to namespacing entries.</p> <code>None</code> <code>submodule</code> <code>Optional[str]</code> <p>Additional namespace segment for nested registries.</p> <code>None</code> Source code in <code>src/lzo/registry/clients.py</code> <pre><code>def register_app_client(\n    client_name: str,\n    client_path: str,\n    module: t.Optional[str] = None,\n    submodule: t.Optional[str] = None,\n) -&gt; None:\n    \"\"\"Register a lazily importable client path.\n\n    Args:\n        client_name: Friendly name used for lookup.\n        client_path: Dotted import path to the client class.\n        module: Optional module prefix used to namespacing entries.\n        submodule: Additional namespace segment for nested registries.\n    \"\"\"\n\n    registry_name = combine_parts(module, submodule, client_name)\n    if registry_name in _cregistry.mregistry:\n        return\n    _cregistry.uninit_registry[registry_name] = client_path\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.clients.register_app_clients","title":"<code>register_app_clients(clients, module=None, submodule=None)</code>","text":"<p>Bulk register lazily loaded client paths.</p> <p>Parameters:</p> Name Type Description Default <code>clients</code> <code>Mapping[str, str]</code> <p>Mapping of client names to dotted import paths.</p> required <code>module</code> <code>Optional[str]</code> <p>Optional module prefix shared across entries.</p> <code>None</code> <code>submodule</code> <code>Optional[str]</code> <p>Optional nested namespace for the group.</p> <code>None</code> Source code in <code>src/lzo/registry/clients.py</code> <pre><code>def register_app_clients(\n    clients: t.Mapping[str, str],\n    module: t.Optional[str] = None,\n    submodule: t.Optional[str] = None,\n) -&gt; None:\n    \"\"\"Bulk register lazily loaded client paths.\n\n    Args:\n        clients: Mapping of client names to dotted import paths.\n        module: Optional module prefix shared across entries.\n        submodule: Optional nested namespace for the group.\n    \"\"\"\n\n    for client_name, client_path in clients.items():\n        register_app_client(client_name, client_path, module=module, submodule=submodule)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.clients.get_app_client","title":"<code>get_app_client(client_name, module=None, submodule=None, **kwargs)</code>","text":"<p>Retrieve a client by name, instantiating it if needed.</p> <p>Parameters:</p> Name Type Description Default <code>client_name</code> <code>str</code> <p>Identifier passed to :func:<code>register_client</code>.</p> required <code>module</code> <code>Optional[str]</code> <p>Optional module prefix used during registration.</p> <code>None</code> <code>submodule</code> <code>Optional[str]</code> <p>Optional nested namespace used during registration.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Forwarded to the registered constructor when lazily importing.</p> <code>{}</code> <p>Returns:</p> Type Description <code>'RegisteredClient'</code> <p>Registered client instance associated with <code>client_name</code>.</p> Source code in <code>src/lzo/registry/clients.py</code> <pre><code>def get_app_client(\n    client_name: str,\n    module: t.Optional[str] = None,\n    submodule: t.Optional[str] = None,\n    **kwargs: t.Any,\n) -&gt; 'RegisteredClient':\n    \"\"\"Retrieve a client by name, instantiating it if needed.\n\n    Args:\n        client_name: Identifier passed to :func:`register_client`.\n        module: Optional module prefix used during registration.\n        submodule: Optional nested namespace used during registration.\n        **kwargs: Forwarded to the registered constructor when lazily importing.\n\n    Returns:\n        Registered client instance associated with ``client_name``.\n    \"\"\"\n\n    registry_name = combine_parts(module, submodule, client_name)\n    return _cregistry.get(registry_name, **kwargs)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.clients.register_client_hook","title":"<code>register_client_hook(client_name, func, kind='post', module=None, submodule=None)</code>","text":"<p>Attach a hook to a registered client.</p> <p>Parameters:</p> Name Type Description Default <code>client_name</code> <code>str</code> <p>Registry key that identifies the client.</p> required <code>func</code> <code>Union[Callable[..., Any], str]</code> <p>Callable or dotted import path executed as the hook.</p> required <code>kind</code> <code>Literal['pre', 'post']</code> <p>Whether to run the hook before (<code>'pre'</code>) or after (<code>'post'</code>) instantiation.</p> <code>'post'</code> <code>module</code> <code>Optional[str]</code> <p>Optional module prefix used during registration.</p> <code>None</code> <code>submodule</code> <code>Optional[str]</code> <p>Optional nested namespace used during registration.</p> <code>None</code> Source code in <code>src/lzo/registry/clients.py</code> <pre><code>def register_client_hook(\n    client_name: str,\n    func: t.Union[t.Callable[..., t.Any], str],\n    kind: t.Literal['pre', 'post'] = 'post',\n    module: t.Optional[str] = None,\n    submodule: t.Optional[str] = None,\n) -&gt; None:\n    \"\"\"Attach a hook to a registered client.\n\n    Args:\n        client_name: Registry key that identifies the client.\n        func: Callable or dotted import path executed as the hook.\n        kind: Whether to run the hook before (``'pre'``) or after (``'post'``)\n            instantiation.\n        module: Optional module prefix used during registration.\n        submodule: Optional nested namespace used during registration.\n    \"\"\"\n\n    registry_name = combine_parts(module, submodule, client_name)\n    _cregistry.register_hook(registry_name, func, kind=kind)\n</code></pre>"},{"location":"api/lzo/state/","title":"lzo.state - State Management","text":"<p>The <code>lzo.state</code> module provides global state management and configuration contexts.</p>"},{"location":"api/lzo/state/#overview","title":"Overview","text":""},{"location":"api/lzo/state/#lzo.state","title":"<code>lzo.state</code>","text":"<p>Registry of Apps / Modules / Objects</p>"},{"location":"api/lzo/types/","title":"lzo.types - Type Definitions","text":"<p>The <code>lzo.types</code> module exports common Pydantic wrappers and application-specific type definitions.</p>"},{"location":"api/lzo/types/#base-models","title":"Base Models","text":""},{"location":"api/lzo/types/#lzo.types.base","title":"<code>lzo.types.base</code>","text":""},{"location":"api/lzo/types/#lzo.types.base.Registered","title":"<code>Registered</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Mixin that auto-registers subclasses as module settings.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>class Registered(abc.ABC):\n    \"\"\"Mixin that auto-registers subclasses as module settings.\"\"\"\n\n    _rmodule: t.Optional[str] = None\n    _rsubmodule: t.Optional[str] = None\n    _rxtra: t.Dict[str, t.Any] = {}\n\n    def __init_subclass__(cls, **kwargs: ConfigDict) -&gt; None:  # pragma: no cover - registration glue\n        from lzo.registry.settings import register_settings\n\n        register_settings(cls)\n        super().__init_subclass__(**kwargs)\n\n    if t.TYPE_CHECKING:\n\n        @property\n        def module_path(self) -&gt; Path:  # pragma: no cover - typing helper\n            ...\n\n        @property\n        def module_config_path(self) -&gt; Path:  # pragma: no cover - typing helper\n            ...\n\n        @property\n        def module_name(self) -&gt; str:  # pragma: no cover - typing helper\n            ...\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings","title":"<code>BaseSettings</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Augmented base settings with environment helpers and logging accessors.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>class BaseSettings(_BaseSettings):\n    \"\"\"Augmented base settings with environment helpers and logging accessors.\"\"\"\n\n    app_env: t.Optional[AppEnv] = None\n    debug_enabled: t.Optional[bool] = None\n\n    if t.TYPE_CHECKING:\n        _rxtra: t.Dict[str, t.Any]\n\n    @eproperty\n    def _is_registered(self) -&gt; bool:\n        \"\"\"Return ``True`` when instantiated via the registry infrastructure.\"\"\"\n\n        return hasattr(self, '_rxtra')\n\n    @eproperty\n    def module_path(self) -&gt; Path:\n        \"\"\"Filesystem path of the module that owns this settings object.\"\"\"\n\n        if self._is_registered and self._rxtra.get('module_path'):\n            return self._rxtra['module_path']\n        return super().module_path\n\n    @eproperty\n    def module_config_path(self) -&gt; Path:\n        \"\"\"Directory containing configuration files for this module.\"\"\"\n\n        if self._is_registered and self._rxtra.get('module_config_path'):\n            return self._rxtra['module_config_path']\n        return super().module_config_path\n\n    @eproperty\n    def module_name(self) -&gt; str:\n        \"\"\"Top-level package name inferred from the module namespace.\"\"\"\n\n        if self._is_registered and self._rxtra.get('module'):\n            return self._rxtra['module']\n        return super().module_name\n\n    @eproperty\n    def logger(self) -&gt; 'Logger':\n        \"\"\"Name-spaced logger for emitting structured diagnostics.\"\"\"\n\n        from lzl.logging import logger\n\n        return logger\n\n    @eproperty\n    def null_logger(self) -&gt; 'NullLogger':\n        \"\"\"No-op logger for silencing diagnostics when debug is disabled.\"\"\"\n\n        from lzl.logging import null_logger\n\n        return null_logger\n\n    @eproperty\n    def autologger(self) -&gt; 'Logger':\n        \"\"\"Return ``logger`` when in debug contexts, else ``null_logger``.\"\"\"\n\n        return self.logger if (self.debug_enabled or self.is_development_env) else self.null_logger\n\n    @eproperty\n    def app_module_name(self) -&gt; t.Optional[str]:\n        \"\"\"Override used to derive the environment prefix for this settings object.\"\"\"\n\n        return self._extra.get('app_module_name')\n\n    @eproperty\n    def ctx(self) -&gt; t.Optional['AppContext']:\n        \"\"\"Return the app context when the settings is registry managed.\"\"\"\n\n        if not self._is_registered:\n            return None\n        from lzo.types.settings.context import AppContextManager\n\n        return AppContextManager.get_ctx(self.module_name)\n\n    @model_validator(mode='after')\n    def validate_app_env(self) -&gt; 'BaseSettings':\n        \"\"\"Populate ``app_env`` based on module or explicit overrides.\"\"\"\n\n        if self.app_env is None:\n            try:\n                if self.app_module_name:\n                    self.app_env = AppEnv.from_module_name(self.app_module_name)\n                elif self.Config.env_prefix:\n                    self.app_env = get_app_env(self.Config.env_prefix.rstrip('_'))\n                else:\n                    self.app_env = get_app_env(self.app_module_name or self.module_name)\n            except Exception:  # pragma: no cover - defensive fallback\n                self.app_env = get_app_env('lzo')\n        elif isinstance(self.app_env, str):\n            self.app_env = AppEnv.from_env(self.app_env)\n        return self\n\n    @property\n    def is_local_env(self) -&gt; bool:\n        \"\"\"Return ``True`` when running in local/development contexts.\"\"\"\n\n        return self.app_env in {AppEnv.DEVELOPMENT, AppEnv.LOCAL} and not self.in_k8s\n\n    @property\n    def is_production_env(self) -&gt; bool:\n        \"\"\"Return ``True`` when production deployments are detected.\"\"\"\n\n        return self.app_env == AppEnv.PRODUCTION and self.in_k8s\n\n    @property\n    def is_development_env(self) -&gt; bool:\n        \"\"\"Return ``True`` when operating in development or CI modes.\"\"\"\n\n        return self.app_env in {AppEnv.DEVELOPMENT, AppEnv.LOCAL, AppEnv.CICD}\n\n    def set_app_env(self, env: AppEnv) -&gt; None:\n        \"\"\"Force the active application environment.\"\"\"\n\n        self.app_env = self.app_env.from_env(env)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.is_local_env","title":"<code>is_local_env</code>  <code>property</code>","text":"<p>Return <code>True</code> when running in local/development contexts.</p>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.is_production_env","title":"<code>is_production_env</code>  <code>property</code>","text":"<p>Return <code>True</code> when production deployments are detected.</p>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.is_development_env","title":"<code>is_development_env</code>  <code>property</code>","text":"<p>Return <code>True</code> when operating in development or CI modes.</p>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.module_path","title":"<code>module_path()</code>","text":"<p>Filesystem path of the module that owns this settings object.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_path(self) -&gt; Path:\n    \"\"\"Filesystem path of the module that owns this settings object.\"\"\"\n\n    if self._is_registered and self._rxtra.get('module_path'):\n        return self._rxtra['module_path']\n    return super().module_path\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.module_config_path","title":"<code>module_config_path()</code>","text":"<p>Directory containing configuration files for this module.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_config_path(self) -&gt; Path:\n    \"\"\"Directory containing configuration files for this module.\"\"\"\n\n    if self._is_registered and self._rxtra.get('module_config_path'):\n        return self._rxtra['module_config_path']\n    return super().module_config_path\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.module_name","title":"<code>module_name()</code>","text":"<p>Top-level package name inferred from the module namespace.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_name(self) -&gt; str:\n    \"\"\"Top-level package name inferred from the module namespace.\"\"\"\n\n    if self._is_registered and self._rxtra.get('module'):\n        return self._rxtra['module']\n    return super().module_name\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.logger","title":"<code>logger()</code>","text":"<p>Name-spaced logger for emitting structured diagnostics.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef logger(self) -&gt; 'Logger':\n    \"\"\"Name-spaced logger for emitting structured diagnostics.\"\"\"\n\n    from lzl.logging import logger\n\n    return logger\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.null_logger","title":"<code>null_logger()</code>","text":"<p>No-op logger for silencing diagnostics when debug is disabled.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef null_logger(self) -&gt; 'NullLogger':\n    \"\"\"No-op logger for silencing diagnostics when debug is disabled.\"\"\"\n\n    from lzl.logging import null_logger\n\n    return null_logger\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.autologger","title":"<code>autologger()</code>","text":"<p>Return <code>logger</code> when in debug contexts, else <code>null_logger</code>.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef autologger(self) -&gt; 'Logger':\n    \"\"\"Return ``logger`` when in debug contexts, else ``null_logger``.\"\"\"\n\n    return self.logger if (self.debug_enabled or self.is_development_env) else self.null_logger\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.app_module_name","title":"<code>app_module_name()</code>","text":"<p>Override used to derive the environment prefix for this settings object.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef app_module_name(self) -&gt; t.Optional[str]:\n    \"\"\"Override used to derive the environment prefix for this settings object.\"\"\"\n\n    return self._extra.get('app_module_name')\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.ctx","title":"<code>ctx()</code>","text":"<p>Return the app context when the settings is registry managed.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef ctx(self) -&gt; t.Optional['AppContext']:\n    \"\"\"Return the app context when the settings is registry managed.\"\"\"\n\n    if not self._is_registered:\n        return None\n    from lzo.types.settings.context import AppContextManager\n\n    return AppContextManager.get_ctx(self.module_name)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.validate_app_env","title":"<code>validate_app_env()</code>","text":"<p>Populate <code>app_env</code> based on module or explicit overrides.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@model_validator(mode='after')\ndef validate_app_env(self) -&gt; 'BaseSettings':\n    \"\"\"Populate ``app_env`` based on module or explicit overrides.\"\"\"\n\n    if self.app_env is None:\n        try:\n            if self.app_module_name:\n                self.app_env = AppEnv.from_module_name(self.app_module_name)\n            elif self.Config.env_prefix:\n                self.app_env = get_app_env(self.Config.env_prefix.rstrip('_'))\n            else:\n                self.app_env = get_app_env(self.app_module_name or self.module_name)\n        except Exception:  # pragma: no cover - defensive fallback\n            self.app_env = get_app_env('lzo')\n    elif isinstance(self.app_env, str):\n        self.app_env = AppEnv.from_env(self.app_env)\n    return self\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseSettings.set_app_env","title":"<code>set_app_env(env)</code>","text":"<p>Force the active application environment.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>def set_app_env(self, env: AppEnv) -&gt; None:\n    \"\"\"Force the active application environment.\"\"\"\n\n    self.app_env = self.app_env.from_env(env)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseModel","title":"<code>BaseModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Thin wrapper over :class:<code>pydantic.BaseModel</code> with permissive extras.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>class BaseModel(_BaseModel):\n    \"\"\"Thin wrapper over :class:`pydantic.BaseModel` with permissive extras.\"\"\"\n\n    if PYDANTIC_VERSION == 2:\n        _extra: t.Dict[str, t.Any] = PrivateAttr(default_factory=dict)\n        model_config = ConfigDict(extra='allow', arbitrary_types_allowed=True)\n    else:\n        _extra: t.Dict[str, t.Any] = Field(default_factory=dict, exclude=True, hidden=True)\n\n        class Config:  # noqa: D106 - pydantic compatibility shim\n            extra = 'allow'\n            arbitrary_types_allowed = True\n\n    def get(self, name: str, default: t.Any = None) -&gt; t.Any:\n        \"\"\"Retrieve ``name`` if present, returning ``default`` otherwise.\"\"\"\n\n        return getattr(self, name, default)\n\n    @classmethod\n    def model_validate_batch(\n        cls: t.Type['ModelT'],\n        items: t.Iterable[t.Any],\n        *,\n        strict: t.Optional[bool] = None,\n        from_attributes: t.Optional[bool] = None,\n        context: t.Optional[t.Dict[str, t.Any]] = None,\n        **kwargs: t.Any,\n    ) -&gt; t.List['ModelT']:\n        \"\"\"Validate many payloads and return instantiated models.\"\"\"\n\n        return [\n            cls.model_validate(item, strict=strict, from_attributes=from_attributes, context=context)\n            for item in items\n        ]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseModel.get","title":"<code>get(name, default=None)</code>","text":"<p>Retrieve <code>name</code> if present, returning <code>default</code> otherwise.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>def get(self, name: str, default: t.Any = None) -&gt; t.Any:\n    \"\"\"Retrieve ``name`` if present, returning ``default`` otherwise.\"\"\"\n\n    return getattr(self, name, default)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.BaseModel.model_validate_batch","title":"<code>model_validate_batch(items, *, strict=None, from_attributes=None, context=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Validate many payloads and return instantiated models.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@classmethod\ndef model_validate_batch(\n    cls: t.Type['ModelT'],\n    items: t.Iterable[t.Any],\n    *,\n    strict: t.Optional[bool] = None,\n    from_attributes: t.Optional[bool] = None,\n    context: t.Optional[t.Dict[str, t.Any]] = None,\n    **kwargs: t.Any,\n) -&gt; t.List['ModelT']:\n    \"\"\"Validate many payloads and return instantiated models.\"\"\"\n\n    return [\n        cls.model_validate(item, strict=strict, from_attributes=from_attributes, context=context)\n        for item in items\n    ]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.RBaseModel","title":"<code>RBaseModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base model variant that exposes module-level metadata helpers.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>class RBaseModel(BaseModel):\n    \"\"\"Base model variant that exposes module-level metadata helpers.\"\"\"\n\n    @eproperty\n    def module_path(self) -&gt; Path:\n        \"\"\"Return the installation path where the module is located.\"\"\"\n\n        import pkg_resources\n\n        path = Path(pkg_resources.get_distribution(self.module_name).location)\n        if 'src' in path.name and path.joinpath(self.module_name).exists():\n            path = path.joinpath(self.module_name)\n        elif path.joinpath('src').exists() and path.joinpath('src', self.module_name).exists():\n            path = path.joinpath('src', self.module_name)\n        return path\n\n    @eproperty\n    def module_config_path(self) -&gt; Path:\n        \"\"\"Directory containing the module configuration files.\"\"\"\n\n        return Path(inspect.getfile(self.__class__)).parent\n\n    @eproperty\n    def module_name(self) -&gt; str:\n        \"\"\"Top-level module name inferred from the class namespace.\"\"\"\n\n        return self.__class__.__module__.split('.')[0]\n\n    @eproperty\n    def module_version(self) -&gt; str:\n        \"\"\"Resolve the installed package version for this module.\"\"\"\n\n        import pkg_resources\n\n        return pkg_resources.get_distribution(self.module_name).version\n\n    @eproperty\n    def module_pkg_name(self) -&gt; str:\n        \"\"\"Return the package-relative path segment hosting configuration.\"\"\"\n\n        config_path = self.module_config_path.as_posix()\n        module_path = self.module_path.as_posix()\n        return config_path.replace(module_path, '').strip().split('/', 2)[1]\n\n    @eproperty\n    def in_k8s(self) -&gt; bool:\n        \"\"\"Return whether the process is detected inside a Kubernetes pod.\"\"\"\n\n        from lzo.utils.system import is_in_kubernetes\n\n        return is_in_kubernetes()\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.RBaseModel.module_path","title":"<code>module_path()</code>","text":"<p>Return the installation path where the module is located.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_path(self) -&gt; Path:\n    \"\"\"Return the installation path where the module is located.\"\"\"\n\n    import pkg_resources\n\n    path = Path(pkg_resources.get_distribution(self.module_name).location)\n    if 'src' in path.name and path.joinpath(self.module_name).exists():\n        path = path.joinpath(self.module_name)\n    elif path.joinpath('src').exists() and path.joinpath('src', self.module_name).exists():\n        path = path.joinpath('src', self.module_name)\n    return path\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.RBaseModel.module_config_path","title":"<code>module_config_path()</code>","text":"<p>Directory containing the module configuration files.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_config_path(self) -&gt; Path:\n    \"\"\"Directory containing the module configuration files.\"\"\"\n\n    return Path(inspect.getfile(self.__class__)).parent\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.RBaseModel.module_name","title":"<code>module_name()</code>","text":"<p>Top-level module name inferred from the class namespace.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_name(self) -&gt; str:\n    \"\"\"Top-level module name inferred from the class namespace.\"\"\"\n\n    return self.__class__.__module__.split('.')[0]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.RBaseModel.module_version","title":"<code>module_version()</code>","text":"<p>Resolve the installed package version for this module.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_version(self) -&gt; str:\n    \"\"\"Resolve the installed package version for this module.\"\"\"\n\n    import pkg_resources\n\n    return pkg_resources.get_distribution(self.module_name).version\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.RBaseModel.module_pkg_name","title":"<code>module_pkg_name()</code>","text":"<p>Return the package-relative path segment hosting configuration.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_pkg_name(self) -&gt; str:\n    \"\"\"Return the package-relative path segment hosting configuration.\"\"\"\n\n    config_path = self.module_config_path.as_posix()\n    module_path = self.module_path.as_posix()\n    return config_path.replace(module_path, '').strip().split('/', 2)[1]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.RBaseModel.in_k8s","title":"<code>in_k8s()</code>","text":"<p>Return whether the process is detected inside a Kubernetes pod.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef in_k8s(self) -&gt; bool:\n    \"\"\"Return whether the process is detected inside a Kubernetes pod.\"\"\"\n\n    from lzo.utils.system import is_in_kubernetes\n\n    return is_in_kubernetes()\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.RegisteredSettings","title":"<code>RegisteredSettings</code>","text":"<p>               Bases: <code>BaseSettings</code>, <code>Registered</code></p> <p>Stub combining :class:<code>BaseSettings</code> and :class:<code>Registered</code>.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>class RegisteredSettings(BaseSettings, Registered):  # pragma: no cover - typing helper\n    \"\"\"Stub combining :class:`BaseSettings` and :class:`Registered`.\"\"\"\n\n    ctx: AppContext\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.get_pydantic_field_names","title":"<code>get_pydantic_field_names(model)</code>","text":"<p>Returns a list of field names from a Pydantic model.</p> Source code in <code>src/lzl/types/base.py</code> <pre><code>def get_pydantic_field_names(model: typing.Type[typing.Union[BaseModel, BaseSettings]]) -&gt; typing.List[str]:\n    \"\"\"\n    Returns a list of field names from a Pydantic model.\n    \"\"\"\n    return list(get_pydantic_fields_dict(model).keys())\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.base.get_schema_extra","title":"<code>get_schema_extra(schema, _)</code>","text":"<p>Helper to get the extra schema</p> Source code in <code>src/lzl/types/base.py</code> <pre><code>def get_schema_extra(schema: typing.Dict[str, typing.Any], _):\n    \"\"\"\n    Helper to get the extra schema\n    \"\"\"\n    props = {\n        k: v\n        for k, v in schema.get('properties', {}).items()\n        if not v.get(\"hidden\", False) and not k.startswith('_')\n    }\n    schema[\"properties\"] = props\n</code></pre>"},{"location":"api/lzo/types/#settings-context","title":"Settings &amp; Context","text":""},{"location":"api/lzo/types/#lzo.types.settings.context","title":"<code>lzo.types.settings.context</code>","text":""},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext","title":"<code>AppContext</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Contains the application context</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>class AppContext(abc.ABC):\n    \"\"\"\n    Contains the application context\n    \"\"\"\n\n    _extra: Dict[str, Any] = {}\n\n    def __init__(\n        self,\n        module_name: str,\n        ingress_domain: Optional[str] = None,\n        ingress_base: Optional[Union[str, bool]] = None,\n        config_path: Optional[Path] = None,\n        assets_dir: Optional[str] = 'assets',\n        **kwargs,\n    ):\n        \"\"\"\n        Creates the app settings context\n        \"\"\"\n\n        self.module_name = module_name\n        self.app_env_var_name = self.module_name.replace(\".\", \"-\").replace(\"_\", \"-\").lower()\n        self.env_var_name = self.module_name.replace(\".\", \"_\").upper()\n        self.is_app_module = '__main__' not in self.module_name\n        if ingress_base is False:\n            self.ingress_base = None\n        else:\n            self.ingress_base = ingress_base or self.module_name\n        self.ingress_domain = ingress_domain\n        if self.is_app_module:\n            from lzo.utils.assets import get_module_assets_path\n            from lzo.utils.assets import create_get_assets_wrapper, create_import_assets_wrapper\n            if config_path is None:\n                try:\n                    config_path = get_module_assets_path(self.module_name, 'configs')\n                except Exception as e:\n                    config_path = Path.cwd()\n            self.import_assets = create_import_assets_wrapper(self.module_name, assets_dir)\n            self.get_assets = create_get_assets_wrapper(self.module_name, assets_dir)\n\n        self.config_path = config_path\n\n        self._kdbs: Dict[str, 'KVDBSession'] = {}\n        self._pdicts: Dict[str, 'PersistentDict'] = {}\n        self._pdict_aliases: Dict[str, str] = {}\n\n    \"\"\"\n    App Environments and Ingress\n    \"\"\"\n\n    @eproperty\n    def app_env(self) -&gt; AppEnv:\n        \"\"\"\n        Retrieves the app environment\n        \"\"\"\n        return self.get_app_env()\n\n    @eproperty\n    def temp_data(self) -&gt; 'TemporaryData':\n        \"\"\"\n        Retrieves the temporary data\n        \"\"\"\n        from lzl.io.persistence import TemporaryData\n        return TemporaryData.from_module(self.module_name)\n\n    @eproperty\n    def settings(self) -&gt; 'BaseSettings':\n        \"\"\"\n        Returns the settings\n        \"\"\"\n        from lzo.registry.settings import get_app_settings\n        return get_app_settings(self.module_name)\n\n    @eproperty\n    def state(self) -&gt; 'AppState':\n        \"\"\"\n        Returns the state\n        \"\"\"\n        from .state import AppState\n        _state = AppState()\n        _state.bind_settings(self.settings)\n        return _state\n\n    @property\n    def is_leader_process(self) -&gt; bool:\n        \"\"\"\n        Returns if this is the leader process\n        \"\"\"\n        return self.state.is_leader_process or multiprocessing.parent_process() is None\n\n    @property\n    def is_primary_server_process(self) -&gt; bool:\n        \"\"\"\n        Returns if this is the primary server process\n        \"\"\"\n        return self.state.is_primary_server_process or multiprocessing.parent_process() is None\n\n\n    def get_app_env(self, module_name: Optional[str] = None) -&gt; AppEnv:\n        \"\"\"\n        Retrieves the app environment\n        \"\"\"\n        module_name = (module_name or self.env_var_name).upper()\n        return AppEnv.from_module_name(module_name)\n\n    def get_app_ingress(\n        self,\n        app_host: Optional[str] = None,\n        app_port: Optional[int] = None,\n    ) -&gt; str:\n        \"\"\"\n        Retrieves the app ingress\n        \"\"\"\n        if self.app_env.is_local or not self.ingress_domain:\n            app_host = app_host or \"localhost\"\n            app_port = app_port or 8080\n            return f\"http://{app_host}:{app_port}\"\n        if self.app_env == AppEnv.DEVELOPMENT:\n            if not self.ingress_base: return f\"https://develop.{self.ingress_domain}\"\n            return f\"https://{self.ingress_base}-develop.{self.ingress_domain}\"\n        if self.app_env == AppEnv.STAGING:\n            if not self.ingress_base: return f\"https://staging.{self.ingress_domain}\"\n            return f\"https://{self.ingress_base}-staging.{self.ingress_domain}\"\n        if self.app_env == AppEnv.PRODUCTION:\n            if not self.ingress_base: return f\"https://{self.ingress_domain}\"\n            return f\"https://{self.ingress_base}.{self.ingress_domain}\"\n        raise ValueError(f\"Invalid app environment: {self.app_env}\")\n\n\n    def get_app_env_file(\n        self,\n        name: Optional[str] = None, \n        required: Optional[bool] = False, \n        allow_default: Optional[bool] = True,\n        configs_path: Optional[Path] = None,\n        env_var: Optional[str] = None,\n    ) -&gt; Optional[Path]:\n        \"\"\"\n        Retrieves the app environment file\n\n        Only valid for local/dev environments\n        \"\"\"\n        if env_var is not None and (env_val := os.getenv(env_var)):\n            env_path = Path(env_val)\n            if env_path.exists(): \n                # print(f'Using Env File: {env_path}')\n                return env_path\n        app_env = self.get_app_env()\n        is_local_env = app_env in [\n            AppEnv.LOCAL,\n            AppEnv.DEVELOPMENT,\n            AppEnv.CICD,\n            AppEnv.TEST,\n        ] or os.environ.get('DISABLE_ENFORCE_ENV', 'false').lower() == 'true'\n        configs_path = configs_path or self.config_path\n        envs_path = configs_path.joinpath('envs')\n        if name is not None:\n            if envs_path.joinpath(f'{name}-{app_env.name}.env').exists():\n                return envs_path.joinpath(f'{name}-{app_env.name}.env')\n            if envs_path.joinpath(f'{name}.env').exists():\n                return envs_path.joinpath(f'{name}.env')\n            if required and not is_local_env: raise ValueError(f\"Invalid app environment file: {name}\")\n        env_path = envs_path.joinpath(f'{app_env.name}.env')\n        if env_path.exists(): return env_path\n        if (is_local_env or not required) and allow_default:\n            return envs_path.joinpath('default.env')\n        return None\n\n\n    def get_app_default_file(\n        self,\n        name: Optional[str] = None, \n        required: Optional[bool] = False, \n        suffix: Optional[str] = None,\n        configs_path: Optional[Path] = None,\n        env_var: Optional[str] = None,\n    ) -&gt; Optional[Path]:\n        \"\"\"\n        Retrieves the app environment file\n\n        Only valid for local/dev environments\n        \"\"\"\n        if env_var is not None and (env_val := os.getenv(env_var)):\n            env_path = Path(env_val)\n            if env_path.exists(): return env_path\n        app_env = self.get_app_env()\n        configs_path = configs_path or self.config_path\n        defaults_path = configs_path.joinpath('defaults')\n        suffix = suffix or 'json'\n        suffix = suffix.lstrip('.')\n        if name is not None:\n            if defaults_path.joinpath(f'{name}-{app_env.name}.{suffix}').exists():\n                return defaults_path.joinpath(f'{name}-{app_env.name}.{suffix}')\n            if defaults_path.joinpath(f'{name}.{suffix}').exists():\n                return defaults_path.joinpath(f'{name}.{suffix}')\n            if required: raise ValueError(f\"Invalid app environment file: {name}\")\n        env_path = defaults_path.joinpath(f'{app_env.name}.{suffix}')\n        if env_path.exists(): return env_path\n        default_path = defaults_path.joinpath(f'default.{suffix}')\n        return default_path if default_path.exists() else None\n\n    def load_app_env_file(\n        self,\n        name: Optional[str] = None, \n        required: Optional[bool] = False, \n        allow_default: Optional[bool] = True,\n        configs_path: Optional[Path] = None,\n        env_var: Optional[str] = None,\n        override: Optional[bool] = True,\n    ) -&gt; Optional[Path]:\n        \"\"\"\n        Retrieves the app environment file and loads the variables\n\n        Only valid for local/dev environments\n        \"\"\"\n        env_path = self.get_app_env_file(name = name, required = required, allow_default = allow_default, configs_path = configs_path, env_var = env_var)\n        if env_path is None: return None\n        import dotenv\n        dotenv.load_dotenv(dotenv_path = env_path.as_posix(), override = override)\n        # print(f'Loaded Env File: {env_path}')\n        return env_path\n\n    def register_client(\n        self,\n        client: 'RClientT',\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        Registers a client\n        \"\"\"\n        from lzo.registry.clients import register_client\n        register_client(client, **kwargs)\n\n\n    def get_client(\n        self, \n        name: str,\n        module: Optional[str] = None,\n        **kwargs,\n    ) -&gt; 'RClientT':\n        \"\"\"\n        Retrieves a client\n        \"\"\"\n        module = module or self.module_name\n        from lzo.registry.clients import get_app_client\n        return get_app_client(name, module = module, **kwargs)\n\n\n    def get_kdb(\n        self,\n        name: Optional[str] = None,\n        serializer: Optional[str] = 'json',\n        **kwargs,\n    ) -&gt; 'KVDBSession':\n        \"\"\"\n        Retrieves or Initializes a KVDB Session\n        \"\"\"\n        name = name or self.module_name\n        if name not in self._kdbs:\n            from kvdb import KVDBClient\n            self._kdbs[name] = KVDBClient.get_session(\n                name = name,\n                serializer = serializer,\n                **kwargs,\n            )\n        return self._kdbs[name]\n\n    def get_pdict(\n        self,\n        base_key: str,\n        expiration: Optional[int] = None,\n        aliases: Optional[List[str]] = None,\n        backend_type: Optional[str] = None,\n        **kwargs,\n    ) -&gt; 'PersistentDict':\n        \"\"\"\n        Lazily initializes a persistent dict\n        \"\"\"\n        if base_key not in self._pdicts and base_key not in self._pdict_aliases:\n            if backend_type is not None:\n                from lzl.io.persistence import PersistentDict as PDict\n                self._pdicts[base_key] = PDict(\n                    base_key = base_key, \n                    backend_type = backend_type, \n                    **kwargs\n                )\n            else:\n                url = kwargs.pop('url', None)\n                session = self.get_kdb('persistence', serializer = None, url = url)\n                self._pdicts[base_key] = session.create_persistence(\n                    base_key = base_key,\n                    expiration = expiration,\n                    **kwargs,\n                )\n            if aliases:\n                for alias in aliases:\n                    self._pdict_aliases[alias] = base_key\n        elif base_key in self._pdict_aliases:\n            base_key = self._pdict_aliases[base_key]\n        return self._pdicts[base_key]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.is_leader_process","title":"<code>is_leader_process</code>  <code>property</code>","text":"<p>Returns if this is the leader process</p>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.is_primary_server_process","title":"<code>is_primary_server_process</code>  <code>property</code>","text":"<p>Returns if this is the primary server process</p>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.app_env","title":"<code>app_env()</code>","text":"<p>Retrieves the app environment</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>@eproperty\ndef app_env(self) -&gt; AppEnv:\n    \"\"\"\n    Retrieves the app environment\n    \"\"\"\n    return self.get_app_env()\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.temp_data","title":"<code>temp_data()</code>","text":"<p>Retrieves the temporary data</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>@eproperty\ndef temp_data(self) -&gt; 'TemporaryData':\n    \"\"\"\n    Retrieves the temporary data\n    \"\"\"\n    from lzl.io.persistence import TemporaryData\n    return TemporaryData.from_module(self.module_name)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.settings","title":"<code>settings()</code>","text":"<p>Returns the settings</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>@eproperty\ndef settings(self) -&gt; 'BaseSettings':\n    \"\"\"\n    Returns the settings\n    \"\"\"\n    from lzo.registry.settings import get_app_settings\n    return get_app_settings(self.module_name)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.state","title":"<code>state()</code>","text":"<p>Returns the state</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>@eproperty\ndef state(self) -&gt; 'AppState':\n    \"\"\"\n    Returns the state\n    \"\"\"\n    from .state import AppState\n    _state = AppState()\n    _state.bind_settings(self.settings)\n    return _state\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.get_app_env","title":"<code>get_app_env(module_name=None)</code>","text":"<p>Retrieves the app environment</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>def get_app_env(self, module_name: Optional[str] = None) -&gt; AppEnv:\n    \"\"\"\n    Retrieves the app environment\n    \"\"\"\n    module_name = (module_name or self.env_var_name).upper()\n    return AppEnv.from_module_name(module_name)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.get_app_ingress","title":"<code>get_app_ingress(app_host=None, app_port=None)</code>","text":"<p>Retrieves the app ingress</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>def get_app_ingress(\n    self,\n    app_host: Optional[str] = None,\n    app_port: Optional[int] = None,\n) -&gt; str:\n    \"\"\"\n    Retrieves the app ingress\n    \"\"\"\n    if self.app_env.is_local or not self.ingress_domain:\n        app_host = app_host or \"localhost\"\n        app_port = app_port or 8080\n        return f\"http://{app_host}:{app_port}\"\n    if self.app_env == AppEnv.DEVELOPMENT:\n        if not self.ingress_base: return f\"https://develop.{self.ingress_domain}\"\n        return f\"https://{self.ingress_base}-develop.{self.ingress_domain}\"\n    if self.app_env == AppEnv.STAGING:\n        if not self.ingress_base: return f\"https://staging.{self.ingress_domain}\"\n        return f\"https://{self.ingress_base}-staging.{self.ingress_domain}\"\n    if self.app_env == AppEnv.PRODUCTION:\n        if not self.ingress_base: return f\"https://{self.ingress_domain}\"\n        return f\"https://{self.ingress_base}.{self.ingress_domain}\"\n    raise ValueError(f\"Invalid app environment: {self.app_env}\")\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.get_app_env_file","title":"<code>get_app_env_file(name=None, required=False, allow_default=True, configs_path=None, env_var=None)</code>","text":"<p>Retrieves the app environment file</p> <p>Only valid for local/dev environments</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>def get_app_env_file(\n    self,\n    name: Optional[str] = None, \n    required: Optional[bool] = False, \n    allow_default: Optional[bool] = True,\n    configs_path: Optional[Path] = None,\n    env_var: Optional[str] = None,\n) -&gt; Optional[Path]:\n    \"\"\"\n    Retrieves the app environment file\n\n    Only valid for local/dev environments\n    \"\"\"\n    if env_var is not None and (env_val := os.getenv(env_var)):\n        env_path = Path(env_val)\n        if env_path.exists(): \n            # print(f'Using Env File: {env_path}')\n            return env_path\n    app_env = self.get_app_env()\n    is_local_env = app_env in [\n        AppEnv.LOCAL,\n        AppEnv.DEVELOPMENT,\n        AppEnv.CICD,\n        AppEnv.TEST,\n    ] or os.environ.get('DISABLE_ENFORCE_ENV', 'false').lower() == 'true'\n    configs_path = configs_path or self.config_path\n    envs_path = configs_path.joinpath('envs')\n    if name is not None:\n        if envs_path.joinpath(f'{name}-{app_env.name}.env').exists():\n            return envs_path.joinpath(f'{name}-{app_env.name}.env')\n        if envs_path.joinpath(f'{name}.env').exists():\n            return envs_path.joinpath(f'{name}.env')\n        if required and not is_local_env: raise ValueError(f\"Invalid app environment file: {name}\")\n    env_path = envs_path.joinpath(f'{app_env.name}.env')\n    if env_path.exists(): return env_path\n    if (is_local_env or not required) and allow_default:\n        return envs_path.joinpath('default.env')\n    return None\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.get_app_default_file","title":"<code>get_app_default_file(name=None, required=False, suffix=None, configs_path=None, env_var=None)</code>","text":"<p>Retrieves the app environment file</p> <p>Only valid for local/dev environments</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>def get_app_default_file(\n    self,\n    name: Optional[str] = None, \n    required: Optional[bool] = False, \n    suffix: Optional[str] = None,\n    configs_path: Optional[Path] = None,\n    env_var: Optional[str] = None,\n) -&gt; Optional[Path]:\n    \"\"\"\n    Retrieves the app environment file\n\n    Only valid for local/dev environments\n    \"\"\"\n    if env_var is not None and (env_val := os.getenv(env_var)):\n        env_path = Path(env_val)\n        if env_path.exists(): return env_path\n    app_env = self.get_app_env()\n    configs_path = configs_path or self.config_path\n    defaults_path = configs_path.joinpath('defaults')\n    suffix = suffix or 'json'\n    suffix = suffix.lstrip('.')\n    if name is not None:\n        if defaults_path.joinpath(f'{name}-{app_env.name}.{suffix}').exists():\n            return defaults_path.joinpath(f'{name}-{app_env.name}.{suffix}')\n        if defaults_path.joinpath(f'{name}.{suffix}').exists():\n            return defaults_path.joinpath(f'{name}.{suffix}')\n        if required: raise ValueError(f\"Invalid app environment file: {name}\")\n    env_path = defaults_path.joinpath(f'{app_env.name}.{suffix}')\n    if env_path.exists(): return env_path\n    default_path = defaults_path.joinpath(f'default.{suffix}')\n    return default_path if default_path.exists() else None\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.load_app_env_file","title":"<code>load_app_env_file(name=None, required=False, allow_default=True, configs_path=None, env_var=None, override=True)</code>","text":"<p>Retrieves the app environment file and loads the variables</p> <p>Only valid for local/dev environments</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>def load_app_env_file(\n    self,\n    name: Optional[str] = None, \n    required: Optional[bool] = False, \n    allow_default: Optional[bool] = True,\n    configs_path: Optional[Path] = None,\n    env_var: Optional[str] = None,\n    override: Optional[bool] = True,\n) -&gt; Optional[Path]:\n    \"\"\"\n    Retrieves the app environment file and loads the variables\n\n    Only valid for local/dev environments\n    \"\"\"\n    env_path = self.get_app_env_file(name = name, required = required, allow_default = allow_default, configs_path = configs_path, env_var = env_var)\n    if env_path is None: return None\n    import dotenv\n    dotenv.load_dotenv(dotenv_path = env_path.as_posix(), override = override)\n    # print(f'Loaded Env File: {env_path}')\n    return env_path\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.register_client","title":"<code>register_client(client, **kwargs)</code>","text":"<p>Registers a client</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>def register_client(\n    self,\n    client: 'RClientT',\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    Registers a client\n    \"\"\"\n    from lzo.registry.clients import register_client\n    register_client(client, **kwargs)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.get_client","title":"<code>get_client(name, module=None, **kwargs)</code>","text":"<p>Retrieves a client</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>def get_client(\n    self, \n    name: str,\n    module: Optional[str] = None,\n    **kwargs,\n) -&gt; 'RClientT':\n    \"\"\"\n    Retrieves a client\n    \"\"\"\n    module = module or self.module_name\n    from lzo.registry.clients import get_app_client\n    return get_app_client(name, module = module, **kwargs)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.get_kdb","title":"<code>get_kdb(name=None, serializer='json', **kwargs)</code>","text":"<p>Retrieves or Initializes a KVDB Session</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>def get_kdb(\n    self,\n    name: Optional[str] = None,\n    serializer: Optional[str] = 'json',\n    **kwargs,\n) -&gt; 'KVDBSession':\n    \"\"\"\n    Retrieves or Initializes a KVDB Session\n    \"\"\"\n    name = name or self.module_name\n    if name not in self._kdbs:\n        from kvdb import KVDBClient\n        self._kdbs[name] = KVDBClient.get_session(\n            name = name,\n            serializer = serializer,\n            **kwargs,\n        )\n    return self._kdbs[name]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContext.get_pdict","title":"<code>get_pdict(base_key, expiration=None, aliases=None, backend_type=None, **kwargs)</code>","text":"<p>Lazily initializes a persistent dict</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>def get_pdict(\n    self,\n    base_key: str,\n    expiration: Optional[int] = None,\n    aliases: Optional[List[str]] = None,\n    backend_type: Optional[str] = None,\n    **kwargs,\n) -&gt; 'PersistentDict':\n    \"\"\"\n    Lazily initializes a persistent dict\n    \"\"\"\n    if base_key not in self._pdicts and base_key not in self._pdict_aliases:\n        if backend_type is not None:\n            from lzl.io.persistence import PersistentDict as PDict\n            self._pdicts[base_key] = PDict(\n                base_key = base_key, \n                backend_type = backend_type, \n                **kwargs\n            )\n        else:\n            url = kwargs.pop('url', None)\n            session = self.get_kdb('persistence', serializer = None, url = url)\n            self._pdicts[base_key] = session.create_persistence(\n                base_key = base_key,\n                expiration = expiration,\n                **kwargs,\n            )\n        if aliases:\n            for alias in aliases:\n                self._pdict_aliases[alias] = base_key\n    elif base_key in self._pdict_aliases:\n        base_key = self._pdict_aliases[base_key]\n    return self._pdicts[base_key]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContextManagerObject","title":"<code>AppContextManagerObject</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Manages application contexts</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>class AppContextManagerObject(abc.ABC):\n    \"\"\"\n    Manages application contexts\n    \"\"\"\n\n    _extra: Dict[str, Any] = {}\n\n    def __init__(self, *args, **kwargs):\n        \"\"\"\n        Creates the context manager\n        \"\"\"\n        self.ctxs: Dict[str, AppContext] = {}\n        self._gctx: Optional[AppContext] = None\n\n    def init_ctx(self, module_name: str, *args, **kwargs) -&gt; AppContext:\n        \"\"\"\n        Initializes the app context\n        \"\"\"\n        if module_name not in self.ctxs:\n            self.ctxs[module_name] = AppContext(module_name, *args, **kwargs)\n        return self.ctxs[module_name]\n\n    def get_ctx(self, module_name: str, *args, **kwargs) -&gt; AppContext:\n        \"\"\"\n        Retrieves the app context\n        \"\"\"\n        if module_name not in self.ctxs:\n            return self.init_ctx(module_name, *args, **kwargs)\n        return self.ctxs[module_name]\n\n    def __getitem__(self, module_name: str) -&gt; AppContext:\n        \"\"\"\n        Gets the app context\n        \"\"\"\n        return self.get_ctx(module_name)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContextManagerObject.init_ctx","title":"<code>init_ctx(module_name, *args, **kwargs)</code>","text":"<p>Initializes the app context</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>def init_ctx(self, module_name: str, *args, **kwargs) -&gt; AppContext:\n    \"\"\"\n    Initializes the app context\n    \"\"\"\n    if module_name not in self.ctxs:\n        self.ctxs[module_name] = AppContext(module_name, *args, **kwargs)\n    return self.ctxs[module_name]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.context.AppContextManagerObject.get_ctx","title":"<code>get_ctx(module_name, *args, **kwargs)</code>","text":"<p>Retrieves the app context</p> Source code in <code>src/lzo/types/settings/context.py</code> <pre><code>def get_ctx(self, module_name: str, *args, **kwargs) -&gt; AppContext:\n    \"\"\"\n    Retrieves the app context\n    \"\"\"\n    if module_name not in self.ctxs:\n        return self.init_ctx(module_name, *args, **kwargs)\n    return self.ctxs[module_name]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.state","title":"<code>lzo.types.settings.state</code>","text":""},{"location":"api/lzo/types/#lzo.types.settings.state.AppState","title":"<code>AppState</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Holds the state of the current settings</p> Source code in <code>src/lzo/types/settings/state.py</code> <pre><code>class AppState(BaseModel):\n    \"\"\"\n    Holds the state of the current settings\n    \"\"\"\n    configured: Set[str] = Field(default_factory=set)\n    initialized: Set[str] = Field(default_factory=set)\n    completed: bool = False\n\n    app_entrypoint: Optional[str] = None\n    worker_entrypoint: Optional[str] = None\n\n    k8s_kubeconfigs: Optional[Dict[str, str]] = Field(default_factory=dict)\n    k8s_active_ctx: Optional[str] = None\n\n    app_module_name: Optional[str] = None\n    data_path: Optional[pathlib.Path] = None\n\n    ctx: Optional[Dict[str, Any]] = {}\n\n\n    @property\n    def is_silent(self) -&gt; bool:\n        \"\"\"\n        Returns whether the current state is silent\n        \"\"\"\n        return self.ctx.get('silent', False)\n\n    @property\n    def settings(self) -&gt; 'BaseSettings':\n        \"\"\"\n        Returns the settings\n        \"\"\"\n        return self.ctx.get('settings', None)\n\n    @property\n    def stx(self) -&gt; Optional['StateData']:\n        \"\"\"\n        Returns the StateData\n        \"\"\"\n        return self.ctx.get('stx', None)\n\n    @property\n    def process_id(self) -&gt; Optional[int]:\n        \"\"\"\n        Returns the process id\n        \"\"\"\n        return self.ctx.get('process_id', None)\n\n    @property\n    def is_primary_process(self) -&gt; bool:\n        \"\"\"\n        Returns whether this is the primary process\n        \"\"\"\n        return self.process_id == self.stx.get('primary_process_id', 0)\n\n    @property\n    def is_primary_server_process(self) -&gt; bool:\n        \"\"\"\n        Returns whether this is the primary server process\n        \"\"\"\n        return self.process_id == self.stx.get('primary_server_process_id', 0)\n\n    @property\n    def is_leader_process(self) -&gt; bool:\n        \"\"\"\n        Returns whether this is the leader process\n        \"\"\"\n        return self.process_id in self.stx.get('leader_process_ids', []) or self.is_primary_process\n\n    @property\n    def server_process_id_path(self) -&gt; pathlib.Path:\n        \"\"\"\n        Returns the server process id path\n        \"\"\"\n        return self.data_path.joinpath(f'{self.app_module_name}.pid')\n\n    def configure_silent(self, _silent: Optional[bool] = None):\n        \"\"\"\n        Configures the silent mode\n        \"\"\"\n        if _silent is not None:\n            self.ctx['silent'] = _silent\n\n    def get_kubeconfig(\n        self, \n        name: Optional[str] = None, \n        set_as_envval: Optional[bool] = True,\n        set_active: Optional[bool] = False,\n    ) -&gt; str:\n        \"\"\"\n        Returns the kubeconfig for the given context\n        \"\"\"\n        name = name or self.k8s_active_ctx\n        if name is not None and name in self.k8s_kubeconfigs:\n            kconfig = self.k8s_kubeconfigs[name]\n        else:\n            from lzo.utils.system import get_local_kubeconfig\n            kconfig = get_local_kubeconfig(name = name, set_as_envval = False)\n            if not name: name = pathlib.Path(kconfig).stem\n            self.k8s_kubeconfigs[name] = kconfig\n        if set_as_envval: os.environ['KUBECONFIG'] = kconfig\n        if not self.k8s_active_ctx or set_active: self.k8s_active_ctx = name\n        return kconfig\n\n    def bind_settings(self, settings: 'BaseSettings'):\n        \"\"\"\n        Binds the settings to this state\n        \"\"\"\n        # puts it in here so that we avoid type checking at the module level.\n        self.ctx['settings'] = settings\n        self.ctx['process_id'] = os.getpid()\n        if hasattr(settings, 'app_module_name'):\n            self.app_module_name = settings.app_module_name\n        else:\n            self.app_module_name = settings.__class__.__module__.split(\".\")[0]\n        if hasattr(settings, 'data_path'):\n            self.data_path = settings.data_path\n        else:\n            from lzo.utils.assets import get_module_path\n            module_path = get_module_path(self.app_module_name)\n            self.data_path = module_path.joinpath('.data')\n        self.configure_stx()\n\n\n    def on_exit(self):\n        \"\"\"\n        Called on exit\n        \"\"\"\n        if 'stx' in self.ctx and self.process_id == self.stx['primary_process_id']:\n            logger.info(f\"Removing AppState File: {self.ctx['stx_filepath']}\", colored = True, prefix = f\"|r|State: {self.app_module_name}|e|\")\n            with contextlib.suppress(FileNotFoundError):\n                self.stx.close()\n                os.unlink(self.ctx['stx_filepath'])\n                os.unlink(self.stx.filelock_path.as_posix())\n\n    def configure_stx(self):\n        \"\"\"\n        Configures the stateful statefuldata\n        \"\"\"\n        if 'stx' not in self.ctx:\n            stx_filepath = self.data_path.joinpath(f'{self.app_module_name}.state.json')\n            self.ctx['stx_filepath'] = stx_filepath.as_posix()\n            from lzl.io.persistence import TemporaryData as StateData\n            stx = StateData(filepath = stx_filepath)\n            self.ctx['stx'] = stx\n            atexit.register(self.on_exit)\n\n    def set_primary_process_id(self, process_id: int):\n        # sourcery skip: class-extract-method\n        \"\"\"\n        Sets the primary process id\n        \"\"\"\n        self.stx['primary_process_id'] = process_id\n\n    def set_primary_server_process_id(self, process_id: Optional[int] = None):\n        \"\"\"\n        Sets the primary server process id\n        \"\"\"\n        # Try to find it\n        if 'primary_server_process_id' in self.stx.keys(): return\n        if process_id is None and self.server_process_id_path.exists():\n            with contextlib.suppress(Exception):\n                process_id = int(self.server_process_id_path.read_text())\n        if process_id is None:\n            return\n        self.stx['primary_server_process_id'] = process_id\n        logger.info(f\"Primary Server Process ID: {process_id}\", colored = True, prefix = \"|g|State|e|\")\n\n    def add_leader_process_id(self, process_id: int, kind: Optional[str] = None):\n        \"\"\"\n        Adds a leader process id\n        \"\"\"\n        self.stx.append('leader_process_ids', process_id)\n\n    def has_logged(self, key: str) -&gt; bool:\n        \"\"\"\n        Returns whether the key has been logged\n        \"\"\"\n        return self.stx.append('logged', key)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.is_silent","title":"<code>is_silent</code>  <code>property</code>","text":"<p>Returns whether the current state is silent</p>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.settings","title":"<code>settings</code>  <code>property</code>","text":"<p>Returns the settings</p>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.stx","title":"<code>stx</code>  <code>property</code>","text":"<p>Returns the StateData</p>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.process_id","title":"<code>process_id</code>  <code>property</code>","text":"<p>Returns the process id</p>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.is_primary_process","title":"<code>is_primary_process</code>  <code>property</code>","text":"<p>Returns whether this is the primary process</p>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.is_primary_server_process","title":"<code>is_primary_server_process</code>  <code>property</code>","text":"<p>Returns whether this is the primary server process</p>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.is_leader_process","title":"<code>is_leader_process</code>  <code>property</code>","text":"<p>Returns whether this is the leader process</p>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.server_process_id_path","title":"<code>server_process_id_path</code>  <code>property</code>","text":"<p>Returns the server process id path</p>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.configure_silent","title":"<code>configure_silent(_silent=None)</code>","text":"<p>Configures the silent mode</p> Source code in <code>src/lzo/types/settings/state.py</code> <pre><code>def configure_silent(self, _silent: Optional[bool] = None):\n    \"\"\"\n    Configures the silent mode\n    \"\"\"\n    if _silent is not None:\n        self.ctx['silent'] = _silent\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.get_kubeconfig","title":"<code>get_kubeconfig(name=None, set_as_envval=True, set_active=False)</code>","text":"<p>Returns the kubeconfig for the given context</p> Source code in <code>src/lzo/types/settings/state.py</code> <pre><code>def get_kubeconfig(\n    self, \n    name: Optional[str] = None, \n    set_as_envval: Optional[bool] = True,\n    set_active: Optional[bool] = False,\n) -&gt; str:\n    \"\"\"\n    Returns the kubeconfig for the given context\n    \"\"\"\n    name = name or self.k8s_active_ctx\n    if name is not None and name in self.k8s_kubeconfigs:\n        kconfig = self.k8s_kubeconfigs[name]\n    else:\n        from lzo.utils.system import get_local_kubeconfig\n        kconfig = get_local_kubeconfig(name = name, set_as_envval = False)\n        if not name: name = pathlib.Path(kconfig).stem\n        self.k8s_kubeconfigs[name] = kconfig\n    if set_as_envval: os.environ['KUBECONFIG'] = kconfig\n    if not self.k8s_active_ctx or set_active: self.k8s_active_ctx = name\n    return kconfig\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.bind_settings","title":"<code>bind_settings(settings)</code>","text":"<p>Binds the settings to this state</p> Source code in <code>src/lzo/types/settings/state.py</code> <pre><code>def bind_settings(self, settings: 'BaseSettings'):\n    \"\"\"\n    Binds the settings to this state\n    \"\"\"\n    # puts it in here so that we avoid type checking at the module level.\n    self.ctx['settings'] = settings\n    self.ctx['process_id'] = os.getpid()\n    if hasattr(settings, 'app_module_name'):\n        self.app_module_name = settings.app_module_name\n    else:\n        self.app_module_name = settings.__class__.__module__.split(\".\")[0]\n    if hasattr(settings, 'data_path'):\n        self.data_path = settings.data_path\n    else:\n        from lzo.utils.assets import get_module_path\n        module_path = get_module_path(self.app_module_name)\n        self.data_path = module_path.joinpath('.data')\n    self.configure_stx()\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.on_exit","title":"<code>on_exit()</code>","text":"<p>Called on exit</p> Source code in <code>src/lzo/types/settings/state.py</code> <pre><code>def on_exit(self):\n    \"\"\"\n    Called on exit\n    \"\"\"\n    if 'stx' in self.ctx and self.process_id == self.stx['primary_process_id']:\n        logger.info(f\"Removing AppState File: {self.ctx['stx_filepath']}\", colored = True, prefix = f\"|r|State: {self.app_module_name}|e|\")\n        with contextlib.suppress(FileNotFoundError):\n            self.stx.close()\n            os.unlink(self.ctx['stx_filepath'])\n            os.unlink(self.stx.filelock_path.as_posix())\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.configure_stx","title":"<code>configure_stx()</code>","text":"<p>Configures the stateful statefuldata</p> Source code in <code>src/lzo/types/settings/state.py</code> <pre><code>def configure_stx(self):\n    \"\"\"\n    Configures the stateful statefuldata\n    \"\"\"\n    if 'stx' not in self.ctx:\n        stx_filepath = self.data_path.joinpath(f'{self.app_module_name}.state.json')\n        self.ctx['stx_filepath'] = stx_filepath.as_posix()\n        from lzl.io.persistence import TemporaryData as StateData\n        stx = StateData(filepath = stx_filepath)\n        self.ctx['stx'] = stx\n        atexit.register(self.on_exit)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.set_primary_process_id","title":"<code>set_primary_process_id(process_id)</code>","text":"<p>Sets the primary process id</p> Source code in <code>src/lzo/types/settings/state.py</code> <pre><code>def set_primary_process_id(self, process_id: int):\n    # sourcery skip: class-extract-method\n    \"\"\"\n    Sets the primary process id\n    \"\"\"\n    self.stx['primary_process_id'] = process_id\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.set_primary_server_process_id","title":"<code>set_primary_server_process_id(process_id=None)</code>","text":"<p>Sets the primary server process id</p> Source code in <code>src/lzo/types/settings/state.py</code> <pre><code>def set_primary_server_process_id(self, process_id: Optional[int] = None):\n    \"\"\"\n    Sets the primary server process id\n    \"\"\"\n    # Try to find it\n    if 'primary_server_process_id' in self.stx.keys(): return\n    if process_id is None and self.server_process_id_path.exists():\n        with contextlib.suppress(Exception):\n            process_id = int(self.server_process_id_path.read_text())\n    if process_id is None:\n        return\n    self.stx['primary_server_process_id'] = process_id\n    logger.info(f\"Primary Server Process ID: {process_id}\", colored = True, prefix = \"|g|State|e|\")\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.add_leader_process_id","title":"<code>add_leader_process_id(process_id, kind=None)</code>","text":"<p>Adds a leader process id</p> Source code in <code>src/lzo/types/settings/state.py</code> <pre><code>def add_leader_process_id(self, process_id: int, kind: Optional[str] = None):\n    \"\"\"\n    Adds a leader process id\n    \"\"\"\n    self.stx.append('leader_process_ids', process_id)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.settings.state.AppState.has_logged","title":"<code>has_logged(key)</code>","text":"<p>Returns whether the key has been logged</p> Source code in <code>src/lzo/types/settings/state.py</code> <pre><code>def has_logged(self, key: str) -&gt; bool:\n    \"\"\"\n    Returns whether the key has been logged\n    \"\"\"\n    return self.stx.append('logged', key)\n</code></pre>"},{"location":"api/lzo/types/#common-types","title":"Common Types","text":""},{"location":"api/lzo/types/#lzo.types.common.appenv","title":"<code>lzo.types.common.appenv</code>","text":""},{"location":"api/lzo/types/#lzo.types.common.appenv.AppEnv","title":"<code>AppEnv</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>src/lzl/types/common.py</code> <pre><code>class AppEnv(str, Enum):\n    CICD = \"cicd\"\n    DEVELOPMENT = \"development\"\n    STAGING = \"staging\"\n    PRODUCTION = \"production\"\n    LOCAL = \"local\"\n    TEST = \"test\"\n\n    @classmethod\n    def from_env(cls, env_value: str) -&gt; \"AppEnv\":\n        \"\"\"\n        Determines the AppEnv from a string value, handling various formats and partial matches.\n\n        Args:\n            env_value: The string value to parse (e.g., \"production\", \"prod\", \"ci/cd\").\n\n        Returns:\n            The corresponding AppEnv member.\n\n        Raises:\n            ValueError: If the value cannot be mapped to a known environment.\n        \"\"\"\n        env_value = env_value.lower()\n        if \"cicd\" in env_value or \"ci/cd\" in env_value: return cls.CICD\n        if \"prod\" in env_value: return cls.PRODUCTION\n        if \"dev\" in env_value: return cls.DEVELOPMENT\n        if \"staging\" in env_value: return cls.STAGING\n        if \"local\" in env_value: return cls.LOCAL\n        if \"test\" in env_value: return cls.TEST\n        raise ValueError(f\"Invalid app environment: {env_value} ({type(env_value)})\")\n\n    @classmethod\n    def from_hostname(cls, hostname: str) -&gt; \"AppEnv\":\n        \"\"\"\n        Get the app environment from the hostname\n        \"\"\"\n        hostname = hostname.lower()\n        if \"dev\" in hostname: return cls.DEVELOPMENT\n        if \"staging\" in hostname: return cls.STAGING\n        if \"test\" in hostname: return cls.TEST\n        return cls.LOCAL if \"local\" in hostname else cls.PRODUCTION\n\n\n    @classmethod\n    def from_module_name(cls, module_name: str) -&gt; 'AppEnv':\n        \"\"\"\n        Retrieves the app environment\n        \"\"\"\n        module_name = module_name.replace(\".\", \"_\").upper()\n        for key in {\n            \"SERVER_ENV\",\n            f\"{module_name}_ENV\",\n            \"APP_ENV\",\n            \"ENVIRONMENT\",\n        }:\n            if env_value := os.getenv(key):\n                return cls.from_env(env_value)\n\n        from lzo.utils.system import is_in_kubernetes, get_host_name\n        if is_in_kubernetes():\n            hn = get_host_name()\n            try:\n                parts = hn.split(\"-\")\n                for p in parts:\n                    if all(\n                        e not in p.lower()\n                        for e in {'development', 'test', 'staging', 'local', 'dev', 'prod', 'production'}\n                    ):\n                        parts.remove(p)\n                return cls.from_env(parts[0]) if len(parts) &gt; 0 else cls.PRODUCTION\n                # return cls.PRODUCTION\n                # return cls.from_env(parts[2]) if len(parts) &gt; 3 else cls.PRODUCTION\n            except Exception as e:\n                return cls.from_hostname(hn)\n\n        return cls.LOCAL\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"\n        Equality operator\n        \"\"\"\n        if isinstance(other, str): return self.value == other.lower()\n        return self.value == other.value if isinstance(other, AppEnv) else False\n\n    @property\n    def is_devel(self) -&gt; bool:\n        \"\"\"\n        Returns True if the app environment is development\n        \"\"\"\n        return self in [self.LOCAL, self.CICD, self.DEVELOPMENT, self.STAGING, self.TEST]\n\n    @property\n    def is_local(self) -&gt; bool:\n        \"\"\"\n        Returns True if the app environment is local\n        \"\"\"\n        return self in [self.LOCAL, self.CICD]\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"\n        Returns the name in lower\n        \"\"\"\n        return self.value.lower()\n\n    @property\n    def short_name(self) -&gt; str:\n        \"\"\"\n        Returns the short name in lower\n        \"\"\"\n        if self == self.DEVELOPMENT: return 'dev'\n        return 'prod' if self == self.PRODUCTION else self.name\n\n    def select(self, values: Dict[Union[str, 'AppEnv'], Any], default: Optional[Any] = None) -&gt; Any:\n        \"\"\"\n        Returns the value for the app env\n        \"\"\"\n        return next((value for key, value in values.items() if key == self), default)\n\n\n    @classmethod\n    def extend(cls, name: str, value: Any):\n        \"\"\"\n        Extends the enum with a new value\n        \"\"\"\n        if not _EXTEND_SUPPORTED: raise ImportError('aenum is not installed. Please install it to use this feature')\n        extend_enum(cls, name, value)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.common.appenv.AppEnv.is_devel","title":"<code>is_devel</code>  <code>property</code>","text":"<p>Returns True if the app environment is development</p>"},{"location":"api/lzo/types/#lzo.types.common.appenv.AppEnv.is_local","title":"<code>is_local</code>  <code>property</code>","text":"<p>Returns True if the app environment is local</p>"},{"location":"api/lzo/types/#lzo.types.common.appenv.AppEnv.name","title":"<code>name</code>  <code>property</code>","text":"<p>Returns the name in lower</p>"},{"location":"api/lzo/types/#lzo.types.common.appenv.AppEnv.short_name","title":"<code>short_name</code>  <code>property</code>","text":"<p>Returns the short name in lower</p>"},{"location":"api/lzo/types/#lzo.types.common.appenv.AppEnv.from_env","title":"<code>from_env(env_value)</code>  <code>classmethod</code>","text":"<p>Determines the AppEnv from a string value, handling various formats and partial matches.</p> <p>Parameters:</p> Name Type Description Default <code>env_value</code> <code>str</code> <p>The string value to parse (e.g., \"production\", \"prod\", \"ci/cd\").</p> required <p>Returns:</p> Type Description <code>AppEnv</code> <p>The corresponding AppEnv member.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the value cannot be mapped to a known environment.</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef from_env(cls, env_value: str) -&gt; \"AppEnv\":\n    \"\"\"\n    Determines the AppEnv from a string value, handling various formats and partial matches.\n\n    Args:\n        env_value: The string value to parse (e.g., \"production\", \"prod\", \"ci/cd\").\n\n    Returns:\n        The corresponding AppEnv member.\n\n    Raises:\n        ValueError: If the value cannot be mapped to a known environment.\n    \"\"\"\n    env_value = env_value.lower()\n    if \"cicd\" in env_value or \"ci/cd\" in env_value: return cls.CICD\n    if \"prod\" in env_value: return cls.PRODUCTION\n    if \"dev\" in env_value: return cls.DEVELOPMENT\n    if \"staging\" in env_value: return cls.STAGING\n    if \"local\" in env_value: return cls.LOCAL\n    if \"test\" in env_value: return cls.TEST\n    raise ValueError(f\"Invalid app environment: {env_value} ({type(env_value)})\")\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.common.appenv.AppEnv.from_hostname","title":"<code>from_hostname(hostname)</code>  <code>classmethod</code>","text":"<p>Get the app environment from the hostname</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef from_hostname(cls, hostname: str) -&gt; \"AppEnv\":\n    \"\"\"\n    Get the app environment from the hostname\n    \"\"\"\n    hostname = hostname.lower()\n    if \"dev\" in hostname: return cls.DEVELOPMENT\n    if \"staging\" in hostname: return cls.STAGING\n    if \"test\" in hostname: return cls.TEST\n    return cls.LOCAL if \"local\" in hostname else cls.PRODUCTION\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.common.appenv.AppEnv.from_module_name","title":"<code>from_module_name(module_name)</code>  <code>classmethod</code>","text":"<p>Retrieves the app environment</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef from_module_name(cls, module_name: str) -&gt; 'AppEnv':\n    \"\"\"\n    Retrieves the app environment\n    \"\"\"\n    module_name = module_name.replace(\".\", \"_\").upper()\n    for key in {\n        \"SERVER_ENV\",\n        f\"{module_name}_ENV\",\n        \"APP_ENV\",\n        \"ENVIRONMENT\",\n    }:\n        if env_value := os.getenv(key):\n            return cls.from_env(env_value)\n\n    from lzo.utils.system import is_in_kubernetes, get_host_name\n    if is_in_kubernetes():\n        hn = get_host_name()\n        try:\n            parts = hn.split(\"-\")\n            for p in parts:\n                if all(\n                    e not in p.lower()\n                    for e in {'development', 'test', 'staging', 'local', 'dev', 'prod', 'production'}\n                ):\n                    parts.remove(p)\n            return cls.from_env(parts[0]) if len(parts) &gt; 0 else cls.PRODUCTION\n            # return cls.PRODUCTION\n            # return cls.from_env(parts[2]) if len(parts) &gt; 3 else cls.PRODUCTION\n        except Exception as e:\n            return cls.from_hostname(hn)\n\n    return cls.LOCAL\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.common.appenv.AppEnv.select","title":"<code>select(values, default=None)</code>","text":"<p>Returns the value for the app env</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>def select(self, values: Dict[Union[str, 'AppEnv'], Any], default: Optional[Any] = None) -&gt; Any:\n    \"\"\"\n    Returns the value for the app env\n    \"\"\"\n    return next((value for key, value in values.items() if key == self), default)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.common.appenv.AppEnv.extend","title":"<code>extend(name, value)</code>  <code>classmethod</code>","text":"<p>Extends the enum with a new value</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef extend(cls, name: str, value: Any):\n    \"\"\"\n    Extends the enum with a new value\n    \"\"\"\n    if not _EXTEND_SUPPORTED: raise ImportError('aenum is not installed. Please install it to use this feature')\n    extend_enum(cls, name, value)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.common.appenv.get_app_env","title":"<code>get_app_env(module_name)</code>","text":"<p>Retrieves the app environment</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>def get_app_env(\n    module_name: str,\n) -&gt; AppEnv:\n    \"\"\"\n    Retrieves the app environment\n    \"\"\"\n    module_name = module_name.replace(\".\", \"_\").upper()\n    for key in {\n        \"SERVER_ENV\",\n        f\"{module_name}_ENV\",\n        \"APP_ENV\",\n        \"ENVIRONMENT\",\n    }:\n        if env_value := os.getenv(key):\n            return AppEnv.from_env(env_value)\n\n    from lzo.utils.system import is_in_kubernetes, get_host_name\n    if is_in_kubernetes():\n        # Name should be\n        # scout-&lt;service&gt;-&lt;index&gt;\n        # or \n        # scout-&lt;service&gt;-&lt;env&gt;-&lt;index&gt;\n        hn = get_host_name()\n        try:\n            parts = hn.split(\"-\")\n            return AppEnv.from_env(parts[1]) if len(parts) &gt; 2 else AppEnv.PRODUCTION\n        except Exception as e:\n            return AppEnv.from_hostname(hn)\n        # parts = get_host_name().split(\"-\")\n        # return AppEnv.from_env(parts[2]) if len(parts) &gt; 3 else AppEnv.PRODUCTION\n\n    return AppEnv.LOCAL\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.common.extra","title":"<code>lzo.types.common.extra</code>","text":"<p>Compatibility aliases for typing features across Python versions.</p>"},{"location":"api/lzo/utils/","title":"lzo.utils - Utilities","text":"<p>The <code>lzo.utils</code> module is a collection of lightweight, dependency-free helpers for common tasks like hashing, serialization, and system interaction.</p>"},{"location":"api/lzo/utils/#submodules","title":"Submodules","text":""},{"location":"api/lzo/utils/#hashing","title":"Hashing","text":"<p>Consistent hashing for objects and arguments. </p>"},{"location":"api/lzo/utils/#lzo.utils.hashing","title":"<code>lzo.utils.hashing</code>","text":""},{"location":"api/lzo/utils/#lzo.utils.hashing.create_object_hash","title":"<code>create_object_hash(obj, _sep=':', _hash_length=None)</code>","text":"<p>Creates a deterministic hash for a given object using xxhash.</p> <p>Supports dictionaries, lists, tuples, sets, and Pydantic models.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>ObjT</code> <p>The object to hash.</p> required <code>_sep</code> <code>Optional[str]</code> <p>Separator used when joining iterable elements (default: ':').</p> <code>':'</code> <code>_hash_length</code> <code>Optional[int]</code> <p>Length/type of hash (8=32bit, 16=64bit, 32/None=128bit).</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The resulting hexadecimal hash string.</p> Source code in <code>src/lzo/utils/hashing.py</code> <pre><code>def create_object_hash(\n    obj: ObjT,\n    _sep: Optional[str] = ':',\n    _hash_length: Optional[int] = None,\n) -&gt; str:\n    \"\"\"\n    Creates a deterministic hash for a given object using xxhash.\n\n    Supports dictionaries, lists, tuples, sets, and Pydantic models.\n\n    Args:\n        obj: The object to hash.\n        _sep: Separator used when joining iterable elements (default: ':').\n        _hash_length: Length/type of hash (8=32bit, 16=64bit, 32/None=128bit).\n\n    Returns:\n        The resulting hexadecimal hash string.\n    \"\"\"\n    if _hash_length is None or _hash_length == 32: _hasher = xxhash.xxh3_128_hexdigest\n    elif _hash_length == 16: _hasher = xxhash.xxh3_64_hexdigest\n    elif _hash_length == 8: _hasher = xxhash.xxh32_hexdigest\n\n    if isinstance(obj, dict):\n        return _hasher(str(obj))\n    if isinstance(obj, (list, tuple, set)):\n        return f'{_sep}'.join(create_object_hash(item, _sep = _sep) for item in obj)\n    if isinstance(obj, BaseModel) or hasattr(obj, \"model_dump\"):\n        return _hasher(obj.model_dump_json(exclude_none=True))\n    return _hasher(str(obj))\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.hashing.create_hash_from_args_and_kwargs","title":"<code>create_hash_from_args_and_kwargs(*args, _typed=False, _key_base=None, _exclude=None, _exclude_none=True, _sep=':', _hash_length=None, **kwargs)</code>","text":"<p>Creates a deterministic hash from function arguments and keyword arguments.</p> <p>Useful for caching mechanisms where the cache key depends on input arguments.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <p>Positional arguments to include in the hash.</p> <code>()</code> <code>_typed</code> <code>Optional[bool]</code> <p>If True, includes the type of positional arguments in the hash key.</p> <code>False</code> <code>_key_base</code> <code>Optional[tuple]</code> <p>An optional initial tuple to prepend to the hash key.</p> <code>None</code> <code>_exclude</code> <code>Optional[List[str]]</code> <p>A list of keyword argument names to exclude from the hash.</p> <code>None</code> <code>_exclude_none</code> <code>Optional[bool]</code> <p>If True, excludes keyword arguments with None values.</p> <code>True</code> <code>_sep</code> <code>Optional[str]</code> <p>Separator used for joining hash components.</p> <code>':'</code> <code>_hash_length</code> <code>Optional[int]</code> <p>Length/type of hash (8=32bit, 16=64bit, 32/None=128bit).</p> <code>None</code> <code>**kwargs</code> <p>Keyword arguments to include in the hash.</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>The resulting hexadecimal hash string.</p> Source code in <code>src/lzo/utils/hashing.py</code> <pre><code>def create_hash_from_args_and_kwargs(\n    *args,\n    _typed: Optional[bool] = False,\n    _key_base: Optional[tuple] = None,\n    _exclude: Optional[List[str]] = None,\n    _exclude_none: Optional[bool] = True,\n    _sep: Optional[str] = ':',\n    _hash_length: Optional[int] = None,\n    **kwargs,\n) -&gt; str:\n    \"\"\"\n    Creates a deterministic hash from function arguments and keyword arguments.\n\n    Useful for caching mechanisms where the cache key depends on input arguments.\n\n    Args:\n        *args: Positional arguments to include in the hash.\n        _typed: If True, includes the type of positional arguments in the hash key.\n        _key_base: An optional initial tuple to prepend to the hash key.\n        _exclude: A list of keyword argument names to exclude from the hash.\n        _exclude_none: If True, excludes keyword arguments with None values.\n        _sep: Separator used for joining hash components.\n        _hash_length: Length/type of hash (8=32bit, 16=64bit, 32/None=128bit).\n        **kwargs: Keyword arguments to include in the hash.\n\n    Returns:\n        The resulting hexadecimal hash string.\n    \"\"\"\n    hash_key = _key_base or ()\n    if args: \n        hash_key += tuple(type(arg) for arg in args) if _typed else args\n    if kwargs:\n        if _exclude: kwargs = {k: v for k, v in kwargs.items() if k not in _exclude}\n        if _exclude_none: kwargs = {k: v for k, v in kwargs.items() if v is not None}\n        sorted_items = sorted(kwargs.items())\n        for item in sorted_items:\n            hash_key += item\n\n    key = f'{_sep}'.join(str(k) for k in hash_key)\n    return create_object_hash(key, _sep = _sep, _hash_length = _hash_length)\n</code></pre>"},{"location":"api/lzo/utils/#key-generation","title":"Key Generation","text":"<p>Helpers for generating secrets, UUIDs, and API keys. </p>"},{"location":"api/lzo/utils/#lzo.utils.keygen","title":"<code>lzo.utils.keygen</code>","text":""},{"location":"api/lzo/utils/#lzo.utils.keygen.Base64","title":"<code>Base64</code>","text":"<p>Convenience wrapper for base64 encoding/decoding strings.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>class Base64:\n    \"\"\"Convenience wrapper for base64 encoding/decoding strings.\"\"\"\n\n    encoding: str = 'utf-8'\n\n    @classmethod\n    def encode(cls, text: str, encoding: str = 'utf-8', *args: t.Any, **kwargs: t.Any) -&gt; str:\n        \"\"\"Encode ``text`` using ``base64.b64encode``.\"\"\"\n\n        return base64.b64encode(text.encode(encoding=encoding), *args, **kwargs).decode(encoding=encoding)\n\n    @classmethod\n    def decode(\n        cls,\n        data: t.Union[str, bytes],\n        encoding: str = 'utf-8',\n        *args: t.Any,\n        **kwargs: t.Any,\n    ) -&gt; str:\n        \"\"\"Decode base64 data back into a UTF-8 string.\"\"\"\n\n        if isinstance(data, str):\n            data = data.encode(encoding=encoding)\n        return base64.b64decode(data, *args, **kwargs).decode(encoding=encoding)\n\n    @classmethod\n    def dumps(cls, data: str, encoding: str = 'utf-8', *args: t.Any, **kwargs: t.Any) -&gt; str:\n        \"\"\"Alias for :meth:`encode` to mirror JSON-like APIs.\"\"\"\n\n        return cls.encode(data, encoding=encoding, *args, **kwargs)\n\n    @classmethod\n    def loads(\n        cls,\n        data: t.Union[str, bytes],\n        encoding: str = 'utf-8',\n        *args: t.Any,\n        **kwargs: t.Any,\n    ) -&gt; str:\n        \"\"\"Alias for :meth:`decode` to mirror JSON-like APIs.\"\"\"\n\n        return cls.decode(data, encoding=encoding, *args, **kwargs)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Base64.encode","title":"<code>encode(text, encoding='utf-8', *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Encode <code>text</code> using <code>base64.b64encode</code>.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef encode(cls, text: str, encoding: str = 'utf-8', *args: t.Any, **kwargs: t.Any) -&gt; str:\n    \"\"\"Encode ``text`` using ``base64.b64encode``.\"\"\"\n\n    return base64.b64encode(text.encode(encoding=encoding), *args, **kwargs).decode(encoding=encoding)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Base64.decode","title":"<code>decode(data, encoding='utf-8', *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Decode base64 data back into a UTF-8 string.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef decode(\n    cls,\n    data: t.Union[str, bytes],\n    encoding: str = 'utf-8',\n    *args: t.Any,\n    **kwargs: t.Any,\n) -&gt; str:\n    \"\"\"Decode base64 data back into a UTF-8 string.\"\"\"\n\n    if isinstance(data, str):\n        data = data.encode(encoding=encoding)\n    return base64.b64decode(data, *args, **kwargs).decode(encoding=encoding)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Base64.dumps","title":"<code>dumps(data, encoding='utf-8', *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Alias for :meth:<code>encode</code> to mirror JSON-like APIs.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef dumps(cls, data: str, encoding: str = 'utf-8', *args: t.Any, **kwargs: t.Any) -&gt; str:\n    \"\"\"Alias for :meth:`encode` to mirror JSON-like APIs.\"\"\"\n\n    return cls.encode(data, encoding=encoding, *args, **kwargs)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Base64.loads","title":"<code>loads(data, encoding='utf-8', *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Alias for :meth:<code>decode</code> to mirror JSON-like APIs.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef loads(\n    cls,\n    data: t.Union[str, bytes],\n    encoding: str = 'utf-8',\n    *args: t.Any,\n    **kwargs: t.Any,\n) -&gt; str:\n    \"\"\"Alias for :meth:`decode` to mirror JSON-like APIs.\"\"\"\n\n    return cls.decode(data, encoding=encoding, *args, **kwargs)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate","title":"<code>Generate</code>","text":"<p>Helpers for creating pseudo-random identifiers and secrets.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>class Generate:\n    \"\"\"Helpers for creating pseudo-random identifiers and secrets.\"\"\"\n\n    default_method: str = 'uuid4'\n\n    @classmethod\n    def uuid(cls, method: t.Optional[str] = None, *args: t.Any, **kwargs: t.Any) -&gt; str:\n        \"\"\"Return a UUID string using ``method`` (falls back to ``uuid4``).\"\"\"\n\n        method_name = method or cls.default_method\n        generator = getattr(_uuid, method_name, getattr(_uuid, cls.default_method))\n        return str(generator(*args, **kwargs))\n\n    @classmethod\n    def uuid_passcode(\n        cls,\n        length: t.Optional[int] = None,\n        clean: bool = True,\n        method: t.Optional[str] = None,\n        raw: bool = False,\n    ) -&gt; str:\n        \"\"\"Return a UUID-derived passcode with optional cleanup/truncation.\"\"\"\n\n        value = cls.uuid(method=method)\n        if raw:\n            return value\n        if clean:\n            value = value.replace('-', '').strip()\n        if length:\n            value = value[:length]\n        return value\n\n    @classmethod\n    def alphanumeric_passcode(cls, length: int = 16, alpha_only: bool = False) -&gt; str:\n        \"\"\"Return a random ASCII alphanumeric string of ``length`` characters.\"\"\"\n\n        select = string.ascii_letters if alpha_only else ALPHA_NUMERIC\n        return ''.join(secrets.choice(select) for _ in range(length))\n\n    @classmethod\n    def token(cls, length: int = 32, safe: bool = False, clean: bool = True) -&gt; str:\n        \"\"\"Generate URL-safe or hex tokens suitable for API keys.\"\"\"\n\n        value = secrets.token_hex(length) if safe else secrets.token_urlsafe(length)\n        if clean:\n            for char in value:\n                if char not in ALPHA_NUMERIC:\n                    value = value.replace(char, secrets.choice(ALPHA_NUMERIC))\n        return value\n\n    @classmethod\n    def openssl_random_key(cls, length: int = 64, base: bool = True) -&gt; str:\n        \"\"\"Mimic ``openssl rand`` with optional base64 encoding.\"\"\"\n\n        key = secrets.token_hex(length)\n        if base:\n            key = Base64.encode(key)\n        return key\n\n    @classmethod\n    def keypair(cls, key_length: int = 16, secret_length: int = 36) -&gt; t.Dict[str, str]:\n        \"\"\"Return a random key/secret pair using ``alphanumeric_passcode``.\"\"\"\n\n        return {\n            'key': cls.alphanumeric_passcode(key_length),\n            'secret': cls.alphanumeric_passcode(secret_length),\n        }\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate.uuid","title":"<code>uuid(method=None, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Return a UUID string using <code>method</code> (falls back to <code>uuid4</code>).</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef uuid(cls, method: t.Optional[str] = None, *args: t.Any, **kwargs: t.Any) -&gt; str:\n    \"\"\"Return a UUID string using ``method`` (falls back to ``uuid4``).\"\"\"\n\n    method_name = method or cls.default_method\n    generator = getattr(_uuid, method_name, getattr(_uuid, cls.default_method))\n    return str(generator(*args, **kwargs))\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate.uuid_passcode","title":"<code>uuid_passcode(length=None, clean=True, method=None, raw=False)</code>  <code>classmethod</code>","text":"<p>Return a UUID-derived passcode with optional cleanup/truncation.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef uuid_passcode(\n    cls,\n    length: t.Optional[int] = None,\n    clean: bool = True,\n    method: t.Optional[str] = None,\n    raw: bool = False,\n) -&gt; str:\n    \"\"\"Return a UUID-derived passcode with optional cleanup/truncation.\"\"\"\n\n    value = cls.uuid(method=method)\n    if raw:\n        return value\n    if clean:\n        value = value.replace('-', '').strip()\n    if length:\n        value = value[:length]\n    return value\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate.alphanumeric_passcode","title":"<code>alphanumeric_passcode(length=16, alpha_only=False)</code>  <code>classmethod</code>","text":"<p>Return a random ASCII alphanumeric string of <code>length</code> characters.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef alphanumeric_passcode(cls, length: int = 16, alpha_only: bool = False) -&gt; str:\n    \"\"\"Return a random ASCII alphanumeric string of ``length`` characters.\"\"\"\n\n    select = string.ascii_letters if alpha_only else ALPHA_NUMERIC\n    return ''.join(secrets.choice(select) for _ in range(length))\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate.token","title":"<code>token(length=32, safe=False, clean=True)</code>  <code>classmethod</code>","text":"<p>Generate URL-safe or hex tokens suitable for API keys.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef token(cls, length: int = 32, safe: bool = False, clean: bool = True) -&gt; str:\n    \"\"\"Generate URL-safe or hex tokens suitable for API keys.\"\"\"\n\n    value = secrets.token_hex(length) if safe else secrets.token_urlsafe(length)\n    if clean:\n        for char in value:\n            if char not in ALPHA_NUMERIC:\n                value = value.replace(char, secrets.choice(ALPHA_NUMERIC))\n    return value\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate.openssl_random_key","title":"<code>openssl_random_key(length=64, base=True)</code>  <code>classmethod</code>","text":"<p>Mimic <code>openssl rand</code> with optional base64 encoding.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef openssl_random_key(cls, length: int = 64, base: bool = True) -&gt; str:\n    \"\"\"Mimic ``openssl rand`` with optional base64 encoding.\"\"\"\n\n    key = secrets.token_hex(length)\n    if base:\n        key = Base64.encode(key)\n    return key\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate.keypair","title":"<code>keypair(key_length=16, secret_length=36)</code>  <code>classmethod</code>","text":"<p>Return a random key/secret pair using <code>alphanumeric_passcode</code>.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef keypair(cls, key_length: int = 16, secret_length: int = 36) -&gt; t.Dict[str, str]:\n    \"\"\"Return a random key/secret pair using ``alphanumeric_passcode``.\"\"\"\n\n    return {\n        'key': cls.alphanumeric_passcode(key_length),\n        'secret': cls.alphanumeric_passcode(secret_length),\n    }\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.generate_htpasswd_key","title":"<code>generate_htpasswd_key(secret, salt=None, rounds=10, repeat=1)</code>","text":"<p>Generates bcrypt hashes suitable for <code>htpasswd</code> file entries.</p> <p>Parameters:</p> Name Type Description Default <code>secret</code> <code>str</code> <p>The plaintext password to hash.</p> required <code>salt</code> <code>Optional[str]</code> <p>Optional custom salt (if None, a random salt is generated).</p> <code>None</code> <code>rounds</code> <code>int</code> <p>The cost factor (logarithmic) for the bcrypt algorithm.</p> <code>10</code> <code>repeat</code> <code>int</code> <p>Number of hashes to generate.</p> <code>1</code> <p>Yields:</p> Type Description <code>str</code> <p>Bcrypt hashed strings.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>def generate_htpasswd_key(\n    secret: str,\n    salt: t.Optional[str] = None,\n    rounds: int = 10,\n    repeat: int = 1,\n) -&gt; t.Generator[str, None, None]:\n    \"\"\"\n    Generates bcrypt hashes suitable for `htpasswd` file entries.\n\n    Args:\n        secret: The plaintext password to hash.\n        salt: Optional custom salt (if None, a random salt is generated).\n        rounds: The cost factor (logarithmic) for the bcrypt algorithm.\n        repeat: Number of hashes to generate.\n\n    Yields:\n        Bcrypt hashed strings.\n    \"\"\"\n    for _ in range(repeat):\n        if salt:\n            hashed = bcrypt.hashpw(secret.encode(), salt.encode())\n        else:\n            hashed = bcrypt.hashpw(secret.encode(), bcrypt.gensalt(rounds = rounds))\n        yield hashed.decode()\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.validate_htpasswd_key","title":"<code>validate_htpasswd_key(secret, hashed)</code>","text":"<p>Validates a plaintext password against a bcrypt hash.</p> <p>Parameters:</p> Name Type Description Default <code>secret</code> <code>str</code> <p>The plaintext password to check.</p> required <code>hashed</code> <code>str</code> <p>The bcrypt hash to validate against.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the password matches the hash, False otherwise.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>def validate_htpasswd_key(\n    secret: str,\n    hashed: str,\n) -&gt; bool:\n    \"\"\"\n    Validates a plaintext password against a bcrypt hash.\n\n    Args:\n        secret: The plaintext password to check.\n        hashed: The bcrypt hash to validate against.\n\n    Returns:\n        True if the password matches the hash, False otherwise.\n    \"\"\"\n    return bcrypt.checkpw(secret.encode(), hashed.encode())\n</code></pre>"},{"location":"api/lzo/utils/#serialization","title":"Serialization","text":"<p>Unified serialization interface. </p>"},{"location":"api/lzo/utils/#lzo.utils.serialization","title":"<code>lzo.utils.serialization</code>","text":""},{"location":"api/lzo/utils/#async-exit","title":"Async Exit","text":"<p>Utilities for handling async shutdown and exit signals. </p>"},{"location":"api/lzo/utils/#lzo.utils.aioexit","title":"<code>lzo.utils.aioexit</code>","text":"<p>asyncio_atexit: atexit for asyncio</p> <p>borrowed from https://github.com/minrk/asyncio-atexit</p>"},{"location":"api/lzo/utils/#lzo.utils.aioexit.register","title":"<code>register(callback, *, loop=None)</code>","text":"<p>Register a callback for when the current event loop closes</p> <p>Like atexit.register, but run when the asyncio loop is closing, rather than process cleanup.</p> <p><code>loop</code> may be specified as a keyword arg to attach to a non-running event loop.</p> <p>Allows coroutines to cleanup their resources.</p> <p>Callback will be passed no arguments. To pass arguments to your callback, use <code>functools.partial</code>.</p> Source code in <code>src/lzo/utils/aioexit.py</code> <pre><code>def register(callback, *, loop=None):\n    \"\"\"\n    Register a callback for when the current event loop closes\n\n    Like atexit.register, but run when the asyncio loop is closing,\n    rather than process cleanup.\n\n    `loop` may be specified as a keyword arg\n    to attach to a non-running event loop.\n\n    Allows coroutines to cleanup their resources.\n\n    Callback will be passed no arguments.\n    To pass arguments to your callback,\n    use `functools.partial`.\n    \"\"\"\n    entry = _get_entry(loop)\n    entry.callbacks.append(callback)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.aioexit.unregister","title":"<code>unregister(callback, *, loop=None)</code>","text":"<p>Unregister a callback registered with asyncio_atexit.register</p> <p><code>loop</code> may be specified as a keyword arg to attach to a non-running event loop.</p> Source code in <code>src/lzo/utils/aioexit.py</code> <pre><code>def unregister(callback, *, loop=None):\n    \"\"\"\n    Unregister a callback registered with asyncio_atexit.register\n\n    `loop` may be specified as a keyword arg\n    to attach to a non-running event loop.\n    \"\"\"\n\n    entry = _get_entry(loop)\n    # remove all instances of the callback\n    while True:\n        try:\n            entry.callbacks.remove(callback)\n        except ValueError:\n            break\n</code></pre>"},{"location":"api/lzo/utils/#file-stream","title":"File Stream","text":"<p>File streaming utilities. </p>"},{"location":"api/lzo/utils/#lzo.utils.filestream","title":"<code>lzo.utils.filestream</code>","text":"<p>File Streaming Support</p>"},{"location":"api/lzo/utils/#lzo.utils.filestream.FileLikeObject","title":"<code>FileLikeObject</code>","text":"<p>               Bases: <code>IOBase</code></p> Source code in <code>src/lzo/utils/filestream.py</code> <pre><code>class FileLikeObject(IOBase):\n\n    def __init__(\n        self, \n        data: t.Iterable[t.Union[bytes, t.Any]],\n        base: t.Type = bytes,\n        # async_enabled: Optional[bool] = False,\n        **kwargs,\n    ):\n        super().__init__()\n        self.base: t.Type[bytes] = base\n        self.chunk = base()\n        self.offset = 0\n        self.iterator = iter(data)\n\n    def up_to_iter(self, size: int) -&gt; t.Iterable[t.Union[bytes, t.Any]]:\n        \"\"\"\n        Yield up to size bytes from the iterator.\n        \"\"\"\n        while size:\n            if self.offset == len(self.chunk):\n                try: self.chunk = next(self.iterator)\n                except StopIteration: break\n                else: self.offset = 0\n            to_yield = min(size, len(self.chunk) - self.offset)\n            self.offset = self.offset + to_yield\n            size -= to_yield\n            yield self.chunk[self.offset - to_yield : self.offset]\n\n    def readable(self):\n        \"\"\"\n        Return True if the stream can be read from. If False, read() will raise\n        \"\"\"\n        return True\n\n    def writable(self):\n        \"\"\"\n        Return True if the stream supports writing. If False, write() will raise\n        \"\"\"\n        return False\n\n    def read(self, size: int = -1) -&gt; bytes:\n        \"\"\"\n        Read and return up to size bytes. If the argument is omitted, None, or\n        \"\"\"\n        return self.base().join(\n            self.up_to_iter(float('inf') if size is None or size &lt; 0 else size)\n        )\n\n    def read1(self, size: int = -1) -&gt; bytes:\n        \"\"\"\n        Read and return up to size bytes, with at most one call to the underlying\n        \"\"\"\n        return self.read(size)\n\n    def as_line_iterator(self, newline: t.Optional[str] = '', encoding: t.Optional[str] = 'utf-8', **kwargs) -&gt; t.Iterable[str]:\n        \"\"\"\n        Return an iterator the yields lines from the stream.\n        \"\"\"\n        return TextIOWrapper(self, newline=newline, encoding=encoding, **kwargs)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.filestream.FileLikeObject.up_to_iter","title":"<code>up_to_iter(size)</code>","text":"<p>Yield up to size bytes from the iterator.</p> Source code in <code>src/lzo/utils/filestream.py</code> <pre><code>def up_to_iter(self, size: int) -&gt; t.Iterable[t.Union[bytes, t.Any]]:\n    \"\"\"\n    Yield up to size bytes from the iterator.\n    \"\"\"\n    while size:\n        if self.offset == len(self.chunk):\n            try: self.chunk = next(self.iterator)\n            except StopIteration: break\n            else: self.offset = 0\n        to_yield = min(size, len(self.chunk) - self.offset)\n        self.offset = self.offset + to_yield\n        size -= to_yield\n        yield self.chunk[self.offset - to_yield : self.offset]\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.filestream.FileLikeObject.readable","title":"<code>readable()</code>","text":"<p>Return True if the stream can be read from. If False, read() will raise</p> Source code in <code>src/lzo/utils/filestream.py</code> <pre><code>def readable(self):\n    \"\"\"\n    Return True if the stream can be read from. If False, read() will raise\n    \"\"\"\n    return True\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.filestream.FileLikeObject.writable","title":"<code>writable()</code>","text":"<p>Return True if the stream supports writing. If False, write() will raise</p> Source code in <code>src/lzo/utils/filestream.py</code> <pre><code>def writable(self):\n    \"\"\"\n    Return True if the stream supports writing. If False, write() will raise\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.filestream.FileLikeObject.read","title":"<code>read(size=-1)</code>","text":"<p>Read and return up to size bytes. If the argument is omitted, None, or</p> Source code in <code>src/lzo/utils/filestream.py</code> <pre><code>def read(self, size: int = -1) -&gt; bytes:\n    \"\"\"\n    Read and return up to size bytes. If the argument is omitted, None, or\n    \"\"\"\n    return self.base().join(\n        self.up_to_iter(float('inf') if size is None or size &lt; 0 else size)\n    )\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.filestream.FileLikeObject.read1","title":"<code>read1(size=-1)</code>","text":"<p>Read and return up to size bytes, with at most one call to the underlying</p> Source code in <code>src/lzo/utils/filestream.py</code> <pre><code>def read1(self, size: int = -1) -&gt; bytes:\n    \"\"\"\n    Read and return up to size bytes, with at most one call to the underlying\n    \"\"\"\n    return self.read(size)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.filestream.FileLikeObject.as_line_iterator","title":"<code>as_line_iterator(newline='', encoding='utf-8', **kwargs)</code>","text":"<p>Return an iterator the yields lines from the stream.</p> Source code in <code>src/lzo/utils/filestream.py</code> <pre><code>def as_line_iterator(self, newline: t.Optional[str] = '', encoding: t.Optional[str] = 'utf-8', **kwargs) -&gt; t.Iterable[str]:\n    \"\"\"\n    Return an iterator the yields lines from the stream.\n    \"\"\"\n    return TextIOWrapper(self, newline=newline, encoding=encoding, **kwargs)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.filestream.AsyncFileLikeObject","title":"<code>AsyncFileLikeObject</code>","text":"<p>               Bases: <code>IOBase</code></p> Source code in <code>src/lzo/utils/filestream.py</code> <pre><code>class AsyncFileLikeObject(IOBase):\n\n    def __init__(\n        self, \n        data: t.Iterable[t.Union[bytes, t.Any]],\n        base: t.Type = bytes,\n        **kwargs,\n    ):\n        super().__init__()\n        self.base: t.Type[bytes] = base\n        self.chunk = base()\n        self.offset = 0\n        self.iterator = aiter(data)\n\n    async def up_to_iter(self, size: int) -&gt; t.Iterable[t.Union[bytes, t.Any]]:\n        \"\"\"\n        Yield up to size bytes from the iterator.\n        \"\"\"\n        while size:\n            if self.offset == len(self.chunk):\n                try: self.chunk = await anext(self.iterator)\n                except StopIteration: break\n                else: self.offset = 0\n            to_yield = min(size, len(self.chunk) - self.offset)\n            self.offset += to_yield\n            size -= to_yield\n            yield self.chunk[self.offset - to_yield : self.offset]\n\n    def readable(self):\n        \"\"\"\n        Return True if the stream can be read from. If False, read() will raise\n        \"\"\"\n        return True\n\n    def writable(self):\n        \"\"\"\n        Return True if the stream supports writing. If False, write() will raise\n        \"\"\"\n        return False\n\n    async def read(self, size: int = -1) -&gt; bytes:\n        \"\"\"\n        Read and return up to size bytes. If the argument is omitted, None, or\n        \"\"\"\n        b = []\n        async for chunk in self.up_to_iter(float('inf') if size is None or size &lt; 0 else size):\n            b += chunk        \n        return self.base().join(b) \n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.filestream.AsyncFileLikeObject.up_to_iter","title":"<code>up_to_iter(size)</code>  <code>async</code>","text":"<p>Yield up to size bytes from the iterator.</p> Source code in <code>src/lzo/utils/filestream.py</code> <pre><code>async def up_to_iter(self, size: int) -&gt; t.Iterable[t.Union[bytes, t.Any]]:\n    \"\"\"\n    Yield up to size bytes from the iterator.\n    \"\"\"\n    while size:\n        if self.offset == len(self.chunk):\n            try: self.chunk = await anext(self.iterator)\n            except StopIteration: break\n            else: self.offset = 0\n        to_yield = min(size, len(self.chunk) - self.offset)\n        self.offset += to_yield\n        size -= to_yield\n        yield self.chunk[self.offset - to_yield : self.offset]\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.filestream.AsyncFileLikeObject.readable","title":"<code>readable()</code>","text":"<p>Return True if the stream can be read from. If False, read() will raise</p> Source code in <code>src/lzo/utils/filestream.py</code> <pre><code>def readable(self):\n    \"\"\"\n    Return True if the stream can be read from. If False, read() will raise\n    \"\"\"\n    return True\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.filestream.AsyncFileLikeObject.writable","title":"<code>writable()</code>","text":"<p>Return True if the stream supports writing. If False, write() will raise</p> Source code in <code>src/lzo/utils/filestream.py</code> <pre><code>def writable(self):\n    \"\"\"\n    Return True if the stream supports writing. If False, write() will raise\n    \"\"\"\n    return False\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.filestream.AsyncFileLikeObject.read","title":"<code>read(size=-1)</code>  <code>async</code>","text":"<p>Read and return up to size bytes. If the argument is omitted, None, or</p> Source code in <code>src/lzo/utils/filestream.py</code> <pre><code>async def read(self, size: int = -1) -&gt; bytes:\n    \"\"\"\n    Read and return up to size bytes. If the argument is omitted, None, or\n    \"\"\"\n    b = []\n    async for chunk in self.up_to_iter(float('inf') if size is None or size &lt; 0 else size):\n        b += chunk        \n    return self.base().join(b) \n</code></pre>"},{"location":"api/lzo/utils/#logs","title":"Logs","text":"<p>Logging helpers. </p>"},{"location":"api/lzo/utils/#lzo.utils.logs","title":"<code>lzo.utils.logs</code>","text":""},{"location":"api/lzo/utils/#usage-guide","title":"Usage Guide","text":""},{"location":"api/lzo/utils/#generating-keys","title":"Generating Keys","text":"<pre><code>from lzo.utils.keygen import Generate\n\n# Random 16-char alphanumeric string\nkey = Generate.alphanumeric_passcode(16)\n\n# UUID\nuid = Generate.uuid()\n</code></pre>"},{"location":"api/lzo/utils/#object-hashing","title":"Object Hashing","text":"<p>Create deterministic hashes for complex objects (dicts, Pydantic models).</p> <pre><code>from lzo.utils.hashing import create_object_hash\n\ndata = {\"a\": 1, \"b\": [2, 3]}\nhash_val = create_object_hash(data)\n</code></pre>"}]}