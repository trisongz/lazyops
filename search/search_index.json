{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"LazyOps Documentation","text":"<p>Welcome to the LazyOps documentation hub. This site captures the refreshed guides, coding standards, and planning notes that accompany the <code>lzl</code> utility namespace and the <code>lzo</code> registry toolkit.</p> <ul> <li>Quick Start: Review Mintlify workflow for local preview   commands.</li> <li>Coding Standards: Follow the conventions in   Code Style when writing or reviewing modules under <code>src/</code>.</li> <li>Roadmap: Track upcoming refactors and documentation follow-ups in   Future Updates and Todo.</li> </ul> <p>Additional pages will be added as the refactor progresses toward the upcoming <code>v0.3.x</code> release.</p>"},{"location":"code-style/","title":"LazyOps Code Style Guide","text":"<p>This document captures incremental conventions as we touch the codebase.  Keep it updated so new contributors have a single reference for style expectations.</p>"},{"location":"code-style/#typing-and-imports","title":"Typing and Imports","text":"<ul> <li>Always import the typing module as <code>import typing as t</code>; prefer <code>t.Dict</code>,   <code>t.Optional</code>, etc., over direct names from <code>typing</code>.</li> <li>Forward references should remain in quotes and grouped near their usage to   minimise runtime import overhead.</li> <li>Add <code>__all__</code> lists when modules act as fa\u00e7ades or re-export symbols to make   the public surface explicit for documentation generators.</li> <li>Aggregator modules (for example <code>lzo.registry</code> and <code>lzo.utils</code>) should   populate <code>__all__</code> with the curated public API so Mintlify exports remain   predictable.</li> </ul>"},{"location":"code-style/#documentation","title":"Documentation","text":"<ul> <li>Every module modified during this effort should include a narrative   module-level docstring that explains its role within the <code>lzl</code>/<code>lzo</code>   ecosystem.  Keep the tone practical so Mintlify can produce helpful   summaries.</li> <li>Expand class and function docstrings with concise context-first language,   followed by parameter descriptions when behaviour is not self-evident.</li> <li>Avoid documenting implementation details that may change; focus on intent and   usage to prevent churn when functionality evolves.</li> </ul>"},{"location":"code-style/#general-style","title":"General Style","text":"<ul> <li>Prefer enriching existing structures (docstrings, typing, comments) over   altering runtime behaviour during documentation-focused sprints.</li> <li>When adding clarifying comments, keep them short and purpose-driven.  Do not   annotate trivial assignments or control flow.</li> <li>Maintain ASCII encoding in source files unless there is a clear reason to do   otherwise and the file already uses non-ASCII characters.</li> </ul>"},{"location":"code-style/#testing","title":"Testing","text":"<ul> <li>Prefer deterministic transports (for example <code>httpx.MockTransport</code>) when   exercising HTTP clients to keep tests network-free and CI friendly.</li> <li>Use <code>tmp_path</code>/<code>tmp_path_factory</code> for filesystem-heavy utilities such as   <code>lzl.io.persistence</code> to avoid leaving artefacts on developer machines.</li> <li>Prefer standard-library modules (for example <code>math</code>) when exercising   <code>LazyLoad</code> to keep tests deterministic and dependency-free.</li> <li>When testing <code>ThreadPool</code>, await background tasks or consume futures so the   event loop does not emit \"task was destroyed\" warnings during teardown.</li> <li>Reset class-level caches (for example <code>ProxyDict._dict</code>) in tests that   mutate proxied registries to avoid leaking state between cases.</li> <li>Mark coroutine tests with <code>@pytest.mark.asyncio</code> rather than managing event   loops manually when exercising async utilities such as <code>retryable</code>.</li> <li>When exercising <code>WorkerContext</code>/<code>MLContext</code>, stub <code>logger.info</code> and resource   fetchers so tests do not rely on real hardware metrics.</li> </ul> <p>Last updated: September 18, 2025</p>"},{"location":"future-updates/","title":"Future Enhancements","text":"<p>Tracks potential improvements discovered while documenting the codebase.  These items should be evaluated in a dedicated refactor sprint so behaviour changes remain intentional.</p>"},{"location":"future-updates/#lzlapiaiohttpx","title":"lzl.api.aiohttpx","text":"<ul> <li>Consider handling environments where <code>os.cpu_count()</code> returns <code>None</code> when   computing preset connection limits; today we mirror the original behaviour   which raises.</li> <li>Evaluate exposing a public API for registering custom preset profiles to   reduce reliance on the mutable <code>PresetMap</code> dictionary.</li> <li>Explore replacing the global monkey patch of <code>httpx.Response.raise_for_status</code>   with a scoped wrapper to avoid affecting consumers outside <code>lzl</code>.</li> </ul>"},{"location":"future-updates/#lzldb","title":"lzl.db","text":"<ul> <li>Several backend helper methods (for example sqlite <code>get_table_column_size</code>)   remain unimplemented placeholders; document desired semantics before adding   behaviour in a future sprint.</li> <li>Evaluate whether importing heavy SQLAlchemy dependencies at module import time   can be deferred to improve startup performance for non-database use cases.</li> </ul>"},{"location":"future-updates/#lzlio","title":"lzl.io","text":"<ul> <li><code>lzl.io.queue.background</code> references an <code>EventQueue</code> class that is not   defined within the package.  Confirm intended implementation and wire in the   missing queue before advertising the API publicly.</li> <li><code>PersistentDict</code> still mixes legacy <code>typing</code> aliases (<code>Optional</code>,   <code>Dict</code>, \u2026); migrate the remainder to <code>import typing as t</code> once behaviour   stabilises to keep type hints consistent with newer modules.</li> </ul>"},{"location":"future-updates/#lzlload","title":"lzl.load","text":"<ul> <li>Investigate whether the default <code>install_missing=True</code> flag for   :class:<code>LazyLoad</code> should be scoped behind an explicit opt-in to avoid   surprising installations at runtime.</li> <li>Consider exposing a public API for clearing the module/object caches managed   by <code>lazy_import</code> to support long-lived processes that hot-reload   configuration.</li> </ul>"},{"location":"future-updates/#lzlpool","title":"lzl.pool","text":"<ul> <li><code>ThreadPool.run</code> currently requires <code>anyio</code>; evaluate providing a graceful   fallback or clearer error message when the optional dependency is missing.</li> <li>Consider pooling executors across interpreter restarts to avoid spinning up   multiple thread pools in short-lived CLI contexts.</li> </ul>"},{"location":"future-updates/#lzlproxied","title":"lzl.proxied","text":"<ul> <li><code>ProxyDict</code> shares class-level caches across subclasses; evaluate providing a   context manager or helper to reset state when used in long-lived processes.</li> <li>Explore exposing thread-safety controls for <code>ProxyObject</code> beyond a simple   boolean to support custom lock strategies when profiling indicates issues.</li> </ul>"},{"location":"future-updates/#lzlsysmon","title":"lzl.sysmon","text":"<ul> <li>GPU/CPU sampling currently depends on <code>lzo.utils.system</code>; consider adding   graceful degradation when those utilities are unavailable.</li> <li>Evaluate emitting structured data (JSON) alongside formatted strings so the   metrics can be ingested by observability tooling without parsing log text.</li> </ul>"},{"location":"future-updates/#lzoregistry","title":"lzo.registry","text":"<ul> <li><code>lzo.registry.objects</code> is still a partial stub that references undefined   client registries; determine whether it should mirror the client registry or   be removed before publishing the API.</li> <li><code>MRegistry</code> currently stores all class-level state on the class itself; consider   migrating to instance-level storage to support multiple independent registries.</li> </ul>"},{"location":"future-updates/#lzotypes","title":"lzo.types","text":"<ul> <li>Explore simplifying the <code>BaseSettings</code> inheritance chain so it no longer needs   to import logging utilities at runtime, reducing the risk of circular   dependencies when documentation generators import the module.</li> <li>Investigate whether <code>set_app_env</code> should call <code>AppEnv.from_env</code> directly   instead of delegating via the potentially <code>None</code> <code>self.app_env</code> attribute.</li> </ul>"},{"location":"future-updates/#lzoutils","title":"lzo.utils","text":"<ul> <li>Several helper modules still use legacy <code>from typing import</code> patterns; sweep   the remaining files (<code>helpers.dates</code>, <code>helpers.caching</code>, etc.) so typing   imports are consistent across the package.</li> <li>The optional bcrypt dependency in <code>keygen.generate_htpasswd_key</code> is lazily   imported; consider surfacing a clearer error message when the dependency is   missing to aid downstream users.</li> </ul>"},{"location":"mintlify/","title":"Mintlify Documentation Workflow","text":"<p>Use the Mintlify CLI (<code>mint</code>) to preview and validate documentation locally. The commands below assume <code>docs.json</code> lives at the project root (next to <code>pyproject.toml</code>).</p> <pre><code># Install or update the CLI\nnpm i -g mint\nmint update\n\n# Preview documentation locally on http://localhost:3000\nmint dev\n\n# Run validation checks\nmint broken-links\nmint openapi-check &lt;openapiFilenameOrUrl&gt;\n</code></pre> <p>When the documentation site is ready, deploy via the Mintlify dashboard or your existing CI workflow.</p>"},{"location":"mintlify/#makefile-shortcuts","title":"Makefile Shortcuts","text":"<p>The project Makefile wraps the common commands above:</p> <pre><code>make docs-preview   # mint dev\nmake docs-generate  # mint broken-links (and optional openapi-check)\nmake docs-publish   # git push origin main (override via DOCS_REMOTE/BRANCH)\n</code></pre>"},{"location":"mkdocs-setup/","title":"MkDocs Setup Guide","text":"<p>This guide explains how to use MkDocs with Material theme for the LazyOps documentation.</p>"},{"location":"mkdocs-setup/#overview","title":"Overview","text":"<p>LazyOps uses MkDocs with the Material theme for generating beautiful, searchable documentation from Markdown files and Python docstrings.</p>"},{"location":"mkdocs-setup/#prerequisites","title":"Prerequisites","text":"<p>Install the documentation dependencies:</p> <pre><code>pip install mkdocs mkdocs-material \"mkdocstrings[python]\" pymdown-extensions\n</code></pre> <p>Or install all docs extras:</p> <pre><code>pip install -e \".[docs]\"\n</code></pre>"},{"location":"mkdocs-setup/#local-development","title":"Local Development","text":""},{"location":"mkdocs-setup/#serve-documentation-locally","title":"Serve Documentation Locally","text":"<p>Run the development server to preview documentation with live reload:</p> <pre><code>make mkdocs-serve\n# or\nmkdocs serve\n</code></pre> <p>The documentation will be available at <code>http://127.0.0.1:8000/</code>.</p>"},{"location":"mkdocs-setup/#build-documentation","title":"Build Documentation","text":"<p>Build the static site:</p> <pre><code>make mkdocs-build\n# or\nmkdocs build\n</code></pre> <p>The built site will be in the <code>site/</code> directory.</p>"},{"location":"mkdocs-setup/#documentation-structure","title":"Documentation Structure","text":"<pre><code>docs/\n\u251c\u2500\u2500 index.md                 # Homepage\n\u251c\u2500\u2500 code-style.md           # Coding standards\n\u251c\u2500\u2500 future-updates.md       # Roadmap\n\u251c\u2500\u2500 todo.md                 # Task tracking\n\u251c\u2500\u2500 mintlify.md            # Mintlify workflow reference\n\u251c\u2500\u2500 mkdocs-setup.md        # This file\n\u2514\u2500\u2500 api/                    # API documentation\n    \u251c\u2500\u2500 lzl/               # lzl namespace docs\n    \u2502   \u251c\u2500\u2500 index.md\n    \u2502   \u251c\u2500\u2500 io.md\n    \u2502   \u251c\u2500\u2500 load.md\n    \u2502   \u251c\u2500\u2500 logging.md\n    \u2502   \u251c\u2500\u2500 pool.md\n    \u2502   \u251c\u2500\u2500 proxied.md\n    \u2502   \u251c\u2500\u2500 require.md\n    \u2502   \u2514\u2500\u2500 sysmon.md\n    \u2514\u2500\u2500 lzo/               # lzo namespace docs\n        \u251c\u2500\u2500 index.md\n        \u251c\u2500\u2500 registry.md\n        \u251c\u2500\u2500 types.md\n        \u2514\u2500\u2500 utils.md\n</code></pre>"},{"location":"mkdocs-setup/#adding-new-documentation","title":"Adding New Documentation","text":""},{"location":"mkdocs-setup/#creating-new-pages","title":"Creating New Pages","text":"<ol> <li>Create a new Markdown file in the <code>docs/</code> directory</li> <li>Add it to the navigation in <code>mkdocs.yml</code></li> </ol> <p>Example:</p> <pre><code>nav:\n  - New Section:\n    - New Page: new-page.md\n</code></pre>"},{"location":"mkdocs-setup/#auto-generating-api-documentation","title":"Auto-generating API Documentation","text":"<p>Use the <code>mkdocstrings</code> plugin to automatically generate documentation from docstrings:</p> <pre><code># My Module\n\n::: my_module.my_function\n    options:\n      show_source: true\n</code></pre> <p>This will render the docstring and source code of <code>my_function</code>.</p>"},{"location":"mkdocs-setup/#supported-features","title":"Supported Features","text":"<ul> <li>Code Blocks: Syntax highlighting for Python and other languages</li> <li>Admonitions: Notes, warnings, tips, etc.</li> <li>Tables: Markdown tables with alignment</li> <li>Links: Internal and external links</li> <li>Images: Embedded images with captions</li> <li>Math: LaTeX math rendering</li> <li>Tabs: Tabbed content sections</li> </ul>"},{"location":"mkdocs-setup/#configuration","title":"Configuration","text":"<p>The documentation configuration is in <code>mkdocs.yml</code>:</p> <ul> <li>Theme: Material theme with custom colors</li> <li>Navigation: Organized into sections and subsections</li> <li>Plugins: Search and mkdocstrings for API docs</li> <li>Extensions: Syntax highlighting, admonitions, etc.</li> </ul>"},{"location":"mkdocs-setup/#deployment","title":"Deployment","text":""},{"location":"mkdocs-setup/#manual-deployment","title":"Manual Deployment","text":"<p>Deploy to GitHub Pages:</p> <pre><code>make mkdocs-deploy\n# or\nmkdocs gh-deploy --force\n</code></pre>"},{"location":"mkdocs-setup/#automatic-deployment","title":"Automatic Deployment","text":"<p>The documentation is automatically deployed to GitHub Pages on every push to <code>main</code> that affects: - Files in <code>docs/</code> - <code>mkdocs.yml</code> - <code>.github/workflows/docs.yml</code></p> <p>The GitHub Actions workflow is defined in <code>.github/workflows/docs.yml</code>.</p>"},{"location":"mkdocs-setup/#tips-and-best-practices","title":"Tips and Best Practices","text":"<ol> <li>Preview Changes: Always preview locally before committing</li> <li>Link Checking: Use relative links for internal pages</li> <li>Code Examples: Include working code examples</li> <li>Docstrings: Use Google-style docstrings for consistency</li> <li>Images: Store images in <code>docs/assets/</code> (create if needed)</li> <li>Search: The search functionality works on the built site</li> </ol>"},{"location":"mkdocs-setup/#troubleshooting","title":"Troubleshooting","text":""},{"location":"mkdocs-setup/#build-warnings","title":"Build Warnings","text":"<ul> <li>Unrecognized links: Ensure link paths are correct (include <code>.md</code> extension)</li> <li>Missing modules: Ensure all Python modules can be imported</li> <li>Syntax errors: Check Python source files for syntax issues</li> </ul>"},{"location":"mkdocs-setup/#local-server-issues","title":"Local Server Issues","text":"<p>If the local server doesn't start: - Check if port 8000 is already in use - Use <code>mkdocs serve -a 127.0.0.1:8001</code> to use a different port</p>"},{"location":"mkdocs-setup/#resources","title":"Resources","text":"<ul> <li>MkDocs Documentation</li> <li>Material for MkDocs</li> <li>mkdocstrings</li> <li>PyMdown Extensions</li> </ul>"},{"location":"todo/","title":"Todo","text":"<ul> <li>[ ] Add Documentation (mintlify)</li> <li>[ ] Add Documentation (readme)</li> <li>[ ] Remove v1</li> <li>[ ] Add proper tests</li> <li>[ ] Rework / refactor code</li> <li>[ ] Rework fileio module</li> </ul>"},{"location":"api/lzl/","title":"lzl - Lazy Libraries/Utilities","text":"<p>The <code>lzl</code> namespace contains foundational utilities, asynchronous helpers, common API client interfaces, I/O operations, logging, type definitions, and more.</p>"},{"location":"api/lzl/#key-modules","title":"Key Modules","text":"<ul> <li>IO: Input/output operations including serialization, persistence, and file handling</li> <li>Load: Lazy loading utilities for deferred imports</li> <li>Logging: Logging configuration and utilities</li> <li>Pool: Thread pool and async execution helpers</li> <li>Proxied: Proxy object patterns for lazy initialization</li> <li>Require: Dependency resolution and requirement management</li> <li>Sysmon: System monitoring and resource tracking</li> </ul>"},{"location":"api/lzl/#overview","title":"Overview","text":"<p>The <code>lzl</code> toolkit provides a comprehensive set of utilities that are commonly used across internal development projects. These utilities are designed to be lightweight, performant, and easy to integrate into existing codebases.</p>"},{"location":"api/lzl/#installation","title":"Installation","text":"<p>The <code>lzl</code> module is included with the base <code>lazyops</code> installation:</p> <pre><code>pip install lazyops\n</code></pre>"},{"location":"api/lzl/#quick-example","title":"Quick Example","text":"<pre><code>import lzl\nfrom lzl.logging import logger\nfrom lzl.load import LazyLoad\n\n# Use lazy loading\nlazy_module = LazyLoad('expensive.module')\n\n# Configure logging\nlogger.info(\"Starting application\")\n</code></pre>"},{"location":"api/lzl/#architecture","title":"Architecture","text":"<p>The <code>lzl</code> namespace is organized into several key areas:</p> <ul> <li>API Clients: HTTP clients, database connectors, and external service integrations</li> <li>I/O Operations: File handling, serialization, and data persistence</li> <li>Utilities: Common helpers for async operations, caching, and more</li> <li>Extensions: Optional integrations with FastAPI, Temporal, and other frameworks</li> </ul> <p>Browse the sidebar to explore specific modules and their documentation.</p>"},{"location":"api/lzl/api/","title":"lzl.api - API Clients","text":"<p>The <code>lzl.api</code> module contains clients and integrations for various external services and APIs.</p>"},{"location":"api/lzl/api/#http-clients","title":"HTTP Clients","text":""},{"location":"api/lzl/api/#aiohttpx","title":"aiohttpx","text":""},{"location":"api/lzl/api/#lzl.api.aiohttpx","title":"<code>lzl.api.aiohttpx</code>","text":""},{"location":"api/lzl/api/#aioreq","title":"aioreq","text":""},{"location":"api/lzl/api/#lzl.api.aioreq","title":"<code>lzl.api.aioreq</code>","text":""},{"location":"api/lzl/api/#service-integrations","title":"Service Integrations","text":""},{"location":"api/lzl/api/#openai","title":"OpenAI","text":""},{"location":"api/lzl/api/#lzl.api.openai","title":"<code>lzl.api.openai</code>","text":"<p>Fork of <code>async_openai</code> to continue extending the library</p>"},{"location":"api/lzl/api/#slack","title":"Slack","text":""},{"location":"api/lzl/api/#lzl.api.slack","title":"<code>lzl.api.slack</code>","text":"<p>This package implements the Slack Client API as a unified async/sync client</p>"},{"location":"api/lzl/api/#keycloak","title":"Keycloak","text":""},{"location":"api/lzl/api/#lzl.api.keycloak","title":"<code>lzl.api.keycloak</code>","text":""},{"location":"api/lzl/api/#argo","title":"Argo","text":""},{"location":"api/lzl/api/#lzl.api.argo","title":"<code>lzl.api.argo</code>","text":""},{"location":"api/lzl/api/#hatchet","title":"Hatchet","text":""},{"location":"api/lzl/api/#lzl.api.hatchet","title":"<code>lzl.api.hatchet</code>","text":"<p>Hatchet API with Modifications</p>"},{"location":"api/lzl/api/#qdrant","title":"Qdrant","text":""},{"location":"api/lzl/api/#lzl.api.qdrant","title":"<code>lzl.api.qdrant</code>","text":"<p>Qdrant Client with Unified Async / Sync</p>"},{"location":"api/lzl/api/#searxng","title":"SearxNG","text":""},{"location":"api/lzl/api/#lzl.api.searxng","title":"<code>lzl.api.searxng</code>","text":"<p>SearxNG API Client</p>"},{"location":"api/lzl/api/#rqlite","title":"RQLite","text":""},{"location":"api/lzl/api/#lzl.api.aiorqlite","title":"<code>lzl.api.aiorqlite</code>","text":""},{"location":"api/lzl/cmd/","title":"lzl.cmd - Command Line Utilities","text":"<p>The <code>lzl.cmd</code> module provides tools for building CLI applications and handling environment variables.</p>"},{"location":"api/lzl/cmd/#builder","title":"Builder","text":""},{"location":"api/lzl/cmd/#lzl.cmd.builder","title":"<code>lzl.cmd.builder</code>","text":""},{"location":"api/lzl/cmd/#lzl.cmd.builder.CustomInstaller","title":"<code>CustomInstaller</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Custom Installer</p> <p>These run during the stage 1 of the builder</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>class CustomInstaller(BaseModel):\n    \"\"\"\n    Custom Installer\n\n    These run during the stage 1 of the builder\n    \"\"\"\n    name: str = Field(None, description = \"The name of the custom installer\")\n    cmds: List[str] = Field(default_factory = list, description = \"The commands to run\")\n\n    @classmethod\n    def load_defaults(cls) -&gt; List[CustomInstaller]:\n        \"\"\"\n        Loads the default installers\n        \"\"\"\n        default_file = ASSETS_PATH.joinpath('default_installers.yaml')\n        if not default_file.exists(): return []\n        data = yaml.safe_load(default_file.read_text())\n        return [CustomInstaller.model_validate(item) for item in data]\n\n    def run(self):\n        \"\"\"\n        Runs the custom installer\n        \"\"\"\n        echo(f'Running Custom Installer: {COLOR.BLUE}{self.name}{COLOR.END}')\n        for cmdstr in self.cmds:\n            os.system(cmdstr)\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.CustomInstaller.load_defaults","title":"<code>load_defaults()</code>  <code>classmethod</code>","text":"<p>Loads the default installers</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>@classmethod\ndef load_defaults(cls) -&gt; List[CustomInstaller]:\n    \"\"\"\n    Loads the default installers\n    \"\"\"\n    default_file = ASSETS_PATH.joinpath('default_installers.yaml')\n    if not default_file.exists(): return []\n    data = yaml.safe_load(default_file.read_text())\n    return [CustomInstaller.model_validate(item) for item in data]\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.CustomInstaller.run","title":"<code>run()</code>","text":"<p>Runs the custom installer</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def run(self):\n    \"\"\"\n    Runs the custom installer\n    \"\"\"\n    echo(f'Running Custom Installer: {COLOR.BLUE}{self.name}{COLOR.END}')\n    for cmdstr in self.cmds:\n        os.system(cmdstr)\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.CustomCommand","title":"<code>CustomCommand</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Custom Command</p> <p>These run during the stage 2 of the builder</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>class CustomCommand(BaseModel):\n    \"\"\"\n    Custom Command\n\n    These run during the stage 2 of the builder\n    \"\"\"\n    name: str = Field(None, description = \"The name of the custom command\")\n    cmds: List[str] = Field(default_factory = list, description = \"The commands to run\")\n\n    def run(self):\n        \"\"\"\n        Runs the custom command\n        \"\"\"\n        echo(f'Running Custom Command: {COLOR.BLUE}{self.name}{COLOR.END}')\n        for cmdstr in self.cmds:\n            os.system(cmdstr)\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.CustomCommand.run","title":"<code>run()</code>","text":"<p>Runs the custom command</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def run(self):\n    \"\"\"\n    Runs the custom command\n    \"\"\"\n    echo(f'Running Custom Command: {COLOR.BLUE}{self.name}{COLOR.END}')\n    for cmdstr in self.cmds:\n        os.system(cmdstr)\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuildRef","title":"<code>BuildRef</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Build Ref</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>class BuildRef(BaseModel):\n    \"\"\"\n    Build Ref\n    \"\"\"\n    name: str = Field('server', description = \"The name of the build reference\")\n    refs: List[str] = Field(default_factory = list, description = \"The names of the build reference\")\n    enabled: Optional[bool] = Field(None, description = \"Whether the build reference is enabled\")\n    custom_install: List[str] = Field(default_factory = list, description = \"Custom Install Commands\")\n    custom_commands: List[str] = Field(default_factory = list, description = \"Custom Commands\")\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig","title":"<code>BuilderConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Builder Config</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>class BuilderConfig(BaseModel):\n    \"\"\"\n    Builder Config\n    \"\"\"\n    app_name: Optional[str] = Field(os.getenv('APP_NAME'), description=\"The name of the app\")\n    refs: List[BuildRef] = Field(default_factory = list, description = \"The build references\")\n    custom_installers: List[CustomInstaller] = Field(default_factory = list, description = \"Custom Installers\")\n    custom_commands: List[CustomCommand] = Field(default_factory = list, description = \"Custom Commands\")\n    enabled_refs: List[str] = Field(BUILDS_ENABLED_REFS, description = \"The enabled build references\")\n\n    extra: Dict[str, Any] = Field(default_factory = dict)\n\n    @model_validator(mode = 'after')\n    def validate_refs(self):\n        \"\"\"\n        Validate the build references\n        \"\"\"\n        if self.extra.get('validated'): return\n        for ref in self.refs:\n            if ref.enabled is None:\n                ref.enabled = ref.name in self.enabled_refs\n\n        if ENABLE_DEFAULT_INSTALLERS:\n            existing = [c.name for c in self.custom_installers]\n            default_installers = CustomInstaller.load_defaults()\n            for installer in default_installers:\n                if installer.name not in existing:\n                    self.custom_installers.append(installer)\n\n        self.extra['validated'] = True\n        return self\n\n    @property\n    def builds(self) -&gt; Dict[str, BuildRef]:\n        \"\"\"\n        Returns the build references\n        \"\"\"\n        return {\n            ref.name: ref\n            for ref in self.refs if ref.enabled\n        }\n\n    @property\n    def enabled_builds(self) -&gt; List[str]:\n        \"\"\"\n        Returns the enabled build services\n        \"\"\"\n        return [ref.name for ref in self.refs if ref.enabled]\n\n    @property\n    def installers(self) -&gt; Dict[str, CustomInstaller]:\n        \"\"\"\n        Returns the custom installers\n        \"\"\"\n        return {\n            installer.name: installer\n            for installer in self.custom_installers\n        }\n\n    @property\n    def commands(self) -&gt; Dict[str, CustomCommand]:\n        \"\"\"\n        Returns the custom commands\n        \"\"\"\n        return {\n            command.name: command\n            for command in self.custom_commands\n        }\n\n    @property\n    def stage(self) -&gt; int:\n        \"\"\"\n        Returns the stage\n        \"\"\"\n        return self.extra.get('stage', 0)\n\n    @stage.setter\n    def stage(self, value: int):\n        \"\"\"\n        Sets the stage\n        \"\"\"\n        self.extra['stage'] = value\n        self.save()\n\n    def show_env(self, step: str):\n        \"\"\"\n        Show the environment\n        \"\"\"\n        echo(f\"Starting Step: {COLOR.GREEN}{step}{COLOR.END}\\n\")\n        echo(f\"[Enabled Builds]: {COLOR.BLUE}{self.enabled_builds}{COLOR.END}\")\n\n    @classmethod\n    def load(cls, path: Optional[Path] = None) -&gt; 'BuilderConfig':\n        \"\"\"\n        Load the build config\n        \"\"\"\n        if path is None:\n            path = BUILD_CONFIG_PATH if BUILD_CONFIG_PATH.exists() else DEFAULT_CONFIG_PATH\n        return cls.model_validate(yaml.safe_load(path.read_text()))\n\n    def save(self):\n        \"\"\"\n        Save the build config\n        \"\"\"\n        BUILD_CONFIG_PATH.write_text(yaml.dump(self.model_dump(), default_flow_style = False))\n\n    def update_config(self, path: Optional[Path] = None, **config: Any):\n        \"\"\"\n        Update the build config\n        \"\"\"\n        data = self.model_dump()\n        if path: \n            update_data = yaml.safe_load(path.read_text())\n            data.update(update_data)\n        if config: data.update(config)\n        BUILD_CONFIG_PATH.write_text(yaml.dump(data, default_flow_style = False))\n\n\n    def get_apt_packages(self, ref: str) -&gt; List[str]:\n        \"\"\"\n        Helper for getting the apt packages for a given ref name\n        \"\"\"\n        pkg_dir = PKGS_PATH\n        if ref not in self.builds: return []\n        for alias in self.builds[ref].refs:\n            pkg_file = pkg_dir.joinpath(f'{alias}.txt')\n            if pkg_file.exists():\n                return parse_text_file(pkg_file)\n        return []\n\n\n    def get_pip_requirements(self, ref: str) -&gt; Optional[str]:\n        \"\"\"\n        Helper for getting the pip requirements file for a given ref name\n        \"\"\"\n        pkg_dir = REQUIREMENTS_PATH.joinpath(ref)\n        if ref not in self.builds: return None\n        for alias in self.builds[ref].refs:\n            req_file = pkg_dir.joinpath(f'{alias}.txt')\n            if req_file.exists():\n                req_file.write_text(req_file.read_text().replace('GITHUB_TOKEN', GITHUB_TOKEN))\n                return req_file.as_posix()\n            req_file = pkg_dir.joinpath(f'requirements.{alias}.txt')\n            if req_file.exists():\n                return req_file.as_posix()\n        return None\n\n\n\n    \"\"\"\n    Step 1: Install Apt Packages\n    \"\"\"\n\n    @property\n    def apt_pkgs(self) -&gt; List[str]:\n        \"\"\"\n        Returns the apt packages\n        \"\"\"\n        if 'apt_pkgs' not in self.extra:\n            self.extra['apt_pkgs'] = []\n        return self.extra['apt_pkgs']\n\n\n    def add_to_apt_pkgs(self, *pkg: str):\n        \"\"\"\n        Helper for adding to the apt packages\n        \"\"\"\n        self.apt_pkgs.extend(pkg)\n\n    def run_apt_install(self):\n        \"\"\"\n        Helper for running apt install\n        \"\"\"\n        if not self.apt_pkgs: return\n        _pkgs = ' '.join(list(set(self.apt_pkgs)))\n        echo(f\"Installing Apt Packages: {COLOR.BLUE}{_pkgs}{COLOR.END}\")\n        os.system(f\"apt-get update &amp;&amp; apt-get -yq install --no-install-recommends {_pkgs}\")\n\n    def get_apt_pkg_requirements(self):\n        \"\"\"\n        Helper for getting the apt package requirements\n        \"\"\"\n        for ref in self.enabled_builds:\n            if service_pkgs := self.get_apt_packages(ref):\n                echo(f'{COLOR.BLUE}[{ref}]{COLOR.END} Adding {COLOR.BOLD}{ref}{COLOR.END} requirements\\n\\n - {COLOR.BOLD}{service_pkgs}{COLOR.END}\\n')\n                self.add_to_apt_pkgs(*service_pkgs)\n        self.save()\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.builds","title":"<code>builds</code>  <code>property</code>","text":"<p>Returns the build references</p>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.enabled_builds","title":"<code>enabled_builds</code>  <code>property</code>","text":"<p>Returns the enabled build services</p>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.installers","title":"<code>installers</code>  <code>property</code>","text":"<p>Returns the custom installers</p>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.commands","title":"<code>commands</code>  <code>property</code>","text":"<p>Returns the custom commands</p>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.stage","title":"<code>stage</code>  <code>property</code> <code>writable</code>","text":"<p>Returns the stage</p>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.apt_pkgs","title":"<code>apt_pkgs</code>  <code>property</code>","text":"<p>Returns the apt packages</p>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.validate_refs","title":"<code>validate_refs()</code>","text":"<p>Validate the build references</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>@model_validator(mode = 'after')\ndef validate_refs(self):\n    \"\"\"\n    Validate the build references\n    \"\"\"\n    if self.extra.get('validated'): return\n    for ref in self.refs:\n        if ref.enabled is None:\n            ref.enabled = ref.name in self.enabled_refs\n\n    if ENABLE_DEFAULT_INSTALLERS:\n        existing = [c.name for c in self.custom_installers]\n        default_installers = CustomInstaller.load_defaults()\n        for installer in default_installers:\n            if installer.name not in existing:\n                self.custom_installers.append(installer)\n\n    self.extra['validated'] = True\n    return self\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.show_env","title":"<code>show_env(step)</code>","text":"<p>Show the environment</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def show_env(self, step: str):\n    \"\"\"\n    Show the environment\n    \"\"\"\n    echo(f\"Starting Step: {COLOR.GREEN}{step}{COLOR.END}\\n\")\n    echo(f\"[Enabled Builds]: {COLOR.BLUE}{self.enabled_builds}{COLOR.END}\")\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.load","title":"<code>load(path=None)</code>  <code>classmethod</code>","text":"<p>Load the build config</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>@classmethod\ndef load(cls, path: Optional[Path] = None) -&gt; 'BuilderConfig':\n    \"\"\"\n    Load the build config\n    \"\"\"\n    if path is None:\n        path = BUILD_CONFIG_PATH if BUILD_CONFIG_PATH.exists() else DEFAULT_CONFIG_PATH\n    return cls.model_validate(yaml.safe_load(path.read_text()))\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.save","title":"<code>save()</code>","text":"<p>Save the build config</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def save(self):\n    \"\"\"\n    Save the build config\n    \"\"\"\n    BUILD_CONFIG_PATH.write_text(yaml.dump(self.model_dump(), default_flow_style = False))\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.update_config","title":"<code>update_config(path=None, **config)</code>","text":"<p>Update the build config</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def update_config(self, path: Optional[Path] = None, **config: Any):\n    \"\"\"\n    Update the build config\n    \"\"\"\n    data = self.model_dump()\n    if path: \n        update_data = yaml.safe_load(path.read_text())\n        data.update(update_data)\n    if config: data.update(config)\n    BUILD_CONFIG_PATH.write_text(yaml.dump(data, default_flow_style = False))\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.get_apt_packages","title":"<code>get_apt_packages(ref)</code>","text":"<p>Helper for getting the apt packages for a given ref name</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def get_apt_packages(self, ref: str) -&gt; List[str]:\n    \"\"\"\n    Helper for getting the apt packages for a given ref name\n    \"\"\"\n    pkg_dir = PKGS_PATH\n    if ref not in self.builds: return []\n    for alias in self.builds[ref].refs:\n        pkg_file = pkg_dir.joinpath(f'{alias}.txt')\n        if pkg_file.exists():\n            return parse_text_file(pkg_file)\n    return []\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.get_pip_requirements","title":"<code>get_pip_requirements(ref)</code>","text":"<p>Helper for getting the pip requirements file for a given ref name</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def get_pip_requirements(self, ref: str) -&gt; Optional[str]:\n    \"\"\"\n    Helper for getting the pip requirements file for a given ref name\n    \"\"\"\n    pkg_dir = REQUIREMENTS_PATH.joinpath(ref)\n    if ref not in self.builds: return None\n    for alias in self.builds[ref].refs:\n        req_file = pkg_dir.joinpath(f'{alias}.txt')\n        if req_file.exists():\n            req_file.write_text(req_file.read_text().replace('GITHUB_TOKEN', GITHUB_TOKEN))\n            return req_file.as_posix()\n        req_file = pkg_dir.joinpath(f'requirements.{alias}.txt')\n        if req_file.exists():\n            return req_file.as_posix()\n    return None\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.add_to_apt_pkgs","title":"<code>add_to_apt_pkgs(*pkg)</code>","text":"<p>Helper for adding to the apt packages</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def add_to_apt_pkgs(self, *pkg: str):\n    \"\"\"\n    Helper for adding to the apt packages\n    \"\"\"\n    self.apt_pkgs.extend(pkg)\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.run_apt_install","title":"<code>run_apt_install()</code>","text":"<p>Helper for running apt install</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def run_apt_install(self):\n    \"\"\"\n    Helper for running apt install\n    \"\"\"\n    if not self.apt_pkgs: return\n    _pkgs = ' '.join(list(set(self.apt_pkgs)))\n    echo(f\"Installing Apt Packages: {COLOR.BLUE}{_pkgs}{COLOR.END}\")\n    os.system(f\"apt-get update &amp;&amp; apt-get -yq install --no-install-recommends {_pkgs}\")\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.builder.BuilderConfig.get_apt_pkg_requirements","title":"<code>get_apt_pkg_requirements()</code>","text":"<p>Helper for getting the apt package requirements</p> Source code in <code>src/lzl/cmd/builder.py</code> <pre><code>def get_apt_pkg_requirements(self):\n    \"\"\"\n    Helper for getting the apt package requirements\n    \"\"\"\n    for ref in self.enabled_builds:\n        if service_pkgs := self.get_apt_packages(ref):\n            echo(f'{COLOR.BLUE}[{ref}]{COLOR.END} Adding {COLOR.BOLD}{ref}{COLOR.END} requirements\\n\\n - {COLOR.BOLD}{service_pkgs}{COLOR.END}\\n')\n            self.add_to_apt_pkgs(*service_pkgs)\n    self.save()\n</code></pre>"},{"location":"api/lzl/cmd/#environment-variables","title":"Environment Variables","text":""},{"location":"api/lzl/cmd/#lzl.cmd.envvars","title":"<code>lzl.cmd.envvars</code>","text":""},{"location":"api/lzl/cmd/#static-files","title":"Static Files","text":""},{"location":"api/lzl/cmd/#lzl.cmd.static","title":"<code>lzl.cmd.static</code>","text":""},{"location":"api/lzl/cmd/#lzl.cmd.static.COLOR","title":"<code>COLOR</code>","text":"<p>Color Constants</p> Source code in <code>src/lzl/cmd/static.py</code> <pre><code>class COLOR:\n    \"\"\"\n    Color Constants\n    \"\"\"\n    RED = '\\033[91m'\n    GREEN = '\\033[92m'\n    YELLOW = '\\033[93m'\n    BLUE = '\\033[94m'\n    PURPLE = '\\033[95m'\n    CYAN = '\\033[96m'\n    WHITE = '\\033[97m'\n    BOLD = '\\033[1m'\n    UNDERLINE = '\\033[4m'\n    END = '\\033[0m'\n</code></pre>"},{"location":"api/lzl/cmd/#utilities","title":"Utilities","text":""},{"location":"api/lzl/cmd/#lzl.cmd.utils","title":"<code>lzl.cmd.utils</code>","text":""},{"location":"api/lzl/cmd/#lzl.cmd.utils.build_aliases","title":"<code>build_aliases(name, additional_names=None)</code>","text":"<p>Create the aliases for a given service name</p> Source code in <code>src/lzl/cmd/utils.py</code> <pre><code>def build_aliases(name: str, additional_names: Optional[List[str]] = None) -&gt; List[str]:\n    \"\"\"\n    Create the aliases for a given service name\n    \"\"\"\n    aliases = [name]\n    if '.' not in name:\n        if '-' in name: aliases.append(name.replace('-', '.'))\n        elif '_' in name: aliases.append(name.replace('_', '.'))\n    if '-' not in name:\n        if '.' in name: aliases.append(name.replace('.', '-'))\n        elif '_' in name: aliases.append(name.replace('_', '-'))\n    if '_' not in name:\n        if '.' in name: aliases.append(name.replace('.', '_'))\n        elif '-' in name: aliases.append(name.replace('-', '_'))\n    if additional_names: aliases.extend(additional_names)\n    return list(set(aliases))\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.utils.add_to_env","title":"<code>add_to_env(envvar, envval, envpath='~/.bashrc')</code>","text":"<p>Helper for adding to the environment variable</p> Source code in <code>src/lzl/cmd/utils.py</code> <pre><code>def add_to_env(\n    envvar: str,\n    envval: Any,\n    envpath: Optional[str] = '~/.bashrc',\n):\n    \"\"\"\n    Helper for adding to the environment variable\n    \"\"\"\n    envval = str(envval)\n    if ' ' in envval: envval = f'\"{envval}\"'\n    os.system(f\"echo 'export {envvar}={envval}' &gt;&gt; {envpath}\")\n    os.environ[envvar] = envval\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.utils.parse_text_file","title":"<code>parse_text_file(path)</code>","text":"<p>Parses a text file</p> Source code in <code>src/lzl/cmd/utils.py</code> <pre><code>def parse_text_file(path: Path) -&gt; List[str]:\n    \"\"\"\n    Parses a text file\n    \"\"\"\n    text_lines = path.read_text().split('\\n')\n    return [line.strip() for line in text_lines if ('#' not in line[:5] and line.strip())]\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.utils.echo","title":"<code>echo(message)</code>","text":"<p>Helper for printing a message</p> Source code in <code>src/lzl/cmd/utils.py</code> <pre><code>def echo(message: str):\n    \"\"\" \n    Helper for printing a message\n    \"\"\"\n    typer.echo(message, color = True)\n</code></pre>"},{"location":"api/lzl/cmd/#lzl.cmd.utils.run_cmd","title":"<code>run_cmd(cmdstr)</code>","text":"<p>Helper for running a command</p> Source code in <code>src/lzl/cmd/utils.py</code> <pre><code>def run_cmd(cmdstr: str):\n    \"\"\"\n    Helper for running a command\n    \"\"\"\n    try:\n        data = subprocess.check_output(cmdstr, shell=True, text=True, stderr=subprocess.PIPE, stdin=subprocess.PIPE)\n        if data[-1:] == '\\n': data = data[:-1]\n        echo(data)\n\n    except subprocess.CalledProcessError as e:\n        echo(f'{COLOR.RED}Failed to run command: {cmdstr}{COLOR.END}')\n        echo(f'{COLOR.RED}Error: {e.stderr}{COLOR.END}')\n        raise e\n</code></pre>"},{"location":"api/lzl/db/","title":"lzl.db - Database Utilities","text":"<p>The <code>lzl.db</code> module provides database adapters, configuration helpers, and backend registries.</p>"},{"location":"api/lzl/db/#configuration","title":"Configuration","text":""},{"location":"api/lzl/db/#lzl.db.configs","title":"<code>lzl.db.configs</code>","text":""},{"location":"api/lzl/db/#backends","title":"Backends","text":""},{"location":"api/lzl/db/#lzl.db.backends","title":"<code>lzl.db.backends</code>","text":""},{"location":"api/lzl/db/#postgres","title":"Postgres","text":""},{"location":"api/lzl/db/#lzl.db.postgres","title":"<code>lzl.db.postgres</code>","text":""},{"location":"api/lzl/db/#sqlite","title":"SQLite","text":""},{"location":"api/lzl/db/#lzl.db.sqlite","title":"<code>lzl.db.sqlite</code>","text":""},{"location":"api/lzl/ext/","title":"lzl.ext - Extensions","text":"<p>The <code>lzl.ext</code> module provides integrations with third-party frameworks and libraries.</p>"},{"location":"api/lzl/ext/#fastapi","title":"FastAPI","text":""},{"location":"api/lzl/ext/#utilities","title":"Utilities","text":""},{"location":"api/lzl/ext/#lzl.ext.fast.utils","title":"<code>lzl.ext.fast.utils</code>","text":""},{"location":"api/lzl/ext/#middlewares","title":"Middlewares","text":""},{"location":"api/lzl/ext/#lzl.ext.fast.middlewares","title":"<code>lzl.ext.fast.middlewares</code>","text":"<p>FastAPI Extensions: Middlewares</p>"},{"location":"api/lzl/ext/#temporal","title":"Temporal","text":""},{"location":"api/lzl/ext/#client","title":"Client","text":""},{"location":"api/lzl/ext/#lzl.ext.temporal.client","title":"<code>lzl.ext.temporal.client</code>","text":""},{"location":"api/lzl/ext/#lzl.ext.temporal.client.TemporalClient","title":"<code>TemporalClient</code>","text":"<p>               Bases: <code>Client</code></p> Source code in <code>src/lzl/ext/temporal/client.py</code> <pre><code>class TemporalClient(Client):\n\n\n    # @staticmethod\n    @classmethod\n    async def connect(\n        cls: t.Type['TemporalClient'],\n        target_host: t.Optional[str] = None,\n        namespace: t.Optional[str] = None,\n        api_key: t.Optional[str] = None,\n        data_converter: t.Optional['DataConverter'] = None,\n        interceptors: t.Sequence['Interceptor'] = [],\n        default_workflow_query_reject_condition: t.Optional[\n            'QueryRejectCondition'\n        ] = None,\n        tls: t.Union[bool, 'TLSConfig'] = False,\n        retry_config: t.Optional['RetryConfig'] = None,\n        keep_alive_config: t.Optional['KeepAliveConfig'] = KeepAliveConfig.default,\n        rpc_metadata: t.Mapping[str, str] = {},\n        identity: t.Optional[str] = None,\n        lazy: bool = False,\n        runtime: t.Optional['Runtime'] = None,\n        http_connect_proxy_config: t.Optional['HttpConnectProxyConfig'] = None,\n        default_task_queue: t.Optional[str] = None,\n        config: t.Optional['TemporalSettings'] = None,\n        **kwargs,\n    ) -&gt; TemporalClient:  # sourcery skip: default-mutable-arg\n        \"\"\"Connect to a Temporal server.\n\n        Args:\n            target_host: ``host:port`` for the Temporal server. For local\n                development, this is often \"localhost:7233\".\n            namespace: Namespace to use for client calls.\n            api_key: API key for Temporal. This becomes the \"Authorization\"\n                HTTP header with \"Bearer \" prepended. This is only set if RPC\n                metadata doesn't already have an \"authorization\" key.\n            data_converter: Data converter to use for all data conversions\n                to/from payloads.\n            interceptors: Set of interceptors that are chained together to allow\n                intercepting of client calls. The earlier interceptors wrap the\n                later ones.\n\n                Any interceptors that also implement\n                :py:class:`temporalio.worker.Interceptor` will be used as worker\n                interceptors too so they should not be given when creating a\n                worker.\n            default_workflow_query_reject_condition: The default rejection\n                condition for workflow queries if not set during query. See\n                :py:meth:`WorkflowHandle.query` for details on the rejection\n                condition.\n            tls: If false, the default, do not use TLS. If true, use system\n                default TLS configuration. If TLS configuration present, that\n                TLS configuration will be used.\n            retry_config: Retry configuration for direct service calls (when\n                opted in) or all high-level calls made by this client (which all\n                opt-in to retries by default). If unset, a default retry\n                configuration is used.\n            keep_alive_config: Keep-alive configuration for the client\n                connection. Default is to check every 30s and kill the\n                connection if a response doesn't come back in 15s. Can be set to\n                ``None`` to disable.\n            rpc_metadata: Headers to use for all calls to the server. Keys here\n                can be overriden by per-call RPC metadata keys.\n            identity: Identity for this client. If unset, a default is created\n                based on the version of the SDK.\n            lazy: If true, the client will not connect until the first call is\n                attempted or a worker is created with it. Lazy clients cannot be\n                used for workers.\n            runtime: The runtime for this client, or the default if unset.\n            http_connect_proxy_config: Configuration for HTTP CONNECT proxy.\n            default_task_queue: The default task queue to use for this client.\n            config: The configuration for this client.\n        \"\"\"\n        if config is None:\n            from lzl.ext.temporal.configs import get_temporal_settings\n            config = get_temporal_settings()\n\n        if not target_host: target_host = config.host\n        # print('target_host: ', target_host)\n        if not namespace and config.namespace: namespace = config.namespace\n        if not api_key and config.api_key: api_key = config.api_key\n        if not default_task_queue and config.default_task_queue: default_task_queue = config.default_task_queue\n        if not tls and config.tls is not None: tls = config.tls\n        if not identity and config.identity: identity = config.identity\n        if not lazy and config.lazy is not None: lazy = config.lazy\n        if data_converter is None: data_converter = config.data_converter\n\n        from temporalio.service import ServiceClient, ConnectConfig\n        connect_config = ConnectConfig(\n            target_host=target_host,\n            api_key=api_key,\n            tls=tls,\n            retry_config=retry_config,\n            keep_alive_config=keep_alive_config,\n            rpc_metadata=rpc_metadata,\n            identity=identity or \"\",\n            lazy=lazy,\n            runtime=runtime,\n            http_connect_proxy_config=http_connect_proxy_config,\n        )\n        new = cls(\n            await ServiceClient.connect(connect_config),\n            namespace=namespace,\n            data_converter=data_converter,\n            interceptors=interceptors,\n            default_workflow_query_reject_condition=default_workflow_query_reject_condition,\n        )\n        new._postinit_config_(config = config, **kwargs)\n        return new\n\n    def _postinit_config_(self, config: t.Optional['TemporalSettings'] = None, **kwargs) -&gt; None:\n        \"\"\"\n        Some post-init config\n        \"\"\"\n        if config is None:\n            from lzl.ext.temporal.configs import get_temporal_settings\n            config = get_temporal_settings()\n        self.tmprl_config = config\n        self.tmprl_registry = self.tmprl_config.registry\n        self._extra: t.Dict[str, t.Any] = {}\n        self.tmprl_registry.register_client(self)\n        # self.tmprl_registry.clients[self.namespace] = self\n        # self.tmprl_registry.client = self\n\n    async def run_worker(\n        self,\n        worker: 'Worker',\n        event: asyncio.Event,\n        **kwargs,\n    ):\n        \"\"\"\n        Runs a Temporal Worker\n        \"\"\"\n        from lzo.utils import Timer\n        ts = Timer(format_short = 1)\n        extra = f'|g|NS|e|: `{self.namespace}`' if self.namespace else ''\n        if worker.task_queue: extra += f', |g|TQ|e|: `{worker.task_queue}`'\n        extra = f' ({extra.strip()})' if extra else ''\n        logger.info(f'Starting Temporal Worker{extra}', colored = True)\n        await worker.run()\n        try:\n            await event.wait()\n        finally:\n            logger.info(f'Shutting Down Temporal Worker. (|g|TTL|e|: {ts.total_s})', prefix = worker.task_queue, colored = True)\n\n    # def run_worker(\n    #     self,\n    #     worker: 'Worker',\n    #     event: t.Optional[asyncio.Event] = None,\n    #     **kwargs,\n    # ):\n    #     \"\"\"\n    #     Runs a Temporal Worker\n    #     \"\"\"\n    #     if event is None: event = asyncio.Event()\n    #     loop = asyncio.get_running_loop()\n    #     try:\n\n    #         loop.run_until_complete(self._run_worker(worker, event, **kwargs))\n    #     except Exception as e:\n    #         logger.error(f'Error Running Temporal Worker: {e}')\n    #         raise e\n    #     finally:\n    #         event.set()\n    #         loop.run_until_complete(loop.shutdown_asyncgens())\n    if t.TYPE_CHECKING:\n        def get_workflow_handle(\n            self,\n            workflow_id: str,\n            *,\n            run_id: t.Optional[str] = None,\n            first_execution_run_id: t.Optional[str] = None,\n            result_type: t.Optional[t.Type] = None,\n        ) -&gt; patches.WorkflowHandle[t.Any, t.Any]:\n            \"\"\"Get a workflow handle to an existing workflow by its ID.\n\n            Args:\n                workflow_id: Workflow ID to get a handle to.\n                run_id: Run ID that will be used for all calls.\n                first_execution_run_id: First execution run ID used for cancellation\n                    and termination.\n                result_type: The result type to deserialize into if known.\n\n            Returns:\n                The workflow handle.\n            \"\"\"\n            ...\n\n\n\n\n    if not t.TYPE_CHECKING:\n        # async def start_workflow(\n        #     self,\n        #     workflow: t.Callable[\n        #         t.Concatenate['SelfType', 'MultiParamSpec'], t.Awaitable['ReturnType']\n        #     ],\n        #     arg: t.Any, \n        #     *,\n        #     args: t.Sequence[t.Any] = [], \n        #     id: str,\n        #     task_queue: t.Optional[str] = None,\n        #     **kwargs,\n        # ):\n        #     if task_queue is None and self._tconf.default_task_queue: task_queue = self._tconf.default_task_queue\n        #     return await super().start_workflow(workflow, arg, args = args, task_queue = task_queue, id = id, **kwargs)\n\n        async def execute_workflow(\n            self,\n            workflow: 'MethodAsyncSingleParam[SelfType, ParamType, ReturnType]',\n            arg: t.Any, \n            *,\n            args: t.Sequence[t.Any] = [], \n            id: str,\n            task_queue: t.Optional[str] = None,\n            **kwargs,\n        ):\n            if task_queue is None and self.tmprl_config.default_task_queue: task_queue = self.tmprl_config.default_task_queue\n            return await super().execute_workflow(workflow, arg, args = args,  task_queue = task_queue, id = id, **kwargs)\n</code></pre>"},{"location":"api/lzl/ext/#lzl.ext.temporal.client.TemporalClient.connect","title":"<code>connect(target_host=None, namespace=None, api_key=None, data_converter=None, interceptors=[], default_workflow_query_reject_condition=None, tls=False, retry_config=None, keep_alive_config=KeepAliveConfig.default, rpc_metadata={}, identity=None, lazy=False, runtime=None, http_connect_proxy_config=None, default_task_queue=None, config=None, **kwargs)</code>  <code>async</code> <code>classmethod</code>","text":"<p>Connect to a Temporal server.</p> <p>Parameters:</p> Name Type Description Default <code>target_host</code> <code>Optional[str]</code> <p><code>host:port</code> for the Temporal server. For local development, this is often \"localhost:7233\".</p> <code>None</code> <code>namespace</code> <code>Optional[str]</code> <p>Namespace to use for client calls.</p> <code>None</code> <code>api_key</code> <code>Optional[str]</code> <p>API key for Temporal. This becomes the \"Authorization\" HTTP header with \"Bearer \" prepended. This is only set if RPC metadata doesn't already have an \"authorization\" key.</p> <code>None</code> <code>data_converter</code> <code>Optional['DataConverter']</code> <p>Data converter to use for all data conversions to/from payloads.</p> <code>None</code> <code>interceptors</code> <code>Sequence['Interceptor']</code> <p>Set of interceptors that are chained together to allow intercepting of client calls. The earlier interceptors wrap the later ones.</p> <p>Any interceptors that also implement :py:class:<code>temporalio.worker.Interceptor</code> will be used as worker interceptors too so they should not be given when creating a worker.</p> <code>[]</code> <code>default_workflow_query_reject_condition</code> <code>Optional['QueryRejectCondition']</code> <p>The default rejection condition for workflow queries if not set during query. See :py:meth:<code>WorkflowHandle.query</code> for details on the rejection condition.</p> <code>None</code> <code>tls</code> <code>Union[bool, 'TLSConfig']</code> <p>If false, the default, do not use TLS. If true, use system default TLS configuration. If TLS configuration present, that TLS configuration will be used.</p> <code>False</code> <code>retry_config</code> <code>Optional['RetryConfig']</code> <p>Retry configuration for direct service calls (when opted in) or all high-level calls made by this client (which all opt-in to retries by default). If unset, a default retry configuration is used.</p> <code>None</code> <code>keep_alive_config</code> <code>Optional['KeepAliveConfig']</code> <p>Keep-alive configuration for the client connection. Default is to check every 30s and kill the connection if a response doesn't come back in 15s. Can be set to <code>None</code> to disable.</p> <code>default</code> <code>rpc_metadata</code> <code>Mapping[str, str]</code> <p>Headers to use for all calls to the server. Keys here can be overriden by per-call RPC metadata keys.</p> <code>{}</code> <code>identity</code> <code>Optional[str]</code> <p>Identity for this client. If unset, a default is created based on the version of the SDK.</p> <code>None</code> <code>lazy</code> <code>bool</code> <p>If true, the client will not connect until the first call is attempted or a worker is created with it. Lazy clients cannot be used for workers.</p> <code>False</code> <code>runtime</code> <code>Optional['Runtime']</code> <p>The runtime for this client, or the default if unset.</p> <code>None</code> <code>http_connect_proxy_config</code> <code>Optional['HttpConnectProxyConfig']</code> <p>Configuration for HTTP CONNECT proxy.</p> <code>None</code> <code>default_task_queue</code> <code>Optional[str]</code> <p>The default task queue to use for this client.</p> <code>None</code> <code>config</code> <code>Optional['TemporalSettings']</code> <p>The configuration for this client.</p> <code>None</code> Source code in <code>src/lzl/ext/temporal/client.py</code> <pre><code>@classmethod\nasync def connect(\n    cls: t.Type['TemporalClient'],\n    target_host: t.Optional[str] = None,\n    namespace: t.Optional[str] = None,\n    api_key: t.Optional[str] = None,\n    data_converter: t.Optional['DataConverter'] = None,\n    interceptors: t.Sequence['Interceptor'] = [],\n    default_workflow_query_reject_condition: t.Optional[\n        'QueryRejectCondition'\n    ] = None,\n    tls: t.Union[bool, 'TLSConfig'] = False,\n    retry_config: t.Optional['RetryConfig'] = None,\n    keep_alive_config: t.Optional['KeepAliveConfig'] = KeepAliveConfig.default,\n    rpc_metadata: t.Mapping[str, str] = {},\n    identity: t.Optional[str] = None,\n    lazy: bool = False,\n    runtime: t.Optional['Runtime'] = None,\n    http_connect_proxy_config: t.Optional['HttpConnectProxyConfig'] = None,\n    default_task_queue: t.Optional[str] = None,\n    config: t.Optional['TemporalSettings'] = None,\n    **kwargs,\n) -&gt; TemporalClient:  # sourcery skip: default-mutable-arg\n    \"\"\"Connect to a Temporal server.\n\n    Args:\n        target_host: ``host:port`` for the Temporal server. For local\n            development, this is often \"localhost:7233\".\n        namespace: Namespace to use for client calls.\n        api_key: API key for Temporal. This becomes the \"Authorization\"\n            HTTP header with \"Bearer \" prepended. This is only set if RPC\n            metadata doesn't already have an \"authorization\" key.\n        data_converter: Data converter to use for all data conversions\n            to/from payloads.\n        interceptors: Set of interceptors that are chained together to allow\n            intercepting of client calls. The earlier interceptors wrap the\n            later ones.\n\n            Any interceptors that also implement\n            :py:class:`temporalio.worker.Interceptor` will be used as worker\n            interceptors too so they should not be given when creating a\n            worker.\n        default_workflow_query_reject_condition: The default rejection\n            condition for workflow queries if not set during query. See\n            :py:meth:`WorkflowHandle.query` for details on the rejection\n            condition.\n        tls: If false, the default, do not use TLS. If true, use system\n            default TLS configuration. If TLS configuration present, that\n            TLS configuration will be used.\n        retry_config: Retry configuration for direct service calls (when\n            opted in) or all high-level calls made by this client (which all\n            opt-in to retries by default). If unset, a default retry\n            configuration is used.\n        keep_alive_config: Keep-alive configuration for the client\n            connection. Default is to check every 30s and kill the\n            connection if a response doesn't come back in 15s. Can be set to\n            ``None`` to disable.\n        rpc_metadata: Headers to use for all calls to the server. Keys here\n            can be overriden by per-call RPC metadata keys.\n        identity: Identity for this client. If unset, a default is created\n            based on the version of the SDK.\n        lazy: If true, the client will not connect until the first call is\n            attempted or a worker is created with it. Lazy clients cannot be\n            used for workers.\n        runtime: The runtime for this client, or the default if unset.\n        http_connect_proxy_config: Configuration for HTTP CONNECT proxy.\n        default_task_queue: The default task queue to use for this client.\n        config: The configuration for this client.\n    \"\"\"\n    if config is None:\n        from lzl.ext.temporal.configs import get_temporal_settings\n        config = get_temporal_settings()\n\n    if not target_host: target_host = config.host\n    # print('target_host: ', target_host)\n    if not namespace and config.namespace: namespace = config.namespace\n    if not api_key and config.api_key: api_key = config.api_key\n    if not default_task_queue and config.default_task_queue: default_task_queue = config.default_task_queue\n    if not tls and config.tls is not None: tls = config.tls\n    if not identity and config.identity: identity = config.identity\n    if not lazy and config.lazy is not None: lazy = config.lazy\n    if data_converter is None: data_converter = config.data_converter\n\n    from temporalio.service import ServiceClient, ConnectConfig\n    connect_config = ConnectConfig(\n        target_host=target_host,\n        api_key=api_key,\n        tls=tls,\n        retry_config=retry_config,\n        keep_alive_config=keep_alive_config,\n        rpc_metadata=rpc_metadata,\n        identity=identity or \"\",\n        lazy=lazy,\n        runtime=runtime,\n        http_connect_proxy_config=http_connect_proxy_config,\n    )\n    new = cls(\n        await ServiceClient.connect(connect_config),\n        namespace=namespace,\n        data_converter=data_converter,\n        interceptors=interceptors,\n        default_workflow_query_reject_condition=default_workflow_query_reject_condition,\n    )\n    new._postinit_config_(config = config, **kwargs)\n    return new\n</code></pre>"},{"location":"api/lzl/ext/#lzl.ext.temporal.client.TemporalClient.run_worker","title":"<code>run_worker(worker, event, **kwargs)</code>  <code>async</code>","text":"<p>Runs a Temporal Worker</p> Source code in <code>src/lzl/ext/temporal/client.py</code> <pre><code>async def run_worker(\n    self,\n    worker: 'Worker',\n    event: asyncio.Event,\n    **kwargs,\n):\n    \"\"\"\n    Runs a Temporal Worker\n    \"\"\"\n    from lzo.utils import Timer\n    ts = Timer(format_short = 1)\n    extra = f'|g|NS|e|: `{self.namespace}`' if self.namespace else ''\n    if worker.task_queue: extra += f', |g|TQ|e|: `{worker.task_queue}`'\n    extra = f' ({extra.strip()})' if extra else ''\n    logger.info(f'Starting Temporal Worker{extra}', colored = True)\n    await worker.run()\n    try:\n        await event.wait()\n    finally:\n        logger.info(f'Shutting Down Temporal Worker. (|g|TTL|e|: {ts.total_s})', prefix = worker.task_queue, colored = True)\n</code></pre>"},{"location":"api/lzl/ext/#lzl.ext.temporal.client.TemporalClient.get_workflow_handle","title":"<code>get_workflow_handle(workflow_id, *, run_id=None, first_execution_run_id=None, result_type=None)</code>","text":"<p>Get a workflow handle to an existing workflow by its ID.</p> <p>Parameters:</p> Name Type Description Default <code>workflow_id</code> <code>str</code> <p>Workflow ID to get a handle to.</p> required <code>run_id</code> <code>Optional[str]</code> <p>Run ID that will be used for all calls.</p> <code>None</code> <code>first_execution_run_id</code> <code>Optional[str]</code> <p>First execution run ID used for cancellation and termination.</p> <code>None</code> <code>result_type</code> <code>Optional[Type]</code> <p>The result type to deserialize into if known.</p> <code>None</code> <p>Returns:</p> Type Description <code>WorkflowHandle[Any, Any]</code> <p>The workflow handle.</p> Source code in <code>src/lzl/ext/temporal/client.py</code> <pre><code>def get_workflow_handle(\n    self,\n    workflow_id: str,\n    *,\n    run_id: t.Optional[str] = None,\n    first_execution_run_id: t.Optional[str] = None,\n    result_type: t.Optional[t.Type] = None,\n) -&gt; patches.WorkflowHandle[t.Any, t.Any]:\n    \"\"\"Get a workflow handle to an existing workflow by its ID.\n\n    Args:\n        workflow_id: Workflow ID to get a handle to.\n        run_id: Run ID that will be used for all calls.\n        first_execution_run_id: First execution run ID used for cancellation\n            and termination.\n        result_type: The result type to deserialize into if known.\n\n    Returns:\n        The workflow handle.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/lzl/ext/#utils","title":"Utils","text":""},{"location":"api/lzl/ext/#lzl.ext.temporal.utils","title":"<code>lzl.ext.temporal.utils</code>","text":""},{"location":"api/lzl/ext/#jinja2","title":"Jinja2","text":""},{"location":"api/lzl/ext/#lzl.ext.jinja","title":"<code>lzl.ext.jinja</code>","text":"<p>Jinja2 Extension</p> <ul> <li>Unifies the Jinja2 Environment handle both sync and async</li> </ul>"},{"location":"api/lzl/ext/#server","title":"Server","text":""},{"location":"api/lzl/ext/#lzl.ext.server","title":"<code>lzl.ext.server</code>","text":"<p>Server Extensions</p>"},{"location":"api/lzl/io/","title":"lzl.io - I/O Operations","text":"<p>The <code>lzl.io</code> module provides comprehensive input/output operations including serialization, persistence, file handling, and data compression.</p>"},{"location":"api/lzl/io/#modules","title":"Modules","text":""},{"location":"api/lzl/io/#lzl.io","title":"<code>lzl.io</code>","text":""},{"location":"api/lzl/io/#lzl.io.File","title":"<code>File</code>","text":"<p>               Bases: <code>Generic[FileLikeT]</code></p> <p>Factory that instantiates concrete path objects for various backends.</p>"},{"location":"api/lzl/io/#lzl.io.File.get_dir","title":"<code>get_dir(path)</code>  <code>classmethod</code>","text":"<p>Return the parent directory for the provided path-like value.</p>"},{"location":"api/lzl/io/#lzl.io.File.get_object_size","title":"<code>get_object_size(obj)</code>  <code>classmethod</code>","text":"<p>Return a convenience wrapper reporting object size in bytes.</p>"},{"location":"api/lzl/io/#lzl.io.File.register_loader","title":"<code>register_loader(ext, loader, overwrite=None)</code>  <code>classmethod</code>","text":"<p>Register a loader callback for the given file extension.</p> <p>Parameters:</p> Name Type Description Default <code>ext</code> <code>str</code> <p>Extension (<code>.json</code>, <code>.csv</code>\u2026) to register the loader against.  A leading dot is optional.</p> required <code>loader</code> <code>Union[Callable[['FileLike'], None], Awaitable['FileLike', None]]</code> <p>Callable that receives the resolved :class:<code>FileLike</code> instance and should return either a processed value or coroutine.</p> required <code>overwrite</code> <code>Optional[bool]</code> <p>When <code>True</code> the loader replaces any existing registration for <code>ext</code>.</p> <code>None</code>"},{"location":"api/lzl/io/#serialization","title":"Serialization","text":"<p>The serialization submodule provides various serializers for common data formats:</p>"},{"location":"api/lzl/io/#lzl.io.ser","title":"<code>lzl.io.ser</code>","text":""},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer","title":"<code>BaseSerializer</code>","text":"<p>               Bases: <code>ABC</code></p> <p>The Base Serializer Class</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>class BaseSerializer(abc.ABC):\n    \"\"\"\n    The Base Serializer Class\n    \"\"\"\n    name: Optional[str] = None\n    encoding: Optional[str] = None\n    binary: Optional[bool] = False\n    compressor: Optional['CompressionT'] = None\n    previous_compressor: Optional['CompressionT'] = None\n    enforce_string_value: Optional[bool] = False\n    enforce_byte_value: Optional[bool] = False\n    ser_mode: Optional[SerMode] = 'auto'\n    _is_ser: Optional[bool] = True\n\n    def __init__(\n        self,\n        compression: Optional[str] = None,\n        compression_level: Optional[int] = None,\n        encoding: Optional[str] = None,\n        raise_errors: bool = False,\n        enforce_string_value: Optional[bool] = None,\n        enforce_byte_value: Optional[bool] = None,\n        ser_mode: Optional[SerMode] = None,\n        deprecated_compression: Optional[str] = None,\n        schema_map: Optional[Dict[str, str]] = None,\n        **kwargs,\n    ):\n        \"\"\"\n        Initializes the serializer\n        \"\"\"\n        if compression is not None or compression_level is not None:\n            from ..compression import get_compression\n            compression_kwargs = kwargs.pop(\"compression_kwargs\", None)\n            decompression_kwargs = kwargs.pop(\"decompression_kwargs\", None)\n            deprecated_compression = kwargs.pop(\"deprecated_compression\", None)\n            self.compressor = get_compression(\n                compression, \n                compression_level = compression_level, \n                compression_kwargs = compression_kwargs, \n                decompression_kwargs = decompression_kwargs,\n            )\n            if deprecated_compression is not None and deprecated_compression != compression:\n                self.previous_compressor = get_compression(deprecated_compression)\n        if encoding is not None: self.encoding = encoding\n        if enforce_string_value is not None: self.enforce_string_value = enforce_string_value\n        if enforce_byte_value is not None: self.enforce_byte_value = enforce_byte_value\n        if ser_mode is not None: self.ser_mode = ser_mode\n        self.schema_map = schema_map\n        self.raise_errors = raise_errors\n        self._kwargs = kwargs\n\n    @property\n    def compression_enabled(self) -&gt; bool:\n        \"\"\"\n        Returns if compression is enabled\n        \"\"\"\n        return self.compressor is not None\n\n    @property\n    def compression_level(self) -&gt; Optional[int]:\n        \"\"\"\n        Returns the compression level\n        \"\"\"\n        return self.compressor.compression_level if self.compressor is not None else None\n\n    @property\n    def is_binary(self) -&gt; bool:\n        \"\"\"\n        Returns whether the serializer output is binary\n        \"\"\"\n        if self.enforce_byte_value: return True\n        if self.enforce_string_value: return False\n        return self.binary or self.compression_enabled\n\n    @staticmethod\n    def fetch_object_classname(obj: ObjectValue, is_type: Optional[bool] = False) -&gt; str:\n        \"\"\"\n        Fetches the object classname\n        \"\"\"\n        return get_object_classname(obj, is_type = is_type)\n\n    @staticmethod\n    def fetch_object_class(name: str) -&gt; Type[SerializableObject]:\n        \"\"\"\n        Gets the object class\n        \"\"\"\n        return get_object_class(name)\n\n    @staticmethod\n    def register_schema(schema: Dict[str, str]) -&gt; None:\n        \"\"\"\n        Registers the schema\n        \"\"\"\n        register_schema_mapping(schema)\n\n    @staticmethod\n    def register_object_class(obj: SerializableObject, is_type: Optional[bool] = False) -&gt; str:\n        \"\"\"\n        Registers the object class\n        \"\"\"\n        return register_object_class(obj, is_type = is_type)\n\n    def create_hash(self, obj: ObjectValue) -&gt; str:\n        \"\"\"\n        Creates a hash for the object\n        \"\"\"\n        return create_object_hash(obj)\n\n    async def acreate_hash(self, obj: ObjectValue) -&gt; str:\n        \"\"\"\n        Creates a hash for the object asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.create_hash, obj)\n\n    def coerce_output_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Coerces the output value\n        \"\"\"\n        if self.enforce_string_value and isinstance(value, bytes): value = value.decode(self.encoding)\n        elif self.enforce_byte_value and not isinstance(value, bytes): value = value.encode(self.encoding)\n        return value\n\n    def compress_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Compresses the value\n        \"\"\"\n        if self.compression_enabled:\n            if isinstance(value, str): value = value.encode(self.encoding)\n            return self.coerce_output_value(self.compressor.compress(value))\n        return self.coerce_output_value(value)\n\n    def deprecated_decompress_value(self, value: Union[str, bytes], **kwargs) -&gt; Optional[Union[str, bytes]]:\n        \"\"\"\n        Attempts to decompress the value using the deprecated compressor\n        \"\"\"\n        e = None\n        attempt_msg = f\"{self.name}\"\n        if self.previous_compressor is not None:\n            try:\n                return self.previous_compressor.decompress(value)\n            except Exception as e:\n                attempt_msg += f\"-&gt; {self.previous_compressor.name}\"\n        try:\n            return zlib.decompress(value)\n        except Exception as e:\n            attempt_msg += \" -&gt; ZLib\"\n            logger.trace(f'[{attempt_msg}] Error in Decompression: {str(value)[:100]}', e)\n            if self.raise_errors: raise e\n            return None\n\n\n    def decompress_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n        # sourcery skip: extract-duplicate-method\n        \"\"\"\n        Decompresses the value\n        \"\"\"\n        if not self.compression_enabled: return value\n        try:\n            value = self.compressor.decompress(value, **kwargs)\n        except Exception as e:\n            if self.previous_compressor is not None:\n                value = self.deprecated_decompress_value(value, **kwargs)\n        if value is not None and not self.binary: value = value.decode(self.encoding)\n        return value\n\n    def encode_value(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Encodes the value\n        \"\"\"\n        raise NotImplementedError\n\n    def encode(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Encodes the value\n        \"\"\"\n        return self.compress_value(self.encode_value(value, **kwargs))\n\n    async def aencode(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Encodes the value asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.encode, value, **kwargs)\n\n    def decode_value(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value\n        \"\"\"\n        raise NotImplementedError\n\n    def decode(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value\n        \"\"\"\n        return self.decode_value(self.decompress_value(value, **kwargs), **kwargs)\n\n    async def adecode(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.decode, value, **kwargs)\n\n    def dumps(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        # sourcery skip: class-extract-method\n        \"\"\"\n        Dumps the value\n        \"\"\"\n        try:\n            return self.encode(value, **kwargs)\n        except Exception as e:\n            logger.trace(f'[{self.name}] Error in Encoding: {str(value)[:500]}', e)\n            if self.raise_errors: raise e\n            return None\n\n    async def adumps(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Dumps the value asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.dumps, value, **kwargs)\n\n    def loads(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Loads the value\n        \"\"\"\n        try:\n            return self.decode(value, **kwargs)\n        except Exception as e:\n            logger.trace(f'[{self.name}] Error in Decoding: {str(value)[:500]}', e)\n            if self.raise_errors: raise e\n            return None\n\n    async def aloads(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Loads the value asynchronously\n        \"\"\"\n        return await ThreadPool.run_async(self.loads, value, **kwargs)\n\n\n    def serialize_obj(self, obj: SerializableObject, mode: Optional[SerMode] = None, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Serializes the object\n        \"\"\"\n        mode = mode or self.ser_mode\n        return serialize_object(obj, mode = mode, **kwargs)\n\n    def deserialize_obj(\n        self, \n        obj: Union[Dict[str, Any], List[Dict[str, Any]], Any], \n        schema_map: Optional[Dict[str, str]] = None, \n        allow_failed_import: Optional[bool] = False,\n        **kwargs\n    ) -&gt; SerializableObject:\n        \"\"\"\n        Deserializes the object\n        \"\"\"\n        return deserialize_object(obj, schema_map = schema_map or self.schema_map, allow_failed_import = allow_failed_import, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.compression_enabled","title":"<code>compression_enabled</code>  <code>property</code>","text":"<p>Returns if compression is enabled</p>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.compression_level","title":"<code>compression_level</code>  <code>property</code>","text":"<p>Returns the compression level</p>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.is_binary","title":"<code>is_binary</code>  <code>property</code>","text":"<p>Returns whether the serializer output is binary</p>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.fetch_object_classname","title":"<code>fetch_object_classname(obj, is_type=False)</code>  <code>staticmethod</code>","text":"<p>Fetches the object classname</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>@staticmethod\ndef fetch_object_classname(obj: ObjectValue, is_type: Optional[bool] = False) -&gt; str:\n    \"\"\"\n    Fetches the object classname\n    \"\"\"\n    return get_object_classname(obj, is_type = is_type)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.fetch_object_class","title":"<code>fetch_object_class(name)</code>  <code>staticmethod</code>","text":"<p>Gets the object class</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>@staticmethod\ndef fetch_object_class(name: str) -&gt; Type[SerializableObject]:\n    \"\"\"\n    Gets the object class\n    \"\"\"\n    return get_object_class(name)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.register_schema","title":"<code>register_schema(schema)</code>  <code>staticmethod</code>","text":"<p>Registers the schema</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>@staticmethod\ndef register_schema(schema: Dict[str, str]) -&gt; None:\n    \"\"\"\n    Registers the schema\n    \"\"\"\n    register_schema_mapping(schema)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.register_object_class","title":"<code>register_object_class(obj, is_type=False)</code>  <code>staticmethod</code>","text":"<p>Registers the object class</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>@staticmethod\ndef register_object_class(obj: SerializableObject, is_type: Optional[bool] = False) -&gt; str:\n    \"\"\"\n    Registers the object class\n    \"\"\"\n    return register_object_class(obj, is_type = is_type)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.create_hash","title":"<code>create_hash(obj)</code>","text":"<p>Creates a hash for the object</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def create_hash(self, obj: ObjectValue) -&gt; str:\n    \"\"\"\n    Creates a hash for the object\n    \"\"\"\n    return create_object_hash(obj)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.acreate_hash","title":"<code>acreate_hash(obj)</code>  <code>async</code>","text":"<p>Creates a hash for the object asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def acreate_hash(self, obj: ObjectValue) -&gt; str:\n    \"\"\"\n    Creates a hash for the object asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.create_hash, obj)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.coerce_output_value","title":"<code>coerce_output_value(value, **kwargs)</code>","text":"<p>Coerces the output value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def coerce_output_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Coerces the output value\n    \"\"\"\n    if self.enforce_string_value and isinstance(value, bytes): value = value.decode(self.encoding)\n    elif self.enforce_byte_value and not isinstance(value, bytes): value = value.encode(self.encoding)\n    return value\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.compress_value","title":"<code>compress_value(value, **kwargs)</code>","text":"<p>Compresses the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def compress_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Compresses the value\n    \"\"\"\n    if self.compression_enabled:\n        if isinstance(value, str): value = value.encode(self.encoding)\n        return self.coerce_output_value(self.compressor.compress(value))\n    return self.coerce_output_value(value)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.deprecated_decompress_value","title":"<code>deprecated_decompress_value(value, **kwargs)</code>","text":"<p>Attempts to decompress the value using the deprecated compressor</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def deprecated_decompress_value(self, value: Union[str, bytes], **kwargs) -&gt; Optional[Union[str, bytes]]:\n    \"\"\"\n    Attempts to decompress the value using the deprecated compressor\n    \"\"\"\n    e = None\n    attempt_msg = f\"{self.name}\"\n    if self.previous_compressor is not None:\n        try:\n            return self.previous_compressor.decompress(value)\n        except Exception as e:\n            attempt_msg += f\"-&gt; {self.previous_compressor.name}\"\n    try:\n        return zlib.decompress(value)\n    except Exception as e:\n        attempt_msg += \" -&gt; ZLib\"\n        logger.trace(f'[{attempt_msg}] Error in Decompression: {str(value)[:100]}', e)\n        if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.decompress_value","title":"<code>decompress_value(value, **kwargs)</code>","text":"<p>Decompresses the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def decompress_value(self, value: Union[str, bytes], **kwargs) -&gt; Union[str, bytes]:\n    # sourcery skip: extract-duplicate-method\n    \"\"\"\n    Decompresses the value\n    \"\"\"\n    if not self.compression_enabled: return value\n    try:\n        value = self.compressor.decompress(value, **kwargs)\n    except Exception as e:\n        if self.previous_compressor is not None:\n            value = self.deprecated_decompress_value(value, **kwargs)\n    if value is not None and not self.binary: value = value.decode(self.encoding)\n    return value\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.encode_value","title":"<code>encode_value(value, **kwargs)</code>","text":"<p>Encodes the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def encode_value(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Encodes the value\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.encode","title":"<code>encode(value, **kwargs)</code>","text":"<p>Encodes the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def encode(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Encodes the value\n    \"\"\"\n    return self.compress_value(self.encode_value(value, **kwargs))\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.aencode","title":"<code>aencode(value, **kwargs)</code>  <code>async</code>","text":"<p>Encodes the value asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def aencode(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Encodes the value asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.encode, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.decode_value","title":"<code>decode_value(value, **kwargs)</code>","text":"<p>Decodes the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def decode_value(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value\n    \"\"\"\n    raise NotImplementedError\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.decode","title":"<code>decode(value, **kwargs)</code>","text":"<p>Decodes the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def decode(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value\n    \"\"\"\n    return self.decode_value(self.decompress_value(value, **kwargs), **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.adecode","title":"<code>adecode(value, **kwargs)</code>  <code>async</code>","text":"<p>Decodes the value asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def adecode(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.decode, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.dumps","title":"<code>dumps(value, **kwargs)</code>","text":"<p>Dumps the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def dumps(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    # sourcery skip: class-extract-method\n    \"\"\"\n    Dumps the value\n    \"\"\"\n    try:\n        return self.encode(value, **kwargs)\n    except Exception as e:\n        logger.trace(f'[{self.name}] Error in Encoding: {str(value)[:500]}', e)\n        if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.adumps","title":"<code>adumps(value, **kwargs)</code>  <code>async</code>","text":"<p>Dumps the value asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def adumps(self, value: ObjectValue, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Dumps the value asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.dumps, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.loads","title":"<code>loads(value, **kwargs)</code>","text":"<p>Loads the value</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def loads(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Loads the value\n    \"\"\"\n    try:\n        return self.decode(value, **kwargs)\n    except Exception as e:\n        logger.trace(f'[{self.name}] Error in Decoding: {str(value)[:500]}', e)\n        if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.aloads","title":"<code>aloads(value, **kwargs)</code>  <code>async</code>","text":"<p>Loads the value asynchronously</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>async def aloads(self, value: Union[str, bytes], **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Loads the value asynchronously\n    \"\"\"\n    return await ThreadPool.run_async(self.loads, value, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.serialize_obj","title":"<code>serialize_obj(obj, mode=None, **kwargs)</code>","text":"<p>Serializes the object</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def serialize_obj(self, obj: SerializableObject, mode: Optional[SerMode] = None, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Serializes the object\n    \"\"\"\n    mode = mode or self.ser_mode\n    return serialize_object(obj, mode = mode, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.BaseSerializer.deserialize_obj","title":"<code>deserialize_obj(obj, schema_map=None, allow_failed_import=False, **kwargs)</code>","text":"<p>Deserializes the object</p> Source code in <code>src/lzl/io/ser/base.py</code> <pre><code>def deserialize_obj(\n    self, \n    obj: Union[Dict[str, Any], List[Dict[str, Any]], Any], \n    schema_map: Optional[Dict[str, str]] = None, \n    allow_failed_import: Optional[bool] = False,\n    **kwargs\n) -&gt; SerializableObject:\n    \"\"\"\n    Deserializes the object\n    \"\"\"\n    return deserialize_object(obj, schema_map = schema_map or self.schema_map, allow_failed_import = allow_failed_import, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer","title":"<code>JsonSerializer</code>","text":"<p>               Bases: <code>BaseSerializer</code></p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>class JsonSerializer(BaseSerializer):\n\n    name: Optional[str] = \"json\"\n    encoding: Optional[str] = \"utf-8\"\n    jsonlib: JsonLibT = default_json\n    disable_object_serialization: Optional[bool] = False\n    disable_nested_values: Optional[bool] = None\n    allow_failed_import: Optional[bool] = False\n\n    def __init__(\n        self, \n        jsonlib: Optional[Union[str, Any]] = None,\n        compression: Optional[str] = None,\n        compression_level: int | None = None, \n        encoding: str | None = None, \n        serialization_obj: Optional[Type[BaseModel]] = None,\n        serialization_obj_kwargs: Optional[Dict[str, Any]] = None,\n        disable_object_serialization: Optional[bool] = None,\n        disable_nested_values: Optional[bool] = None,\n        verbosity: Optional[int] = None,\n        **kwargs\n    ):\n        super().__init__(compression = compression, compression_level = compression_level, encoding = encoding, **kwargs)\n        self.serialization_obj = serialization_obj\n        self.serialization_obj_kwargs = serialization_obj_kwargs or {}\n        self.serialization_schemas: Dict[str, Type[BaseModel]] = {}\n        if disable_object_serialization is not None:\n            self.disable_object_serialization = disable_object_serialization\n        if disable_nested_values is not None:\n            self.disable_nested_values = disable_nested_values\n        if jsonlib is not None:\n            if isinstance(jsonlib, str):\n                jsonlib = lazy_import(jsonlib, is_module=True)\n            assert hasattr(jsonlib, \"dumps\") and hasattr(jsonlib, \"loads\"), f\"Invalid JSON Library: {jsonlib}\"\n            self.jsonlib = jsonlib\n        self.verbosity = verbosity\n        self.jsonlib_name: str = self.jsonlib.__name__\n        if 'bindings' in self.jsonlib_name.lower():\n            self.jsonlib_name = self.jsonlib_name.rsplit('_', 1)[-1]\n\n    @classmethod\n    def set_default_lib(cls, lib: Union[str, JsonLibT, ModuleType]) -&gt; None:\n        \"\"\"\n        Sets the default JSON library\n        \"\"\"\n        global default_json\n        if isinstance(lib, str):\n            lib = lazy_import(lib, is_module=True)\n        assert hasattr(lib, \"dumps\") and hasattr(lib, \"loads\"), f\"Invalid JSON Library: {lib}\"\n        cls.jsonlib = lib\n        default_json = lib\n\n    @property\n    def _is_verbose(self) -&gt; bool:\n        \"\"\"\n        Returns whether the serializer is verbose\n        \"\"\"\n        return self.verbosity is None or self.verbosity &gt;= 1\n\n    @property\n    def _is_silenced(self) -&gt; bool:\n        \"\"\"\n        Returns whether the serializer is verbose\n        \"\"\"\n        return self.verbosity and self.verbosity &lt; 0\n\n    def serialize_obj(self, obj: SerializableObject, mode: Optional[SerMode] = None, **kwargs) -&gt; Union[str, bytes]:\n        \"\"\"\n        Serializes the object\n        \"\"\"\n        mode = mode or self.ser_mode\n        if 'disable_nested_values' not in kwargs and self.disable_nested_values is not None:\n            kwargs['disable_nested_values'] = self.disable_nested_values\n        if 'disable_object_serialization' in kwargs:\n            disable_object_serialization = kwargs.pop('disable_object_serialization')\n            mode = 'raw' if disable_object_serialization else mode\n        elif self.disable_object_serialization:\n            mode = 'raw'\n        return serialize_object(obj, mode = mode, **kwargs)\n\n    def encode_value(self, value: Union[Any, SchemaType], mode: Optional[SerMode] = None, **kwargs) -&gt; str:\n        \"\"\"\n        Encode the value with the JSON Library\n        \"\"\"\n        try:\n            value_dict = self.serialize_obj(value, mode = mode, **kwargs, **self.serialization_obj_kwargs)\n            encoded = self.jsonlib.dumps(value_dict, **kwargs)\n            return self.coerce_output_value(encoded)\n\n        except Exception as e:\n            if not self._is_silenced: logger.trace(f'Error Encoding Value: |r|({type(value)})|e| {str(value)[:1000]}', e, colored = True)\n        try:\n            encoded = self.jsonlib.dumps(value, **kwargs)\n            return self.coerce_output_value(encoded)\n        except Exception as e:\n            if not self._is_silenced: logger.info(f'Error Encoding Value: |r|({type(value)}) {e}|e| {str(value)[:1000]}', colored = True, prefix = self.jsonlib_name)\n            if self.raise_errors: raise e\n        return None\n\n\n    def decode(self, value: Union[str, bytes], schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value\n        \"\"\"\n        try:\n            decompressed_value = self.decompress_value(value, **kwargs)\n            if decompressed_value is not None:\n                value = decompressed_value\n        except Exception as e:\n            if not self._is_silenced: logger.info(f'Error Decompressing Value: |r|({type(value)}) {e}|e| {str(value)[:100]}', colored = True, prefix = self.jsonlib_name)\n            if raise_errors or self.raise_errors: raise ValueError(f\"[{self.name}] Error in Decompression: {str(value)[:100]}\") from e\n            # return self.decode_value(value, **kwargs)\n        return self.decode_value(value, schema_map = schema_map, raise_errors = raise_errors, **kwargs)\n\n\n    def decode_value(self, value: str, schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n        \"\"\"\n        Decode the value with the JSON Library\n        \"\"\"\n        if value is None: return None\n        if isinstance(value, (str, bytes)):\n            try:\n                # value = self.check_encoded_value(value)\n                value = self.jsonlib.loads(value, **kwargs)\n            except Exception as e:\n                if isinstance(value, str) and 'Exception' in value or 'Traceback (most recent call last):' in value:\n                    return value\n                str_value = str(value)\n                if not schema_map: str_value = str_value[:1000]\n                if self._is_verbose: logger.info(f'Error JSON Decoding Value: |r|({type(value)}) {e}|e| {str_value}', colored = True, prefix = self.jsonlib_name)\n                if raise_errors or self.raise_errors: raise e\n        try:\n            return self.deserialize_obj(value, schema_map = schema_map, allow_failed_import = self.allow_failed_import)\n        except Exception as e:\n            str_value = str(value)\n            if not schema_map: str_value = str_value[:1000]\n            if not self._is_silenced: logger.trace(f'Error Deserializing Object: ({type(value)}) {str_value}', e, prefix = self.jsonlib_name)\n            if raise_errors or self.raise_errors: raise e\n        return None\n\n\n    async def adecode(self, value: Union[str, bytes], schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; ObjectValue:\n        \"\"\"\n        Decodes the value asynchronously\n        \"\"\"\n        return await ThreadPool.arun(self.decode, value, schema_map = schema_map, raise_errors = raise_errors, **kwargs)\n\n\n    if TYPE_CHECKING:\n        def dumps(\n            self, \n            value: ObjectValue, \n            skipkeys: bool = False, \n            ensure_ascii: bool = True, \n            check_circular: bool = True,\n            allow_nan: bool = True, \n            cls: Optional[Any] = None, \n            indent: Optional[int] = None, \n            separators: Optional[Tuple[str, str]] = None,\n            default: Optional[Any] = None, \n            sort_keys: bool = False,\n            mode: Optional[SerMode] = None,\n            **kwargs\n        ) -&gt; Union[str, bytes]:\n            \"\"\"Serialize ``obj`` to a JSON formatted ``str``.\n\n            If ``skipkeys`` is true then ``dict`` keys that are not basic types\n            (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n            instead of raising a ``TypeError``.\n\n            If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n            characters if they appear in strings contained in ``obj``. Otherwise, all\n            such characters are escaped in JSON strings.\n\n            If ``check_circular`` is false, then the circular reference check\n            for container types will be skipped and a circular reference will\n            result in an ``RecursionError`` (or worse).\n\n            If ``allow_nan`` is false, then it will be a ``ValueError`` to\n            serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n            strict compliance of the JSON specification, instead of using the\n            JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n\n            If ``indent`` is a non-negative integer, then JSON array elements and\n            object members will be pretty-printed with that indent level. An indent\n            level of 0 will only insert newlines. ``None`` is the most compact\n            representation.\n\n            If specified, ``separators`` should be an ``(item_separator, key_separator)``\n            tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n            ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n            you should specify ``(',', ':')`` to eliminate whitespace.\n\n            ``default(obj)`` is a function that should return a serializable version\n            of obj or raise TypeError. The default simply raises TypeError.\n\n            If *sort_keys* is true (default: ``False``), then the output of\n            dictionaries will be sorted by key.\n\n            To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n            ``.default()`` method to serialize additional types), specify it with\n            the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n\n            \"\"\"\n            ...\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.set_default_lib","title":"<code>set_default_lib(lib)</code>  <code>classmethod</code>","text":"<p>Sets the default JSON library</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>@classmethod\ndef set_default_lib(cls, lib: Union[str, JsonLibT, ModuleType]) -&gt; None:\n    \"\"\"\n    Sets the default JSON library\n    \"\"\"\n    global default_json\n    if isinstance(lib, str):\n        lib = lazy_import(lib, is_module=True)\n    assert hasattr(lib, \"dumps\") and hasattr(lib, \"loads\"), f\"Invalid JSON Library: {lib}\"\n    cls.jsonlib = lib\n    default_json = lib\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.serialize_obj","title":"<code>serialize_obj(obj, mode=None, **kwargs)</code>","text":"<p>Serializes the object</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def serialize_obj(self, obj: SerializableObject, mode: Optional[SerMode] = None, **kwargs) -&gt; Union[str, bytes]:\n    \"\"\"\n    Serializes the object\n    \"\"\"\n    mode = mode or self.ser_mode\n    if 'disable_nested_values' not in kwargs and self.disable_nested_values is not None:\n        kwargs['disable_nested_values'] = self.disable_nested_values\n    if 'disable_object_serialization' in kwargs:\n        disable_object_serialization = kwargs.pop('disable_object_serialization')\n        mode = 'raw' if disable_object_serialization else mode\n    elif self.disable_object_serialization:\n        mode = 'raw'\n    return serialize_object(obj, mode = mode, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.encode_value","title":"<code>encode_value(value, mode=None, **kwargs)</code>","text":"<p>Encode the value with the JSON Library</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def encode_value(self, value: Union[Any, SchemaType], mode: Optional[SerMode] = None, **kwargs) -&gt; str:\n    \"\"\"\n    Encode the value with the JSON Library\n    \"\"\"\n    try:\n        value_dict = self.serialize_obj(value, mode = mode, **kwargs, **self.serialization_obj_kwargs)\n        encoded = self.jsonlib.dumps(value_dict, **kwargs)\n        return self.coerce_output_value(encoded)\n\n    except Exception as e:\n        if not self._is_silenced: logger.trace(f'Error Encoding Value: |r|({type(value)})|e| {str(value)[:1000]}', e, colored = True)\n    try:\n        encoded = self.jsonlib.dumps(value, **kwargs)\n        return self.coerce_output_value(encoded)\n    except Exception as e:\n        if not self._is_silenced: logger.info(f'Error Encoding Value: |r|({type(value)}) {e}|e| {str(value)[:1000]}', colored = True, prefix = self.jsonlib_name)\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.decode","title":"<code>decode(value, schema_map=None, raise_errors=None, **kwargs)</code>","text":"<p>Decodes the value</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def decode(self, value: Union[str, bytes], schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value\n    \"\"\"\n    try:\n        decompressed_value = self.decompress_value(value, **kwargs)\n        if decompressed_value is not None:\n            value = decompressed_value\n    except Exception as e:\n        if not self._is_silenced: logger.info(f'Error Decompressing Value: |r|({type(value)}) {e}|e| {str(value)[:100]}', colored = True, prefix = self.jsonlib_name)\n        if raise_errors or self.raise_errors: raise ValueError(f\"[{self.name}] Error in Decompression: {str(value)[:100]}\") from e\n        # return self.decode_value(value, **kwargs)\n    return self.decode_value(value, schema_map = schema_map, raise_errors = raise_errors, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.decode_value","title":"<code>decode_value(value, schema_map=None, raise_errors=None, **kwargs)</code>","text":"<p>Decode the value with the JSON Library</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def decode_value(self, value: str, schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n    \"\"\"\n    Decode the value with the JSON Library\n    \"\"\"\n    if value is None: return None\n    if isinstance(value, (str, bytes)):\n        try:\n            # value = self.check_encoded_value(value)\n            value = self.jsonlib.loads(value, **kwargs)\n        except Exception as e:\n            if isinstance(value, str) and 'Exception' in value or 'Traceback (most recent call last):' in value:\n                return value\n            str_value = str(value)\n            if not schema_map: str_value = str_value[:1000]\n            if self._is_verbose: logger.info(f'Error JSON Decoding Value: |r|({type(value)}) {e}|e| {str_value}', colored = True, prefix = self.jsonlib_name)\n            if raise_errors or self.raise_errors: raise e\n    try:\n        return self.deserialize_obj(value, schema_map = schema_map, allow_failed_import = self.allow_failed_import)\n    except Exception as e:\n        str_value = str(value)\n        if not schema_map: str_value = str_value[:1000]\n        if not self._is_silenced: logger.trace(f'Error Deserializing Object: ({type(value)}) {str_value}', e, prefix = self.jsonlib_name)\n        if raise_errors or self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.adecode","title":"<code>adecode(value, schema_map=None, raise_errors=None, **kwargs)</code>  <code>async</code>","text":"<p>Decodes the value asynchronously</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>async def adecode(self, value: Union[str, bytes], schema_map: Optional[Dict[str, str]] = None, raise_errors: Optional[bool] = None, **kwargs) -&gt; ObjectValue:\n    \"\"\"\n    Decodes the value asynchronously\n    \"\"\"\n    return await ThreadPool.arun(self.decode, value, schema_map = schema_map, raise_errors = raise_errors, **kwargs)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.JsonSerializer.dumps","title":"<code>dumps(value, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, cls=None, indent=None, separators=None, default=None, sort_keys=False, mode=None, **kwargs)</code>","text":"<p>Serialize <code>obj</code> to a JSON formatted <code>str</code>.</p> <p>If <code>skipkeys</code> is true then <code>dict</code> keys that are not basic types (<code>str</code>, <code>int</code>, <code>float</code>, <code>bool</code>, <code>None</code>) will be skipped instead of raising a <code>TypeError</code>.</p> <p>If <code>ensure_ascii</code> is false, then the return value can contain non-ASCII characters if they appear in strings contained in <code>obj</code>. Otherwise, all such characters are escaped in JSON strings.</p> <p>If <code>check_circular</code> is false, then the circular reference check for container types will be skipped and a circular reference will result in an <code>RecursionError</code> (or worse).</p> <p>If <code>allow_nan</code> is false, then it will be a <code>ValueError</code> to serialize out of range <code>float</code> values (<code>nan</code>, <code>inf</code>, <code>-inf</code>) in strict compliance of the JSON specification, instead of using the JavaScript equivalents (<code>NaN</code>, <code>Infinity</code>, <code>-Infinity</code>).</p> <p>If <code>indent</code> is a non-negative integer, then JSON array elements and object members will be pretty-printed with that indent level. An indent level of 0 will only insert newlines. <code>None</code> is the most compact representation.</p> <p>If specified, <code>separators</code> should be an <code>(item_separator, key_separator)</code> tuple.  The default is <code>(', ', ': ')</code> if indent is <code>None</code> and <code>(',', ': ')</code> otherwise.  To get the most compact JSON representation, you should specify <code>(',', ':')</code> to eliminate whitespace.</p> <p><code>default(obj)</code> is a function that should return a serializable version of obj or raise TypeError. The default simply raises TypeError.</p> <p>If sort_keys is true (default: <code>False</code>), then the output of dictionaries will be sorted by key.</p> <p>To use a custom <code>JSONEncoder</code> subclass (e.g. one that overrides the <code>.default()</code> method to serialize additional types), specify it with the <code>cls</code> kwarg; otherwise <code>JSONEncoder</code> is used.</p> Source code in <code>src/lzl/io/ser/_json.py</code> <pre><code>def dumps(\n    self, \n    value: ObjectValue, \n    skipkeys: bool = False, \n    ensure_ascii: bool = True, \n    check_circular: bool = True,\n    allow_nan: bool = True, \n    cls: Optional[Any] = None, \n    indent: Optional[int] = None, \n    separators: Optional[Tuple[str, str]] = None,\n    default: Optional[Any] = None, \n    sort_keys: bool = False,\n    mode: Optional[SerMode] = None,\n    **kwargs\n) -&gt; Union[str, bytes]:\n    \"\"\"Serialize ``obj`` to a JSON formatted ``str``.\n\n    If ``skipkeys`` is true then ``dict`` keys that are not basic types\n    (``str``, ``int``, ``float``, ``bool``, ``None``) will be skipped\n    instead of raising a ``TypeError``.\n\n    If ``ensure_ascii`` is false, then the return value can contain non-ASCII\n    characters if they appear in strings contained in ``obj``. Otherwise, all\n    such characters are escaped in JSON strings.\n\n    If ``check_circular`` is false, then the circular reference check\n    for container types will be skipped and a circular reference will\n    result in an ``RecursionError`` (or worse).\n\n    If ``allow_nan`` is false, then it will be a ``ValueError`` to\n    serialize out of range ``float`` values (``nan``, ``inf``, ``-inf``) in\n    strict compliance of the JSON specification, instead of using the\n    JavaScript equivalents (``NaN``, ``Infinity``, ``-Infinity``).\n\n    If ``indent`` is a non-negative integer, then JSON array elements and\n    object members will be pretty-printed with that indent level. An indent\n    level of 0 will only insert newlines. ``None`` is the most compact\n    representation.\n\n    If specified, ``separators`` should be an ``(item_separator, key_separator)``\n    tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and\n    ``(',', ': ')`` otherwise.  To get the most compact JSON representation,\n    you should specify ``(',', ':')`` to eliminate whitespace.\n\n    ``default(obj)`` is a function that should return a serializable version\n    of obj or raise TypeError. The default simply raises TypeError.\n\n    If *sort_keys* is true (default: ``False``), then the output of\n    dictionaries will be sorted by key.\n\n    To use a custom ``JSONEncoder`` subclass (e.g. one that overrides the\n    ``.default()`` method to serialize additional types), specify it with\n    the ``cls`` kwarg; otherwise ``JSONEncoder`` is used.\n\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.MsgPackSerializer","title":"<code>MsgPackSerializer</code>","text":"<p>               Bases: <code>BinaryBaseSerializer</code></p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>class MsgPackSerializer(BinaryBaseSerializer):\n    name: Optional[str] = \"msgpack\"\n    encoding: Optional[str] = \"utf-8\"\n    disable_object_serialization: Optional[bool] = False\n    jsonlib: JsonLibT = default_json\n    msgpacklib: MsgPackLibT = default_msgpack\n\n    def __init__(\n        self, \n        msgpacklib: Optional[Union[str, Any]] = None,\n        compression: Optional[str] = None,\n        compression_level: int | None = None, \n        encoding: str | None = None, \n        serialization_obj: Optional[Type[BaseModel]] = None,\n        serialization_obj_kwargs: Optional[Dict[str, Any]] = None,\n        disable_object_serialization: Optional[bool] = None,\n        jsonlib: Optional[Union[str, Any]] = None,\n        **kwargs\n    ):\n        if not default_msgpack:\n            raise ImportError(\"MsgPack Serializer is not available. Please install `msgpack`\")\n        super().__init__(compression = compression, compression_level = compression_level, encoding = encoding, **kwargs)\n        self.serialization_obj = serialization_obj\n        self.serialization_obj_kwargs = serialization_obj_kwargs or {}\n        self.serialization_schemas: Dict[str, Type[BaseModel]] = {}\n        if disable_object_serialization is not None:\n            self.disable_object_serialization = disable_object_serialization\n\n        if msgpacklib is not None:\n            if isinstance(msgpacklib, str):\n                msgpacklib = lazy_import(msgpacklib, is_module=True)\n            assert hasattr(msgpacklib, \"packb\") and hasattr(msgpacklib, \"unpackb\"), f\"Invalid MsgPack Library: {msgpacklib}\"\n            self.msgpacklib = msgpacklib\n        self.msgpacklib_name = self.msgpacklib.__name__\n        if jsonlib is not None:\n            if isinstance(jsonlib, str):\n                jsonlib = lazy_import(jsonlib, is_module=True)\n            assert hasattr(jsonlib, \"dumps\") and hasattr(jsonlib, \"loads\"), f\"Invalid JSON Library: {jsonlib}\"\n            self.jsonlib = jsonlib\n        self.jsonlib_name = self.jsonlib.__name__\n\n\n    @classmethod\n    def set_default_lib(cls, lib: Union[str, MsgPackLibT, ModuleType]) -&gt; None:\n        \"\"\"\n        Sets the default MsgPack library\n        \"\"\"\n        global default_msgpack\n        if isinstance(lib, str):\n            lib = lazy_import(lib, is_module=True)\n        assert hasattr(lib, \"packb\") and hasattr(lib, \"unpackb\"), f\"Invalid Msgpack Library: `{lib}`\"\n        cls.msgpacklib = lib\n        default_msgpack = lib\n\n    def default_serialization_hook(self, obj: ObjectValue):\n        \"\"\"\n        Default Serialization Hook\n        \"\"\"\n        if not isinstance(obj, BaseModel) and not hasattr(obj, 'model_dump'):\n            logger.info(f'Invalid Object Type: |r|{type(obj)}|e| {obj}', colored = True, prefix = \"msgpack\")\n            return obj\n\n        if self.disable_object_serialization: \n            return obj.model_dump_json(**self.serialization_obj_kwargs)\n\n        obj_class_name = self.fetch_object_classname(obj)\n        if obj_class_name not in self.serialization_schemas:\n            self.serialization_schemas[obj_class_name] = obj.__class__\n        data = obj.model_dump(mode = 'json', **self.serialization_obj_kwargs)\n        data['__class__'] = obj_class_name\n        return self.msgpacklib.ExtType(2, self.jsonlib.dumps(data).encode(self.encoding))\n\n    def default_deserialization_hook(self, code: int, data: Union[str, bytes]) -&gt; ObjectValue:\n        \"\"\"\n        Default Deserialization Hook\n        \"\"\"\n        if code != 2: return data\n        if isinstance(data, bytes): data = data.decode(self.encoding)\n        try:\n            data = self.jsonlib.loads(data)\n        except Exception as e:\n            logger.info(f'Error Decoding Value: |r|({type(data)}) {e}|e| {str(data)[:500]}', colored = True, prefix = \"msgpack\")\n            if self.raise_errors: raise e\n            return data\n        if not self.disable_object_serialization:\n            _class = data.pop('__class__', None)\n            if _class is not None:\n                if _class not in self.serialization_schemas:\n                    self.serialization_schemas[_class] = lazy_import(_class)\n                _class = self.serialization_schemas[_class]\n                return _class.model_validate(data, **self.serialization_obj_kwargs)\n        elif self.serialization_obj is not None:\n            return self.serialization_obj.model_validate(data, **self.serialization_obj_kwargs)\n        return data\n\n    def encode_value(self, value: Union[Any, SchemaType], **kwargs) -&gt; bytes:\n        \"\"\"\n        Encode the value with the Pickle Library\n        \"\"\"\n        if 'use_bin_type' not in kwargs: kwargs['use_bin_type'] = True\n        if 'default' not in kwargs: kwargs['default'] = self.default_serialization_hook\n        try:\n            return self.msgpacklib.packb(value, **kwargs)\n        except Exception as e:\n            logger.info(f'Error Encoding Value: |r|({type(value)}) {e}|e| {str(value)[:500]}', colored = True, prefix = \"msgpack\")\n            if self.raise_errors: raise e\n        return None\n\n    def decode_value(self, value: bytes, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n        \"\"\"\n        Decode the value with the Pickle Library\n        \"\"\"\n        try:\n            if 'raw' not in kwargs: kwargs['raw'] = False\n            if 'ext_hook' not in kwargs: kwargs['ext_hook'] = self.default_deserialization_hook\n            return self.msgpacklib.unpackb(value, **kwargs)\n        except Exception as e:\n            logger.info(f'Error Decoding Value: |r|({type(value)}) {e}|e| {str(value)[:500]}', colored = True, prefix = \"msgpack\")\n            if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.MsgPackSerializer.set_default_lib","title":"<code>set_default_lib(lib)</code>  <code>classmethod</code>","text":"<p>Sets the default MsgPack library</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>@classmethod\ndef set_default_lib(cls, lib: Union[str, MsgPackLibT, ModuleType]) -&gt; None:\n    \"\"\"\n    Sets the default MsgPack library\n    \"\"\"\n    global default_msgpack\n    if isinstance(lib, str):\n        lib = lazy_import(lib, is_module=True)\n    assert hasattr(lib, \"packb\") and hasattr(lib, \"unpackb\"), f\"Invalid Msgpack Library: `{lib}`\"\n    cls.msgpacklib = lib\n    default_msgpack = lib\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.MsgPackSerializer.default_serialization_hook","title":"<code>default_serialization_hook(obj)</code>","text":"<p>Default Serialization Hook</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>def default_serialization_hook(self, obj: ObjectValue):\n    \"\"\"\n    Default Serialization Hook\n    \"\"\"\n    if not isinstance(obj, BaseModel) and not hasattr(obj, 'model_dump'):\n        logger.info(f'Invalid Object Type: |r|{type(obj)}|e| {obj}', colored = True, prefix = \"msgpack\")\n        return obj\n\n    if self.disable_object_serialization: \n        return obj.model_dump_json(**self.serialization_obj_kwargs)\n\n    obj_class_name = self.fetch_object_classname(obj)\n    if obj_class_name not in self.serialization_schemas:\n        self.serialization_schemas[obj_class_name] = obj.__class__\n    data = obj.model_dump(mode = 'json', **self.serialization_obj_kwargs)\n    data['__class__'] = obj_class_name\n    return self.msgpacklib.ExtType(2, self.jsonlib.dumps(data).encode(self.encoding))\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.MsgPackSerializer.default_deserialization_hook","title":"<code>default_deserialization_hook(code, data)</code>","text":"<p>Default Deserialization Hook</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>def default_deserialization_hook(self, code: int, data: Union[str, bytes]) -&gt; ObjectValue:\n    \"\"\"\n    Default Deserialization Hook\n    \"\"\"\n    if code != 2: return data\n    if isinstance(data, bytes): data = data.decode(self.encoding)\n    try:\n        data = self.jsonlib.loads(data)\n    except Exception as e:\n        logger.info(f'Error Decoding Value: |r|({type(data)}) {e}|e| {str(data)[:500]}', colored = True, prefix = \"msgpack\")\n        if self.raise_errors: raise e\n        return data\n    if not self.disable_object_serialization:\n        _class = data.pop('__class__', None)\n        if _class is not None:\n            if _class not in self.serialization_schemas:\n                self.serialization_schemas[_class] = lazy_import(_class)\n            _class = self.serialization_schemas[_class]\n            return _class.model_validate(data, **self.serialization_obj_kwargs)\n    elif self.serialization_obj is not None:\n        return self.serialization_obj.model_validate(data, **self.serialization_obj_kwargs)\n    return data\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.MsgPackSerializer.encode_value","title":"<code>encode_value(value, **kwargs)</code>","text":"<p>Encode the value with the Pickle Library</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>def encode_value(self, value: Union[Any, SchemaType], **kwargs) -&gt; bytes:\n    \"\"\"\n    Encode the value with the Pickle Library\n    \"\"\"\n    if 'use_bin_type' not in kwargs: kwargs['use_bin_type'] = True\n    if 'default' not in kwargs: kwargs['default'] = self.default_serialization_hook\n    try:\n        return self.msgpacklib.packb(value, **kwargs)\n    except Exception as e:\n        logger.info(f'Error Encoding Value: |r|({type(value)}) {e}|e| {str(value)[:500]}', colored = True, prefix = \"msgpack\")\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.MsgPackSerializer.decode_value","title":"<code>decode_value(value, **kwargs)</code>","text":"<p>Decode the value with the Pickle Library</p> Source code in <code>src/lzl/io/ser/_msgpack.py</code> <pre><code>def decode_value(self, value: bytes, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n    \"\"\"\n    Decode the value with the Pickle Library\n    \"\"\"\n    try:\n        if 'raw' not in kwargs: kwargs['raw'] = False\n        if 'ext_hook' not in kwargs: kwargs['ext_hook'] = self.default_deserialization_hook\n        return self.msgpacklib.unpackb(value, **kwargs)\n    except Exception as e:\n        logger.info(f'Error Decoding Value: |r|({type(value)}) {e}|e| {str(value)[:500]}', colored = True, prefix = \"msgpack\")\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.PickleSerializer","title":"<code>PickleSerializer</code>","text":"<p>               Bases: <code>BinaryBaseSerializer</code></p> Source code in <code>src/lzl/io/ser/_pickle.py</code> <pre><code>class PickleSerializer(BinaryBaseSerializer):\n    name: Optional[str] = \"pickle\"\n    encoding: Optional[str] = \"utf-8\"\n    picklelib: PickleLibT = default_pickle\n\n    def __init__(\n        self, \n        picklelib: Optional[Union[str, Any]] = None,\n        compression: Optional[str] = None,\n        compression_level: int | None = None, \n        encoding: str | None = None, \n        **kwargs\n    ):\n        super().__init__(compression = compression, compression_level = compression_level, encoding = encoding, **kwargs)\n        if picklelib is not None:\n            if isinstance(picklelib, str):\n                picklelib = lazy_import(picklelib, is_module=True)\n            assert hasattr(picklelib, \"dumps\") and hasattr(picklelib, \"loads\"), f\"Invalid Pickle Library: {picklelib}\"\n            self.picklelib = picklelib\n        self.picklelib_name = self.picklelib.__name__\n\n    @classmethod\n    def set_default_lib(cls, lib: Union[str, PickleLibT, ModuleType]) -&gt; None:\n        \"\"\"\n        Sets the default Pickle library\n        \"\"\"\n        global default_pickle\n        if isinstance(lib, str):\n            lib = lazy_import(lib, is_module=True)\n        assert hasattr(lib, \"loads\") and hasattr(lib, \"dumps\"), f\"Invalid Pickle Library: `{lib}`\"\n        cls.picklelib = lib\n        default_pickle = lib\n\n    def encode_value(self, value: Union[Any, SchemaType], **kwargs) -&gt; bytes:\n        \"\"\"\n        Encode the value with the Pickle Library\n        \"\"\"\n        try:\n            return self.picklelib.dumps(value, **kwargs)\n        except Exception as e:\n            logger.trace(f'Error Encoding Object: ({type(value)}) {str(value)[:1000]}', e, prefix = self.picklelib_name)\n            if self.raise_errors: raise e\n        return None\n\n    def decode_value(self, value: bytes, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n        \"\"\"\n        Decode the value with the Pickle Library\n        \"\"\"\n        try:\n            if self.picklelib_name == 'cloudpickle':\n                if 'encoding' not in kwargs:\n                    kwargs['encoding'] = self.encoding\n                if 'fix_imports' not in kwargs:\n                    kwargs['fix_imports'] = False\n            return self.picklelib.loads(value, **kwargs)\n        except Exception as e:\n            logger.trace(f'Error Deserializing Object: ({type(value)}) {str(value)[:1000]}', e, prefix = self.picklelib_name)\n            if self.raise_errors: raise e\n        return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.PickleSerializer.set_default_lib","title":"<code>set_default_lib(lib)</code>  <code>classmethod</code>","text":"<p>Sets the default Pickle library</p> Source code in <code>src/lzl/io/ser/_pickle.py</code> <pre><code>@classmethod\ndef set_default_lib(cls, lib: Union[str, PickleLibT, ModuleType]) -&gt; None:\n    \"\"\"\n    Sets the default Pickle library\n    \"\"\"\n    global default_pickle\n    if isinstance(lib, str):\n        lib = lazy_import(lib, is_module=True)\n    assert hasattr(lib, \"loads\") and hasattr(lib, \"dumps\"), f\"Invalid Pickle Library: `{lib}`\"\n    cls.picklelib = lib\n    default_pickle = lib\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.PickleSerializer.encode_value","title":"<code>encode_value(value, **kwargs)</code>","text":"<p>Encode the value with the Pickle Library</p> Source code in <code>src/lzl/io/ser/_pickle.py</code> <pre><code>def encode_value(self, value: Union[Any, SchemaType], **kwargs) -&gt; bytes:\n    \"\"\"\n    Encode the value with the Pickle Library\n    \"\"\"\n    try:\n        return self.picklelib.dumps(value, **kwargs)\n    except Exception as e:\n        logger.trace(f'Error Encoding Object: ({type(value)}) {str(value)[:1000]}', e, prefix = self.picklelib_name)\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.PickleSerializer.decode_value","title":"<code>decode_value(value, **kwargs)</code>","text":"<p>Decode the value with the Pickle Library</p> Source code in <code>src/lzl/io/ser/_pickle.py</code> <pre><code>def decode_value(self, value: bytes, **kwargs) -&gt; Union[SchemaType, Dict, Any]:\n    \"\"\"\n    Decode the value with the Pickle Library\n    \"\"\"\n    try:\n        if self.picklelib_name == 'cloudpickle':\n            if 'encoding' not in kwargs:\n                kwargs['encoding'] = self.encoding\n            if 'fix_imports' not in kwargs:\n                kwargs['fix_imports'] = False\n        return self.picklelib.loads(value, **kwargs)\n    except Exception as e:\n        logger.trace(f'Error Deserializing Object: ({type(value)}) {str(value)[:1000]}', e, prefix = self.picklelib_name)\n        if self.raise_errors: raise e\n    return None\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.deserialize_object","title":"<code>deserialize_object(obj, schema_map=None, allow_failed_import=False)</code>","text":"<p>Deserialize an object</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>the object to deserialize</p> required Source code in <code>src/lzl/io/ser/utils.py</code> <pre><code>def deserialize_object(\n    obj: Union[Dict[str, Any], List[Dict[str, Any]], Any], \n    schema_map: Optional[Dict[str, str]] = None, \n    allow_failed_import: Optional[bool] = False\n) -&gt; SerializableObject:\n    # sourcery skip: extract-duplicate-method, low-code-quality\n    \"\"\"\n    Deserialize an object\n\n    Args:\n        obj: the object to deserialize\n    \"\"\"\n    if obj is None: return None\n    if isinstance(obj, (list, tuple)):\n        return [deserialize_object(item, schema_map = schema_map, allow_failed_import = allow_failed_import) for item in obj]\n\n    if isinstance(obj, dict):\n        if \"__type__\" not in obj:\n            return {key: deserialize_object(value, schema_map = schema_map, allow_failed_import = allow_failed_import) for key, value in obj.items()}\n\n        # obj_type = obj[\"__type__\"]\n        obj_type = obj.pop(\"__type__\")\n        if '__class__' in obj:\n            if schema_map is not None and obj['__class__'] in schema_map:\n                obj['__class__'] = schema_map[obj['__class__']]\n            elif obj['__class__'] in _alias_schema_mapping:\n                obj['__class__'] = _alias_schema_mapping[obj['__class__']]\n\n        obj_class_type = obj.pop('__class__', None)\n        if obj_type == \"type\":\n            return get_object_class(obj_class_type)\n\n        obj_value = obj[\"value\"] if len(obj) == 1 and \"value\" in obj else obj\n        if obj_type == \"pydantic\":\n            try:\n                obj_class = get_object_class(obj_class_type)\n                # for k,v in obj_value.items():\n                #     if not is_primitive(v):\n                #         obj_value[k] = deserialize_object(v)\n                if hasattr(obj_class, 'model_validate'):\n                    return obj_class.model_validate(obj_value, context = {'source': 'io', 'method': 'deserializer'})\n                return obj_class(**obj_value)\n            except ImportError as e:\n                if allow_failed_import:\n                    return deserialize_object(obj_value, schema_map = schema_map, allow_failed_import = allow_failed_import)\n                raise e\n\n        if obj_type == \"serializable\":\n            try:\n                obj_class = get_object_class(obj_class_type)\n                return obj_class(**obj_value)\n            except ImportError as e:\n                if allow_failed_import:\n                    return deserialize_object(obj_value, schema_map = schema_map, allow_failed_import = allow_failed_import)\n                raise e\n\n        if obj_type == \"numpy\" and np is not None:\n            # dtype = obj.get(\"__class__\")\n            dtype = obj_class_type\n            if dtype: dtype = dtype.replace(\"numpy.\", \"\")\n            return np.array(obj_value, dtype = dtype)\n\n        if obj_type == \"pickle\":\n            try:\n                obj_value = bytes.fromhex(obj_value)\n                return default_pickle.loads(obj_value)\n            except Exception as e:\n                raise TypeError(f\"Cannot deserialize object of type {obj_type}: {e}\") from e\n\n        if obj_type == \"datetime\":\n            return datetime.datetime.fromisoformat(obj_value)\n\n        if obj_type == \"timedelta\":\n            return datetime.timedelta(seconds=obj_value)\n\n        if obj_type == \"dataclass\":\n            # obj_class_type = obj[\"__class__\"]\n            # if schema_map is not None and obj_class_type in schema_map:\n            #     obj_class_type = schema_map[obj_class_type]\n\n            obj_class = get_object_class(obj_class_type)\n            return obj_class(**obj_value)\n\n        if obj_type == \"path\":\n            obj_class = get_object_class(obj_class_type)\n            return obj_class(obj_value)\n\n        if obj_type == \"enum\":\n            obj_class = get_object_class(obj_class_type)\n            return obj_class(obj_value)\n\n        if obj_type == \"uuid\":\n            return UUID(obj_value)\n\n        if obj_type == \"bytes\":\n            return bytes.fromhex(obj_value)\n\n        if obj_type == \"set\":\n            return set(obj_value)\n\n\n        if obj_type == \"tensor\":\n            return float(obj_value) if (isinstance(obj_value, (int, float)) or not np) else np.array(obj_value)\n\n        raise TypeError(f\"Cannot deserialize object of type {obj_type} - {obj_class_type} with value {obj_value}\")\n\n    if isinstance(obj, bytes):\n        # Try to deserialize with pickle\n        with contextlib.suppress(Exception):\n            return default_pickle.loads(obj)\n\n    return obj\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.get_object_class","title":"<code>get_object_class(name)</code>","text":"<p>Get the class of an object</p> Source code in <code>src/lzl/io/ser/utils.py</code> <pre><code>def get_object_class(name: str) -&gt; Type[SerializableObject]:\n    \"\"\"\n    Get the class of an object\n    \"\"\"\n    global serialization_class_registry\n    if name not in serialization_class_registry:\n        serialization_class_registry[name] = lazy_import(name)\n    return serialization_class_registry[name]\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.get_object_classname","title":"<code>get_object_classname(obj, is_type=False)</code>","text":"<p>Get the classname of an object</p> Source code in <code>src/lzl/io/ser/utils.py</code> <pre><code>def get_object_classname(obj: SerializableObject, is_type: Optional[bool] = False) -&gt; str:\n    \"\"\"\n    Get the classname of an object\n    \"\"\"\n    if is_type: return f'{obj.__module__}.{obj.__name__}'\n    return f\"{obj.__class__.__module__}.{obj.__class__.__name__}\"\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.register_schema_mapping","title":"<code>register_schema_mapping(schemas)</code>","text":"<p>Register the schema mapping</p> Source code in <code>src/lzl/io/ser/utils.py</code> <pre><code>def register_schema_mapping(schemas: Dict[str, str]):\n    \"\"\"\n    Register the schema mapping\n    \"\"\"\n    global _alias_schema_mapping\n    _alias_schema_mapping.update(schemas)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.serialize_object","title":"<code>serialize_object(obj, mode='auto', **kwargs)</code>","text":"<p>Helper to serialize an object</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>SerializableObject</code> <p>the object to serialize</p> required <p>Returns:</p> Type Description <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>the serialized object in dict</p> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>if not disable_nested_values:</p> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>{ \"type\": ..., \"value\": ...,</p> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>}</p> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>otherwise for JSON Objects:</p> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>{ \"type\": ..., ...,</p> <code>Union[Dict[str, Any], List[Dict[str, Any]], Any]</code> <p>}</p> Source code in <code>src/lzl/io/ser/utils.py</code> <pre><code>def serialize_object(\n    obj: SerializableObject,\n    mode: Optional[SerMode] = 'auto',\n    **kwargs\n) -&gt; Union[Dict[str, Any], List[Dict[str, Any]], Any]:\n    # sourcery skip: extract-duplicate-method\n    \"\"\"\n    Helper to serialize an object\n\n    Args:\n        obj: the object to serialize\n\n    Returns:\n        the serialized object in dict\n\n        if not disable_nested_values:\n        {\n            \"__type__\": ...,\n            \"value\": ...,\n        }\n\n        otherwise for JSON Objects:\n\n        {\n            \"__type__\": ...,\n            ...,\n        }\n\n    \"\"\"\n    if obj is None: return None\n    disable_nested_values: Optional[bool] = kwargs.get('disable_nested_values')\n\n    if isinstance(obj, BaseModel) or hasattr(obj, 'model_dump'):\n        obj_class_name = register_object_class(obj)\n        obj_value = obj.model_dump(mode = 'json', round_trip = True, context = {'source': 'io', 'method': 'serializer'}, **extract_model_dumps_kwargs(kwargs))\n        if mode == 'raw': return obj_value\n        if disable_nested_values:\n            return {\n                \"__type__\": \"pydantic\",\n                \"__class__\": obj_class_name,\n                **obj_value,\n            }\n        return {\n            \"__type__\": \"pydantic\",\n            \"__class__\": obj_class_name,\n            \"value\": obj_value,\n        }\n\n    # Move this to the top before primitives\n    if np is not None:\n        # if isinstance(obj, (np.int_, np.intc, np.intp, np.int8, np.int16, np.int32, np.int64, np.uint8, np.uint16, np.uint32, np.uint64)):\n        if isinstance(obj, np_int_types):\n            if mode == 'raw': return int(obj)\n            obj_class_name = register_object_class(obj)\n            return {\n                \"__type__\": \"numpy\",\n                \"__class__\": obj_class_name,\n                \"value\": int(obj),\n            }\n\n\n        # if isinstance(obj, (np.float_, np.float16, np.float32, np.float64)):\n        if isinstance(obj, np_float_types):\n            if mode == 'raw': return float(obj)\n            obj_class_name = register_object_class(obj)\n            return {\n                \"__type__\": \"numpy\",\n                \"__class__\": obj_class_name,\n                \"value\": float(obj),\n            }\n\n\n    if is_primitive(obj, exclude_bytes = True):\n        return obj\n\n    if isinstance(obj, type):\n        obj_class_name = register_object_class(obj, is_type = True)\n        if mode == 'raw': return obj_class_name\n        return {\n            \"__type__\": \"type\",\n            \"__class__\": obj_class_name,\n            \"value\": obj_class_name,\n        }\n\n    if isinstance(obj, (list, tuple)):\n        return [serialize_object(item, mode = mode, **kwargs) for item in obj]\n\n    if isinstance(obj, dict):\n        if \"__type__\" in obj: \n            return obj['value'] if mode == 'raw' and obj.get('value') else obj\n        return {key: serialize_object(value, mode = mode, **kwargs) for key, value in obj.items()}\n\n    if isinstance(obj, (datetime.datetime, datetime.date, datetime.time)):\n        if mode == 'raw': return obj.isoformat()\n        return {\n            \"__type__\": \"datetime\",\n            \"value\": obj.isoformat(),\n        }\n\n    if isinstance(obj, datetime.timedelta):\n        if mode == 'raw': return obj.total_seconds()\n        return {\n            \"__type__\": \"timedelta\",\n            \"value\": obj.total_seconds(),\n        }\n\n    if isinstance(obj, dataclasses.InitVar) or dataclasses.is_dataclass(obj):\n        if mode == 'raw': return dataclasses.asdict(obj)\n        obj_class_name = register_object_class(obj)\n        if disable_nested_values:\n            return {\n                \"__type__\": \"dataclass\",\n                \"__class__\": obj_class_name,\n                **dataclasses.asdict(obj),\n            }\n        return {\n            \"__type__\": \"dataclass\",\n            \"__class__\": obj_class_name,\n            \"value\": dataclasses.asdict(obj),\n        }\n\n    if hasattr(obj, 'as_posix'):\n        if mode == 'raw': return obj.as_posix()\n        obj_class_name = register_object_class(obj)\n        return {\n            \"__type__\": \"path\",\n            \"__class__\": obj_class_name,\n            \"value\": obj.as_posix(),\n        }\n\n    if isinstance(obj, (bytes, bytearray)):\n        if mode == 'raw': return obj\n        return {\n            \"__type__\": \"bytes\",\n            \"value\": obj.hex(),\n        }\n\n    if isinstance(obj, (set, frozenset)):\n        if mode == 'raw': return list(obj)\n        return {\n            \"__type__\": \"set\",\n            \"value\": list(obj),\n        }\n\n    if isinstance(obj, Enum):\n        if mode == 'raw': return obj.value\n        obj_class_name = register_object_class(obj)\n        return {\n            \"__type__\": \"enum\",\n            \"__class__\": obj_class_name,\n            \"value\": obj.value,\n        }\n\n    if isinstance(obj, UUID):\n        if mode == 'raw': return str(obj)\n        return {\n            \"__type__\": \"uuid\",\n            \"value\": str(obj),\n        }\n\n    if hasattr(obj, 'serialize'):\n        if mode == 'raw': return obj.serialize()\n        obj_class_name = register_object_class(obj)\n        return {\n            \"__type__\": \"serializable\",\n            \"__class__\": obj_class_name,\n            \"value\": obj.serialize(),\n        }\n\n    if isinstance(obj, abc.ABC):\n        logger.info(f'Pickle Serializing ABC Object: |r|({type(obj)}) {str(obj)[:1000]}', colored = True)\n        # if mode == 'raw': raise TypeError(f\"Cannot serialize object of type in raw mode {type(obj)}\")\n        obj_bytes = default_pickle.dumps(obj)\n        if mode == 'raw': return obj_bytes\n        return {\n            \"__type__\": \"pickle\",\n            \"value\": obj_bytes.hex(),\n        }\n\n\n    if hasattr(obj, \"numpy\"):  # Checks for TF tensors without needing the import\n        if mode == 'raw': return obj.numpy().tolist()\n        return {\n            \"__type__\": \"tensor\",\n            \"value\": obj.numpy().tolist(),\n        }\n\n    if hasattr(obj, 'tolist'): # Checks for torch tensors without importing\n        if mode == 'raw': return obj.tolist()\n        return {\n            \"__type__\": \"tensor\",\n            \"value\": obj.tolist(),\n        }\n\n    # Try one shot encoding objects\n    # with contextlib.suppress(Exception):\n\n    try:\n        logger.info(f'Pickle Serializing Object: |r|({type(obj)}) {str(obj)[:1000]}', colored = True)\n        obj_bytes = default_pickle.dumps(obj)\n        if mode == 'raw': return obj_bytes\n        return {\n            \"__type__\": \"pickle\",\n            \"value\": obj_bytes.hex(),\n        }\n    except Exception as e:\n\n        logger.info(f'Error Serializing Object: |r|({type(obj)}) {e}|e| {str(obj)[:1000]}', colored = True)\n\n    raise TypeError(f\"Cannot serialize object of type {type(obj)}\")\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.get_default_serializer","title":"<code>get_default_serializer()</code>","text":"<p>Return the globally configured default serializer name.</p> Source code in <code>src/lzl/io/ser/__init__.py</code> <pre><code>def get_default_serializer() -&gt; str:\n    \"\"\"Return the globally configured default serializer name.\"\"\"\n\n    return DEFAULT_SERIALIZER\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.set_default_serializer","title":"<code>set_default_serializer(serializer)</code>","text":"<p>Update the global default serializer.</p> <p>Parameters:</p> Name Type Description Default <code>serializer</code> <code>str</code> <p>Name used when resolving serializers via :func:<code>get_serializer</code>.</p> required Source code in <code>src/lzl/io/ser/__init__.py</code> <pre><code>def set_default_serializer(serializer: str) -&gt; None:\n    \"\"\"Update the global default serializer.\n\n    Args:\n        serializer: Name used when resolving serializers via :func:`get_serializer`.\n    \"\"\"\n\n    global DEFAULT_SERIALIZER\n    DEFAULT_SERIALIZER = serializer\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.register_serializer","title":"<code>register_serializer(name, serializer, override=False, set_as_default=False)</code>","text":"<p>Register a :class:<code>BaseSerializer</code> factory for use throughout LazyOps.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Identifier that callers pass into :func:<code>get_serializer</code>.</p> required <code>serializer</code> <code>SerializerFactory</code> <p>Concrete serializer class implementing the :class:<code>BaseSerializer</code> contract.</p> required <code>override</code> <code>bool | None</code> <p>When <code>True</code> replace an existing registration with the same <code>name</code>; otherwise a :class:<code>ValueError</code> is raised.</p> <code>False</code> <code>set_as_default</code> <code>bool | None</code> <p>When <code>True</code> call :func:<code>set_default_serializer</code> with <code>name</code> to make the serializer the global default.</p> <code>False</code> Source code in <code>src/lzl/io/ser/__init__.py</code> <pre><code>def register_serializer(\n    name: str,\n    serializer: SerializerFactory,\n    override: bool | None = False,\n    set_as_default: bool | None = False,\n) -&gt; None:\n    \"\"\"Register a :class:`BaseSerializer` factory for use throughout LazyOps.\n\n    Args:\n        name: Identifier that callers pass into :func:`get_serializer`.\n        serializer: Concrete serializer class implementing the\n            :class:`BaseSerializer` contract.\n        override: When ``True`` replace an existing registration with the same\n            ``name``; otherwise a :class:`ValueError` is raised.\n        set_as_default: When ``True`` call :func:`set_default_serializer` with\n            ``name`` to make the serializer the global default.\n    \"\"\"\n\n    global RegisteredSerializers\n    if name in RegisteredSerializers and not override:\n        existing = RegisteredSerializers[name]\n        raise ValueError(\n            f\"Serializer `{name}` already registered with {existing} and override is False\"\n        )\n    RegisteredSerializers[name] = serializer\n    if set_as_default:\n        set_default_serializer(name)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.set_default_serializer_lib","title":"<code>set_default_serializer_lib(serializer, lib)</code>","text":"<p>Set the preferred underlying library for a known serializer.</p> Source code in <code>src/lzl/io/ser/__init__.py</code> <pre><code>def set_default_serializer_lib(serializer: str, lib: ModuleType | str) -&gt; None:\n    \"\"\"Set the preferred underlying library for a known serializer.\"\"\"\n\n    if serializer not in RegisteredSerializers:\n        raise ValueError(\n            f\"Serializer `{serializer}` is not registered. Please register the serializer first\"\n        )\n    RegisteredSerializers[serializer].set_default_lib(lib)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.register_serializer_lib","title":"<code>register_serializer_lib(serializer, lib, set_as_default_lib=False)</code>","text":"<p>Register a library backend that a serializer implementation understands.</p> <p>Parameters:</p> Name Type Description Default <code>serializer</code> <code>str</code> <p>Name of the serializer to attach the backend to.</p> required <code>lib</code> <code>ModuleType | str</code> <p>Either the module object or its dotted import path.</p> required <code>set_as_default_lib</code> <code>bool | None</code> <p>When <code>True</code> update the serializer so that <code>lib</code> is used as the default backend for subsequent serializer instances.</p> <code>False</code> Source code in <code>src/lzl/io/ser/__init__.py</code> <pre><code>def register_serializer_lib(\n    serializer: str,\n    lib: ModuleType | str,\n    set_as_default_lib: bool | None = False,\n) -&gt; None:\n    \"\"\"Register a library backend that a serializer implementation understands.\n\n    Args:\n        serializer: Name of the serializer to attach the backend to.\n        lib: Either the module object or its dotted import path.\n        set_as_default_lib: When ``True`` update the serializer so that ``lib``\n            is used as the default backend for subsequent serializer instances.\n    \"\"\"\n\n    global RegisteredSerializerLibs\n    if serializer not in RegisteredSerializers:\n        raise ValueError(\n            f\"Serializer `{serializer}` is not registered. Please register the serializer first\"\n        )\n    if serializer not in RegisteredSerializerLibs:\n        RegisteredSerializerLibs[serializer] = []\n    if isinstance(lib, ModuleType):\n        lib = lib.__name__\n    if lib not in RegisteredSerializerLibs[serializer]:\n        RegisteredSerializerLibs[serializer].append(lib)\n    if set_as_default_lib:\n        RegisteredSerializers[serializer].set_default_lib(lib)\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.ser.get_serializer","title":"<code>get_serializer(serializer=None, **kwargs)</code>","text":"<pre><code>get_serializer(serializer: t.Literal['json'] = ..., jsonlib: str | ModuleType | None = ..., compression: str | None = ..., compression_level: int | None = ..., encoding: str | None = ..., serialization_obj: t.Type[object] | None = ..., serialization_obj_kwargs: dict[str, t.Any] | None = ..., disable_object_serialization: bool | None = ..., disable_nested_values: bool | None = ..., verbosity: int | None = ..., raise_errors: bool = ..., enforce_string_value: bool | None = ..., enforce_byte_value: bool | None = ..., ser_mode: SerMode | None = ..., deprecated_compression: str | None = ..., schema_map: dict[str, str] | None = ..., **kwargs: t.Any) -&gt; JsonSerializer\n</code></pre> <p>Return a serializer instance matching <code>serializer</code> and <code>kwargs</code>.</p> <p>The helper caches instances keyed by their configuration so the same serializer can be reused across the process without repeatedly instantiating identical objects.</p> Source code in <code>src/lzl/io/ser/__init__.py</code> <pre><code>def get_serializer(serializer: str | None = None, **kwargs: t.Any) -&gt; SerT:\n    \"\"\"Return a serializer instance matching ``serializer`` and ``kwargs``.\n\n    The helper caches instances keyed by their configuration so the same\n    serializer can be reused across the process without repeatedly\n    instantiating identical objects.\n    \"\"\"\n\n    global _initialized_sers\n\n    if serializer == \"auto\":\n        serializer = None\n    serializer = serializer or get_default_serializer()\n    ser_hash = create_hash_from_args_and_kwargs(serializer, **kwargs)\n    if ser_hash in _initialized_sers:\n        return _initialized_sers[ser_hash]\n\n    if serializer in RegisteredSerializers:\n        new = RegisteredSerializers[serializer](**kwargs)\n        _initialized_sers[ser_hash] = new\n        return new\n\n    for kind, libs in RegisteredSerializerLibs.items():\n        if serializer in libs:\n            if f\"{kind}lib\" not in kwargs:\n                kwargs[f\"{kind}lib\"] = serializer\n            new = RegisteredSerializers[kind](**kwargs)\n            _initialized_sers[ser_hash] = new\n            return new\n    raise ValueError(f\"Invalid Serializer Type: {serializer}\")\n</code></pre>"},{"location":"api/lzl/io/#persistence","title":"Persistence","text":"<p>Persistent storage backends for caching and data persistence:</p>"},{"location":"api/lzl/io/#lzl.io.persistence","title":"<code>lzl.io.persistence</code>","text":"<p>Persistence Module that supports both local and remote persistence</p> <p>The PersistentDict offers a dict-like interface with some powerful features: - Mutability: Changes to the dict are automatically persisted - Serialization: Values are automatically serialized and deserialized   - Supports JSON, Pickle, MsgPack, and Custom Serializers - Compression: Values are automatically compressed and decompressed     - Supports Zlib Compression - Remote Persistence: Supports Redis as a remote persistence backend - Local Persistence: Supports Local Filesystem as a local persistence backend - Supports async operations</p> <p>Usage:</p> <pre><code>from lzl.io import PersistentDict\n\n# Create a new PersistentDict\n# with default settings\n\ncache = PersistentDict(\"my_cache\")\n\n# Set a key\ncache[\"foo\"] = \"bar\"\ncache[\"x\"] = 1\n\n# Get a key\nprint(cache[\"foo\"])\nprint(cache[\"x\"])\n\n# Mutate a key\ncache[\"x\"] += 1\nprint(cache[\"x\"])\n\n# Delete a key\ndel cache[\"foo\"]\nprint(cache[\"foo\"])\n\n# Check if a key exists\nprint(\"foo\" in cache)\n\n# Get all keys\nprint(cache.keys())\n\n# Get all values\nprint(cache.values())\n\n# Get all items\nprint(cache.items())\n\n# Get the length of the cache\nprint(len(cache))\n\n# Clear the cache\ncache.clear()\n</code></pre>"},{"location":"api/lzl/io/#file-operations","title":"File Operations","text":"<p>File system operations with support for local and cloud storage:</p>"},{"location":"api/lzl/io/#lzl.io.file","title":"<code>lzl.io.file</code>","text":""},{"location":"api/lzl/io/#compression","title":"Compression","text":"<p>Data compression utilities:</p>"},{"location":"api/lzl/io/#lzl.io.compression","title":"<code>lzl.io.compression</code>","text":""},{"location":"api/lzl/io/#lzl.io.compression.get_default_compression","title":"<code>get_default_compression()</code>","text":"<p>Returns the default serializer</p> Source code in <code>src/lzl/io/compression/__init__.py</code> <pre><code>def get_default_compression() -&gt; str:\n    \"\"\"\n    Returns the default serializer\n    \"\"\"\n    return DEFAULT_COMPRESSION\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.compression.set_default_compression","title":"<code>set_default_compression(compression)</code>","text":"<p>Sets the default compression</p> <p>:param compression: The compression to use</p> Source code in <code>src/lzl/io/compression/__init__.py</code> <pre><code>def set_default_compression(\n    compression: str,\n) -&gt; None:\n    \"\"\"\n    Sets the default compression\n\n    :param compression: The compression to use\n    \"\"\"\n    global DEFAULT_COMPRESSION\n    DEFAULT_COMPRESSION = compression\n</code></pre>"},{"location":"api/lzl/io/#lzl.io.compression.get_compression","title":"<code>get_compression(compression_type=None, compression_level=None, **kwargs)</code>","text":"<p>Returns a Compression</p> Source code in <code>src/lzl/io/compression/__init__.py</code> <pre><code>def get_compression(\n    compression_type: Optional[str] = None,\n    compression_level: Optional[int] = None,\n    **kwargs\n) -&gt; CompressionT:\n    \"\"\"\n    Returns a Compression\n    \"\"\"\n    from lzo.utils.hashing import create_hash_from_args_and_kwargs\n    if compression_type == 'auto': compression_type = None\n    compression_type = compression_type or get_default_compression()\n    comp_hash = create_hash_from_args_and_kwargs(compression_type, compression_level = compression_level, **kwargs)\n    if comp_hash in _initialized_compressors:\n        return _initialized_compressors[comp_hash]\n    if compression_type == \"gzip\":\n        new = GzipCompression(compression_level = compression_level, **kwargs)\n    elif compression_type == \"lz4\":\n        new = Lz4Compression(compression_level = compression_level, **kwargs)\n    elif compression_type == \"zlib\":\n        new = ZlibCompression(compression_level = compression_level, **kwargs)\n    elif compression_type == \"zstd\":\n        new = ZstdCompression(compression_level = compression_level, **kwargs)\n    else: raise ValueError(f\"Invalid Compression Type: {compression_type}\")\n    _initialized_compressors[comp_hash] = new\n    return new\n</code></pre>"},{"location":"api/lzl/io/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzl/io/#basic-serialization","title":"Basic Serialization","text":"<pre><code>from lzl.io.ser import serialize, deserialize\n\n# Serialize data\ndata = {\"key\": \"value\", \"number\": 42}\nserialized = serialize(data)\n\n# Deserialize data\nrestored = deserialize(serialized)\n</code></pre>"},{"location":"api/lzl/io/#persistent-storage","title":"Persistent Storage","text":"<pre><code>from lzl.io.persistence import PersistentDict\n\n# Create a persistent dictionary\ncache = PersistentDict(\"my_cache.db\")\ncache[\"key\"] = \"value\"\ncache.sync()  # Save to disk\n</code></pre>"},{"location":"api/lzl/io/#file-operations_1","title":"File Operations","text":"<pre><code>from lzl.io.file import read_file, write_file\n\n# Read and write files\ncontent = await read_file(\"input.txt\")\nawait write_file(\"output.txt\", content)\n</code></pre>"},{"location":"api/lzl/kops/","title":"lzl.kops - Kubernetes Operations","text":"<p>The <code>lzl.kops</code> module provides utilities for Kubernetes operations.</p>"},{"location":"api/lzl/kops/#leader-election","title":"Leader Election","text":""},{"location":"api/lzl/kops/#lzl.kops.leader_election","title":"<code>lzl.kops.leader_election</code>","text":""},{"location":"api/lzl/kops/#lzl.kops.leader_election.KubernetesLeaderElection","title":"<code>KubernetesLeaderElection</code>","text":"<p>Implements leader election using Kubernetes Lease objects.</p> <p>This class ensures that only one instance (pod/worker) can hold the leadership role at any given time, with automatic failover if the leader fails.</p> Source code in <code>src/lzl/kops/leader_election.py</code> <pre><code>class KubernetesLeaderElection:\n    \"\"\"\n    Implements leader election using Kubernetes Lease objects.\n\n    This class ensures that only one instance (pod/worker) can hold the leadership\n    role at any given time, with automatic failover if the leader fails.\n    \"\"\"\n\n    def __init__(\n        self,\n        lease_name: str,\n        namespace: str = None,\n        lease_duration_seconds: int = 15,\n        renew_deadline_seconds: int = 10,\n        retry_period_seconds: int = 2,\n        identity: str = None\n    ):\n        \"\"\"\n        Initialize the leader election manager.\n\n        Args:\n            lease_name: Name of the Kubernetes Lease object\n            namespace: Kubernetes namespace (defaults to current pod's namespace)\n            lease_duration_seconds: How long the lease is valid\n            renew_deadline_seconds: How long before lease expires to renew\n            retry_period_seconds: How often to retry acquiring the lease\n            identity: Unique identifier for this instance (defaults to pod name + worker id)\n        \"\"\"\n        self.lease_name = lease_name\n        self.namespace = namespace or self._get_namespace()\n        self.lease_duration_seconds = lease_duration_seconds\n        self.renew_deadline_seconds = renew_deadline_seconds\n        self.retry_period_seconds = retry_period_seconds\n        self.identity = identity or self._generate_identity()\n\n        self.is_leader = False\n        self._stop_election = False\n        self._election_task = None\n\n        # Initialize Kubernetes client\n        try:\n            kubernetes.config.load_incluster_config()\n        except kubernetes.config.ConfigException:\n            # Fallback for local development\n            kubernetes.config.load_kube_config()\n\n        self.coordination_v1 = kubernetes.client.CoordinationV1Api()\n\n    def _get_namespace(self) -&gt; str:\n        \"\"\"Get the current pod's namespace.\"\"\"\n        namespace_path = \"/var/run/secrets/kubernetes.io/serviceaccount/namespace\"\n        if os.path.exists(namespace_path):\n            with open(namespace_path, 'r') as f:\n                return f.read().strip()\n        return \"default\"\n\n    def _generate_identity(self) -&gt; str:\n        \"\"\"Generate a unique identity for this instance.\"\"\"\n        from lzo.utils.system import get_host_name\n        pod_name = os.environ.get(\"HOSTNAME\", f\"{get_host_name()}-{uuid.uuid4().hex[:8]}\")\n        worker_id = os.environ.get(\"WORKER_ID\", str(os.getpid()))\n        return f\"{pod_name}-{worker_id}\"\n\n    def _create_or_get_lease(self) -&gt; Optional['kubernetes.client.V1Lease']:\n        \"\"\"Create or retrieve the lease object.\"\"\"\n        try:\n            return self.coordination_v1.read_namespaced_lease(\n                name=self.lease_name,\n                namespace=self.namespace\n            )\n        except kubernetes.client.rest.ApiException as e:\n            if e.status == 404:\n                # Lease doesn't exist, create it\n                now = datetime.now(timezone.utc)\n                lease = kubernetes.client.V1Lease(\n                    metadata=kubernetes.client.V1ObjectMeta(\n                        name=self.lease_name,\n                        namespace=self.namespace\n                    ),\n                    spec=kubernetes.client.V1LeaseSpec(\n                        holder_identity=self.identity,\n                        lease_duration_seconds=self.lease_duration_seconds,\n                        acquire_time=now,\n                        renew_time=now\n                    )\n                )\n                try:\n                    return self.coordination_v1.create_namespaced_lease(\n                        namespace=self.namespace,\n                        body=lease\n                    )\n                except kubernetes.client.rest.ApiException as create_error:\n                    if create_error.status == 409:\n                        # Another instance created it concurrently\n                        return self.coordination_v1.read_namespaced_lease(\n                            name=self.lease_name,\n                            namespace=self.namespace\n                        )\n                    raise\n            raise\n\n\n    def _parse_k8s_datetime(self, dt_value) -&gt; datetime:\n        \"\"\"Parse datetime from Kubernetes, handling both string and datetime objects.\"\"\"\n        if dt_value is None:\n            return None\n\n        if isinstance(dt_value, datetime):\n            # Already a datetime object\n            if dt_value.tzinfo is None:\n                # Assume UTC if no timezone\n                return dt_value.replace(tzinfo=timezone.utc)\n            return dt_value\n\n        if isinstance(dt_value, str):\n            # Handle various datetime string formats from Kubernetes\n            # Remove microseconds if present (everything after the dot before timezone)\n            if '.' in dt_value:\n                # Split at the dot and reconstruct without microseconds\n                base, remainder = dt_value.split('.', 1)\n                # Find where timezone info starts (Z, +, or -)\n                for i, char in enumerate(remainder):\n                    if char in ['Z', '+', '-']:\n                        dt_value = base + remainder[i:]\n                        break\n                else:\n                    dt_value = base  # No timezone found\n\n            # Replace Z with +00:00 for ISO format compatibility\n            dt_value = dt_value.replace('Z', '+00:00')\n\n            try:\n                return datetime.fromisoformat(dt_value)\n            except ValueError:\n                # Fallback to parsing without timezone and assume UTC\n                try:\n                    dt_clean = dt_value.split('+')[0].split('-')[0] if '+' in dt_value or dt_value.count('-') &gt; 2 else dt_value\n                    return datetime.fromisoformat(dt_clean).replace(tzinfo=timezone.utc)\n                except Exception as e:\n                    logger.warning(f\"Could not parse datetime: {dt_value}, using current time: {e}\")\n                    return datetime.now(timezone.utc)\n\n        # Fallback for unexpected types\n        logger.warning(f\"Unexpected datetime type: {type(dt_value)}, using current time\")\n        return datetime.now(timezone.utc)\n\n    def _try_acquire_or_renew(self) -&gt; bool:\n        # sourcery skip: extract-duplicate-method, hoist-statement-from-if, remove-unnecessary-else, swap-if-else-branches\n        \"\"\"Try to acquire or renew the lease.\"\"\"\n        lease = self._create_or_get_lease()\n        if not lease:\n            return False\n\n        now = datetime.now(timezone.utc)\n\n        # Check if we can acquire the lease\n        if lease.spec.holder_identity == self.identity:\n            # We already hold the lease, renew it\n            lease.spec.renew_time = now\n        elif lease.spec.renew_time:\n            # Check if the current lease has expired\n            renew_time = self._parse_k8s_datetime(lease.spec.renew_time)\n            expiry_time = renew_time + timedelta(seconds=self.lease_duration_seconds)\n\n            if now &gt; expiry_time:\n                # Lease has expired, we can acquire it\n                lease.spec.holder_identity = self.identity\n                lease.spec.acquire_time = now\n                lease.spec.renew_time = now\n            else:\n                # Lease is held by another instance\n                return False\n        else:\n            # No renew time set, acquire the lease\n            lease.spec.holder_identity = self.identity\n            lease.spec.acquire_time = now\n            lease.spec.renew_time = now\n\n        # Try to update the lease\n        try:\n            self.coordination_v1.replace_namespaced_lease(\n                name=self.lease_name,\n                namespace=self.namespace,\n                body=lease\n            )\n            return lease.spec.holder_identity == self.identity\n        except kubernetes.client.rest.ApiException as e:\n            if e.status == 409:\n                # Conflict - another instance updated the lease\n                return False\n            raise\n\n    async def _election_loop(self):  # sourcery skip: remove-redundant-if\n        \"\"\"Main election loop that runs continuously.\"\"\"\n        retry_count = 0\n        max_retries = 5\n\n        while not self._stop_election:\n            try:\n                acquired = self._try_acquire_or_renew()\n                retry_count = 0  # Reset retry count on success\n\n                if acquired and not self.is_leader:\n                    logger.info(f\"Leadership acquired: |g|{self.identity}|e|\", colored = True)\n                    self.is_leader = True\n                    if hasattr(self, '_on_elected_callback'):\n                        await self._on_elected_callback()\n                elif not acquired and self.is_leader:\n                    logger.info(f\"Leadership lost: |y|{self.identity}|e|\", colored = True)\n                    self.is_leader = False\n                    if hasattr(self, '_on_lost_callback'):\n                        await self._on_lost_callback()\n                elif acquired and self.is_leader:\n                    logger.debug(f\"Leadership renewed: |g|{self.identity}|e|\", colored = True)\n\n                # Sleep before next attempt\n                if self.is_leader:\n                    # If we're the leader, renew more frequently\n                    await asyncio.sleep(self.renew_deadline_seconds)\n                else:\n                    # If we're not the leader, check less frequently\n                    await asyncio.sleep(self.retry_period_seconds)\n\n            except kubernetes.client.rest.ApiException as e:\n                retry_count += 1\n                logger.error(f\"Kubernetes API error in election loop (attempt {retry_count}/{max_retries}): {e.status} - {e.reason}\")\n\n                if e.status == 401:\n                    logger.error(\"Authentication failed. Check service account permissions.\")\n                elif e.status == 403:\n                    logger.error(\"Authorization failed. Check RBAC permissions for leases.\")\n\n                if retry_count &gt;= max_retries:\n                    logger.error(f\"Max retries ({max_retries}) reached. Giving up leadership.\")\n                    self.is_leader = False\n                    retry_count = 0  # Reset for next cycle\n\n                await asyncio.sleep(self.retry_period_seconds * retry_count)  # Exponential backoff\n\n            except Exception as e:\n                retry_count += 1\n                logger.error(f\"Unexpected error in election loop (attempt {retry_count}/{max_retries}): {e}\", exc_info=True)\n\n                if retry_count &gt;= max_retries:\n                    logger.error(f\"Max retries ({max_retries}) reached. Giving up leadership.\")\n                    self.is_leader = False\n                    retry_count = 0\n\n                await asyncio.sleep(self.retry_period_seconds * retry_count)\n\n    async def start(\n        self,\n        on_elected: Optional[Callable] = None,\n        on_lost: Optional[Callable] = None\n    ):\n        \"\"\"\n        Start the leader election process.\n\n        Args:\n            on_elected: Async callback when leadership is acquired\n            on_lost: Async callback when leadership is lost\n        \"\"\"\n        if on_elected:\n            self._on_elected_callback = on_elected\n        if on_lost:\n            self._on_lost_callback = on_lost\n\n        self._stop_election = False\n        self._election_task = asyncio.create_task(self._election_loop())\n        logger.info(f\"Leader election started for {self.identity}\"\n                    )\n\n    async def stop(self):\n        \"\"\"Stop the leader election process.\"\"\"\n        self._stop_election = True\n        if self._election_task:\n            await self._election_task\n        self.is_leader = False\n        logger.info(f\"Leader election stopped for {self.identity}\")\n\n    def leader_only(self, func: Callable) -&gt; Callable:\n        \"\"\"\n        Decorator to ensure a function only runs on the leader.\n\n        Usage:\n            @leader_election.leader_only\n            async def process_batch():\n                # This will only run on the leader\n                pass\n        \"\"\"\n        @wraps(func)\n        async def wrapper(*args, **kwargs):\n            if not self.is_leader:\n                raise fastapi.HTTPException(\n                    status_code=503,\n                    detail=\"This instance is not the leader\"\n                )\n            return await func(*args, **kwargs)\n        return wrapper\n\n    @asynccontextmanager\n    async def as_leader(self):\n        \"\"\"\n        Context manager that only executes if this instance is the leader.\n\n        Usage:\n            async with leader_election.as_leader():\n                # Code here only runs on the leader\n                await process_important_task()\n        \"\"\"\n        if self.is_leader:\n            yield\n        else:\n            raise fastapi.HTTPException(\n                status_code=503,\n                detail=\"This instance is not the leader\"\n            )\n</code></pre>"},{"location":"api/lzl/kops/#lzl.kops.leader_election.KubernetesLeaderElection.start","title":"<code>start(on_elected=None, on_lost=None)</code>  <code>async</code>","text":"<p>Start the leader election process.</p> <p>Parameters:</p> Name Type Description Default <code>on_elected</code> <code>Optional[Callable]</code> <p>Async callback when leadership is acquired</p> <code>None</code> <code>on_lost</code> <code>Optional[Callable]</code> <p>Async callback when leadership is lost</p> <code>None</code> Source code in <code>src/lzl/kops/leader_election.py</code> <pre><code>async def start(\n    self,\n    on_elected: Optional[Callable] = None,\n    on_lost: Optional[Callable] = None\n):\n    \"\"\"\n    Start the leader election process.\n\n    Args:\n        on_elected: Async callback when leadership is acquired\n        on_lost: Async callback when leadership is lost\n    \"\"\"\n    if on_elected:\n        self._on_elected_callback = on_elected\n    if on_lost:\n        self._on_lost_callback = on_lost\n\n    self._stop_election = False\n    self._election_task = asyncio.create_task(self._election_loop())\n    logger.info(f\"Leader election started for {self.identity}\"\n                )\n</code></pre>"},{"location":"api/lzl/kops/#lzl.kops.leader_election.KubernetesLeaderElection.stop","title":"<code>stop()</code>  <code>async</code>","text":"<p>Stop the leader election process.</p> Source code in <code>src/lzl/kops/leader_election.py</code> <pre><code>async def stop(self):\n    \"\"\"Stop the leader election process.\"\"\"\n    self._stop_election = True\n    if self._election_task:\n        await self._election_task\n    self.is_leader = False\n    logger.info(f\"Leader election stopped for {self.identity}\")\n</code></pre>"},{"location":"api/lzl/kops/#lzl.kops.leader_election.KubernetesLeaderElection.leader_only","title":"<code>leader_only(func)</code>","text":"<p>Decorator to ensure a function only runs on the leader.</p> Usage <p>@leader_election.leader_only async def process_batch():     # This will only run on the leader     pass</p> Source code in <code>src/lzl/kops/leader_election.py</code> <pre><code>def leader_only(self, func: Callable) -&gt; Callable:\n    \"\"\"\n    Decorator to ensure a function only runs on the leader.\n\n    Usage:\n        @leader_election.leader_only\n        async def process_batch():\n            # This will only run on the leader\n            pass\n    \"\"\"\n    @wraps(func)\n    async def wrapper(*args, **kwargs):\n        if not self.is_leader:\n            raise fastapi.HTTPException(\n                status_code=503,\n                detail=\"This instance is not the leader\"\n            )\n        return await func(*args, **kwargs)\n    return wrapper\n</code></pre>"},{"location":"api/lzl/kops/#lzl.kops.leader_election.KubernetesLeaderElection.as_leader","title":"<code>as_leader()</code>  <code>async</code>","text":"<p>Context manager that only executes if this instance is the leader.</p> Usage <p>async with leader_election.as_leader():     # Code here only runs on the leader     await process_important_task()</p> Source code in <code>src/lzl/kops/leader_election.py</code> <pre><code>@asynccontextmanager\nasync def as_leader(self):\n    \"\"\"\n    Context manager that only executes if this instance is the leader.\n\n    Usage:\n        async with leader_election.as_leader():\n            # Code here only runs on the leader\n            await process_important_task()\n    \"\"\"\n    if self.is_leader:\n        yield\n    else:\n        raise fastapi.HTTPException(\n            status_code=503,\n            detail=\"This instance is not the leader\"\n        )\n</code></pre>"},{"location":"api/lzl/load/","title":"lzl.load - Lazy Loading","text":"<p>The <code>lzl.load</code> module provides utilities for lazy loading of modules and dependencies, enabling deferred imports and reducing startup time.</p>"},{"location":"api/lzl/load/#module-reference","title":"Module Reference","text":""},{"location":"api/lzl/load/#lzl.load","title":"<code>lzl.load</code>","text":""},{"location":"api/lzl/load/#lzl.load.LazyLoad","title":"<code>LazyLoad</code>","text":"<p>               Bases: <code>Generic[_M]</code></p> <p>Proxy object that defers importing a module until it is accessed.</p>"},{"location":"api/lzl/load/#lzl.load.LazyLoad--parameters","title":"Parameters","text":"<p>name:     The absolute or relative module name that should be imported lazily. package:     Package name used as the anchor for relative imports.  Mirrors     :func:<code>importlib.import_module</code>. install_missing:     When <code>True</code> (default) missing dependencies are installed via     :mod:<code>lzl.require</code>.  This mirrors the legacy behaviour and is kept for     backwards compatibility. install_options:     Keyword arguments forwarded to     :meth:<code>lzl.require.LazyLib.install_pip_package</code> if installation is     required. dependencies:     An optional dependency or iterable of dependencies that should be     loaded before the target module becomes available.  Each dependency is     expected to be another :class:<code>LazyLoad</code> instance.</p> Source code in <code>src/lzl/load/main.py</code> <pre><code>class LazyLoad(t.Generic[_M]):\n    \"\"\"Proxy object that defers importing a module until it is accessed.\n\n    Parameters\n    ----------\n    name:\n        The absolute or relative module name that should be imported lazily.\n    package:\n        Package name used as the anchor for relative imports.  Mirrors\n        :func:`importlib.import_module`.\n    install_missing:\n        When ``True`` (default) missing dependencies are installed via\n        :mod:`lzl.require`.  This mirrors the legacy behaviour and is kept for\n        backwards compatibility.\n    install_options:\n        Keyword arguments forwarded to\n        :meth:`lzl.require.LazyLib.install_pip_package` if installation is\n        required.\n    dependencies:\n        An optional dependency or iterable of dependencies that should be\n        loaded before the target module becomes available.  Each dependency is\n        expected to be another :class:`LazyLoad` instance.\n    \"\"\"\n\n    def __init__(\n        self, \n        name: str, \n        package: str | None = None, \n        install_missing: bool = True,\n        install_options: t.Optional[t.Dict[str, t.Any]] = None,\n        dependencies: t.Optional[t.Union['LazyLoad', t.Iterable['LazyLoad']]] = None,\n    ) -&gt; None:\n        self._lzlname = name  # Ridiculous name avoids name clash with module\n        if dependencies and not isinstance(dependencies, list):\n            dependencies = [dependencies]\n        self._lzldeps: t.Optional[t.Iterable['LazyLoad']] = dependencies\n        self._lzlpackage = package  # Ridiculous name avoids name clash with module\n        self._lzlinstall = install_missing\n        if install_missing:\n            install_options = install_options or {}\n            if 'package' not in install_options: install_options['package'] = package or name\n            self._lzlinstall_options = install_options\n        self.__module__: ModuleType | None = None\n\n    def __do_import__(self) -&gt; _M:\n        \"\"\"Import the target module, optionally installing missing deps.\"\"\"\n        try:\n            return importlib.import_module(self._lzlname, self._lzlpackage)\n        except Exception as e:\n            if self._lzlinstall:\n                from lzl.require import LazyLib\n                LazyLib.install_pip_package(**self._lzlinstall_options)\n                return importlib.import_module(self._lzlname, self._lzlpackage)\n            raise e\n\n    def __do_load_dependencies__(self) -&gt; None:\n        \"\"\"Ensure any declared lazy dependencies are loaded.\"\"\"\n        if not self._lzldeps: return\n        for dep in self._lzldeps:\n            dep.__load__()\n\n    def __do_reload_dependencies__(self) -&gt; None:\n        \"\"\"Force reload on dependencies before returning the module.\"\"\"\n        if not self._lzldeps: return\n        for dep in self._lzldeps:\n            dep.__reload__()\n\n\n    def __load__(self) -&gt; _M:\n        \"\"\"Explicitly load the import if it has not already been resolved.\"\"\"\n        if self.__module__ is None:\n            self.__module__ = self.__do_import__()\n            self.__do_load_dependencies__()\n        return self.__module__\n\n    def __reload__(self) -&gt; _M:\n        \"\"\"Force a reload of the proxied module and its dependencies.\"\"\"\n        try:\n            self.__module__ = importlib.reload(self.__module__)\n            self.__do_reload_dependencies__()\n        except Exception as exc:\n            try:\n                self.__module__ = self.__do_import__()\n                self.__do_load_dependencies__()\n            except Exception as e:\n                raise exc from e\n        return self.__module__\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Return a helpful representation regardless of load state.\"\"\"\n        if self.__module__ is None:\n            if self._lzlpackage:\n                return f\"&lt;Uninitialized module '{self._lzlname}' @ '{self._lzlpackage}'&gt;\"\n            return f\"&lt;Uninitialized module '{self._lzlname}'&gt;\"\n        try:\n            return self.__module__.__repr__()\n        # Shouldn't happen unless someone del'd module __repr__ method for some reason\n        except AttributeError:\n            if self._lzlpackage:\n                return f\"&lt;Initialized module '{self._lzlname}' @ '{self._lzlpackage}'&gt;\"\n            return f\"&lt;Initialized module '{self._lzlname}'&gt;\"\n\n    def __getattribute__(self, __name: str) -&gt; t.Any:\n        \"\"\"Proxy attribute access to the resolved module when available.\"\"\"\n        if __name in {\n            \"_lzlname\",\n            \"_lzlpackage\",\n            \"_lzlinstall\",\n            \"_lzldeps\",\n            \"_lzlinstall_options\",\n            \"__module__\",\n            \"__load__\",\n            \"__reload__\",\n            \"__do_import__\",\n            \"__do_load_dependencies__\",\n            \"__do_reload_dependencies__\",\n        }:\n            return super().__getattribute__(__name)\n        if self.__module__ is None:\n            self.__module__ = self.__do_import__()\n            self.__do_load_dependencies__()\n        return getattr(self.__module__, __name)\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.lazy_load","title":"<code>lazy_load(name, package=None, install_missing=True, install_options=None, dependencies=None)</code>","text":"<p>Create a :class:<code>LazyLoad</code> proxy for a module import.</p>"},{"location":"api/lzl/load/#lzl.load.lazy_load--returns","title":"Returns","text":"<p>LazyLoad     A proxy object that defers the import until attribute access occurs.</p> Source code in <code>src/lzl/load/main.py</code> <pre><code>def lazy_load(\n    name: str,\n    package: str | None = None,\n    install_missing: bool = True,\n    install_options: t.Optional[t.Dict[str, t.Any]] = None,\n    dependencies: t.Optional[t.Union[\"LazyLoad\", t.Iterable[\"LazyLoad\"]]] = None,\n) -&gt; LazyLoad:\n    \"\"\"Create a :class:`LazyLoad` proxy for a module import.\n\n    Returns\n    -------\n    LazyLoad\n        A proxy object that defers the import until attribute access occurs.\n    \"\"\"\n\n    return LazyLoad(\n        name,\n        package=package,\n        install_missing=install_missing,\n        install_options=install_options,\n        dependencies=dependencies,\n    )\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.load","title":"<code>load(__module)</code>","text":"<p>Eagerly resolve a lazy module and return the imported module object.</p> Source code in <code>src/lzl/load/main.py</code> <pre><code>def load(__module: LazyLoad | _M) -&gt; _M:\n    \"\"\"Eagerly resolve a lazy module and return the imported module object.\"\"\"\n\n    return __module.__load__() if isinstance(__module, LazyLoad) else __module\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.lazy_function_wrapper","title":"<code>lazy_function_wrapper(function, *function_args, **function_kwargs)</code>","text":"<p>Defer wrapper creation until the wrapped function is first invoked.</p> <p>The initialiser <code>function</code> is executed at most once.  It may return a callable that itself accepts the original function and returns a wrapped version.  When <code>function</code> returns <code>None</code> the original callable is used as-is, preserving the legacy behaviour relied on by existing integrations.</p> Source code in <code>src/lzl/load/wrappers.py</code> <pre><code>def lazy_function_wrapper(\n    function: t.Callable[..., ReturnT],\n    *function_args: t.Any,\n    **function_kwargs: t.Any,\n) -&gt; t.Callable[[t.Callable[..., ReturnT]], t.Callable[..., ReturnT]]:\n    \"\"\"Defer wrapper creation until the wrapped function is first invoked.\n\n    The initialiser ``function`` is executed at most once.  It may return a\n    callable that itself accepts the original function and returns a wrapped\n    version.  When ``function`` returns ``None`` the original callable is used\n    as-is, preserving the legacy behaviour relied on by existing integrations.\n    \"\"\"\n\n    _initialized = False\n    _initialized_function: t.Optional[t.Callable[[t.Callable[..., ReturnT]], t.Callable[..., ReturnT]]] = None\n\n    def lazywrapped(func: t.Callable[..., ReturnT]) -&gt; t.Callable[..., ReturnT]:\n        from lzl.pool import ThreadPool, is_coro_func\n\n        if is_coro_func(func):\n            @functools.wraps(func)\n            async def _wrapper(*args: t.Any, **kwargs: t.Any) -&gt; ReturnT:\n                nonlocal _initialized, _initialized_function\n                if not _initialized:\n                    _initialized_function = await ThreadPool.asyncish(\n                        function,\n                        *function_args,\n                        **function_kwargs,\n                    )\n                    _initialized = True\n                if _initialized_function is None:\n                    return await func(*args, **kwargs)\n                return await _initialized_function(func)(*args, **kwargs)\n\n            return _wrapper\n\n        @functools.wraps(func)\n        def _wrapper(*args: t.Any, **kwargs: t.Any) -&gt; ReturnT:\n            nonlocal _initialized, _initialized_function\n            if not _initialized:\n                _initialized_function = function(*function_args, **function_kwargs)\n                _initialized = True\n            if _initialized_function is None:\n                return func(*args, **kwargs)\n            return _initialized_function(func)(*args, **kwargs)\n\n        return _wrapper\n\n    return lazywrapped\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.import_from_string","title":"<code>import_from_string(import_str)</code>","text":"<p>Resolve <code>\"module:attribute\"</code> style import strings.</p> <p>The function mirrors patterns popularised by frameworks such as Celery and Pydantic.  When <code>import_str</code> is not a string the value is returned unchanged to preserve legacy call sites.</p> Source code in <code>src/lzl/load/utils.py</code> <pre><code>def import_from_string(import_str: t.Any) -&gt; t.Any:\n    \"\"\"Resolve ``\"module:attribute\"`` style import strings.\n\n    The function mirrors patterns popularised by frameworks such as Celery and\n    Pydantic.  When ``import_str`` is not a string the value is returned\n    unchanged to preserve legacy call sites.\n    \"\"\"\n\n    if not isinstance(import_str, str):\n        return import_str\n\n    module_str, _, attrs_str = import_str.partition(\":\")\n    if not module_str or not attrs_str:\n        message = 'Import string \"{import_str}\" must be in format \"&lt;module&gt;:&lt;attribute&gt;\".'\n        raise ImportFromStringError(message.format(import_str=import_str))\n\n    try:\n        module = importlib.import_module(module_str)\n    except ImportError as exc:  # pragma: no cover - passthrough for clarity\n        if exc.name != module_str:\n            raise exc\n        message = 'Could not import module \"{module_str}\".'\n        raise ImportFromStringError(message.format(module_str=module_str)) from exc\n\n    instance: t.Any = module\n    try:\n        for attr_str in attrs_str.split(\".\"):\n            instance = getattr(instance, attr_str)\n    except AttributeError as exc:\n        message = 'Attribute \"{attrs_str}\" not found in module \"{module_str}\".'\n        raise ImportFromStringError(\n            message.format(attrs_str=attrs_str, module_str=module_str)\n        ) from exc\n\n    return instance\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.import_function","title":"<code>import_function(func)</code>  <code>cached</code>","text":"<p>Return a callable from either a dotted import path or the callable itself.</p> Source code in <code>src/lzl/load/utils.py</code> <pre><code>@functools.lru_cache()\ndef import_function(func: str | t.Callable[..., t.Any]) -&gt; t.Callable[..., t.Any]:\n    \"\"\"Return a callable from either a dotted import path or the callable itself.\"\"\"\n\n    return func if callable(func) else t.cast(t.Callable[..., t.Any], lazy_import(func))\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.import_string","title":"<code>import_string(dotted_path, is_module=None, allow_module=False)</code>","text":"<p>Import a dotted path and return either the module or attribute requested.</p> Source code in <code>src/lzl/load/utils.py</code> <pre><code>def import_string(\n    dotted_path: str,\n    is_module: bool | None = None,\n    allow_module: bool | None = False,\n) -&gt; _Importable:\n    \"\"\"Import a dotted path and return either the module or attribute requested.\"\"\"\n\n    if is_module:\n        return importlib.import_module(dotted_path)\n\n    try:\n        module_path, class_name = dotted_path.strip().rsplit(\".\", 1)\n    except ValueError as exc:\n        raise ImportError(f'\"{dotted_path}\" doesn\\'t look like a module path') from exc\n\n    module = importlib.import_module(module_path)\n    try:\n        return getattr(module, class_name)\n    except AttributeError as exc:\n        if allow_module:\n            return module\n        raise ImportError(\n            f'Module \"{module_path}\" does not define a \"{class_name}\" attribute'\n        ) from exc\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.is_coro_func","title":"<code>is_coro_func(obj, func_name=None)</code>","text":"<p>Return <code>True</code> when <code>obj</code> or <code>obj.func_name</code> is awaitable.</p> Source code in <code>src/lzl/load/utils.py</code> <pre><code>def is_coro_func(obj: t.Any, func_name: str | None = None) -&gt; bool:\n    \"\"\"Return ``True`` when ``obj`` or ``obj.func_name`` is awaitable.\"\"\"\n\n    try:\n        if inspect.iscoroutinefunction(obj) or inspect.isawaitable(obj):\n            return True\n        if func_name and hasattr(obj, func_name):\n            maybe_func = getattr(obj, func_name)\n            if inspect.iscoroutinefunction(maybe_func):\n                return True\n        return bool(hasattr(obj, \"__call__\") and inspect.iscoroutinefunction(obj.__call__))\n    except Exception:  # pragma: no cover - mirrors legacy lenient behaviour\n        return False\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.lazy_function","title":"<code>lazy_function(validator, function, *args, **kwargs)</code>","text":"<p>Decorator factory that defers wrapper creation until validation passes.</p> Source code in <code>src/lzl/load/utils.py</code> <pre><code>def lazy_function(\n    validator: t.Callable[[], bool],\n    function: t.Callable[..., t.Any],\n    *args: t.Any,\n    **kwargs: t.Any,\n) -&gt; t.Callable[[t.Callable[..., t.Any]], t.Callable[..., t.Any]]:\n    \"\"\"Decorator factory that defers wrapper creation until validation passes.\"\"\"\n\n    def wrapper_func(func: t.Callable[..., t.Any]) -&gt; t.Callable[..., t.Any]:\n        if not validator():  # pragma: no cover - guarded branch maintained for compatibility\n            return func\n\n        if is_coro_func(func):\n            @functools.wraps(func)\n            async def wrapped_func(*f_args: t.Any, **f_kwargs: t.Any) -&gt; t.Any:\n                return await function(*f_args, **f_kwargs)\n        else:\n            @functools.wraps(func)\n            def wrapped_func(*f_args: t.Any, **f_kwargs: t.Any) -&gt; t.Any:\n                return function(*f_args, **f_kwargs)\n        return wrapped_func\n\n    return wrapper_func\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.lazy_import","title":"<code>lazy_import(dotted_path, is_module=None, allow_module=False)</code>","text":"<p>Import <code>dotted_path</code> once and cache the resolved object for reuse.</p> Source code in <code>src/lzl/load/utils.py</code> <pre><code>def lazy_import(\n    dotted_path: str,\n    is_module: bool | None = None,\n    allow_module: bool | None = False,\n) -&gt; _Importable:\n    \"\"\"Import ``dotted_path`` once and cache the resolved object for reuse.\"\"\"\n\n    if dotted_path not in _imported_strings:\n        _imported_strings[dotted_path] = import_string(\n            dotted_path,\n            is_module=is_module,\n            allow_module=allow_module,\n        )\n    return _imported_strings[dotted_path]\n</code></pre>"},{"location":"api/lzl/load/#lzl.load.validate_callable","title":"<code>validate_callable(value)</code>","text":"<p>Return a callable object when <code>value</code> is either <code>None</code> or a string.</p> Source code in <code>src/lzl/load/utils.py</code> <pre><code>def validate_callable(value: str | t.Callable[..., t.Any] | None) -&gt; t.Callable[..., t.Any] | None:\n    \"\"\"Return a callable object when ``value`` is either ``None`` or a string.\"\"\"\n\n    if value is None:\n        return None\n    return lazy_import(value) if isinstance(value, str) else value\n</code></pre>"},{"location":"api/lzl/load/#overview","title":"Overview","text":"<p>Lazy loading defers the import of modules until they are actually needed, which can significantly improve application startup time and reduce memory footprint.</p>"},{"location":"api/lzl/load/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzl/load/#basic-lazy-loading","title":"Basic Lazy Loading","text":"<pre><code>from lzl.load import LazyLoad\n\n# Create a lazy reference to a module\nnumpy = LazyLoad('numpy')\n\n# The module is only imported when accessed\narray = numpy.array([1, 2, 3])  # Import happens here\n</code></pre>"},{"location":"api/lzl/load/#lazy-loading-with-aliases","title":"Lazy Loading with Aliases","text":"<pre><code>from lzl.load import LazyLoad\n\n# Load with an alias\npd = LazyLoad('pandas', 'pd')\n\n# Use as normal\ndf = pd.DataFrame({'a': [1, 2, 3]})\n</code></pre>"},{"location":"api/lzl/load/#conditional-imports","title":"Conditional Imports","text":"<pre><code>from lzl.load import LazyLoad\n\n# Only import if actually used\noptional_module = LazyLoad('some.optional.module')\n\nif needs_feature:\n    optional_module.do_something()\n</code></pre>"},{"location":"api/lzl/load/#benefits","title":"Benefits","text":"<ul> <li>Faster Startup: Modules are only imported when needed</li> <li>Reduced Memory: Unused modules don't consume memory</li> <li>Simplified Dependencies: Optional dependencies can be handled gracefully</li> <li>Better Testing: Mock imports more easily in tests</li> </ul>"},{"location":"api/lzl/load/#implementation-details","title":"Implementation Details","text":"<p>The <code>LazyLoad</code> class uses Python's import system to defer module loading. When you access an attribute on a lazy-loaded module, the actual import is triggered transparently.</p>"},{"location":"api/lzl/logging/","title":"lzl.logging - Logging Utilities","text":"<p>The <code>lzl.logging</code> module provides enhanced logging capabilities built on top of <code>loguru</code>, with additional configuration options and integration helpers.</p>"},{"location":"api/lzl/logging/#module-reference","title":"Module Reference","text":""},{"location":"api/lzl/logging/#lzl.logging","title":"<code>lzl.logging</code>","text":""},{"location":"api/lzl/logging/#lzl.logging.NullLogger","title":"<code>NullLogger</code>","text":"<p>               Bases: <code>Logger</code>, <code>LoggingMixin</code></p> <p>Logger that delegates output to hooks without emitting messages.</p> Source code in <code>src/lzl/logging/null_logger.py</code> <pre><code>class NullLogger(logging.Logger, LoggingMixin):\n    \"\"\"Logger that delegates output to hooks without emitting messages.\"\"\"\n\n    def _format_item(\n        self,\n        msg: MsgItem,\n        max_length: int | None = None,\n        colored: bool | None = False,\n        level: str | None = None,\n        _is_part: bool | None = False,\n    ) -&gt; str:\n        return format_item(msg, max_length=max_length, colored=colored, level=level, _is_part=_is_part)\n\n    def _format_message(\n        self,\n        message: MsgItem,\n        *args: MsgItem,\n        prefix: str | None = None,\n        max_length: int | None = None,\n        level: str | None = None,\n        colored: bool | None = False,\n        extra: dict[str, t.Any] | None = None,\n    ) -&gt; str:\n        return format_message(\n            message,\n            *args,\n            prefix=prefix,\n            max_length=max_length,\n            level=level,\n            colored=colored,\n            extra=extra,\n        )\n\n    def _get_level(self, level: t.Union[str, int]) -&gt; str:\n        return get_logging_level(level)\n\n    def log(\n        self,\n        level: t.Union[str, int],\n        message: t.Any,\n        *args: MsgItem,\n        prefix: str | None = None,\n        max_length: int | None = None,\n        colored: bool | None = False,\n        hook: t.Callable[[str], None] | None = None,\n        **kwargs: t.Any,\n    ) -&gt; None:  # noqa: N805\n        if not hook:\n            return\n        resolved_level = self._get_level(level)\n        extra = kwargs.get(\"extra\")\n        rendered = self._format_message(\n            message,\n            *args,\n            prefix=prefix,\n            max_length=max_length,\n            colored=colored,\n            level=resolved_level,\n            extra=extra,\n        )\n        self.run_logging_hooks(rendered, hook=hook)\n\n    def info(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n        self.log(\"INFO\", *args, **kwargs)\n\n    def debug(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n        self.log(\"DEBUG\", *args, **kwargs)\n\n    def warning(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n        self.log(\"WARNING\", *args, **kwargs)\n\n    def error(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n        self.log(\"ERROR\", *args, **kwargs)\n\n    def trace(\n        self,\n        msg: t.Union[str, t.Any],\n        error: type[BaseException] | None = None,\n        level: str = \"ERROR\",\n        limit: int | None = None,\n        chain: bool | None = True,\n        colored: bool | None = False,\n        prefix: str | None = None,\n        max_length: int | None = None,\n        hook: t.Callable[[str], None] | None = None,\n        **kwargs: t.Any,\n    ) -&gt; None:\n        if not hook:\n            return\n        depth = kwargs.pop(\"depth\", None)\n        if depth is not None:\n            limit = depth\n        extra = kwargs.get(\"extra\")\n        if isinstance(msg, str):\n            rendered = msg\n            if extra:\n                extra_rendered = format_item(extra, max_length=max_length, colored=colored, level=level)\n                extra_rendered = extra_rendered.lstrip(\"\\n\")\n                if extra_rendered:\n                    rendered = f\"{rendered}\\n{extra_rendered}\" if rendered else extra_rendered\n        else:\n            rendered = self._format_message(\n                msg,\n                colored=colored,\n                prefix=prefix,\n                max_length=max_length,\n                level=level,\n                extra=extra,\n            )\n        rendered += f\"\\n{traceback.format_exc(chain=chain, limit=limit)}\"\n        if error:\n            rendered += f\" - {error}\"\n        self.run_logging_hooks(rendered, hook=hook)\n\n    def exception(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n        self.log(\"ERROR\", *args, **kwargs)\n\n    def success(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n        self.log(\"SUCCESS\", *args, **kwargs)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger","title":"<code>Logger</code>","text":"<p>               Bases: <code>Logger</code>, <code>LoggingMixin</code></p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>class Logger(_Logger, LoggingMixin):\n\n    name: str = None\n    settings: Type['BaseSettings'] = None\n    conditions: Dict[str, Tuple[Union[Callable, bool], str]] = {}\n    default_trace_depth: Optional[int] = None\n    is_global: bool = False\n    _colored_opts = None\n    _current_level: Optional[str] = None\n\n    @property\n    def colored_opts(self):\n        \"\"\"\n        Returns the colored options\n        \"\"\"\n        if not self._colored_opts:\n            (exception, depth, record, lazy, colors, raw, capture, patchers, extra) = self._options\n            self._colored_opts = (exception, depth, record, lazy, True, raw, capture, patchers, extra)\n        return self._colored_opts\n\n    def _get_opts(self, colored: Optional[bool] = False, **kwargs):\n        \"\"\"\n        Returns the options\n        \"\"\"\n        return self.colored_opts if colored else self._options\n\n    def get_log_mode(self, level: str = \"info\"):\n        \"\"\"\n        Returns the log mode based on the level\n        \"\"\"\n        return self.dev if level.upper() in {'DEV'} else getattr(self, level.lower())\n\n    def add_if_condition(\n        self, \n        name: str, \n        condition: Union[Callable, bool],\n        level: Optional[Union[str, int]] = 'INFO',\n    ):\n        \"\"\"\n        Adds a condition to the logger\n        \"\"\"\n        self.conditions[name] = (condition, self._get_level(level))\n\n    def remove_if_condition(self, name: str):\n        \"\"\"\n        Removes a condition from the logger\n        \"\"\"\n        if name in self.conditions:\n            del self.conditions[name]\n\n    def _is_dev_condition(self, record: logging.LogRecord) -&gt; bool:\n        \"\"\"\n        Returns whether the dev condition is met\n        \"\"\"\n        if not self.settings: return True\n        if record.levelname == 'DEV':\n            for key in {'api_dev_mode', 'debug_enabled'}:\n                if (\n                    hasattr(self.settings, key)\n                    and getattr(self.settings, key) is False\n                ):\n                    return False\n        return True\n\n    def _filter_if(self, name: str, record: Optional[logging.LogRecord] = None, message: Optional[Any] = None, level: Optional[Union[str, int]] = None) -&gt; Tuple[bool, str]:\n        \"\"\"\n        Filters out messages based on conditions\n        \"\"\"\n        if name in self.conditions:\n            condition, clevel = self.conditions[name]\n            if isinstance(condition, bool):\n                return condition, clevel\n            elif isinstance(condition, type(None)):\n                return False, clevel\n            elif isinstance(condition, Callable):\n                return condition(record or message), clevel\n        return True, (record.levelname if record else self._get_level(level or 'INFO'))\n\n    def _filter_module_name(self, name: str) -&gt; bool:\n        \"\"\"\n        Filter based on module name\n\n        - True if the module is not registered and is_global is False \n        - False if the module is registered and is_global is False\n        \"\"\"\n        _is_registered = is_registered_logger_module(name)\n        if self.is_global: \n            return _is_registered is not False\n        return _is_registered is False\n\n\n    def _filter(self, record: logging.LogRecord, name: Optional[str] = None) -&gt; bool:\n        \"\"\"\n        Filters out messages based on conditions\n\n        - True if the message should be filtered out\n        - False if the message should be logged\n        \"\"\"\n        if self.check_silenced(record):\n            return True\n        if self._filter_module_name(record['name']): \n            return True\n\n        if name is not None:\n            return self._filter_if(name, record)[0]\n        if not self.conditions: return False\n        return not any(\n            isinstance(value, bool)\n            and value is False\n            or not isinstance(value, bool)\n            and isinstance(value, Callable)\n            and value(record) is False\n            for key, value in self.conditions.items()\n        )\n\n    def _filter_dev(self, record: logging.LogRecord, **kwargs):\n        if not self.settings:\n            return True\n        if record.levelname == 'DEV':\n            for key in {'api_dev_mode', 'debug_enabled'}:\n                if (\n                    hasattr(self.settings, key)\n                    and getattr(self.settings, key) is False\n                ):\n                    return False\n        return True\n\n    def opt(\n        self,\n        *,\n        exception=None,\n        record=False,\n        lazy=False,\n        colors=False,\n        raw=False,\n        capture=True,\n        depth=0,\n        ansi=False\n    ):\n        \"\"\"\n        Return a new logger with the specified options changed.\n        \"\"\"\n        if ansi: colors = True\n        args = self._options[-2:]\n        return type(self)(self._core, exception, depth, record, lazy, colors, raw, capture, *args)\n\n\n\n    \"\"\"\n    Newly Added APIs\n    \"\"\"\n\n    def _get_level(self, level: Union[str, int]) -&gt; str:\n        \"\"\"\n        Returns the log level\n        \"\"\"\n        return get_logging_level(level)\n\n    def _format_item(\n        self,\n        msg: 'MsgItem',\n        max_length: Optional[int] = None,\n        colored: Optional[bool] = False,\n        level: Optional[str] = None,\n        _is_part: Optional[bool] = False,\n    ) -&gt; str:  # sourcery skip: extract-duplicate-method, low-code-quality, split-or-ifs\n        \"\"\"\n        Formats an item\n        \"\"\"\n        return format_item(msg, max_length = max_length, colored = colored, level = level, _is_part = _is_part)\n\n\n    def _format_message(\n        self, \n        message: 'MsgItem',\n        *args,\n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        level: Optional[str] = None,\n        colored: Optional[bool] = False,\n        extra: Optional[Dict[str, Any]] = None,\n    ) -&gt; str:\n        \"\"\"\n        Formats the message\n\n        \"example |b|msg|e|\"\n        -&gt; \"example &lt;blue&gt;msg&lt;/&gt;&lt;reset&gt;\"\n        \"\"\"\n        return format_message(\n            message,\n            *args,\n            prefix = prefix,\n            max_length = max_length,\n            level = level,\n            colored = colored,\n            extra = extra,\n        )\n\n    def log_if(\n        self, \n        name: str, \n        message: 'MsgItem',\n        *args, \n        level: Optional[Union[str, int]] = None, \n        **kwargs\n    ):  # noqa: N805\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``level`` if condition is met.\n        \"\"\"\n        condition, clevel = self._filter_if(name, message = message, level = level)\n        if condition:\n            return self.log((level or clevel), message, *args, **kwargs)\n\n    def log(\n        self, \n        level: Union[str, int], \n        message: 'MsgItem',\n        *args, \n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        colored: Optional[bool] = False,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):  # noqa: N805\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``level``.\n        \"\"\"\n        level = self._get_level(level)\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = level,\n            extra = extra,\n        )\n        try:\n            self._log(level, False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            # level_id, static_level_no, from_decorator, options, message, args, kwargs\n            static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 20)\n            self._log(level, static_log_no, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def info(\n        self, \n        message: 'MsgItem',\n        *args, \n        colored: Optional[bool] = None, \n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):  # noqa: N805\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``'INFO'``.\n        \"\"\"\n        if colored is None and isinstance(message, str) and '|e|' in message: colored = True\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            *args,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'INFO',\n            extra = extra,\n        )\n        if not is_global_muted():\n            try:\n                self._log(\"INFO\", False, self._get_opts(colored = colored), message, args, kwargs)\n            except TypeError:\n                # Compatibility with &lt; 0.6.0\n                self._log(\"INFO\", 20, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def success(\n        self, \n        message: 'MsgItem', \n        *args, \n        colored: Optional[bool] = False, \n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):  # noqa: N805\n        r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'SUCCESS'``.\"\"\"\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            *args,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'SUCCESS',\n            extra = extra,\n        )\n        if not is_global_muted():\n            try:\n                self._log(\"SUCCESS\", False, self._get_opts(colored = colored), message, args, kwargs)\n            except TypeError:\n                # Compatibility with &lt; 0.6.0\n                self._log(\"SUCCESS\", 20, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def warning(\n        self, \n        message, \n        *args, \n        colored: Optional[bool] = False, \n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):  # noqa: N805\n        r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'WARNING'``.\"\"\"\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'WARNING',\n            extra = extra,\n        )\n\n        try:\n            self._log(\"WARNING\", False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            self._log(\"WARNING\", 30, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def error(\n        self,\n        message: Any,\n        *args,\n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        colored: Optional[bool] = False,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        exc_info: Optional[bool] = False,\n        **kwargs\n    ) -&gt; None:\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``'ERROR'``.\n        \"\"\"\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'ERROR',\n            extra = extra,\n        )\n        if exc_info: message += f\"\\n{traceback.format_exc()}\"\n\n        try:\n            self._log(\"ERROR\", False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            self._log(\"ERROR\", 40, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def trace(\n        self, \n        msg: 'MsgItem',\n        error: Optional[Type[Exception]] = None, \n        level: str = \"ERROR\",\n        limit: Optional[int] = None,\n        chain: Optional[bool] = True,\n        colored: Optional[bool] = False,\n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        This method logs the traceback of an exception.\n\n        :param error: The exception to log.\n        \"\"\"\n        _depth = kwargs.pop('depth', None)\n        extra = kwargs.pop('extra', None)\n        if _depth is not None: limit = _depth\n        if isinstance(msg, str):\n            _msg = msg\n            if extra:\n                extras_rendered = format_item(extra, max_length = max_length, colored = colored, level = level)\n                extras_rendered = extras_rendered.lstrip('\\n')\n                if extras_rendered:\n                    if _msg:\n                        _msg += f\"\\n{extras_rendered}\"\n                    else:\n                        _msg = extras_rendered\n        else:\n            _msg = self._format_message(\n                msg,\n                colored = colored,\n                level = level,\n                prefix = prefix,\n                max_length = max_length,\n                extra = extra,\n            )\n        # pprint.pformat(msg)\n        _msg += f\"\\n{traceback.format_exc(chain = chain, limit = limit)}\"\n        if error: _msg += f\" - {error}\"\n\n        try:\n            self._log(level, False, self._get_opts(colored = colored), _msg, (), {})\n        except TypeError:\n            static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 40)\n            self._log(level, static_log_no, False, self._get_opts(colored = colored), _msg, (), {})\n        self.run_logging_hooks(_msg, hook = hook)\n\n    def exception(\n        self,\n        message: 'MsgItem',\n        *args,\n        colored: Optional[bool] = False,\n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``'ERROR'``.\n        \"\"\"\n        extra = kwargs.get('extra')\n        message = self._format_message(\n            message,\n            *args,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'ERROR',\n            extra = extra,\n        )\n        super().exception(message, *args, **kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n\n    def __call__(self, message: 'MsgItem', *args, level: str = 'info', **kwargs):\n        r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'INFO'``.\"\"\"\n        if isinstance(message, list):\n            __message = \"\".join(f'- {item}\\n' for item in message)\n        elif isinstance(message, dict):\n            __message = \"\".join(f'- {key}: {value}\\n' for key, value in message.items())\n        else:\n            __message = str(message)\n        _log = self.get_log_mode(level)\n        _log(__message.strip(), *args, **kwargs)\n\n    def _logcompat(\n        self, level, from_decorator, options, message, args, kwargs\n    ):\n        \"\"\"\n        Compatible to &lt; 0.6.0\n        \"\"\"\n        try:\n            self._log(level, from_decorator, options, message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            # level_id, static_level_no, from_decorator, options, message, args, kwargs\n            static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 20)\n            self._log(level, static_log_no, from_decorator, options, message, args, kwargs)\n\n\n    \"\"\"\n    Utilties\n    \"\"\"\n\n    def change_logger_level(\n        self,\n        level: str,\n    ):\n        \"\"\"\n        Changes the logger level\n\n        :TODO\n        \"\"\"\n        return\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.colored_opts","title":"<code>colored_opts</code>  <code>property</code>","text":"<p>Returns the colored options</p>"},{"location":"api/lzl/logging/#lzl.logging.Logger.get_log_mode","title":"<code>get_log_mode(level='info')</code>","text":"<p>Returns the log mode based on the level</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def get_log_mode(self, level: str = \"info\"):\n    \"\"\"\n    Returns the log mode based on the level\n    \"\"\"\n    return self.dev if level.upper() in {'DEV'} else getattr(self, level.lower())\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.add_if_condition","title":"<code>add_if_condition(name, condition, level='INFO')</code>","text":"<p>Adds a condition to the logger</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def add_if_condition(\n    self, \n    name: str, \n    condition: Union[Callable, bool],\n    level: Optional[Union[str, int]] = 'INFO',\n):\n    \"\"\"\n    Adds a condition to the logger\n    \"\"\"\n    self.conditions[name] = (condition, self._get_level(level))\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.remove_if_condition","title":"<code>remove_if_condition(name)</code>","text":"<p>Removes a condition from the logger</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def remove_if_condition(self, name: str):\n    \"\"\"\n    Removes a condition from the logger\n    \"\"\"\n    if name in self.conditions:\n        del self.conditions[name]\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.opt","title":"<code>opt(*, exception=None, record=False, lazy=False, colors=False, raw=False, capture=True, depth=0, ansi=False)</code>","text":"<p>Return a new logger with the specified options changed.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def opt(\n    self,\n    *,\n    exception=None,\n    record=False,\n    lazy=False,\n    colors=False,\n    raw=False,\n    capture=True,\n    depth=0,\n    ansi=False\n):\n    \"\"\"\n    Return a new logger with the specified options changed.\n    \"\"\"\n    if ansi: colors = True\n    args = self._options[-2:]\n    return type(self)(self._core, exception, depth, record, lazy, colors, raw, capture, *args)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.log_if","title":"<code>log_if(name, message, *args, level=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>level</code> if condition is met.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def log_if(\n    self, \n    name: str, \n    message: 'MsgItem',\n    *args, \n    level: Optional[Union[str, int]] = None, \n    **kwargs\n):  # noqa: N805\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``level`` if condition is met.\n    \"\"\"\n    condition, clevel = self._filter_if(name, message = message, level = level)\n    if condition:\n        return self.log((level or clevel), message, *args, **kwargs)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.log","title":"<code>log(level, message, *args, prefix=None, max_length=None, colored=False, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>level</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def log(\n    self, \n    level: Union[str, int], \n    message: 'MsgItem',\n    *args, \n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    colored: Optional[bool] = False,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):  # noqa: N805\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``level``.\n    \"\"\"\n    level = self._get_level(level)\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = level,\n        extra = extra,\n    )\n    try:\n        self._log(level, False, self._get_opts(colored = colored), message, args, kwargs)\n    except TypeError:\n        # Compatibility with &lt; 0.6.0\n        # level_id, static_level_no, from_decorator, options, message, args, kwargs\n        static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 20)\n        self._log(level, static_log_no, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.info","title":"<code>info(message, *args, colored=None, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'INFO'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def info(\n    self, \n    message: 'MsgItem',\n    *args, \n    colored: Optional[bool] = None, \n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):  # noqa: N805\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``'INFO'``.\n    \"\"\"\n    if colored is None and isinstance(message, str) and '|e|' in message: colored = True\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        *args,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'INFO',\n        extra = extra,\n    )\n    if not is_global_muted():\n        try:\n            self._log(\"INFO\", False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            self._log(\"INFO\", 20, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.success","title":"<code>success(message, *args, colored=False, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'SUCCESS'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def success(\n    self, \n    message: 'MsgItem', \n    *args, \n    colored: Optional[bool] = False, \n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):  # noqa: N805\n    r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'SUCCESS'``.\"\"\"\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        *args,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'SUCCESS',\n        extra = extra,\n    )\n    if not is_global_muted():\n        try:\n            self._log(\"SUCCESS\", False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            self._log(\"SUCCESS\", 20, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.warning","title":"<code>warning(message, *args, colored=False, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'WARNING'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def warning(\n    self, \n    message, \n    *args, \n    colored: Optional[bool] = False, \n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):  # noqa: N805\n    r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'WARNING'``.\"\"\"\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'WARNING',\n        extra = extra,\n    )\n\n    try:\n        self._log(\"WARNING\", False, self._get_opts(colored = colored), message, args, kwargs)\n    except TypeError:\n        # Compatibility with &lt; 0.6.0\n        self._log(\"WARNING\", 30, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.error","title":"<code>error(message, *args, prefix=None, max_length=None, colored=False, hook=None, exc_info=False, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'ERROR'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def error(\n    self,\n    message: Any,\n    *args,\n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    colored: Optional[bool] = False,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    exc_info: Optional[bool] = False,\n    **kwargs\n) -&gt; None:\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``'ERROR'``.\n    \"\"\"\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'ERROR',\n        extra = extra,\n    )\n    if exc_info: message += f\"\\n{traceback.format_exc()}\"\n\n    try:\n        self._log(\"ERROR\", False, self._get_opts(colored = colored), message, args, kwargs)\n    except TypeError:\n        self._log(\"ERROR\", 40, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.trace","title":"<code>trace(msg, error=None, level='ERROR', limit=None, chain=True, colored=False, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>This method logs the traceback of an exception.</p> <p>:param error: The exception to log.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def trace(\n    self, \n    msg: 'MsgItem',\n    error: Optional[Type[Exception]] = None, \n    level: str = \"ERROR\",\n    limit: Optional[int] = None,\n    chain: Optional[bool] = True,\n    colored: Optional[bool] = False,\n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    This method logs the traceback of an exception.\n\n    :param error: The exception to log.\n    \"\"\"\n    _depth = kwargs.pop('depth', None)\n    extra = kwargs.pop('extra', None)\n    if _depth is not None: limit = _depth\n    if isinstance(msg, str):\n        _msg = msg\n        if extra:\n            extras_rendered = format_item(extra, max_length = max_length, colored = colored, level = level)\n            extras_rendered = extras_rendered.lstrip('\\n')\n            if extras_rendered:\n                if _msg:\n                    _msg += f\"\\n{extras_rendered}\"\n                else:\n                    _msg = extras_rendered\n    else:\n        _msg = self._format_message(\n            msg,\n            colored = colored,\n            level = level,\n            prefix = prefix,\n            max_length = max_length,\n            extra = extra,\n        )\n    # pprint.pformat(msg)\n    _msg += f\"\\n{traceback.format_exc(chain = chain, limit = limit)}\"\n    if error: _msg += f\" - {error}\"\n\n    try:\n        self._log(level, False, self._get_opts(colored = colored), _msg, (), {})\n    except TypeError:\n        static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 40)\n        self._log(level, static_log_no, False, self._get_opts(colored = colored), _msg, (), {})\n    self.run_logging_hooks(_msg, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.exception","title":"<code>exception(message, *args, colored=False, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'ERROR'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def exception(\n    self,\n    message: 'MsgItem',\n    *args,\n    colored: Optional[bool] = False,\n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``'ERROR'``.\n    \"\"\"\n    extra = kwargs.get('extra')\n    message = self._format_message(\n        message,\n        *args,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'ERROR',\n        extra = extra,\n    )\n    super().exception(message, *args, **kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.Logger.change_logger_level","title":"<code>change_logger_level(level)</code>","text":"<p>Changes the logger level</p> <p>:TODO</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def change_logger_level(\n    self,\n    level: str,\n):\n    \"\"\"\n    Changes the logger level\n\n    :TODO\n    \"\"\"\n    return\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.register_logger_module","title":"<code>register_logger_module(module)</code>","text":"<p>Record <code>module</code> as having an explicit LazyOps logger configured.</p> Source code in <code>src/lzl/logging/state.py</code> <pre><code>def register_logger_module(module: str) -&gt; None:\n    \"\"\"Record ``module`` as having an explicit LazyOps logger configured.\"\"\"\n\n    _registered_logger_modules.add(extract_module_name(module))\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.is_registered_logger_module","title":"<code>is_registered_logger_module(name)</code>  <code>cached</code>","text":"<p>Return <code>True</code> when <code>name</code> (or its root) has been registered.</p> Source code in <code>src/lzl/logging/state.py</code> <pre><code>@functools.lru_cache(maxsize=1000)\ndef is_registered_logger_module(name: str) -&gt; bool:\n    \"\"\"Return ``True`` when ``name`` (or its root) has been registered.\"\"\"\n\n    module_name = extract_module_name(name)\n    return module_name in _registered_logger_modules\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.add_api_log_filters","title":"<code>add_api_log_filters(modules=('gunicorn', 'uvicorn'), routes=('/healthz',), status_codes=None, verbose=False)</code>","text":"<p>Attach filters to common HTTP server loggers to hide noisy endpoints.</p> Source code in <code>src/lzl/logging/state.py</code> <pre><code>def add_api_log_filters(\n    modules: t.Optional[t.Union[t.Sequence[str], str]] = (\"gunicorn\", \"uvicorn\"),\n    routes: t.Optional[t.Union[t.Sequence[str], str]] = (\"/healthz\",),\n    status_codes: t.Optional[t.Union[t.Sequence[int], int]] = None,\n    verbose: bool = False,\n) -&gt; None:  # sourcery skip: default-mutable-arg\n    \"\"\"Attach filters to common HTTP server loggers to hide noisy endpoints.\"\"\"\n\n    modules_list = [modules] if isinstance(modules, str) else list(modules or [])\n    routes_list = [routes] if isinstance(routes, str) else list(routes or [])\n    status_list = [status_codes] if isinstance(status_codes, int) else list(status_codes or [])\n\n    def filter_api_record(record: logging.LogRecord) -&gt; bool:\n        if routes_list:\n            for route in routes_list:\n                if route in record.args:\n                    return False\n        if status_list:\n            for sc in status_list:\n                if sc in record.args:\n                    return False\n        return True\n\n    for module in modules_list:\n        target = module\n        if module == \"gunicorn\":\n            target = \"gunicorn.glogging.Logger\"\n        elif module == \"uvicorn\":\n            target = \"uvicorn.logging.Logger\"\n        api_logger = logging.getLogger(target)\n        from .main import default_logger\n\n        if verbose:\n            default_logger.info(\n                \"Adding API filters to %s for routes=%s status_codes=%s\",\n                target,\n                routes_list or None,\n                status_list or None,\n            )\n        api_logger.addFilter(filter_api_record)\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.set_global_muted","title":"<code>set_global_muted(muted)</code>","text":"<p>Toggle a process-wide muted flag checked by LazyOps loggers.</p> Source code in <code>src/lzl/logging/state.py</code> <pre><code>def set_global_muted(muted: bool) -&gt; None:\n    \"\"\"Toggle a process-wide muted flag checked by LazyOps loggers.\"\"\"\n\n    global _is_global_muted\n    _is_global_muted = muted\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.create_default_logger","title":"<code>create_default_logger(name=None, level='INFO', format=None, filter=None, handlers=None, settings=None, **kwargs)</code>","text":"<p>Return a named logger that proxies calls to the global instance.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str | None</code> <p>Optional logger namespace.  If omitted the global logger is returned.</p> <code>None</code> <code>level</code> <code>str | int</code> <p>Minimum log level once the logger is registered.</p> <code>'INFO'</code> <code>format</code> <code>Callable[['LogRecord'], str] | None</code> <p>Formatter applied when a dedicated handler is configured.</p> <code>None</code> <code>filter</code> <code>Callable[['LogRecord'], bool] | None</code> <p>Optional filtering callable.</p> <code>None</code> <code>handlers</code> <code>Sequence['LoggingHandler'] | None</code> <p>Additional logging handlers to attach.</p> <code>None</code> <code>settings</code> <code>'BaseSettings' | None</code> <p>Optional settings object attached to the logger for runtime reference.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Extra keyword arguments forwarded to the Loguru <code>add</code> call.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Logger</code> <code>Logger</code> <p>Either the global logger or a namespaced proxy.</p> Source code in <code>src/lzl/logging/main.py</code> <pre><code>def create_default_logger(\n    name: str | None = None,\n    level: str | int = \"INFO\",\n    format: t.Callable[[\"LogRecord\"], str] | None = None,\n    filter: t.Callable[[\"LogRecord\"], bool] | None = None,\n    handlers: t.Sequence['LoggingHandler'] | None = None,\n    settings: 'BaseSettings' | None = None,\n    **kwargs: t.Any,\n) -&gt; Logger:\n    \"\"\"Return a named logger that proxies calls to the global instance.\n\n    Args:\n        name: Optional logger namespace.  If omitted the global logger is\n            returned.\n        level: Minimum log level once the logger is registered.\n        format: Formatter applied when a dedicated handler is configured.\n        filter: Optional filtering callable.\n        handlers: Additional logging handlers to attach.\n        settings: Optional settings object attached to the logger for runtime\n            reference.\n        **kwargs: Extra keyword arguments forwarded to the Loguru ``add`` call.\n\n    Returns:\n        Logger: Either the global logger or a namespaced proxy.\n    \"\"\"\n    global _logger_contexts\n    if name:\n        if name.upper() in REVERSE_LOGLEVEL_MAPPING:\n            # If name is a level, then set level to name\n            level = name\n            name = None\n        else:\n            name = extract_module_name(name)\n\n    if name is None: name = 'lzl'\n    if name in _logger_contexts:\n        return _logger_contexts[name]\n\n    with _lock:\n        if name == 'lzl':\n            return create_global_logger(\n                name = name,\n                level = level,\n                format = format,\n                filter = filter,\n                handlers = handlers,\n                settings = settings,\n            )\n\n        if isinstance(level, str): level = level.upper()\n        _logger = _logger_contexts['lzl']\n\n        if name and format is not None:\n            # Add a new handler\n            def _filter_func(record: 'LogRecord') -&gt; bool:\n                \"\"\"\n                Filter out messages from other modules\n                \"\"\"\n                return extract_module_name(record.name) == name\n\n            _logger.add(\n                sys.stdout,\n                enqueue = not _DISABLE_QUEUE,\n                backtrace = True,\n                colorize = True,\n                level = level,\n                format = format,\n                filter = _filter_func,\n                **kwargs,\n            )\n            return _logger\n\n        *options, extra = _logger._options\n        new_logger = Logger(_logger._core, *options, {**extra})\n        if name: \n            _logger_contexts[name] = new_logger\n            new_logger.name = name\n            register_logger_module(name)\n\n        if settings: new_logger.settings = settings\n        # if _is_global_logger: new_logger.is_global = True\n        return new_logger\n</code></pre>"},{"location":"api/lzl/logging/#lzl.logging.change_logger_level","title":"<code>change_logger_level(name=None, level='INFO', verbose=False, **kwargs)</code>","text":"<p>Update the minimum level for the global or named logger.</p> Source code in <code>src/lzl/logging/main.py</code> <pre><code>def change_logger_level(\n    name: str | None = None,\n    level: str | int = \"INFO\",\n    verbose: bool = False,\n    **kwargs: t.Any,\n) -&gt; None:\n    \"\"\"Update the minimum level for the global or named logger.\"\"\"\n    global logger, logger_level\n    if isinstance(level, str): level = level.upper()\n    # Skip if the level is the same\n    if level == logger_level: return\n    name = name or 'lzl'\n    name = name.split('.')[0]\n    logger_level = level\n    if name != 'lzl':\n        __logger = get_logger(name, logger_level, **kwargs)\n    else:\n        __logger = logger\n    if verbose: __logger.info(f\"[{name}] Changing logger level from {logger_level} -&gt; {level}\")\n    __logger._core.min_level = float(REVERSE_LOGLEVEL_MAPPING[logger_level.upper()])\n</code></pre>"},{"location":"api/lzl/logging/#overview","title":"Overview","text":"<p>The logging module provides a flexible, powerful logging system that integrates seamlessly with the rest of the <code>lzl</code> toolkit.</p>"},{"location":"api/lzl/logging/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzl/logging/#basic-logging","title":"Basic Logging","text":"<pre><code>from lzl.logging import logger\n\nlogger.info(\"Application started\")\nlogger.debug(\"Debug information\")\nlogger.warning(\"Warning message\")\nlogger.error(\"Error occurred\")\n</code></pre>"},{"location":"api/lzl/logging/#structured-logging","title":"Structured Logging","text":"<pre><code>from lzl.logging import logger\n\nlogger.info(\"User action\", user_id=123, action=\"login\", ip=\"192.168.1.1\")\n</code></pre>"},{"location":"api/lzl/logging/#custom-configuration","title":"Custom Configuration","text":"<pre><code>from lzl.logging import configure_logging\n\n# Configure logging with custom settings\nconfigure_logging(\n    level=\"DEBUG\",\n    format=\"&lt;green&gt;{time}&lt;/green&gt; | &lt;level&gt;{level}&lt;/level&gt; | {message}\",\n    rotation=\"100 MB\"\n)\n</code></pre>"},{"location":"api/lzl/logging/#context-management","title":"Context Management","text":"<pre><code>from lzl.logging import logger\n\nwith logger.contextualize(request_id=\"abc-123\"):\n    logger.info(\"Processing request\")  # Includes request_id in log\n</code></pre>"},{"location":"api/lzl/logging/#features","title":"Features","text":"<ul> <li>Structured Logging: Easy-to-parse structured log output</li> <li>Rotation Support: Automatic log file rotation</li> <li>Context Injection: Add contextual information to logs</li> <li>Performance: Minimal overhead with efficient formatting</li> <li>Integration: Works well with async code and multiple threads</li> </ul>"},{"location":"api/lzl/logging/#configuration","title":"Configuration","text":"<p>The logging module can be configured through environment variables or programmatically:</p> <ul> <li><code>LOG_LEVEL</code>: Set the minimum log level (DEBUG, INFO, WARNING, ERROR)</li> <li><code>LOG_FORMAT</code>: Custom log format string</li> <li><code>LOG_FILE</code>: Path to log file (if file logging is desired)</li> </ul>"},{"location":"api/lzl/pool/","title":"lzl.pool - Thread Pool Utilities","text":"<p>The <code>lzl.pool</code> module provides thread pool management and execution utilities for concurrent operations.</p>"},{"location":"api/lzl/pool/#module-reference","title":"Module Reference","text":""},{"location":"api/lzl/pool/#lzl.pool","title":"<code>lzl.pool</code>","text":""},{"location":"api/lzl/pool/#lzl.pool.ThreadPool","title":"<code>ThreadPool</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Singleton-style proxy wrapping LazyOps thread/process pools.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>@proxied\nclass ThreadPool(abc.ABC):\n    \"\"\"Singleton-style proxy wrapping LazyOps thread/process pools.\"\"\"\n\n    allow_task_completion: Optional[bool] = True\n    register_exit: Optional[bool] = True\n\n    def __init__(\n        self,\n        max_workers: Optional[int] = None,\n        allow_task_completion: Optional[bool] = None,\n        register_exit: Optional[bool] = None,\n        **kwargs\n    ):\n        \"\"\"Initialise backing executors and configure automatic shutdown hooks.\"\"\"\n        if allow_task_completion is not None: self.allow_task_completion = allow_task_completion\n        if register_exit is not None: self.register_exit = register_exit\n        if max_workers is None:\n            max_workers = int(os.getenv(\"MAX_WORKERS\", os.cpu_count()))\n\n        self.max_workers = max_workers\n        self.tasks: Optional[Set[asyncio.Task]] = set()\n        self._pool: Optional[futures.ThreadPoolExecutor] = None\n        self._ppool: Optional[futures.ProcessPoolExecutor] = None\n\n        self._kwargs = kwargs\n        if self.register_exit:\n            import atexit\n            atexit.register(self.on_exit)\n\n    @staticmethod\n    def is_coro(obj: Any) -&gt; bool:\n        \"\"\"Return ``True`` when ``obj`` is a coroutine function or awaitable.\"\"\"\n        return is_coro_func(obj)\n\n    def ensure_coro(self, func: Callable[..., RT]) -&gt; Callable[..., Awaitable[RT]]:\n        \"\"\"Return an awaitable wrapper around ``func`` when it is sync.\"\"\"\n        if asyncio.iscoroutinefunction(func): return func\n        @functools.wraps(func)\n        async def inner(*args, **kwargs):\n            return await self.arun(func, *args, **kwargs)\n        return inner\n\n    def ensure_coro_function(self, func: Callable[..., RT]) -&gt; Callable[..., Awaitable[RT]]:\n        \"\"\"Return an awaitable wrapper preserving context variables.\"\"\"\n        if asyncio.iscoroutinefunction(func): return func\n        @functools.wraps(func)\n        async def inner(*args, **kwargs):\n            loop = asyncio.get_running_loop()\n            ctx = contextvars.copy_context()\n            return await loop.run_in_executor(\n                executor = self.pool, \n                func = lambda: ctx.run(func, *args, **kwargs)\n            )\n        return inner\n\n    @property\n    def pool(self) -&gt; futures.ThreadPoolExecutor:\n        \"\"\"Return (and lazily create) the shared thread pool executor.\"\"\"\n        if self._pool is None:\n            self._pool = futures.ThreadPoolExecutor(max_workers = self.max_workers)\n        return self._pool\n\n    @property\n    def ppool(self) -&gt; futures.ProcessPoolExecutor:\n        \"\"\"Return (and lazily create) the shared process pool executor.\"\"\"\n        if self._ppool is None:\n            self._ppool = futures.ProcessPoolExecutor(max_workers = self.max_workers)\n        return self._ppool\n\n    @property\n    def in_async_loop(self) -&gt; bool:\n        \"\"\"Return ``True`` when executed inside a running event loop.\"\"\"\n        try:\n            return asyncio.get_running_loop() is not None\n        except RuntimeError:\n            return False\n\n    def get_pool(\n        self, \n        num_workers: Optional[int] = None, \n        process_pool: bool = False\n    ) -&gt; futures.Executor:\n        \"\"\"Create a dedicated executor honouring ``num_workers`` preferences.\"\"\"\n        pool_cls = futures.ProcessPoolExecutor if process_pool else futures.ThreadPoolExecutor\n        if num_workers is None: num_workers = self.max_workers\n        return pool_cls(max_workers = num_workers)\n\n    def add_task(\n        self, \n        task: asyncio.Task, \n        callback: Optional[Callable] = None,\n        callback_args: Optional[Tuple] = None,\n        callback_kwargs: Optional[Dict] = None\n    ):\n        \"\"\"Track ``task`` and optionally invoke ``callback`` when it completes.\"\"\"\n        self.tasks.add(task)\n        if callback is not None:\n            if callback_args or callback_kwargs:\n                callback_args = callback_args or ()\n                callback_kwargs = callback_kwargs or {}\n                callback = functools.partial(callback, *callback_args, **callback_kwargs)\n            task.add_done_callback(callback)\n        task.add_done_callback(self.tasks.discard)\n\n\n    def on_exit(self):\n        \"\"\"Cancel tracked tasks and shut down executors at interpreter exit.\"\"\"\n        for task in self.tasks:\n            with contextlib.suppress(Exception):\n                task.cancel()\n        with contextlib.suppress(Exception):\n            if self._pool is not None: self._pool.shutdown(wait = self.allow_task_completion, cancel_futures = not self.allow_task_completion)\n        with contextlib.suppress(Exception):\n            if self._ppool is not None: self._ppool.shutdown(wait = self.allow_task_completion, cancel_futures = not self.allow_task_completion)\n\n    \"\"\"\n    Core\n    \"\"\"\n\n    def run(self, func: Coroutine[RT], *args, **kwargs) -&gt; RT:\n        \"\"\"Execute ``func`` synchronously, bridging any active AnyIO loop.\"\"\"\n        current_async_module = getattr(anyio._core._eventloop.threadlocals, \"current_async_module\", None)\n        partial_f = functools.partial(func, *args, **kwargs)\n        if current_async_module is None:\n            return anyio.run(partial_f)\n        return anyio.from_thread.run(partial_f)\n\n\n    async def arun(self, func: Callable[..., RT], *args, **kwargs) -&gt; RT:\n        \"\"\"Execute ``func`` in the shared thread pool and await the result.\"\"\"\n        blocking = functools.partial(func, *args, **kwargs)\n        loop = asyncio.get_running_loop()\n        return await loop.run_in_executor(self.pool, blocking)\n\n    async def asyncish(self, func: Callable[..., RT], *args, **kwargs) -&gt; RT:\n        \"\"\"Await ``func`` when async, otherwise delegate to :meth:`arun`.\"\"\"\n        if is_coro_func(func): return await func(*args, **kwargs)\n        return await self.arun(func, *args, **kwargs)\n\n    run_async = arun\n    run_sync = run\n\n    \"\"\"\n    Background Tasks\n    \"\"\"    \n\n    def threadpool_task(\n        self, \n        func: Callable, \n        *args, \n        task_callback: Optional[Callable[..., RT]] = None, \n        task_callback_args: Optional[Tuple] = None,\n        task_callback_kwargs: Optional[Dict] = None,\n        **kwargs\n    ) -&gt; futures.Future[RT]:\n        \"\"\"Submit ``func`` to the thread pool and return the future.\"\"\"\n        task = self.pool.submit(func, *args, **kwargs)\n        self.add_task(task, task_callback, callback_args=task_callback_args, callback_kwargs=task_callback_kwargs)\n        return task\n\n    def background_task(\n        self, \n        func: Callable[..., RT],\n        *args, \n        task_callback: Optional[Callable] = None, \n        task_callback_args: Optional[Tuple] = None,\n        task_callback_kwargs: Optional[Dict] = None,\n        **kwargs\n    ) -&gt; Awaitable[RT]:\n        \"\"\"Schedule ``func`` in the appropriate executor based on loop state.\"\"\"\n        if inspect.isawaitable(func): task = asyncio.create_task(func)\n        else: task = asyncio.create_task(self.asyncish(func, *args, **kwargs))\n        self.add_task(task, task_callback, callback_args = task_callback_args, callback_kwargs=task_callback_kwargs)\n        return task\n\n    def background(\n        self, \n        func: Callable[..., RT], \n        *args, \n        task_callback: Optional[Callable] = None, \n        task_callback_args: Optional[Tuple] = None,\n        task_callback_kwargs: Optional[Dict] = None,\n        **kwargs\n    ) -&gt; Awaitable[RT]:\n        \"\"\"\n        Runs a function in the background.\n        If the current thread is in an async loop, it runs the function as an async function.\n        Otherwise, it runs the function as a sync function in the threadpool.\n\n        Returns a `asyncio.Task` if the current thread is in an async loop.\n        Otherwise, it returns a `futures.Future`.\n        \"\"\"\n        method = self.background_task if self.in_async_loop else self.threadpool_task\n        return method(func, *args, task_callback = task_callback, task_callback_args = task_callback_args, task_callback_kwargs = task_callback_kwargs, **kwargs)\n\n    create_threadpool_task = threadpool_task\n    create_background_task = background_task\n    create_background = background\n\n    \"\"\"\n    Iterators\n    \"\"\"\n\n    def map(\n        self,\n        func: Callable[..., RT],\n        iterable: Iterable[Any],\n        *args,\n        return_ordered: Optional[bool] = True,\n        use_process_pool: Optional[bool] = False, \n        **kwargs\n    ) -&gt; List[RT]:  # sourcery skip: assign-if-exp\n        \"\"\"Return the results of applying ``func`` across ``iterable``.\"\"\"\n        num_workers = kwargs.pop('num_workers', None)\n        partial_func = functools.partial(func, *args, **kwargs)\n        with self.get_pool(num_workers = num_workers, process_pool = use_process_pool) as executor:\n            _futures = [\n                executor.submit(partial_func, item) for item in iterable\n            ]\n            if not return_ordered: return [f.result() for f in futures.as_completed(_futures)]\n            futures.wait(_futures)\n            return [f.result() for f in _futures]\n\n\n    def iterate(\n        self,\n        func: Callable[..., RT],\n        iterable: Iterable[Any],\n        *args,\n        use_process_pool: Optional[bool] = False, \n        return_ordered: Optional[bool] = True,\n        **kwargs\n    ) -&gt; Generator[RT, None, None]:  # sourcery skip: assign-if-exp\n        \"\"\"Yield items produced by applying ``func`` across ``iterable``.\"\"\"\n        num_workers = kwargs.pop('num_workers', None)\n        partial_func = functools.partial(func, *args, **kwargs)\n        with self.get_pool(num_workers = num_workers, process_pool = use_process_pool) as executor:\n            _futures = [\n                executor.submit(partial_func, item) for item in iterable\n            ]\n            if not return_ordered:\n                for f in futures.as_completed(_futures):\n                    yield f.result()\n            else:\n                futures.wait(_futures)\n                for f in _futures:\n                    yield f.result()\n\n    async def amap(\n        self,\n        func: Callable[..., Awaitable[RT]],\n        iterable: Iterable[Any], \n        *args,\n        return_ordered: Optional[bool] = True,\n        concurrency_limit: Optional[int] = None,\n        **kwargs,\n    ) -&gt; List[RT]:\n        \"\"\"Await results serially while respecting the concurrency limit.\"\"\"\n        return_when = kwargs.pop('return_when', 'ALL_COMPLETED' if return_ordered else 'FIRST_COMPLETED')\n        concurrency_limit = kwargs.pop('limit', concurrency_limit)\n        func = self.ensure_coro(func)\n        partial = functools.partial(func, *args, **kwargs)\n        try: mapped_iterable = map(partial, iterable)\n        except TypeError: mapped_iterable = (partial(x) async for x in iterable)\n        results = []\n        async for result in amap_iterable(\n            mapped_iterable, \n            return_when = return_when, \n            concurrency_limit = concurrency_limit\n        ):\n            results.append(await result)\n        return results\n\n    async def aiterate(\n        self,\n        func: Callable[..., Awaitable[RT]],\n        iterable: Iterable[Any], \n        *args,\n        return_ordered: Optional[bool] = True,\n        concurrency_limit: Optional[int] = None,\n        **kwargs,\n    ) -&gt; AsyncGenerator[RT, None]:\n        \"\"\"Async generator yielding results as soon as underlying tasks finish.\"\"\"\n        return_when = kwargs.pop('return_when', 'ALL_COMPLETED' if return_ordered else 'FIRST_COMPLETED')\n        concurrency_limit = kwargs.pop('limit', concurrency_limit)\n        func = self.ensure_coro(func)\n        partial = functools.partial(func, *args, **kwargs)\n        try: mapped_iterable = map(partial, iterable)\n        except TypeError: mapped_iterable = (partial(x) async for x in iterable)\n        async for result in amap_iterable(\n            mapped_iterable, \n            return_when = return_when, \n            concurrency_limit = concurrency_limit\n        ):\n            yield await result\n\n    sync_map = map\n    sync_iterate = iterate\n    async_map = amap\n    async_iterate = aiterate\n\n    \"\"\"\n    CMD\n    \"\"\"\n\n    @staticmethod\n    def cmd(\n        command: Union[List[str], str], \n        shell: bool = True, \n        raise_error: bool = True, \n        **kwargs\n    ):\n        if isinstance(command, list): command = \" \".join(command)\n        try:\n            out = subprocess.check_output(command, shell=shell, **kwargs)\n            if isinstance(out, bytes): out = out.decode('utf8')\n            return out.strip()\n        except Exception as e:\n            if not raise_error: return \"\"\n            raise e\n\n    @staticmethod\n    async def acmd(\n        command: Union[str, List[str]], \n        output_only: bool = True, \n        stdout = asyncio.subprocess.PIPE, \n        stderr = asyncio.subprocess.PIPE, \n        output_encoding: str = 'UTF-8', \n        output_errors: str = 'ignore', \n        *args,\n        **kwargs\n    ) -&gt; Union[str, asyncio.subprocess.Process]:\n        \"\"\"Execute a shell command asynchronously, optionally returning stdout.\"\"\"\n        if isinstance(command, list): command = ' '.join(command)\n        p = await asyncio.subprocess.create_subprocess_shell(command, *args, stdout = stdout, stderr = stderr, **kwargs)\n        if not output_only: return p\n        stdout, _ = await p.communicate()\n        return stdout.decode(encoding = output_encoding, errors = output_errors).strip()\n\n    run_command = cmd\n    async_run_command = acmd\n\n\n    @staticmethod\n    async def acmd_exec(\n        command: Union[str, List[str]], \n        output_only: bool = True, \n        stdout = asyncio.subprocess.PIPE, \n        stderr = asyncio.subprocess.PIPE, \n        output_encoding: str = 'UTF-8', \n        output_errors: str = 'ignore', \n        **kwargs\n    ) -&gt; Union[str, asyncio.subprocess.Process]:\n        \"\"\"Execute a command using ``create_subprocess_exec`` and return stdout when requested.\"\"\"\n        if isinstance(command, str): command = shlex.split(command)\n        p = await asyncio.subprocess.create_subprocess_exec(*command, stdout = stdout, stderr = stderr, **kwargs)\n        if not output_only: return p\n        stdout, _ = await p.communicate()\n        return stdout.decode(encoding = output_encoding, errors = output_errors).strip()\n\n    @staticmethod\n    async def acmd_stream(\n        command: Union[str, List[str]], \n        stdout_cb: t.Union[t.Callable, t.Awaitable], \n        stderr_cb: t.Optional[t.Union[t.Callable, t.Awaitable]] = None,\n        **kwargs \n    ) -&gt; asyncio.subprocess.Process:\n        \"\"\"Stream subprocess output into the supplied callbacks.\"\"\"\n        return await _stream_subprocess(command, stdout_cb, stderr_cb, **kwargs)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.pool","title":"<code>pool</code>  <code>property</code>","text":"<p>Return (and lazily create) the shared thread pool executor.</p>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.ppool","title":"<code>ppool</code>  <code>property</code>","text":"<p>Return (and lazily create) the shared process pool executor.</p>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.in_async_loop","title":"<code>in_async_loop</code>  <code>property</code>","text":"<p>Return <code>True</code> when executed inside a running event loop.</p>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.run_sync","title":"<code>run_sync = run</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Background Tasks</p>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.create_background","title":"<code>create_background = background</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Iterators</p>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.async_iterate","title":"<code>async_iterate = aiterate</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>CMD</p>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.is_coro","title":"<code>is_coro(obj)</code>  <code>staticmethod</code>","text":"<p>Return <code>True</code> when <code>obj</code> is a coroutine function or awaitable.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>@staticmethod\ndef is_coro(obj: Any) -&gt; bool:\n    \"\"\"Return ``True`` when ``obj`` is a coroutine function or awaitable.\"\"\"\n    return is_coro_func(obj)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.ensure_coro","title":"<code>ensure_coro(func)</code>","text":"<p>Return an awaitable wrapper around <code>func</code> when it is sync.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def ensure_coro(self, func: Callable[..., RT]) -&gt; Callable[..., Awaitable[RT]]:\n    \"\"\"Return an awaitable wrapper around ``func`` when it is sync.\"\"\"\n    if asyncio.iscoroutinefunction(func): return func\n    @functools.wraps(func)\n    async def inner(*args, **kwargs):\n        return await self.arun(func, *args, **kwargs)\n    return inner\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.ensure_coro_function","title":"<code>ensure_coro_function(func)</code>","text":"<p>Return an awaitable wrapper preserving context variables.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def ensure_coro_function(self, func: Callable[..., RT]) -&gt; Callable[..., Awaitable[RT]]:\n    \"\"\"Return an awaitable wrapper preserving context variables.\"\"\"\n    if asyncio.iscoroutinefunction(func): return func\n    @functools.wraps(func)\n    async def inner(*args, **kwargs):\n        loop = asyncio.get_running_loop()\n        ctx = contextvars.copy_context()\n        return await loop.run_in_executor(\n            executor = self.pool, \n            func = lambda: ctx.run(func, *args, **kwargs)\n        )\n    return inner\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.get_pool","title":"<code>get_pool(num_workers=None, process_pool=False)</code>","text":"<p>Create a dedicated executor honouring <code>num_workers</code> preferences.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def get_pool(\n    self, \n    num_workers: Optional[int] = None, \n    process_pool: bool = False\n) -&gt; futures.Executor:\n    \"\"\"Create a dedicated executor honouring ``num_workers`` preferences.\"\"\"\n    pool_cls = futures.ProcessPoolExecutor if process_pool else futures.ThreadPoolExecutor\n    if num_workers is None: num_workers = self.max_workers\n    return pool_cls(max_workers = num_workers)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.add_task","title":"<code>add_task(task, callback=None, callback_args=None, callback_kwargs=None)</code>","text":"<p>Track <code>task</code> and optionally invoke <code>callback</code> when it completes.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def add_task(\n    self, \n    task: asyncio.Task, \n    callback: Optional[Callable] = None,\n    callback_args: Optional[Tuple] = None,\n    callback_kwargs: Optional[Dict] = None\n):\n    \"\"\"Track ``task`` and optionally invoke ``callback`` when it completes.\"\"\"\n    self.tasks.add(task)\n    if callback is not None:\n        if callback_args or callback_kwargs:\n            callback_args = callback_args or ()\n            callback_kwargs = callback_kwargs or {}\n            callback = functools.partial(callback, *callback_args, **callback_kwargs)\n        task.add_done_callback(callback)\n    task.add_done_callback(self.tasks.discard)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.on_exit","title":"<code>on_exit()</code>","text":"<p>Cancel tracked tasks and shut down executors at interpreter exit.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def on_exit(self):\n    \"\"\"Cancel tracked tasks and shut down executors at interpreter exit.\"\"\"\n    for task in self.tasks:\n        with contextlib.suppress(Exception):\n            task.cancel()\n    with contextlib.suppress(Exception):\n        if self._pool is not None: self._pool.shutdown(wait = self.allow_task_completion, cancel_futures = not self.allow_task_completion)\n    with contextlib.suppress(Exception):\n        if self._ppool is not None: self._ppool.shutdown(wait = self.allow_task_completion, cancel_futures = not self.allow_task_completion)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.run","title":"<code>run(func, *args, **kwargs)</code>","text":"<p>Execute <code>func</code> synchronously, bridging any active AnyIO loop.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def run(self, func: Coroutine[RT], *args, **kwargs) -&gt; RT:\n    \"\"\"Execute ``func`` synchronously, bridging any active AnyIO loop.\"\"\"\n    current_async_module = getattr(anyio._core._eventloop.threadlocals, \"current_async_module\", None)\n    partial_f = functools.partial(func, *args, **kwargs)\n    if current_async_module is None:\n        return anyio.run(partial_f)\n    return anyio.from_thread.run(partial_f)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.arun","title":"<code>arun(func, *args, **kwargs)</code>  <code>async</code>","text":"<p>Execute <code>func</code> in the shared thread pool and await the result.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>async def arun(self, func: Callable[..., RT], *args, **kwargs) -&gt; RT:\n    \"\"\"Execute ``func`` in the shared thread pool and await the result.\"\"\"\n    blocking = functools.partial(func, *args, **kwargs)\n    loop = asyncio.get_running_loop()\n    return await loop.run_in_executor(self.pool, blocking)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.asyncish","title":"<code>asyncish(func, *args, **kwargs)</code>  <code>async</code>","text":"<p>Await <code>func</code> when async, otherwise delegate to :meth:<code>arun</code>.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>async def asyncish(self, func: Callable[..., RT], *args, **kwargs) -&gt; RT:\n    \"\"\"Await ``func`` when async, otherwise delegate to :meth:`arun`.\"\"\"\n    if is_coro_func(func): return await func(*args, **kwargs)\n    return await self.arun(func, *args, **kwargs)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.threadpool_task","title":"<code>threadpool_task(func, *args, task_callback=None, task_callback_args=None, task_callback_kwargs=None, **kwargs)</code>","text":"<p>Submit <code>func</code> to the thread pool and return the future.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def threadpool_task(\n    self, \n    func: Callable, \n    *args, \n    task_callback: Optional[Callable[..., RT]] = None, \n    task_callback_args: Optional[Tuple] = None,\n    task_callback_kwargs: Optional[Dict] = None,\n    **kwargs\n) -&gt; futures.Future[RT]:\n    \"\"\"Submit ``func`` to the thread pool and return the future.\"\"\"\n    task = self.pool.submit(func, *args, **kwargs)\n    self.add_task(task, task_callback, callback_args=task_callback_args, callback_kwargs=task_callback_kwargs)\n    return task\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.background_task","title":"<code>background_task(func, *args, task_callback=None, task_callback_args=None, task_callback_kwargs=None, **kwargs)</code>","text":"<p>Schedule <code>func</code> in the appropriate executor based on loop state.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def background_task(\n    self, \n    func: Callable[..., RT],\n    *args, \n    task_callback: Optional[Callable] = None, \n    task_callback_args: Optional[Tuple] = None,\n    task_callback_kwargs: Optional[Dict] = None,\n    **kwargs\n) -&gt; Awaitable[RT]:\n    \"\"\"Schedule ``func`` in the appropriate executor based on loop state.\"\"\"\n    if inspect.isawaitable(func): task = asyncio.create_task(func)\n    else: task = asyncio.create_task(self.asyncish(func, *args, **kwargs))\n    self.add_task(task, task_callback, callback_args = task_callback_args, callback_kwargs=task_callback_kwargs)\n    return task\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.background","title":"<code>background(func, *args, task_callback=None, task_callback_args=None, task_callback_kwargs=None, **kwargs)</code>","text":"<p>Runs a function in the background. If the current thread is in an async loop, it runs the function as an async function. Otherwise, it runs the function as a sync function in the threadpool.</p> <p>Returns a <code>asyncio.Task</code> if the current thread is in an async loop. Otherwise, it returns a <code>futures.Future</code>.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def background(\n    self, \n    func: Callable[..., RT], \n    *args, \n    task_callback: Optional[Callable] = None, \n    task_callback_args: Optional[Tuple] = None,\n    task_callback_kwargs: Optional[Dict] = None,\n    **kwargs\n) -&gt; Awaitable[RT]:\n    \"\"\"\n    Runs a function in the background.\n    If the current thread is in an async loop, it runs the function as an async function.\n    Otherwise, it runs the function as a sync function in the threadpool.\n\n    Returns a `asyncio.Task` if the current thread is in an async loop.\n    Otherwise, it returns a `futures.Future`.\n    \"\"\"\n    method = self.background_task if self.in_async_loop else self.threadpool_task\n    return method(func, *args, task_callback = task_callback, task_callback_args = task_callback_args, task_callback_kwargs = task_callback_kwargs, **kwargs)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.map","title":"<code>map(func, iterable, *args, return_ordered=True, use_process_pool=False, **kwargs)</code>","text":"<p>Return the results of applying <code>func</code> across <code>iterable</code>.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def map(\n    self,\n    func: Callable[..., RT],\n    iterable: Iterable[Any],\n    *args,\n    return_ordered: Optional[bool] = True,\n    use_process_pool: Optional[bool] = False, \n    **kwargs\n) -&gt; List[RT]:  # sourcery skip: assign-if-exp\n    \"\"\"Return the results of applying ``func`` across ``iterable``.\"\"\"\n    num_workers = kwargs.pop('num_workers', None)\n    partial_func = functools.partial(func, *args, **kwargs)\n    with self.get_pool(num_workers = num_workers, process_pool = use_process_pool) as executor:\n        _futures = [\n            executor.submit(partial_func, item) for item in iterable\n        ]\n        if not return_ordered: return [f.result() for f in futures.as_completed(_futures)]\n        futures.wait(_futures)\n        return [f.result() for f in _futures]\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.iterate","title":"<code>iterate(func, iterable, *args, use_process_pool=False, return_ordered=True, **kwargs)</code>","text":"<p>Yield items produced by applying <code>func</code> across <code>iterable</code>.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def iterate(\n    self,\n    func: Callable[..., RT],\n    iterable: Iterable[Any],\n    *args,\n    use_process_pool: Optional[bool] = False, \n    return_ordered: Optional[bool] = True,\n    **kwargs\n) -&gt; Generator[RT, None, None]:  # sourcery skip: assign-if-exp\n    \"\"\"Yield items produced by applying ``func`` across ``iterable``.\"\"\"\n    num_workers = kwargs.pop('num_workers', None)\n    partial_func = functools.partial(func, *args, **kwargs)\n    with self.get_pool(num_workers = num_workers, process_pool = use_process_pool) as executor:\n        _futures = [\n            executor.submit(partial_func, item) for item in iterable\n        ]\n        if not return_ordered:\n            for f in futures.as_completed(_futures):\n                yield f.result()\n        else:\n            futures.wait(_futures)\n            for f in _futures:\n                yield f.result()\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.amap","title":"<code>amap(func, iterable, *args, return_ordered=True, concurrency_limit=None, **kwargs)</code>  <code>async</code>","text":"<p>Await results serially while respecting the concurrency limit.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>async def amap(\n    self,\n    func: Callable[..., Awaitable[RT]],\n    iterable: Iterable[Any], \n    *args,\n    return_ordered: Optional[bool] = True,\n    concurrency_limit: Optional[int] = None,\n    **kwargs,\n) -&gt; List[RT]:\n    \"\"\"Await results serially while respecting the concurrency limit.\"\"\"\n    return_when = kwargs.pop('return_when', 'ALL_COMPLETED' if return_ordered else 'FIRST_COMPLETED')\n    concurrency_limit = kwargs.pop('limit', concurrency_limit)\n    func = self.ensure_coro(func)\n    partial = functools.partial(func, *args, **kwargs)\n    try: mapped_iterable = map(partial, iterable)\n    except TypeError: mapped_iterable = (partial(x) async for x in iterable)\n    results = []\n    async for result in amap_iterable(\n        mapped_iterable, \n        return_when = return_when, \n        concurrency_limit = concurrency_limit\n    ):\n        results.append(await result)\n    return results\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.aiterate","title":"<code>aiterate(func, iterable, *args, return_ordered=True, concurrency_limit=None, **kwargs)</code>  <code>async</code>","text":"<p>Async generator yielding results as soon as underlying tasks finish.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>async def aiterate(\n    self,\n    func: Callable[..., Awaitable[RT]],\n    iterable: Iterable[Any], \n    *args,\n    return_ordered: Optional[bool] = True,\n    concurrency_limit: Optional[int] = None,\n    **kwargs,\n) -&gt; AsyncGenerator[RT, None]:\n    \"\"\"Async generator yielding results as soon as underlying tasks finish.\"\"\"\n    return_when = kwargs.pop('return_when', 'ALL_COMPLETED' if return_ordered else 'FIRST_COMPLETED')\n    concurrency_limit = kwargs.pop('limit', concurrency_limit)\n    func = self.ensure_coro(func)\n    partial = functools.partial(func, *args, **kwargs)\n    try: mapped_iterable = map(partial, iterable)\n    except TypeError: mapped_iterable = (partial(x) async for x in iterable)\n    async for result in amap_iterable(\n        mapped_iterable, \n        return_when = return_when, \n        concurrency_limit = concurrency_limit\n    ):\n        yield await result\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.acmd","title":"<code>acmd(command, output_only=True, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE, output_encoding='UTF-8', output_errors='ignore', *args, **kwargs)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>Execute a shell command asynchronously, optionally returning stdout.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>@staticmethod\nasync def acmd(\n    command: Union[str, List[str]], \n    output_only: bool = True, \n    stdout = asyncio.subprocess.PIPE, \n    stderr = asyncio.subprocess.PIPE, \n    output_encoding: str = 'UTF-8', \n    output_errors: str = 'ignore', \n    *args,\n    **kwargs\n) -&gt; Union[str, asyncio.subprocess.Process]:\n    \"\"\"Execute a shell command asynchronously, optionally returning stdout.\"\"\"\n    if isinstance(command, list): command = ' '.join(command)\n    p = await asyncio.subprocess.create_subprocess_shell(command, *args, stdout = stdout, stderr = stderr, **kwargs)\n    if not output_only: return p\n    stdout, _ = await p.communicate()\n    return stdout.decode(encoding = output_encoding, errors = output_errors).strip()\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.acmd_exec","title":"<code>acmd_exec(command, output_only=True, stdout=asyncio.subprocess.PIPE, stderr=asyncio.subprocess.PIPE, output_encoding='UTF-8', output_errors='ignore', **kwargs)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>Execute a command using <code>create_subprocess_exec</code> and return stdout when requested.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>@staticmethod\nasync def acmd_exec(\n    command: Union[str, List[str]], \n    output_only: bool = True, \n    stdout = asyncio.subprocess.PIPE, \n    stderr = asyncio.subprocess.PIPE, \n    output_encoding: str = 'UTF-8', \n    output_errors: str = 'ignore', \n    **kwargs\n) -&gt; Union[str, asyncio.subprocess.Process]:\n    \"\"\"Execute a command using ``create_subprocess_exec`` and return stdout when requested.\"\"\"\n    if isinstance(command, str): command = shlex.split(command)\n    p = await asyncio.subprocess.create_subprocess_exec(*command, stdout = stdout, stderr = stderr, **kwargs)\n    if not output_only: return p\n    stdout, _ = await p.communicate()\n    return stdout.decode(encoding = output_encoding, errors = output_errors).strip()\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ThreadPool.acmd_stream","title":"<code>acmd_stream(command, stdout_cb, stderr_cb=None, **kwargs)</code>  <code>async</code> <code>staticmethod</code>","text":"<p>Stream subprocess output into the supplied callbacks.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>@staticmethod\nasync def acmd_stream(\n    command: Union[str, List[str]], \n    stdout_cb: t.Union[t.Callable, t.Awaitable], \n    stderr_cb: t.Optional[t.Union[t.Callable, t.Awaitable]] = None,\n    **kwargs \n) -&gt; asyncio.subprocess.Process:\n    \"\"\"Stream subprocess output into the supplied callbacks.\"\"\"\n    return await _stream_subprocess(command, stdout_cb, stderr_cb, **kwargs)\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.amap_iterable","title":"<code>amap_iterable(mapped_iterable, concurrency_limit=None, return_when='FIRST_COMPLETED')</code>  <code>async</code>","text":"<p>Yield tasks from <code>mapped_iterable</code> while respecting <code>concurrency_limit</code>.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>async def amap_iterable(\n    mapped_iterable: Union[Callable[[], Awaitable[Any]], Awaitable[Any], Coroutine[Any, Any, Any], Callable[[], Any]],\n    concurrency_limit: Optional[int] = None,\n    return_when: Optional[str] = 'FIRST_COMPLETED',\n):\n    \"\"\"Yield tasks from ``mapped_iterable`` while respecting ``concurrency_limit``.\"\"\"\n    try:\n        iterable = aiter(mapped_iterable)\n        is_async = True\n    except (TypeError, AttributeError):\n        iterable = iter(mapped_iterable)\n        is_async = False\n\n    iterable_ended: bool = False\n    pending = set()\n    concurrency_limit = get_concurrency_limit() if concurrency_limit is None else concurrency_limit\n    return_when = getattr(asyncio, return_when) if isinstance(return_when, str) else return_when\n\n    while pending or not iterable_ended:\n        while len(pending) &lt; concurrency_limit and not iterable_ended:\n            try: iter_item = await anext(iterable) if is_async else next(iterable)\n            except StopAsyncIteration if is_async else StopIteration:\n                iterable_ended = True\n            else: pending.add(asyncio.ensure_future(iter_item))\n\n        if not pending: return\n        done, pending = await asyncio.wait(pending,  return_when = return_when)\n        while done: yield done.pop()\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.ensure_coro","title":"<code>ensure_coro(func)</code>","text":"<p>Return an awaitable wrapper around <code>func</code> using :class:<code>ThreadPool</code>.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def ensure_coro(\n    func: Callable[..., Any]\n) -&gt; Callable[..., Awaitable[Any]]:\n    \"\"\"Return an awaitable wrapper around ``func`` using :class:`ThreadPool`.\"\"\"\n    if asyncio.iscoroutinefunction(func): return func\n    @functools.wraps(func)\n    async def inner(*args, **kwargs):\n        return await ThreadPool.arun(func, *args, **kwargs)\n    return inner\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.get_concurrency_limit","title":"<code>get_concurrency_limit()</code>","text":"<p>Return the currently configured concurrency limit.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def get_concurrency_limit() -&gt; Optional[int]:\n    \"\"\"Return the currently configured concurrency limit.\"\"\"\n    global _concurrency_limit\n    if _concurrency_limit is None: set_concurrency_limit()\n    return _concurrency_limit\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.is_coro_func","title":"<code>is_coro_func(obj, func_name=None)</code>","text":"<p>Return <code>True</code> when <code>obj</code> (or <code>obj.func_name</code>) is awaitable.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def is_coro_func(obj, func_name: str = None) -&gt; bool:\n    \"\"\"Return ``True`` when ``obj`` (or ``obj.func_name``) is awaitable.\"\"\"\n    try:\n        if inspect.iscoroutinefunction(obj): return True\n        if inspect.isawaitable(obj): return True\n        if func_name and hasattr(obj, func_name) and inspect.iscoroutinefunction(getattr(obj, func_name)):\n            return True\n        return bool(hasattr(obj, '__call__') and inspect.iscoroutinefunction(obj.__call__))\n\n    except Exception:\n        return False\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.set_concurrency_limit","title":"<code>set_concurrency_limit(limit=None)</code>","text":"<p>Override the maximum number of concurrently scheduled background tasks.</p> <p>When <code>limit</code> is <code>None</code> the value falls back to <code>os.cpu_count() * 4</code> for parity with the original implementation.</p> Source code in <code>src/lzl/pool/base.py</code> <pre><code>def set_concurrency_limit(\n    limit: Optional[int] = None\n):\n    \"\"\"Override the maximum number of concurrently scheduled background tasks.\n\n    When ``limit`` is ``None`` the value falls back to ``os.cpu_count() * 4``\n    for parity with the original implementation.\n    \"\"\"\n    global _concurrency_limit\n    if limit is None: limit = os.cpu_count() * 4\n    _concurrency_limit = limit\n</code></pre>"},{"location":"api/lzl/pool/#lzl.pool.is_in_async_loop","title":"<code>is_in_async_loop()</code>","text":"<p>Return <code>True</code> when called from within a running event loop.</p> Source code in <code>src/lzl/pool/utils.py</code> <pre><code>def is_in_async_loop() -&gt; bool:\n    \"\"\"Return ``True`` when called from within a running event loop.\"\"\"\n\n    with contextlib.suppress(Exception):\n        return asyncio.get_event_loop().is_running()\n    return False\n</code></pre>"},{"location":"api/lzl/pool/#overview","title":"Overview","text":"<p>The pool module offers efficient thread pool management for CPU-bound and I/O-bound tasks, with support for both synchronous and asynchronous execution patterns.</p>"},{"location":"api/lzl/pool/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzl/pool/#basic-thread-pool","title":"Basic Thread Pool","text":"<pre><code>from lzl.pool import ThreadPool\n\npool = ThreadPool(max_workers=4)\n\ndef process_item(item):\n    return item * 2\n\n# Submit tasks to the pool\nfutures = [pool.submit(process_item, i) for i in range(10)]\n\n# Get results\nresults = [f.result() for f in futures]\n</code></pre>"},{"location":"api/lzl/pool/#async-context-manager","title":"Async Context Manager","text":"<pre><code>from lzl.pool import ThreadPool\n\nasync def main():\n    async with ThreadPool(max_workers=4) as pool:\n        result = await pool.run_in_thread(blocking_function, arg1, arg2)\n</code></pre>"},{"location":"api/lzl/pool/#batch-processing","title":"Batch Processing","text":"<pre><code>from lzl.pool import ThreadPool\n\ndef process_batch(items):\n    pool = ThreadPool(max_workers=8)\n    results = pool.map(process_item, items)\n    return list(results)\n\nitems = range(100)\nprocessed = process_batch(items)\n</code></pre>"},{"location":"api/lzl/pool/#resource-management","title":"Resource Management","text":"<pre><code>from lzl.pool import ThreadPool\n\n# Pool automatically cleans up threads\nwith ThreadPool(max_workers=4) as pool:\n    pool.submit(task1)\n    pool.submit(task2)\n# Threads are shut down here\n</code></pre>"},{"location":"api/lzl/pool/#features","title":"Features","text":"<ul> <li>Automatic Scaling: Thread count adapts to workload</li> <li>Resource Management: Proper cleanup with context managers</li> <li>Async Integration: Works seamlessly with asyncio</li> <li>Error Handling: Proper exception propagation</li> <li>Monitoring: Track pool status and worker utilization</li> </ul>"},{"location":"api/lzl/pool/#configuration","title":"Configuration","text":"<p>Thread pool behavior can be customized:</p> <ul> <li><code>max_workers</code>: Maximum number of worker threads</li> <li><code>thread_name_prefix</code>: Prefix for thread names (useful for debugging)</li> <li><code>initializer</code>: Function to run when each thread starts</li> <li><code>initargs</code>: Arguments for the initializer function</li> </ul>"},{"location":"api/lzl/proxied/","title":"lzl.proxied - Proxy Objects","text":"<p>The <code>lzl.proxied</code> module provides proxy object patterns for lazy initialization and dynamic behavior.</p>"},{"location":"api/lzl/proxied/#module-reference","title":"Module Reference","text":""},{"location":"api/lzl/proxied/#lzl.proxied","title":"<code>lzl.proxied</code>","text":""},{"location":"api/lzl/proxied/#lzl.proxied.ProxyObject","title":"<code>ProxyObject</code>","text":"<p>               Bases: <code>Generic[ProxyObjT]</code></p> Source code in <code>src/lzl/proxied/base.py</code> <pre><code>class ProxyObject(t.Generic[ProxyObjT]):\n\n    _wrapped = None\n\n    if t.TYPE_CHECKING:\n        def __new__(cls: t.Type[ProxyObjT], *args, **kwargs) -&gt; ProxyObjT:\n            ...\n\n    def __init__(\n        self,\n        obj_cls: t.Optional[t.Union[t.Type[ProxyObjT], str]] = None,\n        obj_getter: t.Optional[t.Union[t.Callable[..., ProxyObjT], str]] = None,\n        obj_args: t.Optional[t.Union[str, t.Callable[..., t.Iterable[t.Any]], t.Iterable[t.Any]]] = None,\n        obj_kwargs: t.Optional[t.Union[str, t.Callable[..., t.Dict[str, t.Any]], t.Dict[str, t.Any]]] = None,\n        obj_initialize: t.Optional[bool] = True,\n        threadsafe: t.Optional[bool] = True,\n    ) -&gt; ProxyObjT:\n        \"\"\"Create a lazily-evaluated proxy.\n\n        Args:\n            obj_cls: Class or import string for the wrapped object.  Used when\n                no ``obj_getter`` is provided.\n            obj_getter: Callable or import string that constructs the wrapped\n                object on demand.\n            obj_args: Positional arguments (or callable returning positional\n                arguments) forwarded to the constructor.\n            obj_kwargs: Keyword arguments (or callable returning keyword\n                arguments) forwarded to the constructor.\n            obj_initialize: When ``True`` the proxy will immediately instantiate\n                ``obj_cls`` on first access; otherwise the class itself is\n                returned.\n            threadsafe: When ``True`` access to the underlying object is\n                protected by a re-entrant lock.\n        \"\"\"\n\n        assert obj_cls or obj_getter, \"Either `obj_cls` or `obj_getter` must be provided\"\n        self._wrapped = empty\n        self.__dict__['__obj_cls_'] = obj_cls\n        # Defer until called.\n        self.__dict__['__obj_getter_'] = obj_getter\n        self.__dict__['__threadlock_'] = None if threadsafe else threading.Lock()\n        self.__dict__['__obj_args_'] = obj_args or []\n        self.__dict__['__obj_kwargs_'] = obj_kwargs or {}\n        self.__dict__['__obj_initialize_'] = obj_initialize\n        # self.__dict__['__debug_enabled_'] = debug_enabled\n        self.__dict__['__last_attrs_'] = {}\n\n\n    @contextlib.contextmanager\n    def _objlock_(self):\n        \"\"\"Context manager guarding the underlying object lock.\"\"\"\n        if self.__dict__['__threadlock_'] is not None:\n            try:\n                with self.__dict__['__threadlock_']:\n                    yield\n            except Exception as e:\n                raise e\n        else:\n            yield\n\n    __getattr__ = new_method_proxy(getattr)\n\n    def __setattr__(self, name, value):\n        if name == \"_wrapped\":\n            # Assign to __dict__ to avoid infinite __setattr__ loops.\n            self.__dict__[\"_wrapped\"] = value\n        else:\n            if self._wrapped is empty:\n                self._setup()\n            setattr(self._wrapped, name, value)\n\n    def __delattr__(self, name):\n        if name == \"_wrapped\":\n            raise TypeError(\"can't delete _wrapped.\")\n        if self._wrapped is empty:\n            self._setup()\n        delattr(self._wrapped, name)\n\n    def __call__(self, *args: t.Any, **kwargs: t.Any) -&gt; t.Any:\n        \"\"\"Proxy call invocations to the wrapped object.\"\"\"\n        if self._wrapped is empty:\n            self._setup()\n        return self._wrapped(*args, **kwargs)\n\n    def _setup_init(self) -&gt; None:\n        \"\"\"Load callables/import strings used to build the underlying object.\"\"\"\n        from lzl.load import lazy_import\n        # from lazyops.utils.helpers import lazy_import\n        if self.__dict__['__obj_args_'] is not None and not isinstance(self.__dict__['__obj_args_'], (list, tuple)):\n            if isinstance(self.__dict__['__obj_args_'], str):\n                self.__dict__['__obj_args_'] = lazy_import(self.__dict__['__obj_args_'])\n            if callable(self.__dict__['__obj_args_']):\n                self.__dict__['__obj_args_'] = self.__dict__['__obj_args_']()\n\n        if self.__dict__['__obj_kwargs_'] is not None and not isinstance(self.__dict__['__obj_kwargs_'], dict):\n            if isinstance(self.__dict__['__obj_kwargs_'], str):\n                self.__dict__['__obj_kwargs_'] = lazy_import(self.__dict__['__obj_kwargs_'])\n            if callable(self.__dict__['__obj_kwargs_']):\n                self.__dict__['__obj_kwargs_'] = self.__dict__['__obj_kwargs_']()\n\n        if self.__dict__['__obj_getter_'] is not None and isinstance(self.__dict__['__obj_getter_'], str):\n            self.__dict__['__obj_getter_'] = lazy_import(self.__dict__['__obj_getter_'])\n\n        elif self.__dict__['__obj_cls_'] is not None and isinstance(self.__dict__['__obj_cls_'], str):\n            self.__dict__['__obj_cls_'] = lazy_import(self.__dict__['__obj_cls_'])\n\n\n    def _setup(self) -&gt; None:\n        \"\"\"Instantiate (or fetch) the wrapped object if it isn't available.\"\"\"\n        # if self.__dict__['__obj_'] is not None: return\n\n        with self._objlock_():\n            self._setup_init()    \n            if self.__dict__['__obj_getter_'] is not None:\n                self.__dict__['_wrapped'] = self.__dict__['__obj_getter_'](*self.__dict__['__obj_args_'], **self.__dict__['__obj_kwargs_'])\n\n            elif self.__dict__['__obj_cls_']:\n                if self.__dict__['__obj_initialize_']:\n                    self.__dict__['_wrapped'] = self.__dict__['__obj_cls_'](*self.__dict__['__obj_args_'], **self.__dict__['__obj_kwargs_'])\n                else:\n                    self.__dict__['_wrapped'] = self.__dict__['__obj_cls_']\n\n\n    # Because we have messed with __class__ below, we confuse pickle as to what\n    # class we are pickling. It also appears to stop __reduce__ from being\n    # called. So, we define __getstate__ in a way that cooperates with the way\n    # that pickle interprets this class.  This fails when the wrapped class is\n    # a builtin, but it is better than nothing.\n    def __getstate__(self):\n        if self._wrapped is empty:\n            self._setup()\n        return self._wrapped.__dict__\n\n    # Python 3.3 will call __reduce__ when pickling; this method is needed\n    # to serialize and deserialize correctly.\n    @classmethod\n    def __newobj__(cls, *args):\n        return cls.__new__(cls, *args)\n\n    def __reduce_ex__(self, proto):\n        return (self.__newobj__, (self.__class__,), self.__getstate__())\n\n\n    def __deepcopy__(self, memo):\n        if self._wrapped is empty:\n            # We have to use type(self), not self.__class__, because the\n            # latter is proxied.\n            result = type(self)()\n            memo[id(self)] = result # type: ignore\n            return result\n        return copy.deepcopy(self._wrapped, memo)\n\n    __bytes__ = new_method_proxy(bytes)\n    __str__ = new_method_proxy(str)\n    __bool__ = new_method_proxy(bool)\n    # Introspection support\n    __dir__ = new_method_proxy(dir)\n\n    # Need to pretend to be the wrapped class, for the sake of objects that\n    # care about this (especially in equality tests)\n    __class__ = property(new_method_proxy(operator.attrgetter(\"__class__\")))\n    __eq__ = new_method_proxy(operator.eq)\n    __ne__ = new_method_proxy(operator.ne)\n    __hash__ = new_method_proxy(hash)\n\n    # Dictionary methods support\n    __getitem__ = new_method_proxy(operator.getitem)\n    __setitem__ = new_method_proxy(operator.setitem)\n    __delitem__ = new_method_proxy(operator.delitem)\n\n    __len__ = new_method_proxy(len)\n    __contains__ = new_method_proxy(operator.contains)\n\n    # Additions for DotObject\n    __gt__ = new_method_proxy(operator.gt)\n    __lt__ = new_method_proxy(operator.lt)\n    __ge__ = new_method_proxy(operator.ge)\n    __le__ = new_method_proxy(operator.le)\n    __add__ = new_method_proxy(operator.add)\n    __radd__ = new_method_proxy(operator.add)\n    __sub__ = new_method_proxy(operator.sub)\n    __rsub__ = new_method_proxy(operator.sub)\n    __mul__ = new_method_proxy(operator.mul)\n    __rmul__ = new_method_proxy(operator.mul)\n    __floordiv__ = new_method_proxy(operator.floordiv)\n    __div__ = new_method_proxy(operator.truediv)\n    __rdiv__ = new_method_proxy(operator.truediv)\n    __truediv__ = new_method_proxy(operator.truediv)\n    __rtruediv__ = new_method_proxy(operator.truediv)\n    __mod__ = new_method_proxy(operator.mod)\n    __rmod__ = new_method_proxy(operator.mod)\n    __pow__ = new_method_proxy(operator.pow)\n    __rpow__ = new_method_proxy(operator.pow)\n    __lshift__ = new_method_proxy(operator.lshift)\n    __rshift__ = new_method_proxy(operator.rshift)\n    __and__ = new_method_proxy(operator.and_)\n    __or__ = new_method_proxy(operator.or_)\n    __xor__ = new_method_proxy(operator.xor)\n</code></pre>"},{"location":"api/lzl/proxied/#lzl.proxied.LockedSingleton","title":"<code>LockedSingleton</code>","text":"<p>Singleton protected by a re-entrant lock for multi-thread scenarios.</p> Source code in <code>src/lzl/proxied/extra.py</code> <pre><code>class LockedSingleton:\n    \"\"\"Singleton protected by a re-entrant lock for multi-thread scenarios.\"\"\"\n\n    __instance: t.ClassVar[\"LockedSingleton | None\"] = None\n    __instance_lock: t.ClassVar[threading.RLock] = threading.RLock()\n\n    def __new__(cls) -&gt; \"LockedSingleton\":  # type: ignore[override]\n        if cls.__instance is None:\n            with cls.__instance_lock:\n                if cls.__instance is None:\n                    cls.__instance = super().__new__(cls)\n        return cls.__instance\n</code></pre>"},{"location":"api/lzl/proxied/#lzl.proxied.Singleton","title":"<code>Singleton</code>","text":"<p>Basic singleton that is safe for single-threaded initialisation.</p> Source code in <code>src/lzl/proxied/extra.py</code> <pre><code>class Singleton:\n    \"\"\"Basic singleton that is safe for single-threaded initialisation.\"\"\"\n\n    __instance: t.ClassVar[\"Singleton | None\"] = None\n\n    def __new__(cls) -&gt; \"Singleton\":  # type: ignore[override]\n        if cls.__instance is None:\n            cls.__instance = super().__new__(cls)\n        return cls.__instance\n</code></pre>"},{"location":"api/lzl/proxied/#lzl.proxied.proxied","title":"<code>proxied(obj_cls=None, obj_getter=None, obj_args=None, obj_kwargs=None, obj_initialize=True, threadsafe=True)</code>","text":"<pre><code>proxied(obj_cls: t.Optional[ObjT] = None, obj_getter: t.Optional[t.Union[t.Callable[..., ObjT], str]] = None, obj_args: t.Optional[t.List[t.Any]] = None, obj_kwargs: t.Optional[t.Dict[str, t.Any]] = None, obj_initialize: t.Optional[bool] = True, threadsafe: t.Optional[bool] = True) -&gt; ObjT\n</code></pre><pre><code>proxied(**kwargs: t.Any) -&gt; t.Callable[..., ObjT]\n</code></pre> <p>Return a proxy that defers constructing <code>obj_cls</code> until first use.</p> Source code in <code>src/lzl/proxied/wraps.py</code> <pre><code>def proxied(\n    obj_cls: t.Optional[ObjT] = None,\n    obj_getter: t.Optional[t.Union[t.Callable[..., ObjT], str]] = None,\n    obj_args: t.Optional[t.List[t.Any]] = None,\n    obj_kwargs: t.Optional[t.Dict[str, t.Any]] = None,\n    obj_initialize: t.Optional[bool] = True,\n    threadsafe: t.Optional[bool] = True,\n) -&gt; t.Union[t.Callable[..., ObjT], ObjT]:\n    \"\"\"Return a proxy that defers constructing ``obj_cls`` until first use.\"\"\"\n\n    if obj_cls is not None:\n        return ProxyObject(\n            obj_cls=obj_cls,\n            obj_getter=obj_getter,\n            obj_args=obj_args,\n            obj_kwargs=obj_kwargs,\n            obj_initialize=obj_initialize,\n            threadsafe=threadsafe,\n        )\n\n    def wrapper(inner_cls: ObjT) -&gt; ProxyObjT:\n        return ProxyObject(\n            obj_cls=inner_cls,\n            obj_getter=obj_getter,\n            obj_args=obj_args,\n            obj_kwargs=obj_kwargs,\n            obj_initialize=obj_initialize,\n            threadsafe=threadsafe,\n        )\n\n    return wrapper\n</code></pre>"},{"location":"api/lzl/proxied/#overview","title":"Overview","text":"<p>Proxy objects allow you to defer initialization of expensive resources until they are actually needed, and to intercept attribute access for dynamic behavior.</p>"},{"location":"api/lzl/proxied/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzl/proxied/#lazy-initialization","title":"Lazy Initialization","text":"<pre><code>from lzl.proxied import ProxyObject\n\nclass ExpensiveResource:\n    def __init__(self):\n        # Expensive initialization\n        self.data = load_large_dataset()\n\n    def process(self):\n        return self.data\n\n# Create a proxy - doesn't initialize yet\nresource = ProxyObject(ExpensiveResource)\n\n# Initialization happens on first access\nresult = resource.process()\n</code></pre>"},{"location":"api/lzl/proxied/#proxy-dictionary","title":"Proxy Dictionary","text":"<pre><code>from lzl.proxied import ProxyDict\n\n# Create a dictionary that proxies access\nregistry = ProxyDict()\n\nregistry['config'] = lambda: load_config()\nregistry['database'] = lambda: connect_database()\n\n# Values are only created when accessed\nconfig = registry['config']  # load_config() called here\n</code></pre>"},{"location":"api/lzl/proxied/#dynamic-behavior","title":"Dynamic Behavior","text":"<pre><code>from lzl.proxied import ProxyObject\n\nclass LoggingProxy(ProxyObject):\n    def __getattr__(self, name):\n        print(f\"Accessing: {name}\")\n        return super().__getattr__(name)\n\nobj = LoggingProxy(MyClass())\nobj.method()  # Logs \"Accessing: method\" before calling\n</code></pre>"},{"location":"api/lzl/proxied/#features","title":"Features","text":"<ul> <li>Deferred Initialization: Resources created only when needed</li> <li>Transparent Access: Proxies behave like the underlying object</li> <li>Interception: Hook into attribute access and method calls</li> <li>Memory Efficient: Avoid loading unnecessary resources</li> </ul>"},{"location":"api/lzl/proxied/#use-cases","title":"Use Cases","text":"<ul> <li>Configuration Management: Lazy load configuration files</li> <li>Database Connections: Defer connection until first query</li> <li>API Clients: Initialize clients only when making requests</li> <li>Resource Pooling: Manage expensive resource allocation</li> </ul>"},{"location":"api/lzl/proxied/#implementation-details","title":"Implementation Details","text":"<p>The proxy pattern uses Python's <code>__getattr__</code> and <code>__setattr__</code> methods to intercept attribute access and forward it to the underlying object after initialization.</p>"},{"location":"api/lzl/require/","title":"lzl.require - Dependency Management","text":"<p>The <code>lzl.require</code> module provides dependency resolution and requirement management utilities.</p>"},{"location":"api/lzl/require/#module-reference","title":"Module Reference","text":""},{"location":"api/lzl/require/#lzl.require","title":"<code>lzl.require</code>","text":""},{"location":"api/lzl/require/#lzl.require.LazyLib","title":"<code>LazyLib</code>","text":"<p>Concrete helper exposing <code>LazyLibType</code> utilities via attribute access.</p> Source code in <code>src/lzl/require/base.py</code> <pre><code>class LazyLib(metaclass=LazyLibType):\n    \"\"\"Concrete helper exposing ``LazyLibType`` utilities via attribute access.\"\"\"\n\n    pass\n</code></pre>"},{"location":"api/lzl/require/#lzl.require.LazyLibType","title":"<code>LazyLibType</code>","text":"<p>               Bases: <code>type</code></p> <p>Metaclass providing lazy import/install helpers.</p> Source code in <code>src/lzl/require/base.py</code> <pre><code>class LazyLibType(type):\n    \"\"\"Metaclass providing lazy import/install helpers.\"\"\"\n\n    @classmethod\n    def install_binary(cls, binary: str, flags: list[str] | None = None) -&gt; None:\n        if cls.get_binary_path(binary):\n            return\n        args = PkgInstall.get_args(binary, flags)\n        subprocess.check_call(args, stdout=subprocess.DEVNULL)\n\n    @classmethod\n    def get_requirement(cls, name: str, clean: bool = True) -&gt; str:\n        name = name.replace(\"-\", \"_\")\n        return name.split(\"=\")[0].replace(\"&gt;\", \"\").replace(\"&lt;\", \"\").strip() if clean else name.strip()\n\n    @classmethod\n    def install_library(cls, library: str, upgrade: bool = True) -&gt; None:\n        if _has_uv():\n            try:\n                pip_exec = [\"uv\", \"pip\", \"install\"]\n                if \"=\" not in library or upgrade:\n                    pip_exec.append(\"--upgrade\")\n                pip_exec.append(library)\n                subprocess.check_call(pip_exec, stdout=subprocess.DEVNULL)\n                return\n            except Exception as exc:  # pragma: no cover - fallback path\n                logger.warning(\"Failed to install %s using uv: %s. Falling back to pip.\", library, exc)\n\n        pip_exec = [sys.executable, \"-m\", \"pip\", \"install\"]\n        if \"=\" not in library or upgrade:\n            pip_exec.append(\"--upgrade\")\n        pip_exec.append(library)\n        subprocess.check_call(pip_exec, stdout=subprocess.DEVNULL)\n\n    @classmethod\n    def install_pip_package(\n        cls,\n        package: str,\n        version: str | None = None,\n        **options: t.Any,\n    ) -&gt; None:\n        if _has_uv():\n            try:\n                if version:\n                    if \"=\" not in version:\n                        version = f\"=={version}\"\n                    package = f\"{package}{version}\"\n                pip_exec = [\"uv\", \"pip\", \"install\", package]\n                for key, value in options.items():\n                    opt = key if key.startswith(\"--\") else f\"--{key}\"\n                    if value and not isinstance(value, bool):\n                        pip_exec.append(f\"{opt}={value}\")\n                    else:\n                        pip_exec.append(opt)\n                subprocess.check_call(pip_exec, stdout=subprocess.DEVNULL)\n                return\n            except Exception as exc:  # pragma: no cover - fallback path\n                logger.warning(\"Failed to install %s using uv: %s. Falling back to pip.\", package, exc)\n\n        pip_exec = [sys.executable, \"-m\", \"pip\", \"install\"]\n        for key, value in options.items():\n            opt = key if key.startswith(\"--\") else f\"--{key}\"\n            if value and not isinstance(value, bool):\n                pip_exec.append(f\"{opt}={value}\")\n            else:\n                pip_exec.append(opt)\n        if version:\n            if \"=\" not in version:\n                version = f\"=={version}\"\n            package = f\"{package}{version}\"\n        pip_exec.append(package)\n        subprocess.check_call(pip_exec, stdout=subprocess.DEVNULL)\n\n    @classmethod\n    def is_available(cls, library: str) -&gt; bool:\n        try:\n            importlib.metadata.version(library)\n            return True\n        except importlib.metadata.PackageNotFoundError:\n            return False\n\n    @classmethod\n    def __is_available(cls, library: str) -&gt; bool:\n        try:\n            import pkg_resources\n        except ImportError:\n            cls.install_pip_package(\"setuptools\")\n            import pkg_resources\n        try:\n            pkg_resources.get_distribution(library)\n            return True\n        except pkg_resources.DistributionNotFound:  # pragma: no cover - legacy path\n            return False\n\n    @classmethod\n    def is_imported(cls, library: str) -&gt; bool:\n        return library in sys.modules\n\n    @classmethod\n    def _ensure_lib_imported(cls, library: str) -&gt; ModuleType:\n        clean_lib = cls.get_requirement(library, True)\n        if not cls.is_imported(clean_lib):\n            sys.modules[clean_lib] = importlib.import_module(clean_lib)\n        return sys.modules[clean_lib]\n\n    @classmethod\n    def _ensure_lib_installed(cls, library: str, pip_name: str | None = None, upgrade: bool = False) -&gt; None:\n        clean_lib = cls.get_requirement(library, True)\n        if not cls.is_available(clean_lib):\n            cls.install_library(pip_name or library, upgrade=upgrade)\n\n    @classmethod\n    def _ensure_binary_installed(cls, binary: str, flags: list[str] | None = None) -&gt; None:\n        cls.install_binary(binary, flags)\n\n    @classmethod\n    def import_lib(\n        cls,\n        library: str,\n        pip_name: str | None = None,\n        resolve_missing: bool = True,\n        require: bool = False,\n        upgrade: bool = False,\n    ) -&gt; ModuleType:\n        clean_lib = cls.get_requirement(library, True)\n        if not cls.is_available(clean_lib):\n            if require and not resolve_missing:\n                raise ImportError(f\"Required Lib {library} is not available.\")\n            if not resolve_missing:\n                return None  # type: ignore[return-value]\n            cls.install_library(pip_name or library, upgrade=upgrade)\n        return cls._ensure_lib_imported(library)\n\n    @classmethod\n    def import_module(\n        cls,\n        name: str,\n        library: str | None = None,\n        pip_name: str | None = None,\n        resolve_missing: bool = True,\n        require: bool = False,\n        upgrade: bool = False,\n    ) -&gt; ModuleType:\n        if library:\n            cls.import_lib(library, pip_name, resolve_missing, require, upgrade)\n            return importlib.import_module(name, package=library)\n        return importlib.import_module(name)\n\n    @classmethod\n    def import_module_attr(\n        cls,\n        name: str,\n        module_name: str,\n        library: str | None = None,\n        pip_name: str | None = None,\n        resolve_missing: bool = True,\n        require: bool = False,\n        upgrade: bool = False,\n    ) -&gt; t.Any:\n        module = cls.import_module(\n            name=module_name,\n            library=library,\n            pip_name=pip_name,\n            resolve_missing=resolve_missing,\n            require=require,\n            upgrade=upgrade,\n        )\n        return getattr(module, name)\n\n    @classmethod\n    def import_cmd(\n        cls,\n        binary: str,\n        resolve_missing: bool = True,\n        require: bool = False,\n        flags: list[str] | None = None,\n    ) -&gt; t.Any:\n        if not cls.is_exec_available(binary):\n            if require and not resolve_missing:\n                raise ImportError(f\"Required Executable {binary} is not available.\")\n            if not resolve_missing:\n                return None\n            cls.install_binary(binary, flags=flags)\n        from lazy.cmd import Cmd  # type: ignore\n\n        return Cmd(binary=binary)\n\n    @classmethod\n    def get_binary_path(cls, executable: str) -&gt; str | None:\n        if \"PATH\" not in os.environ:\n            return None\n        for directory in os.environ[\"PATH\"].split(get_variable_separator()):\n            binary = os.path.abspath(os.path.join(directory, executable))\n            if os.path.isfile(binary) and os.access(binary, os.X_OK):\n                return binary\n        return None\n\n    @classmethod\n    def is_exec_available(cls, executable: str) -&gt; bool:\n        return cls.get_binary_path(executable) is not None\n\n    @staticmethod\n    def reload_module(module: ModuleType) -&gt; ModuleType:\n        return importlib.reload(module)\n\n    @staticmethod\n    def get_cwd(*paths: t.Any, string: bool = True) -&gt; str | pathlib.Path:\n        if not paths:\n            return pathlib.Path.cwd().as_posix() if string else pathlib.Path.cwd()\n        resolved = pathlib.Path.cwd().joinpath(*paths)\n        return resolved.as_posix() if string else resolved\n\n    @staticmethod\n    def run_cmd(cmd: str, raise_error: bool = True) -&gt; str:\n        try:\n            out = subprocess.check_output(cmd, shell=True)\n            return out.decode(\"utf8\") if isinstance(out, bytes) else out.strip()\n        except Exception as exc:\n            if not raise_error:\n                return \"\"\n            raise exc\n\n    def __getattr__(cls, key: str) -&gt; t.Any:\n        if key.startswith(\"is_avail_bin_\") or key.startswith(\"is_avail_exec_\"):\n            exec_name = key.split(\"_\", 3)[-1].strip()\n            return cls.is_exec_available(exec_name)\n        if key.startswith(\"is_avail_lib_\") or key.startswith(\"is_avail_\"):\n            lib_name = key.split(\"is_avail_\")[-1].strip()\n            return cls.is_available(lib_name)\n        if key.startswith(\"is_imported_\"):\n            lib_name = key.split(\"is_imported_\")[-1].strip()\n            return cls.is_imported(lib_name)\n        if key.startswith(\"cmd_\"):\n            binary_name = key.split(\"cmd_\")[-1].strip()\n            return cls.import_cmd(binary=binary_name)\n        return cls.import_lib(key, resolve_missing=False, require=False)\n\n    @classmethod\n    def get(\n        cls,\n        name: str,\n        attr_name: str | None = None,\n        pip_name: str | None = None,\n        resolve_missing: bool = True,\n    ) -&gt; ModuleType | t.Any:\n        parsed = cls._parse_name(name)\n        if attr_name is not None:\n            parsed[\"attr_name\"] = attr_name\n        if pip_name is not None:\n            parsed[\"pip_name\"] = pip_name\n\n        library = t.cast(str, parsed[\"library\"])\n        module_name = parsed[\"module_name\"] or library\n\n        if parsed.get(\"attr_name\"):\n            return cls.import_module_attr(\n                parsed[\"attr_name\"],\n                module_name=module_name,\n                library=library,\n                pip_name=parsed[\"pip_name\"],\n                resolve_missing=resolve_missing,\n            )\n        if parsed.get(\"module_name\"):\n            return cls.import_module(\n                module_name,\n                library=library,\n                pip_name=parsed[\"pip_name\"],\n                resolve_missing=resolve_missing,\n            )\n        return cls.import_lib(library, pip_name=parsed[\"pip_name\"], resolve_missing=resolve_missing)\n\n    @classmethod\n    def _parse_name(cls, name: str) -&gt; dict[str, str | None]:\n        result: dict[str, str | None] = {\n            \"library\": \"\",\n            \"pip_name\": None,\n            \"module_name\": None,\n            \"attr_name\": None,\n        }\n        current = name.strip()\n        if \":\" in current:\n            current, attr = current.split(\":\", 1)\n            result[\"attr_name\"] = attr\n        if \"|\" in current:\n            pip, current = current.split(\"|\", 1)\n            result[\"pip_name\"] = pip\n        if \".\" in current:\n            result[\"module_name\"] = current\n            result[\"library\"] = current.split(\".\", 1)[0]\n        else:\n            result[\"library\"] = current\n        return result\n\n    @classmethod\n    def __getitem__(cls, name: str) -&gt; ModuleType:\n        parsed = cls._parse_name(name)\n        library = t.cast(str, parsed[\"library\"])\n        module_name = parsed[\"module_name\"] or library\n        if parsed.get(\"attr_name\"):\n            return cls.import_module_attr(\n                parsed[\"attr_name\"],\n                module_name=module_name,\n                library=library,\n                pip_name=parsed[\"pip_name\"],\n                resolve_missing=True,\n                require=True,\n            )\n        if parsed.get(\"module_name\"):\n            return cls.import_module(\n                name=parsed[\"module_name\"],\n                library=library,\n                pip_name=parsed[\"pip_name\"],\n                resolve_missing=True,\n                require=True,\n            )\n        return cls.import_lib(\n            library,\n            pip_name=parsed[\"pip_name\"],\n            resolve_missing=True,\n            require=True,\n        )\n</code></pre>"},{"location":"api/lzl/require/#lzl.require.PkgInstall","title":"<code>PkgInstall</code>","text":"<p>Platform-specific installer command templates.</p> Source code in <code>src/lzl/require/base.py</code> <pre><code>class PkgInstall:\n    \"\"\"Platform-specific installer command templates.\"\"\"\n\n    win: str = \"choco install [flags]\"\n    mac: str = \"brew [flags] install\"\n    linux: str = \"apt-get -y [flags] install\"\n\n    @classmethod\n    def get_args(cls, binary: str, flags: list[str] | None = None) -&gt; list[str]:\n        \"\"\"Return a shell-escaped argument list for installing ``binary``.\"\"\"\n\n        flag_str = \" \".join(flags) if flags else \"\"\n        if sys.platform.startswith(\"win\"):\n            command = f\"{cls.win} {binary}\".replace(\"[flags]\", flag_str)\n        elif sys.platform.startswith(\"linux\"):\n            command = f\"{cls.linux} {binary}\".replace(\"[flags]\", flag_str)\n        else:\n            command = f\"{cls.mac} {binary}\".replace(\"[flags]\", flag_str)\n        return shlex.split(command)\n</code></pre>"},{"location":"api/lzl/require/#lzl.require.PkgInstall.get_args","title":"<code>get_args(binary, flags=None)</code>  <code>classmethod</code>","text":"<p>Return a shell-escaped argument list for installing <code>binary</code>.</p> Source code in <code>src/lzl/require/base.py</code> <pre><code>@classmethod\ndef get_args(cls, binary: str, flags: list[str] | None = None) -&gt; list[str]:\n    \"\"\"Return a shell-escaped argument list for installing ``binary``.\"\"\"\n\n    flag_str = \" \".join(flags) if flags else \"\"\n    if sys.platform.startswith(\"win\"):\n        command = f\"{cls.win} {binary}\".replace(\"[flags]\", flag_str)\n    elif sys.platform.startswith(\"linux\"):\n        command = f\"{cls.linux} {binary}\".replace(\"[flags]\", flag_str)\n    else:\n        command = f\"{cls.mac} {binary}\".replace(\"[flags]\", flag_str)\n    return shlex.split(command)\n</code></pre>"},{"location":"api/lzl/require/#overview","title":"Overview","text":"<p>The require module helps manage optional dependencies and ensures that required packages are available before use.</p>"},{"location":"api/lzl/require/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzl/require/#basic-requirement-checking","title":"Basic Requirement Checking","text":"<pre><code>from lzl.require import require\n\n# Ensure a package is available\nrequire('numpy')\nimport numpy as np\n\n# Multiple packages\nrequire(['pandas', 'matplotlib'])\n</code></pre>"},{"location":"api/lzl/require/#optional-dependencies","title":"Optional Dependencies","text":"<pre><code>from lzl.require import optional_require\n\n# Try to import, return None if not available\nnumpy = optional_require('numpy')\n\nif numpy is not None:\n    array = numpy.array([1, 2, 3])\nelse:\n    print(\"NumPy not available, using fallback\")\n</code></pre>"},{"location":"api/lzl/require/#version-checking","title":"Version Checking","text":"<pre><code>from lzl.require import require_version\n\n# Ensure minimum version\nrequire_version('requests', '2.28.0')\n</code></pre>"},{"location":"api/lzl/require/#installation-hints","title":"Installation Hints","text":"<pre><code>from lzl.require import require_with_hint\n\n# Provide installation instructions\nrequire_with_hint(\n    'torch',\n    install_hint=\"Install with: pip install torch\"\n)\n</code></pre>"},{"location":"api/lzl/require/#dependency-groups","title":"Dependency Groups","text":"<pre><code>from lzl.require import require_group\n\n# Check for a group of related dependencies\nrequire_group('ml', [\n    'numpy',\n    'pandas',\n    'scikit-learn',\n])\n</code></pre>"},{"location":"api/lzl/require/#features","title":"Features","text":"<ul> <li>Automatic Checking: Verify dependencies at import time</li> <li>Clear Error Messages: Helpful installation instructions</li> <li>Version Validation: Ensure compatible versions are installed</li> <li>Optional Dependencies: Graceful degradation when optional packages are missing</li> <li>Group Management: Manage related dependencies together</li> </ul>"},{"location":"api/lzl/require/#use-cases","title":"Use Cases","text":"<ul> <li>Optional Features: Features that require additional packages</li> <li>Plugin Systems: Validate plugin dependencies</li> <li>Environment Validation: Ensure development environment is properly configured</li> <li>Documentation: Make dependencies explicit in code</li> </ul>"},{"location":"api/lzl/require/#best-practices","title":"Best Practices","text":"<ol> <li>Check requirements early in your module's initialization</li> <li>Provide clear installation instructions in error messages</li> <li>Use optional requirements for non-critical features</li> <li>Group related dependencies for easier management</li> </ol>"},{"location":"api/lzl/sysmon/","title":"lzl.sysmon - System Monitoring","text":"<p>The <code>lzl.sysmon</code> module provides system monitoring and resource tracking capabilities.</p>"},{"location":"api/lzl/sysmon/#module-reference","title":"Module Reference","text":""},{"location":"api/lzl/sysmon/#lzl.sysmon","title":"<code>lzl.sysmon</code>","text":""},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext","title":"<code>WorkerContext</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Capture CPU/GPU statistics around long-running worker operations.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>class WorkerContext(abc.ABC):\n    \"\"\"Capture CPU/GPU statistics around long-running worker operations.\"\"\"\n\n    def __init__(self, **kwargs: t.Any) -&gt; None:\n        \"\"\"Initialise timer/logging helpers used during metric collection.\"\"\"\n\n        from lzl.logging import logger\n        from lzo.utils import Timer\n        from lzo.utils.system import aget_gpu_data, get_gpu_data, get_resource_data\n        from pydantic.types import ByteSize\n\n        self._extra: dict[str, t.Any] = {}\n        self._kwargs = kwargs\n\n        self.timer = Timer\n        self.logger = logger\n        self._bs = ByteSize\n\n        self.get_gpu_data = get_gpu_data\n        self.aget_gpu_data = aget_gpu_data\n        self.get_resource_data = get_resource_data\n\n        self.t = self.timer()\n        self.idx: int = 0\n        self.num_batches: int = 0\n        self.last_batch_size: int = 0\n        self.total_duration: float = 0.0\n        self.last_duration: float = 0.0\n\n        self.last_resource_data: t.Optional[\"ResourceData\"] = None\n        self.last_gpu_data: t.Optional[\"GPUData\"] = None\n\n    # ------------------------------------------------------------------\n    # Properties\n    # ------------------------------------------------------------------\n\n    @eproperty\n    def torch_device_name(self) -&gt; str:\n        \"\"\"Return the active PyTorch device name.\"\"\"\n\n        from lzo.utils.system import get_torch_device_name\n\n        return get_torch_device_name()\n\n    @eproperty\n    def torch_device(self):\n        \"\"\"Return the active PyTorch device instance.\"\"\"\n\n        from lzo.utils.system import get_torch_device\n\n        return get_torch_device()\n\n    @eproperty\n    def has_gpu(self) -&gt; bool:\n        \"\"\"Return ``True`` when the runtime is backed by CUDA.\"\"\"\n\n        return self.torch_device_name.startswith(\"cuda\")\n\n    @eproperty\n    def model_name(self) -&gt; t.Optional[str]:\n        \"\"\"Optional model identifier surfaced in log prefixes.\"\"\"\n\n        return self._extra.get(\"model_name\")\n\n    @eproperty\n    def worker_name(self) -&gt; t.Optional[str]:\n        \"\"\"Optional worker identifier used in log prefixes.\"\"\"\n\n        return self._extra.get(\"worker_name\")\n\n    # ------------------------------------------------------------------\n    # GPU helpers\n    # ------------------------------------------------------------------\n\n    def build_gpu_data_string(\n        self,\n        current_usage: \"GPUData\",\n        compare: bool | None = None,\n        previous_usage: \"GPUData\" | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        \"\"\"Format GPU usage statistics with optional comparison.\"\"\"\n\n        curr_mem_used = current_usage[\"memory_used\"]\n        curr_mem_percent = current_usage[\"utilization_memory\"]\n        curr_mem_total = current_usage[\"memory_total\"]\n        gpu_name = current_usage[\"name\"]\n\n        previous_usage = previous_usage or self.last_gpu_data\n        self.last_gpu_data = current_usage\n\n        if compare and previous_usage:\n            comparison = {\n                \"memory_used\": self._bs(curr_mem_used - previous_usage[\"memory_used\"]),\n                \"utilization_memory\": curr_mem_percent - previous_usage[\"utilization_memory\"],\n            }\n            if not colored:\n                return (\n                    f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; \"\n                    f\"{curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} + \"\n                    f\"{comparison['memory_used'].human_readable()} \"\n                    f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n                )\n            return (\n                f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; |y|{curr_mem_used.human_readable()}|e| / \"\n                f\"|g|{curr_mem_total.human_readable()}|e| + |r|{comparison['memory_used'].human_readable()}|e| \"\n                f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n            )\n\n        if not colored:\n            return (\n                f\"{gpu_name}: {curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} \"\n                f\"({curr_mem_percent}%)\"\n            )\n        return (\n            f\"{gpu_name}: |y|{curr_mem_used.human_readable()}|e| / |g|{curr_mem_total.human_readable()}|e| \"\n            f\"({curr_mem_percent}%)\"\n        )\n\n    def get_gpu_memory(\n        self,\n        compare: bool | None = None,\n        previous_usage: \"GPUData\" | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        \"\"\"Return formatted GPU usage, optionally comparing against a prior sample.\"\"\"\n\n        current_usage = self.get_gpu_data()\n        if not current_usage:\n            return None\n        return self.build_gpu_data_string(\n            current_usage,\n            compare=compare,\n            previous_usage=previous_usage,\n            colored=colored,\n        )\n\n    async def aget_gpu_memory(\n        self,\n        compare: bool | None = None,\n        previous_usage: \"GPUData\" | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        \"\"\"Asynchronous variant of :meth:`get_gpu_memory`.\"\"\"\n\n        current_usage = await self.aget_gpu_data()\n        if not current_usage:\n            return None\n        return self.build_gpu_data_string(\n            current_usage,\n            compare=compare,\n            previous_usage=previous_usage,\n            colored=colored,\n        )\n\n    # ------------------------------------------------------------------\n    # Resource helpers\n    # ------------------------------------------------------------------\n\n    def build_resource_data_string(\n        self,\n        current_usage: \"ResourceData\",\n        compare: bool | None = None,\n        previous_usage: \"ResourceData\" | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        \"\"\"Format CPU/RAM usage into a human-readable string.\"\"\"\n\n        curr_mem_used = current_usage[\"memory_used\"]\n        curr_mem_percent = current_usage[\"utilization_memory\"]\n        curr_mem_total = current_usage[\"memory_total\"]\n        curr_cpu_percent = current_usage[\"utilization_cpu\"]\n        num_cpu = current_usage[\"cpu_count\"]\n\n        previous_usage = previous_usage or self.last_resource_data\n        self.last_resource_data = current_usage\n\n        if compare and previous_usage:\n            comparison = {\n                \"memory_used\": self._bs(curr_mem_used - previous_usage[\"memory_used\"]),\n            }\n            base = (\n                f\"{num_cpu} vCPU: {curr_cpu_percent}% | RAM: {previous_usage['memory_used'].human_readable()} -&gt; \"\n                f\"{curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} + \"\n                f\"{comparison['memory_used'].human_readable()} ({curr_mem_percent}%)\"\n            )\n            if not colored:\n                return base\n            return (\n                f\"{num_cpu} vCPU: |g|{curr_cpu_percent}%|e| | RAM: {previous_usage['memory_used'].human_readable()} -&gt; \"\n                f\"|y|{curr_mem_used.human_readable()}|e| / |g|{curr_mem_total.human_readable()}|e| + \"\n                f\"|r|{comparison['memory_used'].human_readable()}|e| ({curr_mem_percent}%)\"\n            )\n\n        if not colored:\n            return (\n                f\"{num_cpu} vCPU: {curr_cpu_percent}% | RAM: {curr_mem_used.human_readable()} / \"\n                f\"{curr_mem_total.human_readable()} ({curr_mem_percent}%)\"\n            )\n        return (\n            f\"{num_cpu} vCPU: |g|{curr_cpu_percent}%|e| RAM: |y|{curr_mem_used.human_readable()}|e| / \"\n            f\"|g|{curr_mem_total.human_readable()}|e| ({curr_mem_percent}%)\"\n        )\n\n    def get_resource_info(\n        self,\n        compare: bool | None = None,\n        previous_usage: \"ResourceData\" | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        \"\"\"Return formatted CPU/memory usage snapshot.\"\"\"\n\n        current_usage = self.get_resource_data()\n        if not current_usage:\n            return None\n        return self.build_resource_data_string(\n            current_usage,\n            compare=compare,\n            previous_usage=previous_usage,\n            colored=colored,\n        )\n    # ------------------------------------------------------------------\n    # Context managers\n    # ------------------------------------------------------------------\n\n    @contextlib.contextmanager\n    def inference_mode(\n        self,\n        batch_size: int | None = 1,\n        obj_name: str | None = None,\n        enable_gc: bool | None = None,\n        enable_summary: bool | None = None,\n        hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n        **kwargs: t.Any,\n    ):\n        \"\"\"Wrap a block of inference work with resource logging.\"\"\"\n\n        ts = self.timer(format_ms=True, format_short=1)\n        start_text = \"Starting Inference\"\n        if obj_name:\n            start_text += f\" for |g|{obj_name}|e|\"\n        start_text += f\" ({batch_size})\"\n        self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n        start_resource_data = self.get_resource_data()\n        start_gpu_data = self.get_gpu_data() if self.has_gpu else None\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - logging path\n            self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n            raise\n        finally:\n            total_s = ts.total\n            self.total_duration += total_s\n            self.last_duration = total_s\n            self.num_batches += batch_size or 0\n            self.idx += 1\n\n            end_text = \"Inference Completed\"\n            if obj_name:\n                end_text += f\" for |g|{obj_name}|e|\"\n            end_text += f\" ({batch_size}) in {ts.total_s}\"\n            if enable_gc:\n                gc.collect()\n\n            self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n            if enable_summary:\n                self.logger.info(\n                    f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                    f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n                self.logger.info(\n                    f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                    f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n            self.logger.info(\n                self.get_resource_info(compare=True, previous_usage=start_resource_data, colored=True),\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n            if self.has_gpu and start_gpu_data is not None:\n                self.logger.info(\n                    self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n\n    @contextlib.asynccontextmanager\n    async def ainference_mode(\n        self,\n        batch_size: int | None = 1,\n        obj_name: str | None = None,\n        enable_gc: bool | None = None,\n        enable_summary: bool | None = None,\n        hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n        **kwargs: t.Any,\n    ):\n        \"\"\"Async variant of :meth:`inference_mode`.\"\"\"\n\n        ts = self.timer(format_ms=True, format_short=1)\n        start_text = \"Starting Inference\"\n        if obj_name:\n            start_text += f\" for |g|{obj_name}|e|\"\n        start_text += f\" ({batch_size})\"\n        self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n        start_resource_data = self.get_resource_data()\n        start_gpu_data = await self.aget_gpu_data() if self.has_gpu else None\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - logging path\n            self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n            raise\n        finally:\n            total_s = ts.total\n            self.total_duration += total_s\n            self.last_duration = total_s\n            self.num_batches += batch_size or 0\n            self.idx += 1\n\n            end_text = \"Inference Completed\"\n            if obj_name:\n                end_text += f\" for |g|{obj_name}|e|\"\n            end_text += f\" ({batch_size}) in {ts.total_s}\"\n            if enable_gc:\n                gc.collect()\n\n            self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n            if enable_summary:\n                self.logger.info(\n                    f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                    f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n                self.logger.info(\n                    f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                    f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n            self.logger.info(\n                self.get_resource_info(compare=True, previous_usage=start_resource_data, colored=True),\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n            if self.has_gpu and start_gpu_data is not None:\n                self.logger.info(\n                    await self.aget_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n\n    @contextlib.contextmanager\n    def capture(\n        self,\n        message: str | None = None,\n        prefix: str | None = None,\n        hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n        **kwargs: t.Any,\n    ):\n        \"\"\"Capture resources across an arbitrary block of work.\"\"\"\n\n        ts = self.timer(format_ms=True, format_short=1)\n        base_name = self.model_name or self.worker_name\n        prefix = f\"{prefix} {base_name}\" if prefix else base_name\n        start_resource_data = self.get_resource_data()\n        start_gpu_data = self.get_gpu_data() if self.has_gpu else None\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - logging path\n            self.logger.trace(f\"[{prefix}] Error in Capture: \", exc, hook=hook)\n            raise\n        finally:\n            message = (message or \"Capture Complete\") + f\" in {ts.total_s}\"\n            self.logger.info(message, colored=True, prefix=prefix, hook=hook)\n            self.logger.info(\n                self.get_resource_info(compare=True, previous_usage=start_resource_data, colored=True),\n                colored=True,\n                prefix=prefix,\n                hook=hook,\n            )\n            if self.has_gpu and start_gpu_data is not None:\n                self.logger.info(\n                    self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                    colored=True,\n                    prefix=prefix,\n                    hook=hook,\n                )\n\n    @contextlib.contextmanager\n    def start_task(\n        self,\n        batch_size: int | None = 1,\n        obj_name: str | None = None,\n        task_name: str | None = None,\n        enable_gc: bool | None = None,\n        enable_summary: bool | None = None,\n        hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n        **kwargs: t.Any,\n    ):\n        \"\"\"Track a generic worker task, logging CPU/GPU usage.\"\"\"\n\n        ts = self.timer(format_ms=True, format_short=1)\n        base_name = self.model_name or self.worker_name\n        start_text = \"Starting Task\"\n        if task_name:\n            start_text += f\": |g|{task_name}|e|\"\n        if obj_name:\n            start_text += f\" for |g|{obj_name}|e|\"\n        start_text += f\" ({batch_size})\"\n        self.logger.info(start_text, prefix=base_name, colored=True, hook=hook)\n        start_gpu_data = self.get_gpu_data() if self.has_gpu else None\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - logging path\n            self.logger.trace(f\"[{base_name}] Error in Task: \", exc, hook=hook)\n            raise\n        finally:\n            total_s = ts.total\n            self.total_duration += total_s\n            self.last_duration = total_s\n            self.num_batches += batch_size or 0\n            self.idx += 1\n\n            end_text = \"Task Completed\"\n            if task_name:\n                end_text += f\": |g|{task_name}|e|\"\n            if obj_name:\n                end_text += f\" for |g|{obj_name}|e|\"\n            end_text += f\" ({batch_size}) in {ts.total_s}\"\n            if enable_gc:\n                gc.collect()\n\n            self.logger.info(end_text, colored=True, prefix=base_name, hook=hook)\n            if enable_summary:\n                self.logger.info(\n                    f\"Total Tasks: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                    f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                    colored=True,\n                    prefix=base_name,\n                    hook=hook,\n                )\n                self.logger.info(\n                    f\"Total Task Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                    f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                    colored=True,\n                    prefix=base_name,\n                    hook=hook,\n                )\n            self.logger.info(\n                self.get_resource_info(compare=False, colored=True),\n                colored=True,\n                prefix=base_name,\n                hook=hook,\n            )\n            if self.has_gpu and start_gpu_data is not None:\n                self.logger.info(\n                    self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                    colored=True,\n                    prefix=base_name,\n                    hook=hook,\n                )\n\n    def __enter__(self) -&gt; \"WorkerContext\":\n        return self\n\n    def __exit__(self, exc_type, exc, tb) -&gt; None:\n        return None\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.torch_device_name","title":"<code>torch_device_name()</code>","text":"<p>Return the active PyTorch device name.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@eproperty\ndef torch_device_name(self) -&gt; str:\n    \"\"\"Return the active PyTorch device name.\"\"\"\n\n    from lzo.utils.system import get_torch_device_name\n\n    return get_torch_device_name()\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.torch_device","title":"<code>torch_device()</code>","text":"<p>Return the active PyTorch device instance.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@eproperty\ndef torch_device(self):\n    \"\"\"Return the active PyTorch device instance.\"\"\"\n\n    from lzo.utils.system import get_torch_device\n\n    return get_torch_device()\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.has_gpu","title":"<code>has_gpu()</code>","text":"<p>Return <code>True</code> when the runtime is backed by CUDA.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@eproperty\ndef has_gpu(self) -&gt; bool:\n    \"\"\"Return ``True`` when the runtime is backed by CUDA.\"\"\"\n\n    return self.torch_device_name.startswith(\"cuda\")\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.model_name","title":"<code>model_name()</code>","text":"<p>Optional model identifier surfaced in log prefixes.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@eproperty\ndef model_name(self) -&gt; t.Optional[str]:\n    \"\"\"Optional model identifier surfaced in log prefixes.\"\"\"\n\n    return self._extra.get(\"model_name\")\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.worker_name","title":"<code>worker_name()</code>","text":"<p>Optional worker identifier used in log prefixes.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@eproperty\ndef worker_name(self) -&gt; t.Optional[str]:\n    \"\"\"Optional worker identifier used in log prefixes.\"\"\"\n\n    return self._extra.get(\"worker_name\")\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.build_gpu_data_string","title":"<code>build_gpu_data_string(current_usage, compare=None, previous_usage=None, colored=False)</code>","text":"<p>Format GPU usage statistics with optional comparison.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>def build_gpu_data_string(\n    self,\n    current_usage: \"GPUData\",\n    compare: bool | None = None,\n    previous_usage: \"GPUData\" | None = None,\n    colored: bool = False,\n) -&gt; t.Optional[str]:\n    \"\"\"Format GPU usage statistics with optional comparison.\"\"\"\n\n    curr_mem_used = current_usage[\"memory_used\"]\n    curr_mem_percent = current_usage[\"utilization_memory\"]\n    curr_mem_total = current_usage[\"memory_total\"]\n    gpu_name = current_usage[\"name\"]\n\n    previous_usage = previous_usage or self.last_gpu_data\n    self.last_gpu_data = current_usage\n\n    if compare and previous_usage:\n        comparison = {\n            \"memory_used\": self._bs(curr_mem_used - previous_usage[\"memory_used\"]),\n            \"utilization_memory\": curr_mem_percent - previous_usage[\"utilization_memory\"],\n        }\n        if not colored:\n            return (\n                f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; \"\n                f\"{curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} + \"\n                f\"{comparison['memory_used'].human_readable()} \"\n                f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n            )\n        return (\n            f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; |y|{curr_mem_used.human_readable()}|e| / \"\n            f\"|g|{curr_mem_total.human_readable()}|e| + |r|{comparison['memory_used'].human_readable()}|e| \"\n            f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n        )\n\n    if not colored:\n        return (\n            f\"{gpu_name}: {curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} \"\n            f\"({curr_mem_percent}%)\"\n        )\n    return (\n        f\"{gpu_name}: |y|{curr_mem_used.human_readable()}|e| / |g|{curr_mem_total.human_readable()}|e| \"\n        f\"({curr_mem_percent}%)\"\n    )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.get_gpu_memory","title":"<code>get_gpu_memory(compare=None, previous_usage=None, colored=False)</code>","text":"<p>Return formatted GPU usage, optionally comparing against a prior sample.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>def get_gpu_memory(\n    self,\n    compare: bool | None = None,\n    previous_usage: \"GPUData\" | None = None,\n    colored: bool = False,\n) -&gt; t.Optional[str]:\n    \"\"\"Return formatted GPU usage, optionally comparing against a prior sample.\"\"\"\n\n    current_usage = self.get_gpu_data()\n    if not current_usage:\n        return None\n    return self.build_gpu_data_string(\n        current_usage,\n        compare=compare,\n        previous_usage=previous_usage,\n        colored=colored,\n    )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.aget_gpu_memory","title":"<code>aget_gpu_memory(compare=None, previous_usage=None, colored=False)</code>  <code>async</code>","text":"<p>Asynchronous variant of :meth:<code>get_gpu_memory</code>.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>async def aget_gpu_memory(\n    self,\n    compare: bool | None = None,\n    previous_usage: \"GPUData\" | None = None,\n    colored: bool = False,\n) -&gt; t.Optional[str]:\n    \"\"\"Asynchronous variant of :meth:`get_gpu_memory`.\"\"\"\n\n    current_usage = await self.aget_gpu_data()\n    if not current_usage:\n        return None\n    return self.build_gpu_data_string(\n        current_usage,\n        compare=compare,\n        previous_usage=previous_usage,\n        colored=colored,\n    )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.build_resource_data_string","title":"<code>build_resource_data_string(current_usage, compare=None, previous_usage=None, colored=False)</code>","text":"<p>Format CPU/RAM usage into a human-readable string.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>def build_resource_data_string(\n    self,\n    current_usage: \"ResourceData\",\n    compare: bool | None = None,\n    previous_usage: \"ResourceData\" | None = None,\n    colored: bool = False,\n) -&gt; t.Optional[str]:\n    \"\"\"Format CPU/RAM usage into a human-readable string.\"\"\"\n\n    curr_mem_used = current_usage[\"memory_used\"]\n    curr_mem_percent = current_usage[\"utilization_memory\"]\n    curr_mem_total = current_usage[\"memory_total\"]\n    curr_cpu_percent = current_usage[\"utilization_cpu\"]\n    num_cpu = current_usage[\"cpu_count\"]\n\n    previous_usage = previous_usage or self.last_resource_data\n    self.last_resource_data = current_usage\n\n    if compare and previous_usage:\n        comparison = {\n            \"memory_used\": self._bs(curr_mem_used - previous_usage[\"memory_used\"]),\n        }\n        base = (\n            f\"{num_cpu} vCPU: {curr_cpu_percent}% | RAM: {previous_usage['memory_used'].human_readable()} -&gt; \"\n            f\"{curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} + \"\n            f\"{comparison['memory_used'].human_readable()} ({curr_mem_percent}%)\"\n        )\n        if not colored:\n            return base\n        return (\n            f\"{num_cpu} vCPU: |g|{curr_cpu_percent}%|e| | RAM: {previous_usage['memory_used'].human_readable()} -&gt; \"\n            f\"|y|{curr_mem_used.human_readable()}|e| / |g|{curr_mem_total.human_readable()}|e| + \"\n            f\"|r|{comparison['memory_used'].human_readable()}|e| ({curr_mem_percent}%)\"\n        )\n\n    if not colored:\n        return (\n            f\"{num_cpu} vCPU: {curr_cpu_percent}% | RAM: {curr_mem_used.human_readable()} / \"\n            f\"{curr_mem_total.human_readable()} ({curr_mem_percent}%)\"\n        )\n    return (\n        f\"{num_cpu} vCPU: |g|{curr_cpu_percent}%|e| RAM: |y|{curr_mem_used.human_readable()}|e| / \"\n        f\"|g|{curr_mem_total.human_readable()}|e| ({curr_mem_percent}%)\"\n    )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.get_resource_info","title":"<code>get_resource_info(compare=None, previous_usage=None, colored=False)</code>","text":"<p>Return formatted CPU/memory usage snapshot.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>def get_resource_info(\n    self,\n    compare: bool | None = None,\n    previous_usage: \"ResourceData\" | None = None,\n    colored: bool = False,\n) -&gt; t.Optional[str]:\n    \"\"\"Return formatted CPU/memory usage snapshot.\"\"\"\n\n    current_usage = self.get_resource_data()\n    if not current_usage:\n        return None\n    return self.build_resource_data_string(\n        current_usage,\n        compare=compare,\n        previous_usage=previous_usage,\n        colored=colored,\n    )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.inference_mode","title":"<code>inference_mode(batch_size=1, obj_name=None, enable_gc=None, enable_summary=None, hook=None, **kwargs)</code>","text":"<p>Wrap a block of inference work with resource logging.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@contextlib.contextmanager\ndef inference_mode(\n    self,\n    batch_size: int | None = 1,\n    obj_name: str | None = None,\n    enable_gc: bool | None = None,\n    enable_summary: bool | None = None,\n    hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n    **kwargs: t.Any,\n):\n    \"\"\"Wrap a block of inference work with resource logging.\"\"\"\n\n    ts = self.timer(format_ms=True, format_short=1)\n    start_text = \"Starting Inference\"\n    if obj_name:\n        start_text += f\" for |g|{obj_name}|e|\"\n    start_text += f\" ({batch_size})\"\n    self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n    start_resource_data = self.get_resource_data()\n    start_gpu_data = self.get_gpu_data() if self.has_gpu else None\n    try:\n        yield\n    except Exception as exc:  # pragma: no cover - logging path\n        self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n        raise\n    finally:\n        total_s = ts.total\n        self.total_duration += total_s\n        self.last_duration = total_s\n        self.num_batches += batch_size or 0\n        self.idx += 1\n\n        end_text = \"Inference Completed\"\n        if obj_name:\n            end_text += f\" for |g|{obj_name}|e|\"\n        end_text += f\" ({batch_size}) in {ts.total_s}\"\n        if enable_gc:\n            gc.collect()\n\n        self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n        if enable_summary:\n            self.logger.info(\n                f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n            self.logger.info(\n                f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n        self.logger.info(\n            self.get_resource_info(compare=True, previous_usage=start_resource_data, colored=True),\n            colored=True,\n            prefix=self.model_name,\n            hook=hook,\n        )\n        if self.has_gpu and start_gpu_data is not None:\n            self.logger.info(\n                self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.ainference_mode","title":"<code>ainference_mode(batch_size=1, obj_name=None, enable_gc=None, enable_summary=None, hook=None, **kwargs)</code>  <code>async</code>","text":"<p>Async variant of :meth:<code>inference_mode</code>.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@contextlib.asynccontextmanager\nasync def ainference_mode(\n    self,\n    batch_size: int | None = 1,\n    obj_name: str | None = None,\n    enable_gc: bool | None = None,\n    enable_summary: bool | None = None,\n    hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n    **kwargs: t.Any,\n):\n    \"\"\"Async variant of :meth:`inference_mode`.\"\"\"\n\n    ts = self.timer(format_ms=True, format_short=1)\n    start_text = \"Starting Inference\"\n    if obj_name:\n        start_text += f\" for |g|{obj_name}|e|\"\n    start_text += f\" ({batch_size})\"\n    self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n    start_resource_data = self.get_resource_data()\n    start_gpu_data = await self.aget_gpu_data() if self.has_gpu else None\n    try:\n        yield\n    except Exception as exc:  # pragma: no cover - logging path\n        self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n        raise\n    finally:\n        total_s = ts.total\n        self.total_duration += total_s\n        self.last_duration = total_s\n        self.num_batches += batch_size or 0\n        self.idx += 1\n\n        end_text = \"Inference Completed\"\n        if obj_name:\n            end_text += f\" for |g|{obj_name}|e|\"\n        end_text += f\" ({batch_size}) in {ts.total_s}\"\n        if enable_gc:\n            gc.collect()\n\n        self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n        if enable_summary:\n            self.logger.info(\n                f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n            self.logger.info(\n                f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n        self.logger.info(\n            self.get_resource_info(compare=True, previous_usage=start_resource_data, colored=True),\n            colored=True,\n            prefix=self.model_name,\n            hook=hook,\n        )\n        if self.has_gpu and start_gpu_data is not None:\n            self.logger.info(\n                await self.aget_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.capture","title":"<code>capture(message=None, prefix=None, hook=None, **kwargs)</code>","text":"<p>Capture resources across an arbitrary block of work.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@contextlib.contextmanager\ndef capture(\n    self,\n    message: str | None = None,\n    prefix: str | None = None,\n    hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n    **kwargs: t.Any,\n):\n    \"\"\"Capture resources across an arbitrary block of work.\"\"\"\n\n    ts = self.timer(format_ms=True, format_short=1)\n    base_name = self.model_name or self.worker_name\n    prefix = f\"{prefix} {base_name}\" if prefix else base_name\n    start_resource_data = self.get_resource_data()\n    start_gpu_data = self.get_gpu_data() if self.has_gpu else None\n    try:\n        yield\n    except Exception as exc:  # pragma: no cover - logging path\n        self.logger.trace(f\"[{prefix}] Error in Capture: \", exc, hook=hook)\n        raise\n    finally:\n        message = (message or \"Capture Complete\") + f\" in {ts.total_s}\"\n        self.logger.info(message, colored=True, prefix=prefix, hook=hook)\n        self.logger.info(\n            self.get_resource_info(compare=True, previous_usage=start_resource_data, colored=True),\n            colored=True,\n            prefix=prefix,\n            hook=hook,\n        )\n        if self.has_gpu and start_gpu_data is not None:\n            self.logger.info(\n                self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                colored=True,\n                prefix=prefix,\n                hook=hook,\n            )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.WorkerContext.start_task","title":"<code>start_task(batch_size=1, obj_name=None, task_name=None, enable_gc=None, enable_summary=None, hook=None, **kwargs)</code>","text":"<p>Track a generic worker task, logging CPU/GPU usage.</p> Source code in <code>src/lzl/sysmon/workerctx.py</code> <pre><code>@contextlib.contextmanager\ndef start_task(\n    self,\n    batch_size: int | None = 1,\n    obj_name: str | None = None,\n    task_name: str | None = None,\n    enable_gc: bool | None = None,\n    enable_summary: bool | None = None,\n    hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n    **kwargs: t.Any,\n):\n    \"\"\"Track a generic worker task, logging CPU/GPU usage.\"\"\"\n\n    ts = self.timer(format_ms=True, format_short=1)\n    base_name = self.model_name or self.worker_name\n    start_text = \"Starting Task\"\n    if task_name:\n        start_text += f\": |g|{task_name}|e|\"\n    if obj_name:\n        start_text += f\" for |g|{obj_name}|e|\"\n    start_text += f\" ({batch_size})\"\n    self.logger.info(start_text, prefix=base_name, colored=True, hook=hook)\n    start_gpu_data = self.get_gpu_data() if self.has_gpu else None\n    try:\n        yield\n    except Exception as exc:  # pragma: no cover - logging path\n        self.logger.trace(f\"[{base_name}] Error in Task: \", exc, hook=hook)\n        raise\n    finally:\n        total_s = ts.total\n        self.total_duration += total_s\n        self.last_duration = total_s\n        self.num_batches += batch_size or 0\n        self.idx += 1\n\n        end_text = \"Task Completed\"\n        if task_name:\n            end_text += f\": |g|{task_name}|e|\"\n        if obj_name:\n            end_text += f\" for |g|{obj_name}|e|\"\n        end_text += f\" ({batch_size}) in {ts.total_s}\"\n        if enable_gc:\n            gc.collect()\n\n        self.logger.info(end_text, colored=True, prefix=base_name, hook=hook)\n        if enable_summary:\n            self.logger.info(\n                f\"Total Tasks: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                colored=True,\n                prefix=base_name,\n                hook=hook,\n            )\n            self.logger.info(\n                f\"Total Task Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                colored=True,\n                prefix=base_name,\n                hook=hook,\n            )\n        self.logger.info(\n            self.get_resource_info(compare=False, colored=True),\n            colored=True,\n            prefix=base_name,\n            hook=hook,\n        )\n        if self.has_gpu and start_gpu_data is not None:\n            self.logger.info(\n                self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                colored=True,\n                prefix=base_name,\n                hook=hook,\n            )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext","title":"<code>MLContext</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Capture GPU statistics during ML inference workloads.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>class MLContext(abc.ABC):\n    \"\"\"Capture GPU statistics during ML inference workloads.\"\"\"\n\n    def __init__(self, **kwargs: t.Any) -&gt; None:\n        \"\"\"Initialise timer/logging helpers used for metric collection.\"\"\"\n\n        from lzl.logging import logger\n        from lzo.utils import Timer\n        from lzo.utils.system import aget_gpu_data, get_gpu_data\n        from pydantic.types import ByteSize\n\n        self._extra: dict[str, t.Any] = {}\n        self._kwargs = kwargs\n\n        self.timer = Timer\n        self.logger = logger\n        self._bs = ByteSize\n\n        self.get_gpu_data = get_gpu_data\n        self.aget_gpu_data = aget_gpu_data\n\n        self.t = self.timer()\n        self.idx: int = 0\n        self.num_batches: int = 0\n        self.last_batch_size: int = 0\n        self.total_duration: float = 0.0\n        self.last_duration: float = 0.0\n        self.last_gpu_data: t.Optional[t.Dict[str, t.Any]] = None\n\n    @eproperty\n    def torch_device_name(self) -&gt; str:\n        \"\"\"Return the active PyTorch device name.\"\"\"\n\n        from lzo.utils.system import get_torch_device_name\n\n        return get_torch_device_name()\n\n    @eproperty\n    def torch_device(self):\n        \"\"\"Return the active PyTorch device instance.\"\"\"\n\n        from lzo.utils.system import get_torch_device\n\n        return get_torch_device()\n\n    @eproperty\n    def has_gpu(self) -&gt; bool:\n        \"\"\"Return ``True`` when the runtime has a CUDA device.\"\"\"\n\n        return self.torch_device_name.startswith(\"cuda\")\n\n    @eproperty\n    def model_name(self) -&gt; t.Optional[str]:\n        \"\"\"Optional model identifier used in log prefixes.\"\"\"\n\n        return self._extra.get(\"model_name\")\n\n    def build_gpu_data_string(\n        self,\n        current_usage: GPUData,\n        compare: bool | None = None,\n        previous_usage: GPUData | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        \"\"\"Format GPU usage details with optional comparison.\"\"\"\n\n        curr_mem_used = current_usage[\"memory_used\"]\n        curr_mem_percent = current_usage[\"utilization_memory\"]\n        curr_mem_total = current_usage[\"memory_total\"]\n        gpu_name = current_usage[\"name\"]\n\n        previous_usage = previous_usage or self.last_gpu_data\n        self.last_gpu_data = current_usage\n        if compare and previous_usage:\n            comparison: GPUData = {\n                \"memory_used\": self._bs(curr_mem_used - previous_usage[\"memory_used\"]),\n                \"utilization_memory\": curr_mem_percent - previous_usage[\"utilization_memory\"],\n            }\n            if not colored:\n                return (\n                    f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; \"\n                    f\"{curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} + \"\n                    f\"{comparison['memory_used'].human_readable()} \"\n                    f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n                )\n            return (\n                f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; |y|{curr_mem_used.human_readable()}|e| / \"\n                f\"|g|{curr_mem_total.human_readable()}|e| + |r|{comparison['memory_used'].human_readable()}|e| \"\n                f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n            )\n        if not colored:\n            return (\n                f\"{gpu_name}: {curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} \"\n                f\"({curr_mem_percent}%)\"\n            )\n        return (\n            f\"{gpu_name}: |y|{curr_mem_used.human_readable()}|e| / |g|{curr_mem_total.human_readable()}|e| \"\n            f\"({curr_mem_percent}%)\"\n        )\n\n    def get_gpu_memory(\n        self,\n        compare: bool | None = None,\n        previous_usage: GPUData | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        current_usage = self.get_gpu_data()\n        if not current_usage:\n            return None\n        return self.build_gpu_data_string(\n            current_usage,\n            compare=compare,\n            previous_usage=previous_usage,\n            colored=colored,\n        )\n\n    async def aget_gpu_memory(\n        self,\n        compare: bool | None = None,\n        previous_usage: GPUData | None = None,\n        colored: bool = False,\n    ) -&gt; t.Optional[str]:\n        current_usage = await self.aget_gpu_data()\n        if not current_usage:\n            return None\n        return self.build_gpu_data_string(\n            current_usage,\n            compare=compare,\n            previous_usage=previous_usage,\n            colored=colored,\n        )\n\n    @contextlib.contextmanager\n    def inference_mode(\n        self,\n        batch_size: int | None = 1,\n        obj_name: str | None = None,\n        enable_gc: bool | None = None,\n        enable_summary: bool | None = None,\n        hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n        **kwargs: t.Any,\n    ):\n        \"\"\"Track a block of inference work, logging GPU usage before/after.\"\"\"\n\n        ts = self.timer(format_ms=True, format_short=1)\n        start_text = \"Starting Inference\"\n        if obj_name:\n            start_text += f\" for |g|{obj_name}|e|\"\n        start_text += f\" ({batch_size})\"\n        self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n        start_gpu_data = self.get_gpu_data()\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - logging path\n            self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n            raise\n        finally:\n            total_s = ts.total\n            self.total_duration += total_s\n            self.last_duration = total_s\n            self.num_batches += batch_size or 0\n            self.idx += 1\n\n            end_text = \"Inference Completed\"\n            if obj_name:\n                end_text += f\" for |g|{obj_name}|e|\"\n            end_text += f\" ({batch_size}) in {ts.total_s}\"\n            if enable_gc:\n                gc.collect()\n\n            self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n            if enable_summary:\n                self.logger.info(\n                    f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                    f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n                self.logger.info(\n                    f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                    f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n            self.logger.info(\n                self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n\n    @contextlib.asynccontextmanager\n    async def ainference_mode(\n        self,\n        batch_size: int | None = 1,\n        obj_name: str | None = None,\n        enable_gc: bool | None = None,\n        enable_summary: bool | None = None,\n        hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n        **kwargs: t.Any,\n    ):\n        \"\"\"Async variant of :meth:`inference_mode`.\"\"\"\n\n        ts = self.timer(format_ms=True, format_short=1)\n        start_text = \"Starting Inference\"\n        if obj_name:\n            start_text += f\" for |g|{obj_name}|e|\"\n        start_text += f\" ({batch_size})\"\n        self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n        start_gpu_data = await self.aget_gpu_data()\n        try:\n            yield\n        except Exception as exc:  # pragma: no cover - logging path\n            self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n            raise\n        finally:\n            total_s = ts.total\n            self.total_duration += total_s\n            self.last_duration = total_s\n            self.num_batches += batch_size or 0\n            self.idx += 1\n\n            end_text = \"Inference Completed\"\n            if obj_name:\n                end_text += f\" for |g|{obj_name}|e|\"\n            end_text += f\" ({batch_size}) in {ts.total_s}\"\n            if enable_gc:\n                gc.collect()\n\n            self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n            if enable_summary:\n                self.logger.info(\n                    f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                    f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n                self.logger.info(\n                    f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                    f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                    colored=True,\n                    prefix=self.model_name,\n                    hook=hook,\n                )\n            self.logger.info(\n                await self.aget_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.torch_device_name","title":"<code>torch_device_name()</code>","text":"<p>Return the active PyTorch device name.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>@eproperty\ndef torch_device_name(self) -&gt; str:\n    \"\"\"Return the active PyTorch device name.\"\"\"\n\n    from lzo.utils.system import get_torch_device_name\n\n    return get_torch_device_name()\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.torch_device","title":"<code>torch_device()</code>","text":"<p>Return the active PyTorch device instance.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>@eproperty\ndef torch_device(self):\n    \"\"\"Return the active PyTorch device instance.\"\"\"\n\n    from lzo.utils.system import get_torch_device\n\n    return get_torch_device()\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.has_gpu","title":"<code>has_gpu()</code>","text":"<p>Return <code>True</code> when the runtime has a CUDA device.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>@eproperty\ndef has_gpu(self) -&gt; bool:\n    \"\"\"Return ``True`` when the runtime has a CUDA device.\"\"\"\n\n    return self.torch_device_name.startswith(\"cuda\")\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.model_name","title":"<code>model_name()</code>","text":"<p>Optional model identifier used in log prefixes.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>@eproperty\ndef model_name(self) -&gt; t.Optional[str]:\n    \"\"\"Optional model identifier used in log prefixes.\"\"\"\n\n    return self._extra.get(\"model_name\")\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.build_gpu_data_string","title":"<code>build_gpu_data_string(current_usage, compare=None, previous_usage=None, colored=False)</code>","text":"<p>Format GPU usage details with optional comparison.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>def build_gpu_data_string(\n    self,\n    current_usage: GPUData,\n    compare: bool | None = None,\n    previous_usage: GPUData | None = None,\n    colored: bool = False,\n) -&gt; t.Optional[str]:\n    \"\"\"Format GPU usage details with optional comparison.\"\"\"\n\n    curr_mem_used = current_usage[\"memory_used\"]\n    curr_mem_percent = current_usage[\"utilization_memory\"]\n    curr_mem_total = current_usage[\"memory_total\"]\n    gpu_name = current_usage[\"name\"]\n\n    previous_usage = previous_usage or self.last_gpu_data\n    self.last_gpu_data = current_usage\n    if compare and previous_usage:\n        comparison: GPUData = {\n            \"memory_used\": self._bs(curr_mem_used - previous_usage[\"memory_used\"]),\n            \"utilization_memory\": curr_mem_percent - previous_usage[\"utilization_memory\"],\n        }\n        if not colored:\n            return (\n                f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; \"\n                f\"{curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} + \"\n                f\"{comparison['memory_used'].human_readable()} \"\n                f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n            )\n        return (\n            f\"{gpu_name}: {previous_usage['memory_used'].human_readable()} -&gt; |y|{curr_mem_used.human_readable()}|e| / \"\n            f\"|g|{curr_mem_total.human_readable()}|e| + |r|{comparison['memory_used'].human_readable()}|e| \"\n            f\"({comparison['utilization_memory']} -&gt; {curr_mem_percent}%)\"\n        )\n    if not colored:\n        return (\n            f\"{gpu_name}: {curr_mem_used.human_readable()} / {curr_mem_total.human_readable()} \"\n            f\"({curr_mem_percent}%)\"\n        )\n    return (\n        f\"{gpu_name}: |y|{curr_mem_used.human_readable()}|e| / |g|{curr_mem_total.human_readable()}|e| \"\n        f\"({curr_mem_percent}%)\"\n    )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.inference_mode","title":"<code>inference_mode(batch_size=1, obj_name=None, enable_gc=None, enable_summary=None, hook=None, **kwargs)</code>","text":"<p>Track a block of inference work, logging GPU usage before/after.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>@contextlib.contextmanager\ndef inference_mode(\n    self,\n    batch_size: int | None = 1,\n    obj_name: str | None = None,\n    enable_gc: bool | None = None,\n    enable_summary: bool | None = None,\n    hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n    **kwargs: t.Any,\n):\n    \"\"\"Track a block of inference work, logging GPU usage before/after.\"\"\"\n\n    ts = self.timer(format_ms=True, format_short=1)\n    start_text = \"Starting Inference\"\n    if obj_name:\n        start_text += f\" for |g|{obj_name}|e|\"\n    start_text += f\" ({batch_size})\"\n    self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n    start_gpu_data = self.get_gpu_data()\n    try:\n        yield\n    except Exception as exc:  # pragma: no cover - logging path\n        self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n        raise\n    finally:\n        total_s = ts.total\n        self.total_duration += total_s\n        self.last_duration = total_s\n        self.num_batches += batch_size or 0\n        self.idx += 1\n\n        end_text = \"Inference Completed\"\n        if obj_name:\n            end_text += f\" for |g|{obj_name}|e|\"\n        end_text += f\" ({batch_size}) in {ts.total_s}\"\n        if enable_gc:\n            gc.collect()\n\n        self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n        if enable_summary:\n            self.logger.info(\n                f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n            self.logger.info(\n                f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n        self.logger.info(\n            self.get_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n            colored=True,\n            prefix=self.model_name,\n            hook=hook,\n        )\n</code></pre>"},{"location":"api/lzl/sysmon/#lzl.sysmon.MLContext.ainference_mode","title":"<code>ainference_mode(batch_size=1, obj_name=None, enable_gc=None, enable_summary=None, hook=None, **kwargs)</code>  <code>async</code>","text":"<p>Async variant of :meth:<code>inference_mode</code>.</p> Source code in <code>src/lzl/sysmon/mlctx.py</code> <pre><code>@contextlib.asynccontextmanager\nasync def ainference_mode(\n    self,\n    batch_size: int | None = 1,\n    obj_name: str | None = None,\n    enable_gc: bool | None = None,\n    enable_summary: bool | None = None,\n    hook: t.Optional[t.Callable[[dict[str, t.Any]], None]] = None,\n    **kwargs: t.Any,\n):\n    \"\"\"Async variant of :meth:`inference_mode`.\"\"\"\n\n    ts = self.timer(format_ms=True, format_short=1)\n    start_text = \"Starting Inference\"\n    if obj_name:\n        start_text += f\" for |g|{obj_name}|e|\"\n    start_text += f\" ({batch_size})\"\n    self.logger.info(start_text, prefix=self.model_name, colored=True, hook=hook)\n    start_gpu_data = await self.aget_gpu_data()\n    try:\n        yield\n    except Exception as exc:  # pragma: no cover - logging path\n        self.logger.trace(f\"[{self.model_name}] Error in Inference Mode: \", exc, hook=hook)\n        raise\n    finally:\n        total_s = ts.total\n        self.total_duration += total_s\n        self.last_duration = total_s\n        self.num_batches += batch_size or 0\n        self.idx += 1\n\n        end_text = \"Inference Completed\"\n        if obj_name:\n            end_text += f\" for |g|{obj_name}|e|\"\n        end_text += f\" ({batch_size}) in {ts.total_s}\"\n        if enable_gc:\n            gc.collect()\n\n        self.logger.info(end_text, colored=True, prefix=self.model_name, hook=hook)\n        if enable_summary:\n            self.logger.info(\n                f\"Total Requests: |g|{self.idx}|e|. Total Batches Handled: |g|{self.num_batches}|e|. \"\n                f\"Handled Last Batch Size of |g|{self.last_batch_size}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n            self.logger.info(\n                f\"Total Inference Duration: |g|{self.timer.pformat_duration(self.total_duration)}|e|. \"\n                f\"Total Time Alive: |g|{self.t.total_s}|e|\",\n                colored=True,\n                prefix=self.model_name,\n                hook=hook,\n            )\n        self.logger.info(\n            await self.aget_gpu_memory(compare=True, previous_usage=start_gpu_data, colored=True),\n            colored=True,\n            prefix=self.model_name,\n            hook=hook,\n        )\n</code></pre>"},{"location":"api/lzl/sysmon/#overview","title":"Overview","text":"<p>The system monitoring module tracks CPU, memory, GPU, and other system resources, providing real-time insights into application performance.</p>"},{"location":"api/lzl/sysmon/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzl/sysmon/#basic-resource-monitoring","title":"Basic Resource Monitoring","text":"<pre><code>from lzl.sysmon import get_system_info\n\ninfo = get_system_info()\nprint(f\"CPU Usage: {info.cpu_percent}%\")\nprint(f\"Memory Usage: {info.memory_percent}%\")\nprint(f\"Available Memory: {info.memory_available_mb}MB\")\n</code></pre>"},{"location":"api/lzl/sysmon/#context-based-monitoring","title":"Context-Based Monitoring","text":"<pre><code>from lzl.sysmon import SystemMonitor\n\nwith SystemMonitor() as monitor:\n    # Your code here\n    expensive_operation()\n\n# Monitor automatically captures metrics\nprint(f\"Peak memory: {monitor.peak_memory_mb}MB\")\nprint(f\"Average CPU: {monitor.avg_cpu_percent}%\")\n</code></pre>"},{"location":"api/lzl/sysmon/#gpu-monitoring","title":"GPU Monitoring","text":"<pre><code>from lzl.sysmon import get_gpu_info\n\nif get_gpu_info().available:\n    gpu = get_gpu_info()\n    print(f\"GPU Memory: {gpu.memory_used_mb}MB / {gpu.memory_total_mb}MB\")\n    print(f\"GPU Utilization: {gpu.utilization_percent}%\")\n</code></pre>"},{"location":"api/lzl/sysmon/#worker-context","title":"Worker Context","text":"<pre><code>from lzl.sysmon import WorkerContext\n\n# Track resources for a worker process\nwith WorkerContext(worker_id=\"worker-1\") as ctx:\n    process_batch(data)\n\nprint(f\"Worker {ctx.worker_id} used {ctx.peak_memory_mb}MB\")\n</code></pre>"},{"location":"api/lzl/sysmon/#ml-context","title":"ML Context","text":"<pre><code>from lzl.sysmon import MLContext\n\n# Specialized monitoring for ML workloads\nwith MLContext(model_name=\"resnet50\") as ctx:\n    train_model(model, data)\n\nprint(f\"Training used {ctx.peak_gpu_memory_mb}MB GPU memory\")\nprint(f\"Total training time: {ctx.elapsed_seconds}s\")\n</code></pre>"},{"location":"api/lzl/sysmon/#features","title":"Features","text":"<ul> <li>Real-Time Monitoring: Track system resources in real-time</li> <li>GPU Support: Monitor NVIDIA GPUs with CUDA</li> <li>Context Managers: Easy integration with Python context managers</li> <li>Metrics Collection: Capture peak, average, and current metrics</li> <li>Low Overhead: Minimal performance impact</li> <li>Cross-Platform: Works on Linux, macOS, and Windows</li> </ul>"},{"location":"api/lzl/sysmon/#metrics-tracked","title":"Metrics Tracked","text":"<ul> <li>CPU: Utilization percentage, core count, load average</li> <li>Memory: Used, available, percentage, swap usage</li> <li>GPU: Memory usage, utilization, temperature (NVIDIA)</li> <li>Disk: I/O operations, read/write speeds</li> <li>Network: Bandwidth usage, connections</li> </ul>"},{"location":"api/lzl/sysmon/#use-cases","title":"Use Cases","text":"<ul> <li>Performance Profiling: Identify resource bottlenecks</li> <li>Capacity Planning: Understand resource requirements</li> <li>ML Training: Monitor GPU utilization during training</li> <li>Production Monitoring: Track application resource usage</li> <li>Debugging: Identify memory leaks and resource issues</li> </ul>"},{"location":"api/lzl/types/","title":"lzl.types - Type Definitions","text":"<p>The <code>lzl.types</code> module provides common type aliases, protocols, and utility types.</p>"},{"location":"api/lzl/types/#common-types","title":"Common Types","text":""},{"location":"api/lzl/types/#lzl.types.common","title":"<code>lzl.types.common</code>","text":"<p>Common Types</p>"},{"location":"api/lzl/types/#lzl.types.common.StrEnumMeta","title":"<code>StrEnumMeta</code>","text":"<p>               Bases: <code>EnumMeta</code></p> Source code in <code>src/lzl/types/common.py</code> <pre><code>class StrEnumMeta(EnumMeta):\n\n    @singledispatchmethod\n    def __getitem__(self, key):\n        return super().__getitem__(key)\n\n    @__getitem__.register\n    def _(self, index: int):\n        return list(self)[index]\n\n    @property\n    def _reversed_members_(cls) -&gt; Dict[str, str]:\n        \"\"\"\n        Returns the reversed members\n        \"\"\"\n        return {v: k for k, v in cls.__members__.items()}\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.StrEnum","title":"<code>StrEnum</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> <p>StrEnum is a string enum that allows for case-insensitive comparisons</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>class StrEnum(str, Enum, metaclass=StrEnumMeta):\n    \"\"\"\n    StrEnum is a string enum that allows for case-insensitive comparisons\n    \"\"\"\n\n    def __eq__(self, other: Any) -&gt; bool:\n        return self.value.lower() == other.lower() if \\\n            isinstance(other, str) else \\\n                super().__eq__(other)\n\n    def __ne__(self, other: Any) -&gt; bool:\n        return self.value.lower() != other.lower() if \\\n            isinstance(other, str) else \\\n                super().__ne__(other)\n\n    def __str__(self) -&gt; str:\n        return str.__str__(self)\n\n    def __hash__(self) -&gt; int:\n        return id(self)\n\n    @classmethod\n    def extend(cls, name: str, value: Any):\n        \"\"\"\n        Dynamically extends the enum with a new member.\n\n        Requires the `aenum` package to be installed.\n\n        Args:\n            name: The name of the new enum member.\n            value: The value of the new enum member.\n\n        Raises:\n            ImportError: If `aenum` is not installed.\n        \"\"\"\n        if not _EXTEND_SUPPORTED: raise ImportError('aenum is not installed. Please install it to use this feature')\n        extend_enum(cls, name, value)\n\n    @classmethod\n    def __validate__(cls, value: Union[str, 'StrEnumT']) -&gt; 'StrEnumT':\n        \"\"\"\n        Validates and converts a value to the corresponding Enum member.\n\n        It attempts to match the value against member names (case-insensitive)\n        and values.\n\n        Args:\n            value: The value to validate.\n\n        Returns:\n            The matching Enum member.\n\n        Raises:\n            ValueError: If the value cannot be mapped to any Enum member.\n        \"\"\"\n        if hasattr(value, '__members__'): return value\n        # return cls(value.__name__)\n        reversed_members = {v: k for k, v in cls.__members__.items()}\n        if value in cls.__members__:\n            return cls.__members__[value]\n        elif value in reversed_members:\n            return cls.__members__[reversed_members[value]]\n        elif value.lower() in cls.__members__:\n            return cls.__members__[value.lower()]\n        elif value.capitalize() in cls.__members__:\n            return cls.__members__[value.capitalize()]\n        elif value.upper() in cls.__members__:\n            return cls.__members__[value.upper()]\n        elif value.lower() in reversed_members:\n            return cls.__members__[reversed_members[value.lower()]]\n        raise ValueError(f\"Invalid {cls.__name__} value: {value}\")\n\n    if TYPE_CHECKING:\n        from pydantic_core import core_schema, SchemaSerializer\n        from pydantic.annotated_handlers import GetCoreSchemaHandler, GetJsonSchemaHandler\n        from pydantic.json_schema import JsonSchemaValue\n\n    if PYDANTIC_VERSION == 2:\n\n        @classmethod\n        def __get_pydantic_json_schema__(\n            cls, \n            _core_schema: 'core_schema.CoreSchema', \n            _handler: 'GetJsonSchemaHandler'\n        ) -&gt; 'JsonSchemaValue':\n            \"\"\"\n            Get the Pydantic JSON Schema for the given source\n            \"\"\"\n            return {'enum': [m.name for m in cls], 'type': 'string'}\n\n        @classmethod\n        def __get_pydantic_core_schema__(\n            cls, \n            source: type[Any], \n            handler: 'GetCoreSchemaHandler'\n        ) -&gt; 'core_schema.CoreSchema':\n            \"\"\"\n            Get the Pydantic CoreSchema for the given source\n            \"\"\"\n            from pydantic_core import core_schema, SchemaSerializer\n            schema = core_schema.no_info_after_validator_function(\n                cls.__validate__,\n                core_schema.any_schema(),\n                serialization = core_schema.plain_serializer_function_ser_schema(_get_serialized_value),\n                # serialization = core_schema.plain_serializer_function_ser_schema(lambda x: x),\n            )\n            cls.__pydantic_serializer__ = SchemaSerializer(schema)\n            return schema\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.StrEnum.extend","title":"<code>extend(name, value)</code>  <code>classmethod</code>","text":"<p>Dynamically extends the enum with a new member.</p> <p>Requires the <code>aenum</code> package to be installed.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the new enum member.</p> required <code>value</code> <code>Any</code> <p>The value of the new enum member.</p> required <p>Raises:</p> Type Description <code>ImportError</code> <p>If <code>aenum</code> is not installed.</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef extend(cls, name: str, value: Any):\n    \"\"\"\n    Dynamically extends the enum with a new member.\n\n    Requires the `aenum` package to be installed.\n\n    Args:\n        name: The name of the new enum member.\n        value: The value of the new enum member.\n\n    Raises:\n        ImportError: If `aenum` is not installed.\n    \"\"\"\n    if not _EXTEND_SUPPORTED: raise ImportError('aenum is not installed. Please install it to use this feature')\n    extend_enum(cls, name, value)\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.UpperStrEnum","title":"<code>UpperStrEnum</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>UpperStrEnum is a string enum that allows for case-insensitive comparisons</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>class UpperStrEnum(StrEnum):\n    \"\"\"\n    UpperStrEnum is a string enum that allows for case-insensitive comparisons\n    \"\"\"\n\n    def __eq__(self, other: Any) -&gt; bool:\n        return self.value.upper() == other.upper() if \\\n            isinstance(other, str) else \\\n                super().__eq__(other)\n\n    def __ne__(self, other: Any) -&gt; bool:\n        return self.value.upper() != other.upper() if \\\n            isinstance(other, str) else \\\n                super().__ne__(other)\n\n\n    def __str__(self) -&gt; str:\n        return str.__str__(self)\n\n    def __hash__(self) -&gt; int:\n        return id(self)\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv","title":"<code>AppEnv</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>src/lzl/types/common.py</code> <pre><code>class AppEnv(str, Enum):\n    CICD = \"cicd\"\n    DEVELOPMENT = \"development\"\n    STAGING = \"staging\"\n    PRODUCTION = \"production\"\n    LOCAL = \"local\"\n    TEST = \"test\"\n\n    @classmethod\n    def from_env(cls, env_value: str) -&gt; \"AppEnv\":\n        \"\"\"\n        Determines the AppEnv from a string value, handling various formats and partial matches.\n\n        Args:\n            env_value: The string value to parse (e.g., \"production\", \"prod\", \"ci/cd\").\n\n        Returns:\n            The corresponding AppEnv member.\n\n        Raises:\n            ValueError: If the value cannot be mapped to a known environment.\n        \"\"\"\n        env_value = env_value.lower()\n        if \"cicd\" in env_value or \"ci/cd\" in env_value: return cls.CICD\n        if \"prod\" in env_value: return cls.PRODUCTION\n        if \"dev\" in env_value: return cls.DEVELOPMENT\n        if \"staging\" in env_value: return cls.STAGING\n        if \"local\" in env_value: return cls.LOCAL\n        if \"test\" in env_value: return cls.TEST\n        raise ValueError(f\"Invalid app environment: {env_value} ({type(env_value)})\")\n\n    @classmethod\n    def from_hostname(cls, hostname: str) -&gt; \"AppEnv\":\n        \"\"\"\n        Get the app environment from the hostname\n        \"\"\"\n        hostname = hostname.lower()\n        if \"dev\" in hostname: return cls.DEVELOPMENT\n        if \"staging\" in hostname: return cls.STAGING\n        if \"test\" in hostname: return cls.TEST\n        return cls.LOCAL if \"local\" in hostname else cls.PRODUCTION\n\n\n    @classmethod\n    def from_module_name(cls, module_name: str) -&gt; 'AppEnv':\n        \"\"\"\n        Retrieves the app environment\n        \"\"\"\n        module_name = module_name.replace(\".\", \"_\").upper()\n        for key in {\n            \"SERVER_ENV\",\n            f\"{module_name}_ENV\",\n            \"APP_ENV\",\n            \"ENVIRONMENT\",\n        }:\n            if env_value := os.getenv(key):\n                return cls.from_env(env_value)\n\n        from lzo.utils.system import is_in_kubernetes, get_host_name\n        if is_in_kubernetes():\n            hn = get_host_name()\n            try:\n                parts = hn.split(\"-\")\n                for p in parts:\n                    if all(\n                        e not in p.lower()\n                        for e in {'development', 'test', 'staging', 'local', 'dev', 'prod', 'production'}\n                    ):\n                        parts.remove(p)\n                return cls.from_env(parts[0]) if len(parts) &gt; 0 else cls.PRODUCTION\n                # return cls.PRODUCTION\n                # return cls.from_env(parts[2]) if len(parts) &gt; 3 else cls.PRODUCTION\n            except Exception as e:\n                return cls.from_hostname(hn)\n\n        return cls.LOCAL\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"\n        Equality operator\n        \"\"\"\n        if isinstance(other, str): return self.value == other.lower()\n        return self.value == other.value if isinstance(other, AppEnv) else False\n\n    @property\n    def is_devel(self) -&gt; bool:\n        \"\"\"\n        Returns True if the app environment is development\n        \"\"\"\n        return self in [self.LOCAL, self.CICD, self.DEVELOPMENT, self.STAGING, self.TEST]\n\n    @property\n    def is_local(self) -&gt; bool:\n        \"\"\"\n        Returns True if the app environment is local\n        \"\"\"\n        return self in [self.LOCAL, self.CICD]\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"\n        Returns the name in lower\n        \"\"\"\n        return self.value.lower()\n\n    @property\n    def short_name(self) -&gt; str:\n        \"\"\"\n        Returns the short name in lower\n        \"\"\"\n        if self == self.DEVELOPMENT: return 'dev'\n        return 'prod' if self == self.PRODUCTION else self.name\n\n    def select(self, values: Dict[Union[str, 'AppEnv'], Any], default: Optional[Any] = None) -&gt; Any:\n        \"\"\"\n        Returns the value for the app env\n        \"\"\"\n        return next((value for key, value in values.items() if key == self), default)\n\n\n    @classmethod\n    def extend(cls, name: str, value: Any):\n        \"\"\"\n        Extends the enum with a new value\n        \"\"\"\n        if not _EXTEND_SUPPORTED: raise ImportError('aenum is not installed. Please install it to use this feature')\n        extend_enum(cls, name, value)\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.is_devel","title":"<code>is_devel</code>  <code>property</code>","text":"<p>Returns True if the app environment is development</p>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.is_local","title":"<code>is_local</code>  <code>property</code>","text":"<p>Returns True if the app environment is local</p>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.name","title":"<code>name</code>  <code>property</code>","text":"<p>Returns the name in lower</p>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.short_name","title":"<code>short_name</code>  <code>property</code>","text":"<p>Returns the short name in lower</p>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.from_env","title":"<code>from_env(env_value)</code>  <code>classmethod</code>","text":"<p>Determines the AppEnv from a string value, handling various formats and partial matches.</p> <p>Parameters:</p> Name Type Description Default <code>env_value</code> <code>str</code> <p>The string value to parse (e.g., \"production\", \"prod\", \"ci/cd\").</p> required <p>Returns:</p> Type Description <code>AppEnv</code> <p>The corresponding AppEnv member.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the value cannot be mapped to a known environment.</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef from_env(cls, env_value: str) -&gt; \"AppEnv\":\n    \"\"\"\n    Determines the AppEnv from a string value, handling various formats and partial matches.\n\n    Args:\n        env_value: The string value to parse (e.g., \"production\", \"prod\", \"ci/cd\").\n\n    Returns:\n        The corresponding AppEnv member.\n\n    Raises:\n        ValueError: If the value cannot be mapped to a known environment.\n    \"\"\"\n    env_value = env_value.lower()\n    if \"cicd\" in env_value or \"ci/cd\" in env_value: return cls.CICD\n    if \"prod\" in env_value: return cls.PRODUCTION\n    if \"dev\" in env_value: return cls.DEVELOPMENT\n    if \"staging\" in env_value: return cls.STAGING\n    if \"local\" in env_value: return cls.LOCAL\n    if \"test\" in env_value: return cls.TEST\n    raise ValueError(f\"Invalid app environment: {env_value} ({type(env_value)})\")\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.from_hostname","title":"<code>from_hostname(hostname)</code>  <code>classmethod</code>","text":"<p>Get the app environment from the hostname</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef from_hostname(cls, hostname: str) -&gt; \"AppEnv\":\n    \"\"\"\n    Get the app environment from the hostname\n    \"\"\"\n    hostname = hostname.lower()\n    if \"dev\" in hostname: return cls.DEVELOPMENT\n    if \"staging\" in hostname: return cls.STAGING\n    if \"test\" in hostname: return cls.TEST\n    return cls.LOCAL if \"local\" in hostname else cls.PRODUCTION\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.from_module_name","title":"<code>from_module_name(module_name)</code>  <code>classmethod</code>","text":"<p>Retrieves the app environment</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef from_module_name(cls, module_name: str) -&gt; 'AppEnv':\n    \"\"\"\n    Retrieves the app environment\n    \"\"\"\n    module_name = module_name.replace(\".\", \"_\").upper()\n    for key in {\n        \"SERVER_ENV\",\n        f\"{module_name}_ENV\",\n        \"APP_ENV\",\n        \"ENVIRONMENT\",\n    }:\n        if env_value := os.getenv(key):\n            return cls.from_env(env_value)\n\n    from lzo.utils.system import is_in_kubernetes, get_host_name\n    if is_in_kubernetes():\n        hn = get_host_name()\n        try:\n            parts = hn.split(\"-\")\n            for p in parts:\n                if all(\n                    e not in p.lower()\n                    for e in {'development', 'test', 'staging', 'local', 'dev', 'prod', 'production'}\n                ):\n                    parts.remove(p)\n            return cls.from_env(parts[0]) if len(parts) &gt; 0 else cls.PRODUCTION\n            # return cls.PRODUCTION\n            # return cls.from_env(parts[2]) if len(parts) &gt; 3 else cls.PRODUCTION\n        except Exception as e:\n            return cls.from_hostname(hn)\n\n    return cls.LOCAL\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.select","title":"<code>select(values, default=None)</code>","text":"<p>Returns the value for the app env</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>def select(self, values: Dict[Union[str, 'AppEnv'], Any], default: Optional[Any] = None) -&gt; Any:\n    \"\"\"\n    Returns the value for the app env\n    \"\"\"\n    return next((value for key, value in values.items() if key == self), default)\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.AppEnv.extend","title":"<code>extend(name, value)</code>  <code>classmethod</code>","text":"<p>Extends the enum with a new value</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef extend(cls, name: str, value: Any):\n    \"\"\"\n    Extends the enum with a new value\n    \"\"\"\n    if not _EXTEND_SUPPORTED: raise ImportError('aenum is not installed. Please install it to use this feature')\n    extend_enum(cls, name, value)\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.common.get_app_env","title":"<code>get_app_env(module_name)</code>","text":"<p>Retrieves the app environment</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>def get_app_env(\n    module_name: str,\n) -&gt; AppEnv:\n    \"\"\"\n    Retrieves the app environment\n    \"\"\"\n    module_name = module_name.replace(\".\", \"_\").upper()\n    for key in {\n        \"SERVER_ENV\",\n        f\"{module_name}_ENV\",\n        \"APP_ENV\",\n        \"ENVIRONMENT\",\n    }:\n        if env_value := os.getenv(key):\n            return AppEnv.from_env(env_value)\n\n    from lzo.utils.system import is_in_kubernetes, get_host_name\n    if is_in_kubernetes():\n        # Name should be\n        # scout-&lt;service&gt;-&lt;index&gt;\n        # or \n        # scout-&lt;service&gt;-&lt;env&gt;-&lt;index&gt;\n        hn = get_host_name()\n        try:\n            parts = hn.split(\"-\")\n            return AppEnv.from_env(parts[1]) if len(parts) &gt; 2 else AppEnv.PRODUCTION\n        except Exception as e:\n            return AppEnv.from_hostname(hn)\n        # parts = get_host_name().split(\"-\")\n        # return AppEnv.from_env(parts[2]) if len(parts) &gt; 3 else AppEnv.PRODUCTION\n\n    return AppEnv.LOCAL\n</code></pre>"},{"location":"api/lzl/types/#dynamic-types","title":"Dynamic Types","text":""},{"location":"api/lzl/types/#lzl.types.dynamic","title":"<code>lzl.types.dynamic</code>","text":""},{"location":"api/lzl/types/#lzl.types.dynamic.BaseDynamicLoader","title":"<code>BaseDynamicLoader</code>","text":"<p>A utility class for dynamically discovering and loading classes from a module structure.</p> <p>This class recursively scans the directory of the specified <code>MODULE</code> for Python files, imports them, and identifies classes that are subclasses of <code>class_to_find</code>.</p> <p>Attributes:</p> Name Type Description <code>MODULE</code> <code>str</code> <p>The dotted module path to start the search from.</p> Source code in <code>src/lzl/types/dynamic.py</code> <pre><code>class BaseDynamicLoader:\n    \"\"\"\n    A utility class for dynamically discovering and loading classes from a module structure.\n\n    This class recursively scans the directory of the specified `MODULE` for Python files,\n    imports them, and identifies classes that are subclasses of `class_to_find`.\n\n    Attributes:\n        MODULE (str): The dotted module path to start the search from.\n    \"\"\"\n    MODULE: str\n\n    def __init__(self, class_to_find: T):\n        \"\"\"\n        Initialize the loader.\n\n        Args:\n            class_to_find: The base class type to search for.\n        \"\"\"\n        self.module = importlib.import_module(self.MODULE)\n        self.class_to_find = class_to_find\n        self._found_classes = self.__dynamic_class_loader()\n\n    def __dynamic_class_loader(self) -&gt; t.Dict[str, T]:\n        \"\"\"\n        Recursively finds and loads classes inheriting from `self.class_to_find` within `self.MODULE`.\n\n        Returns:\n            A dictionary mapping class names to the loaded class objects.\n        \"\"\"\n        found_classes: t.Dict[str, T] = {}\n        logger.info(\n            f\"Loading {self.class_to_find.__name__} classes from &lt;{self.MODULE}&gt;\",\n            prefix = self.__class__.__name__\n        )\n        root_dir = self.module.__path__[0]\n        for root, _, files in os.walk(root_dir):\n            for file in files:\n                # Check if the file is a Python file and not a special file\n                if file.endswith(\".py\") and not file.startswith(\"__\"):\n                    mod_name = os.path.splitext(file)[0]\n                    module = importlib.import_module(f\"{self.MODULE}.{mod_name}\")\n                    for cls in dir(module):\n                        # Check if the class is a subclass of class_to_find\n                        if (\n                            isinstance(getattr(module, cls), type)\n                            and issubclass(getattr(module, cls), self.class_to_find)\n                            and getattr(module, cls) is not self.class_to_find\n                        ):\n                            # Check if the class is a class_to_find\n                            logger.info(\n                                f\"Found {self.class_to_find.__name__} class &lt;{cls}&gt; in &lt;{file}&gt;\",\n                                prefix = self.__class__.__name__\n                            )\n                            found_classes[cls] = getattr(module, cls)\n        return found_classes\n</code></pre>"},{"location":"api/lzl/types/#typed-utilities","title":"Typed Utilities","text":""},{"location":"api/lzl/types/#lzl.types.typed","title":"<code>lzl.types.typed</code>","text":""},{"location":"api/lzl/types/#lzl.types.typed.CallableAsyncNoParam","title":"<code>CallableAsyncNoParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class CallableAsyncNoParam(Protocol[ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(self) -&gt; Awaitable[ProtocolReturnType]:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.CallableSyncNoParam","title":"<code>CallableSyncNoParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class CallableSyncNoParam(Protocol[ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(self) -&gt; ProtocolReturnType:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.CallableAsyncSingleParam","title":"<code>CallableAsyncSingleParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolParamType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class CallableAsyncSingleParam(Protocol[ProtocolParamType, ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(self, __arg: ProtocolParamType) -&gt; Awaitable[ProtocolReturnType]:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.CallableSyncSingleParam","title":"<code>CallableSyncSingleParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolParamType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class CallableSyncSingleParam(Protocol[ProtocolParamType, ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(self, __arg: ProtocolParamType) -&gt; ProtocolReturnType:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.MethodAsyncNoParam","title":"<code>MethodAsyncNoParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolSelfType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class MethodAsyncNoParam(Protocol[ProtocolSelfType, ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(__self, self: ProtocolSelfType) -&gt; Awaitable[ProtocolReturnType]:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.MethodSyncNoParam","title":"<code>MethodSyncNoParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolSelfType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class MethodSyncNoParam(Protocol[ProtocolSelfType, ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(__self, self: ProtocolSelfType) -&gt; ProtocolReturnType:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.MethodAsyncSingleParam","title":"<code>MethodAsyncSingleParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolSelfType, ProtocolParamType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class MethodAsyncSingleParam(\n    Protocol[ProtocolSelfType, ProtocolParamType, ProtocolReturnType]\n):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(\n        self, __self: ProtocolSelfType, __arg: ProtocolParamType, /\n    ) -&gt; Awaitable[ProtocolReturnType]:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.MethodSyncSingleParam","title":"<code>MethodSyncSingleParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolSelfType, ProtocolParamType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class MethodSyncSingleParam(\n    Protocol[ProtocolSelfType, ProtocolParamType, ProtocolReturnType]\n):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(\n        self, __self: ProtocolSelfType, __arg: ProtocolParamType, /\n    ) -&gt; ProtocolReturnType:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.MethodSyncOrAsyncNoParam","title":"<code>MethodSyncOrAsyncNoParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolSelfType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class MethodSyncOrAsyncNoParam(Protocol[ProtocolSelfType, ProtocolReturnType]):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(\n        self, __self: ProtocolSelfType\n    ) -&gt; Union[ProtocolReturnType, Awaitable[ProtocolReturnType]]:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.MethodSyncOrAsyncSingleParam","title":"<code>MethodSyncOrAsyncSingleParam</code>","text":"<p>               Bases: <code>Protocol[ProtocolSelfType, ProtocolParamType, ProtocolReturnType]</code></p> <p>Generic callable type.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class MethodSyncOrAsyncSingleParam(\n    Protocol[ProtocolSelfType, ProtocolParamType, ProtocolReturnType]\n):\n    \"\"\"Generic callable type.\"\"\"\n\n    def __call__(\n        self, __self: ProtocolSelfType, __param: ProtocolParamType, /\n    ) -&gt; Union[ProtocolReturnType, Awaitable[ProtocolReturnType]]:\n        \"\"\"Generic callable type callback.\"\"\"\n        ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.AsyncGenerator","title":"<code>AsyncGenerator</code>","text":"<p>               Bases: <code>ABC</code>, <code>AsyncIterator[TYield]</code>, <code>Generic[TYield, TSend]</code></p> <p>Represents a one-shot \"asynchronous generator-iterator\" (as it is referred to in the docs). The concept referred to as an \"asynchronous generator function\" is the function defined with <code>async def</code> that has a return type of AsyncGenerator.</p> <p>In other words, <code>fn</code> here is an asynchronous generator function:</p> <pre><code>async def fn() -&gt; AsyncGenerator[...]:\n    ...\n</code></pre> <p>And <code>agen</code> here is an asynchronous generator-iterator:</p> <pre><code>agen = fn()\n</code></pre> <p>The lifetime of an AsyncGenerator is as follows:</p> <ol> <li> <p>The asynchronous generator-iterator is started by awaiting anext() or asend(None). This begins executing the asynchronous generator function.</p> </li> <li> <p>Once started, you may (but are not required to):</p> <p>2a. Call asend() with a TSend value and await the result, to continue executing the asynchronous generator function.</p> <p>2b. Await athrow() to raise an exception inside the asynchronous generator function, which may respond by yielding a value.</p> </li> <li> <p>You may repeat step 2 as long as the awaitable returned does not raise an exception.</p> </li> <li> <p>At any point, you may await aclose() to raise GeneratorExit inside the asynchronous generator function, requesting that it exit. This has no effect if an awaitable from step 2 already raised an exception, or if the asynchronous generator function never began executing, so it is always safe to invoke.</p> </li> <li> <p>Once the asynchronous generator function has exited (gracefully or through an exception), or the generator has been closed (even if the function was never started), the asynchronous generator-iterator instance may not be restarted. However, a new one can be obtained by calling the function again:</p> <p>agen = fn()</p> </li> </ol> Source code in <code>src/lzl/types/typed.py</code> <pre><code>class AsyncGenerator(ABC, AsyncIterator[TYield], Generic[TYield, TSend]):\n    \"\"\"\n    Represents a one-shot \"asynchronous generator-iterator\" (as it is\n    referred to in the docs). The concept referred to as an \"asynchronous\n    generator _function_\" is the function defined with `async def` that has a\n    return type of AsyncGenerator.\n\n    In other words, `fn` here is an asynchronous generator function:\n\n        async def fn() -&gt; AsyncGenerator[...]:\n            ...\n\n    And `agen` here is an asynchronous generator-iterator:\n\n        agen = fn()\n\n    The lifetime of an AsyncGenerator is as follows:\n\n    1. The asynchronous generator-iterator is started by awaiting __anext__()\n    or asend(None). This begins executing the asynchronous generator\n    function.\n\n    2. Once started, you may (but are not required to):\n\n        2a. Call asend() with a TSend value and await the result, to continue\n        executing the asynchronous generator function.\n\n        2b. Await athrow() to raise an exception inside the asynchronous\n        generator function, which may respond by yielding a value.\n\n    3. You may repeat step 2 as long as the awaitable returned does not raise\n    an exception.\n\n    4. At any point, you may await aclose() to raise GeneratorExit inside the\n    asynchronous generator function, requesting that it exit. This has no\n    effect if an awaitable from step 2 already raised an exception, or if the\n    asynchronous generator function never began executing, so it is always\n    safe to invoke.\n\n    5. Once the asynchronous generator function has exited (gracefully or\n    through an exception), or the generator has been closed (even if the\n    function was never started), the asynchronous generator-iterator instance\n    may not be restarted. However, a new one can be obtained by calling the\n    function again:\n\n        agen = fn()\n    \"\"\"\n\n    def __aiter__(self) -&gt; AsyncIterator[TYield]:\n        return self\n\n    async def __anext__(self) -&gt; TYield:  # throws: StopAsyncIteration, ...\n        \"\"\"\n        Returns an awaitable which, when run, starts to execute the\n        asynchronous generator, or resumes it from the last executed yield\n        expression.\n\n        If the generator has already exited (gracefully or through an\n        exception) or been closed previously, nothing happens, and the\n        awaitable returned by __anext__() will raise a StopAsyncIteration\n        exception.\n\n        If resuming from a yield expression, the expression will evaluate to\n        None inside the generator, because no value is being provided (use\n        asend() if you want that).\n\n        The generator will run until the next yield expression or it exits\n        (e.g., through a return statement).\n\n        If the generator yields a value, the awaitable returned by\n        __anext__() will return that value, and the generator's execution\n        will be re-suspended. (Under the hood, this is implemented as the\n        generator raising StopIteration, but you don't need to care about\n        that.)\n\n        If the generator raises an exception, the awaitable returned by\n        __anext__() will raise the same exception. (Note that if a generator\n        attempts to _explicitly_ raise StopIteration or StopAsyncIteration in\n        its implementation, it will instead be converted into a RuntimeError,\n        per PEP 479.)\n\n        If the generator exits gracefully, the awaitable returned by\n        __anext__() will raise a StopAsyncIteration exception.\n        \"\"\"\n        return await self.asend(None)\n\n    async def asend(\n        self,\n        input: Optional[TSend]\n    ) -&gt; TYield:  # throws: StopAsyncIteration, ...\n        \"\"\"\n        Returns an awaitable which, when run, starts to execute the\n        asynchronous generator, or resumes it from the last executed yield\n        expression.\n\n        If asend() is being called to start the generator, it must be called\n        with None as the argument, because there is no yield expression that\n        could receive the value. (This is the only reason `input` is typed as\n        Optional[TSend].)\n\n        If the generator has already exited (gracefully or through an\n        exception) or been closed previously, nothing happens, and the\n        awaitable returned by asend() will raise a StopAsyncIteration\n        exception.\n\n        If resuming from a yield expression, the expression will evaluate to\n        `input` inside the generator.\n\n        The generator will run until the next yield expression or it exits\n        (e.g., through a return statement).\n\n        If the generator yields a value, the awaitable returned by asend()\n        will return that value, and the generator's execution will be\n        re-suspended. (Under the hood, this is implemented as the generator\n        raising StopIteration, but you don't need to consider that.)\n\n        If the generator raises an exception, the awaitable returned by\n        asend() will raise the same exception. (Note that if a generator\n        attempts to _explicitly_ raise StopIteration or StopAsyncIteration in\n        its implementation, it will instead be converted into a RuntimeError,\n        per PEP 479.)\n\n        If the generator exits gracefully, the awaitable returned by asend()\n        will raise a StopAsyncIteration exception.\n        \"\"\"\n        ...\n\n    async def athrow(\n        self,\n        exc_type: Type[BaseException],\n        exc_value: Optional[BaseException] = None,\n        traceback: Optional[TracebackType] = None,\n    ) -&gt; Optional[TYield]:  # throws: exc_type, StopAsyncIteration, ...\n        \"\"\"\n        Returns an awaitable which, when run, raises an exception _inside_\n        the generator at the point of execution where it was last suspended.\n\n        If the generator has not yet been started, the awaitable returned by\n        athrow() will immediately raise the passed-in exception, and the\n        generator will be closed. In other words, the generator is not given\n        any opportunity to catch the exception, and it will not be able to be\n        started afterward.\n\n        If the generator has already exited (gracefully or through an\n        exception) or been closed previously, nothing happens, and the\n        awaitable returned by athrow() will return None.\n\n        Otherwise, after raising the exception inside the generator, athrow()\n        behaves exactly like __anext__().\n\n        In other words:\n\n        If the generator does not catch the passed-in exception, or raises a\n        different exception, then the awaitable returned by athrow() will\n        propagate that exception. (Note that if a generator attempts to\n        _explicitly_ raise StopIteration or StopAsyncIteration in its\n        implementation, it will instead be converted into a RuntimeError, per\n        PEP 479.)\n\n        If the generator catches the passed-in exception, then yields a\n        value, the awaitable returned by athrow() will return that value, and\n        the generator's execution will be re-suspended. (Under the hood, this\n        is implemented as the generator raising StopIteration, but you don't\n        need to consider that.)\n\n        If the generator catches the passed-in exception, then exits\n        gracefully, the awaitable returned by athrow() will raise a\n        StopAsyncIteration exception.\n        \"\"\"\n        ...\n\n    async def aclose(\n        self\n    ) -&gt; None:  # throws RuntimeError, ...\n        \"\"\"\n        Returns an awaitable which, when run, raises a GeneratorExit\n        exception _inside_ the generator at the point of execution where it\n        was last suspended.\n\n        If the generator has already exited (gracefully or through an\n        exception) or been closed previously, or the generator was never\n        started, nothing happens, and the awaitable returned by aclose() will\n        return gracefully.\n\n        If the generator does not catch the GeneratorExit exception, or\n        catches GeneratorExit then exits gracefully, the awaitable returned\n        by aclose() will return gracefully.\n\n        If the generator raises a different exception, then the awaitable\n        returned by aclose() will propagate that exception.\n\n        The generator _must not_ yield a value. If the generator catches the\n        GeneratorExit exception then yields a value, the awaitable returned\n        by aclose() will raise a RuntimeError.\n        \"\"\"\n\n        try:\n            await self.athrow(GeneratorExit)\n        except (GeneratorExit, StopAsyncIteration):\n            pass\n        else:\n            raise RuntimeError(\"...\")\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.AsyncGenerator.asend","title":"<code>asend(input)</code>  <code>async</code>","text":"<p>Returns an awaitable which, when run, starts to execute the asynchronous generator, or resumes it from the last executed yield expression.</p> <p>If asend() is being called to start the generator, it must be called with None as the argument, because there is no yield expression that could receive the value. (This is the only reason <code>input</code> is typed as Optional[TSend].)</p> <p>If the generator has already exited (gracefully or through an exception) or been closed previously, nothing happens, and the awaitable returned by asend() will raise a StopAsyncIteration exception.</p> <p>If resuming from a yield expression, the expression will evaluate to <code>input</code> inside the generator.</p> <p>The generator will run until the next yield expression or it exits (e.g., through a return statement).</p> <p>If the generator yields a value, the awaitable returned by asend() will return that value, and the generator's execution will be re-suspended. (Under the hood, this is implemented as the generator raising StopIteration, but you don't need to consider that.)</p> <p>If the generator raises an exception, the awaitable returned by asend() will raise the same exception. (Note that if a generator attempts to explicitly raise StopIteration or StopAsyncIteration in its implementation, it will instead be converted into a RuntimeError, per PEP 479.)</p> <p>If the generator exits gracefully, the awaitable returned by asend() will raise a StopAsyncIteration exception.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>async def asend(\n    self,\n    input: Optional[TSend]\n) -&gt; TYield:  # throws: StopAsyncIteration, ...\n    \"\"\"\n    Returns an awaitable which, when run, starts to execute the\n    asynchronous generator, or resumes it from the last executed yield\n    expression.\n\n    If asend() is being called to start the generator, it must be called\n    with None as the argument, because there is no yield expression that\n    could receive the value. (This is the only reason `input` is typed as\n    Optional[TSend].)\n\n    If the generator has already exited (gracefully or through an\n    exception) or been closed previously, nothing happens, and the\n    awaitable returned by asend() will raise a StopAsyncIteration\n    exception.\n\n    If resuming from a yield expression, the expression will evaluate to\n    `input` inside the generator.\n\n    The generator will run until the next yield expression or it exits\n    (e.g., through a return statement).\n\n    If the generator yields a value, the awaitable returned by asend()\n    will return that value, and the generator's execution will be\n    re-suspended. (Under the hood, this is implemented as the generator\n    raising StopIteration, but you don't need to consider that.)\n\n    If the generator raises an exception, the awaitable returned by\n    asend() will raise the same exception. (Note that if a generator\n    attempts to _explicitly_ raise StopIteration or StopAsyncIteration in\n    its implementation, it will instead be converted into a RuntimeError,\n    per PEP 479.)\n\n    If the generator exits gracefully, the awaitable returned by asend()\n    will raise a StopAsyncIteration exception.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.AsyncGenerator.athrow","title":"<code>athrow(exc_type, exc_value=None, traceback=None)</code>  <code>async</code>","text":"<p>Returns an awaitable which, when run, raises an exception inside the generator at the point of execution where it was last suspended.</p> <p>If the generator has not yet been started, the awaitable returned by athrow() will immediately raise the passed-in exception, and the generator will be closed. In other words, the generator is not given any opportunity to catch the exception, and it will not be able to be started afterward.</p> <p>If the generator has already exited (gracefully or through an exception) or been closed previously, nothing happens, and the awaitable returned by athrow() will return None.</p> <p>Otherwise, after raising the exception inside the generator, athrow() behaves exactly like anext().</p> <p>In other words:</p> <p>If the generator does not catch the passed-in exception, or raises a different exception, then the awaitable returned by athrow() will propagate that exception. (Note that if a generator attempts to explicitly raise StopIteration or StopAsyncIteration in its implementation, it will instead be converted into a RuntimeError, per PEP 479.)</p> <p>If the generator catches the passed-in exception, then yields a value, the awaitable returned by athrow() will return that value, and the generator's execution will be re-suspended. (Under the hood, this is implemented as the generator raising StopIteration, but you don't need to consider that.)</p> <p>If the generator catches the passed-in exception, then exits gracefully, the awaitable returned by athrow() will raise a StopAsyncIteration exception.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>async def athrow(\n    self,\n    exc_type: Type[BaseException],\n    exc_value: Optional[BaseException] = None,\n    traceback: Optional[TracebackType] = None,\n) -&gt; Optional[TYield]:  # throws: exc_type, StopAsyncIteration, ...\n    \"\"\"\n    Returns an awaitable which, when run, raises an exception _inside_\n    the generator at the point of execution where it was last suspended.\n\n    If the generator has not yet been started, the awaitable returned by\n    athrow() will immediately raise the passed-in exception, and the\n    generator will be closed. In other words, the generator is not given\n    any opportunity to catch the exception, and it will not be able to be\n    started afterward.\n\n    If the generator has already exited (gracefully or through an\n    exception) or been closed previously, nothing happens, and the\n    awaitable returned by athrow() will return None.\n\n    Otherwise, after raising the exception inside the generator, athrow()\n    behaves exactly like __anext__().\n\n    In other words:\n\n    If the generator does not catch the passed-in exception, or raises a\n    different exception, then the awaitable returned by athrow() will\n    propagate that exception. (Note that if a generator attempts to\n    _explicitly_ raise StopIteration or StopAsyncIteration in its\n    implementation, it will instead be converted into a RuntimeError, per\n    PEP 479.)\n\n    If the generator catches the passed-in exception, then yields a\n    value, the awaitable returned by athrow() will return that value, and\n    the generator's execution will be re-suspended. (Under the hood, this\n    is implemented as the generator raising StopIteration, but you don't\n    need to consider that.)\n\n    If the generator catches the passed-in exception, then exits\n    gracefully, the awaitable returned by athrow() will raise a\n    StopAsyncIteration exception.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api/lzl/types/#lzl.types.typed.AsyncGenerator.aclose","title":"<code>aclose()</code>  <code>async</code>","text":"<p>Returns an awaitable which, when run, raises a GeneratorExit exception inside the generator at the point of execution where it was last suspended.</p> <p>If the generator has already exited (gracefully or through an exception) or been closed previously, or the generator was never started, nothing happens, and the awaitable returned by aclose() will return gracefully.</p> <p>If the generator does not catch the GeneratorExit exception, or catches GeneratorExit then exits gracefully, the awaitable returned by aclose() will return gracefully.</p> <p>If the generator raises a different exception, then the awaitable returned by aclose() will propagate that exception.</p> <p>The generator must not yield a value. If the generator catches the GeneratorExit exception then yields a value, the awaitable returned by aclose() will raise a RuntimeError.</p> Source code in <code>src/lzl/types/typed.py</code> <pre><code>async def aclose(\n    self\n) -&gt; None:  # throws RuntimeError, ...\n    \"\"\"\n    Returns an awaitable which, when run, raises a GeneratorExit\n    exception _inside_ the generator at the point of execution where it\n    was last suspended.\n\n    If the generator has already exited (gracefully or through an\n    exception) or been closed previously, or the generator was never\n    started, nothing happens, and the awaitable returned by aclose() will\n    return gracefully.\n\n    If the generator does not catch the GeneratorExit exception, or\n    catches GeneratorExit then exits gracefully, the awaitable returned\n    by aclose() will return gracefully.\n\n    If the generator raises a different exception, then the awaitable\n    returned by aclose() will propagate that exception.\n\n    The generator _must not_ yield a value. If the generator catches the\n    GeneratorExit exception then yields a value, the awaitable returned\n    by aclose() will raise a RuntimeError.\n    \"\"\"\n\n    try:\n        await self.athrow(GeneratorExit)\n    except (GeneratorExit, StopAsyncIteration):\n        pass\n    else:\n        raise RuntimeError(\"...\")\n</code></pre>"},{"location":"api/lzo/","title":"lzo - Lazy Objects/Registry","text":"<p>The <code>lzo</code> namespace provides object registry patterns, state management, settings configuration, and related functionalities.</p>"},{"location":"api/lzo/#key-modules","title":"Key Modules","text":"<ul> <li>Registry: Object registry with lifecycle hooks and dependency injection</li> <li>Types: Pydantic-based configuration and settings management</li> <li>Utils: Lightweight utility helpers for common operations</li> </ul>"},{"location":"api/lzo/#overview","title":"Overview","text":"<p>The <code>lzo</code> toolkit focuses on object lifecycle management, configuration handling, and reusable patterns for building robust applications. It provides a clean, type-safe way to manage application state and dependencies.</p>"},{"location":"api/lzo/#installation","title":"Installation","text":"<p>The <code>lzo</code> module is included with the base <code>lazyops</code> installation:</p> <pre><code>pip install lazyops\n</code></pre>"},{"location":"api/lzo/#quick-example","title":"Quick Example","text":"<pre><code>import lzo\nfrom lzo.registry import MRegistry\nfrom lzo.types import BaseSettings\n\n# Define configuration\nclass AppConfig(BaseSettings):\n    app_name: str\n    debug: bool = False\n\n# Register and retrieve\nregistry = MRegistry()\nregistry.register('config', AppConfig(app_name=\"MyApp\"))\nconfig = registry.get('config')\n</code></pre>"},{"location":"api/lzo/#core-concepts","title":"Core Concepts","text":""},{"location":"api/lzo/#registry-pattern","title":"Registry Pattern","text":"<p>The registry pattern provides a centralized way to manage objects throughout your application's lifecycle. It supports:</p> <ul> <li>Lifecycle Hooks: Pre/post instantiation callbacks</li> <li>Dependency Injection: Automatic resolution of dependencies</li> <li>Singleton Management: Control object creation and reuse</li> <li>Type Safety: Full typing support with Pydantic</li> </ul>"},{"location":"api/lzo/#settings-management","title":"Settings Management","text":"<p>The types module extends Pydantic's settings management with:</p> <ul> <li>Environment Integration: Automatic environment variable loading</li> <li>Validation: Type-safe configuration validation</li> <li>Serialization: Easy conversion to/from various formats</li> <li>Nested Configuration: Support for complex configuration structures</li> </ul>"},{"location":"api/lzo/#utility-helpers","title":"Utility Helpers","text":"<p>The utils module provides lightweight helpers that avoid heavy dependencies:</p> <ul> <li>Retry Decorators: Automatic retry with exponential backoff</li> <li>Key Generators: Consistent key generation for caching</li> <li>Formatting: String and data formatting utilities</li> <li>Batching: Efficient batch processing helpers</li> </ul>"},{"location":"api/lzo/#architecture","title":"Architecture","text":"<p>The <code>lzo</code> namespace follows these design principles:</p> <ol> <li>Type Safety: Extensive use of type hints and Pydantic models</li> <li>Minimal Dependencies: Keep the core lightweight</li> <li>Extensibility: Easy to extend with custom patterns</li> <li>Documentation: Well-documented with clear examples</li> </ol> <p>Browse the sidebar to explore specific modules and their documentation.</p>"},{"location":"api/lzo/cmd/","title":"lzo.cmd - Command Line Utilities","text":"<p>The <code>lzo.cmd</code> module contains command-line interface tools and scripts.</p>"},{"location":"api/lzo/cmd/#key-generation","title":"Key Generation","text":""},{"location":"api/lzo/cmd/#lzo.cmd.keygen","title":"<code>lzo.cmd.keygen</code>","text":""},{"location":"api/lzo/cmd/#lzo.cmd.keygen.create_secret_key","title":"<code>create_secret_key(length=Argument(32, help='Length of Secret Key'), repeat=Option(1, '-r', '-n', '--repeat', help='Number of Secret Keys to Generate'), alpha_only=Option(False, help='Use only Alpha Characters'), hash=Option(None, help='Hash the Secret Key. Ex: sha256'), lower=Option(False, help='Lowercase the Secret Key'), prefix=Option(None, '-p', help='Prefix for the Secret Key'), from_string=Option(None, '-s', '--string', help='Generate from a length string'), from_file=Option(None, '-f', '--file', help='Generate and replace secrets within a file'), file_key=Option('&lt;key&gt;', '-k', '--key', help='Key to replace in the file'))</code>","text":"<p>Generate a random alphanumeric secret key.</p> <p>lzo kg secret</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('secret', help = \"Create an alphanmeric secret\")\ndef create_secret_key(\n    length: int = Argument(32, help = \"Length of Secret Key\"),\n    repeat: int = Option(1, '-r', '-n', '--repeat', help = \"Number of Secret Keys to Generate\"),\n    alpha_only: bool = Option(False, help = \"Use only Alpha Characters\"),\n    hash: t.Optional[str] = Option(None, help = \"Hash the Secret Key. Ex: sha256\"),\n    lower: bool = Option(False, help = \"Lowercase the Secret Key\"),\n    prefix: t.Optional[str] = Option(None, '-p', help = \"Prefix for the Secret Key\"),\n    from_string: t.Optional[str] = Option(None, '-s', '--string', help = \"Generate from a length string\"),\n    from_file: t.Optional[pathlib.Path] = Option(None, '-f', '--file', help = \"Generate and replace secrets within a file\"),\n    file_key: t.Optional[str] = Option('&lt;key&gt;', '-k', '--key', help = \"Key to replace in the file\"),\n):\n    \"\"\"\n    Generate a random alphanumeric secret key.\n\n    &gt;&gt;&gt; lzo kg secret\n    \"\"\"\n    if from_string: length = len(from_string)\n    existing = None\n    if from_file:\n        existing = from_file.read_text()\n        if file_key not in existing:\n            raise ValueError(f\"Key '{file_key}' not found in file '{from_file}'\")\n        # Find the number of times the key appears in the file\n        repeat = existing.count(file_key)\n    for _ in range(repeat):\n        value = Generate.alphanumeric_passcode(length, alpha_only)\n        if lower: value = value.lower()\n        if prefix: value = f'{prefix}{value}'\n        echo(value)\n        if existing and not hash: existing = existing.replace(file_key, value, 1)\n        if hash:\n            hashed_value = getattr(hashlib, hash)(value.encode()).hexdigest()\n            if lower: hashed_value = hashed_value.lower()\n            echo(hashed_value)\n            if existing: existing = existing.replace(file_key, hashed_value, 1)\n    if from_file: \n        from_file.write_text(existing)\n        echo(f\"Replaced '{file_key}' x {repeat}\")\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.create_uuid_key","title":"<code>create_uuid_key(length=Argument(None, help='Length of UUID Key'), clean=Option(True, help=\"Strip '-' from UUID\"), repeat=Option(1, help='Number of Secret Keys to Generate'), raw=Option(False, help='Return Raw UUID Key'))</code>","text":"<p>Generate a UUID key.</p> <p>lzo kg uuid</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('uuid', help = \"Generate UUID Key\")\ndef create_uuid_key(\n    length: int = Argument(None, help = \"Length of UUID Key\"),\n    clean: bool = Option(True, help = \"Strip '-' from UUID\"),\n    repeat: int = Option(1, help = \"Number of Secret Keys to Generate\"),\n    raw: bool = Option(False, help = \"Return Raw UUID Key\"),\n):\n    \"\"\"\n    Generate a UUID key.\n\n    &gt;&gt;&gt; lzo kg uuid\n    \"\"\"\n    for _ in range(repeat):\n        value = Generate.uuid_passcode(length = length, clean = clean, raw = raw)\n        echo(value)\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.generate_htpasswd","title":"<code>generate_htpasswd(secret=Argument(..., help='Secret Key to Hash'), salt=Option(None, '-s', '--salt', help='Salt for the Hash'), rounds=Option(10, '-r', '--rounds', help='Number of Rounds for the Hash'), repeat=Option(1, '-n', '--num', help='Number of Secret Keys to Generate'))</code>","text":"<p>Generate a bcrypt hashed password for use in htpasswd files.</p> <p>lzo kg htpass mysecret</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('htpass', help = \"Generate htpasswd Key using bcrypt\")\ndef generate_htpasswd(\n    secret: str = Argument(..., help = \"Secret Key to Hash\"),\n    salt: t.Optional[str] = Option(None,  \"-s\", \"--salt\", help = \"Salt for the Hash\"),\n    rounds: int = Option(10, \"-r\", \"--rounds\", help = \"Number of Rounds for the Hash\"),\n    repeat: int = Option(1, \"-n\", \"--num\",  help = \"Number of Secret Keys to Generate\"),\n):\n    \"\"\"\n    Generate a bcrypt hashed password for use in htpasswd files.\n\n    &gt;&gt;&gt; lzo kg htpass mysecret\n    \"\"\"\n    for hashed in generate_htpasswd_key(secret, salt=salt, rounds=rounds, repeat=repeat):\n        echo(hashed)\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.validate_htpasswd","title":"<code>validate_htpasswd(secret=Argument(..., help='Secret Key to Validate'), hashed=Argument(..., help='Hashed Key to Validate Against'))</code>","text":"<p>Validate a bcrypt hashed password against a plain text password.</p> <p>lzo kg htpass-validate mysecret $2b$12$eImiTMZG4ELQ2Z8K1z3uOe</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('htpass-validate', help = \"Validate a bcrypt hashed password\")\ndef validate_htpasswd(\n    secret: str = Argument(..., help = \"Secret Key to Validate\"),\n    hashed: str = Argument(..., help = \"Hashed Key to Validate Against\"),\n):\n    \"\"\"\n    Validate a bcrypt hashed password against a plain text password.\n\n    &gt;&gt;&gt; lzo kg htpass-validate mysecret $2b$12$eImiTMZG4ELQ2Z8K1z3uOe\n    \"\"\"\n    echo(validate_htpasswd_key(secret, hashed))\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.create_keypair","title":"<code>create_keypair(key_length=Argument(16, help='Length of Key'), secret_length=Argument(32, help='Length of Secret'), repeat=Option(1, help='Number of Secret Keys to Generate'))</code>","text":"<p>Create a Key Pair.</p> <p>lzo kg keypair</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('keypair', help = \"Create Key Pair\")\ndef create_keypair(\n    key_length: int = Argument(16, help = \"Length of Key\"),\n    secret_length: int = Argument(32, help = \"Length of Secret\"),\n    repeat: int = Option(1, help = \"Number of Secret Keys to Generate\"),\n):\n    \"\"\"\n    Create a Key Pair.\n\n    &gt;&gt;&gt; lzo kg keypair\n    \"\"\"\n    for _ in range(repeat):\n        value = Generate.keypair(key_length = key_length, secret_length = secret_length)\n        echo(f'{value[\"key\"]}:{value[\"secret\"]}')\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.create_token","title":"<code>create_token(length=Argument(32, help='Length of Token'), safe=Option(False, help='Use URL Safe Token'), clean=Option(True, help='Remove non-alphanumeric from Token'), repeat=Option(1, help='Number of Tokens to Generate'))</code>","text":"<p>Create a Token.</p> <p>lzo kg token</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('token', help = \"Create a Token\")\ndef create_token(\n    length: int = Argument(32, help = \"Length of Token\"),\n    safe: bool = Option(False, help = \"Use URL Safe Token\"),\n    clean: bool = Option(True, help = \"Remove non-alphanumeric from Token\"),\n    repeat: bool = Option(1, help = \"Number of Tokens to Generate\"),\n):\n    \"\"\"\n    Create a Token.\n\n    &gt;&gt;&gt; lzo kg token\n    \"\"\"\n    for _ in range(repeat):\n        value = Generate.token(length = length, safe = safe, clean = clean)\n        echo(value)\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.create_ssl_token","title":"<code>create_ssl_token(length=Argument(64, help='Length of Token'), base_encode=Option(False, help='Base64 Encode the Token'), repeat=Option(1, help='Number of Secret Keys to Generate'))</code>","text":"<p>Create a Token using OpenSSL.</p> <p>lzo kg ssl</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('ssl', help = \"Create a Token using OpenSSL\")\ndef create_ssl_token(\n    length: int = Argument(64, help = \"Length of Token\"),\n    base_encode: bool = Option(False, help = \"Base64 Encode the Token\"),\n    repeat: int = Option(1, help = \"Number of Secret Keys to Generate\"),\n):\n    \"\"\"\n    Create a Token using OpenSSL.\n\n    &gt;&gt;&gt; lzo kg ssl\n    \"\"\"\n    for _ in range(repeat):\n        value = Generate.openssl_random_key(length = length, base = base_encode)\n        echo(value)\n</code></pre>"},{"location":"api/lzo/cmd/#lzo.cmd.keygen.create_key","title":"<code>create_key(method=Option(SecretMethod.secret, help='Method to generate Key'), length=Option(32, help='Length of Key'), secret_length=Option(32, help='[Optional] Length of Secret'), clean=Option(True, help='[Optional] Remove non-alphanumeric from Key'), safe=Option(False, help='[Optional] Use URL Safe Token'), base_encode=Option(True, help='[Optional] Base64 Encode the Token'), repeat=Option(1, help='[Optional] Number of Tokens to Generate'))</code>","text":"<p>Generate a Unique Key.</p> <p>lzo kg create secret</p> Source code in <code>src/lzo/cmd/keygen.py</code> <pre><code>@cmd.command('create', help = \"Generate a Unique Key\")\ndef create_key(\n    method: SecretMethod = Option(SecretMethod.secret, help = \"Method to generate Key\"),\n    length: int = Option(32, help = \"Length of Key\"),\n    secret_length: int = Option(32, help = \"[Optional] Length of Secret\"),\n    clean: bool = Option(True, help = \"[Optional] Remove non-alphanumeric from Key\"),\n    safe: bool = Option(False, help = \"[Optional] Use URL Safe Token\"),\n    base_encode: bool = Option(True, help = \"[Optional] Base64 Encode the Token\"),\n    repeat: bool = Option(1, help = \"[Optional] Number of Tokens to Generate\"),\n):\n    \"\"\"\n    Generate a Unique Key.\n\n    &gt;&gt;&gt; lzo kg create secret\n    \"\"\"\n    for _ in range(repeat):\n        if method == SecretMethod.secret:\n            value = Generate.alphanumeric_passcode(length = length)\n        elif method == SecretMethod.uuid:\n            value = Generate.uuid_passcode(length = length, clean = clean)\n        elif method == SecretMethod.keypair:\n            value = Generate.keypair(key_length = length, secret_length = secret_length)\n        elif method == SecretMethod.token:\n            value = Generate.token(length = length, clean = clean, safe = safe)\n        elif method == SecretMethod.ssl:\n            value = Generate.openssl_random_key(length = length, base = base_encode)\n        if isinstance(value, dict):\n            echo(f'{value[\"key\"]}:{value[\"secret\"]}')\n        else:\n            echo(value)\n</code></pre>"},{"location":"api/lzo/cmd/#s3-operations","title":"S3 Operations","text":""},{"location":"api/lzo/cmd/#lzo.cmd.s3","title":"<code>lzo.cmd.s3</code>","text":""},{"location":"api/lzo/io/","title":"lzo.io - Input/Output Operations","text":"<p>The <code>lzo.io</code> module handles data downloading and resource resolution.</p>"},{"location":"api/lzo/io/#download","title":"Download","text":""},{"location":"api/lzo/io/#lzo.io.download","title":"<code>lzo.io.download</code>","text":""},{"location":"api/lzo/io/#lzo.io.download.download_url_to_bytes","title":"<code>download_url_to_bytes(url, follow_redirects=True, verbose=True, return_response=False, **kwargs)</code>","text":"<p>Synchronously downloads content from a URL into bytes.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to download from.</p> required <code>follow_redirects</code> <code>Optional[bool]</code> <p>Whether to follow HTTP redirects.</p> <code>True</code> <code>verbose</code> <code>Optional[bool]</code> <p>If True, logs errors.</p> <code>True</code> <code>return_response</code> <code>Optional[bool]</code> <p>If True, returns a tuple of (content, response_object).</p> <code>False</code> <code>**kwargs</code> <p>Additional arguments passed to <code>aiohttpx.Client.get</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[Union[bytes, Tuple[bytes, 'Response']]]</code> <p>The file content as bytes, or (bytes, Response) if return_response is True.</p> <code>Optional[Union[bytes, Tuple[bytes, 'Response']]]</code> <p>Returns None if the request fails.</p> Source code in <code>src/lzo/io/download.py</code> <pre><code>def download_url_to_bytes(\n    url: str,\n    follow_redirects: Optional[bool] = True,\n    verbose: Optional[bool] = True,\n    return_response: Optional[bool] = False,\n    **kwargs,\n) -&gt; Optional[Union[bytes, Tuple[bytes, 'Response']]]:\n    \"\"\"\n    Synchronously downloads content from a URL into bytes.\n\n    Args:\n        url: The URL to download from.\n        follow_redirects: Whether to follow HTTP redirects.\n        verbose: If True, logs errors.\n        return_response: If True, returns a tuple of (content, response_object).\n        **kwargs: Additional arguments passed to `aiohttpx.Client.get`.\n\n    Returns:\n        The file content as bytes, or (bytes, Response) if return_response is True.\n        Returns None if the request fails.\n    \"\"\"\n    from lzo.utils import logger\n    url = normalize_url(url)\n    with contextlib.suppress(Exception):\n        with aiohttpx.Client() as client:\n            response = client.get(url, follow_redirects = follow_redirects, **kwargs)\n            if response.status_code &gt; 400:\n                if verbose: logger.error(f\"[{response.status_code}] Error fetching url {url}\\n{response.text[:1000]}...\")\n                if return_response: return (None, response)\n                return\n            return (response.read(), response) if return_response else response.read()\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.download.adownload_url_to_bytes","title":"<code>adownload_url_to_bytes(url, follow_redirects=True, verbose=True, return_response=False, **kwargs)</code>  <code>async</code>","text":"<p>Asynchronously downloads content from a URL into bytes.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to download from.</p> required <code>follow_redirects</code> <code>Optional[bool]</code> <p>Whether to follow HTTP redirects.</p> <code>True</code> <code>verbose</code> <code>Optional[bool]</code> <p>If True, logs errors.</p> <code>True</code> <code>return_response</code> <code>Optional[bool]</code> <p>If True, returns a tuple of (content, response_object).</p> <code>False</code> <code>**kwargs</code> <p>Additional arguments passed to <code>aiohttpx.Client.async_get</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[Union[bytes, Tuple[bytes, 'Response']]]</code> <p>The file content as bytes, or (bytes, Response) if return_response is True.</p> <code>Optional[Union[bytes, Tuple[bytes, 'Response']]]</code> <p>Returns None if the request fails.</p> Source code in <code>src/lzo/io/download.py</code> <pre><code>async def adownload_url_to_bytes(\n    url: str,\n    follow_redirects: Optional[bool] = True,\n    verbose: Optional[bool] = True,\n    return_response: Optional[bool] = False,\n    **kwargs,\n) -&gt; Optional[Union[bytes, Tuple[bytes, 'Response']]]:\n    \"\"\"\n    Asynchronously downloads content from a URL into bytes.\n\n    Args:\n        url: The URL to download from.\n        follow_redirects: Whether to follow HTTP redirects.\n        verbose: If True, logs errors.\n        return_response: If True, returns a tuple of (content, response_object).\n        **kwargs: Additional arguments passed to `aiohttpx.Client.async_get`.\n\n    Returns:\n        The file content as bytes, or (bytes, Response) if return_response is True.\n        Returns None if the request fails.\n    \"\"\"\n    from lzo.utils import logger\n    url = normalize_url(url)\n    with contextlib.suppress(Exception):\n        async with aiohttpx.Client() as client:\n            response = await client.async_get(url, follow_redirects = follow_redirects, **kwargs)\n            if response.status_code &gt; 400:\n                if verbose: logger.error(f\"[{response.status_code}] Error fetching url {url}\\n{response.text[:1000]}...\")\n                if return_response: return (None, response)\n                return\n            return (response.read(), response) if return_response else response.read()\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.download.download_url_to_tempfile","title":"<code>download_url_to_tempfile(url, follow_redirects=True, verbose=True, **kwargs)</code>","text":"<p>Synchronously downloads a URL and saves it to a temporary file.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to download.</p> required <code>follow_redirects</code> <code>Optional[bool]</code> <p>Whether to follow redirects.</p> <code>True</code> <code>verbose</code> <code>Optional[bool]</code> <p>If True, logs success/failure messages.</p> <code>True</code> <code>**kwargs</code> <p>Additional arguments passed to the download function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The absolute path to the temporary file, or None if download failed.</p> Source code in <code>src/lzo/io/download.py</code> <pre><code>def download_url_to_tempfile(\n    url: str,\n    follow_redirects: Optional[bool] = True,\n    verbose: Optional[bool] = True,\n    **kwargs,\n) -&gt; Optional[str]:\n    \"\"\"\n    Synchronously downloads a URL and saves it to a temporary file.\n\n    Args:\n        url: The URL to download.\n        follow_redirects: Whether to follow redirects.\n        verbose: If True, logs success/failure messages.\n        **kwargs: Additional arguments passed to the download function.\n\n    Returns:\n        The absolute path to the temporary file, or None if download failed.\n    \"\"\"\n    # from lzo.utils import logger\n    from lazyops.utils import Timer, logger\n    t = Timer()\n    tmp_file = None\n    headers = kwargs.pop('headers', None)\n    headers = headers or get_http_download_headers()\n    file_bytes, response = download_url_to_bytes(url, follow_redirects = follow_redirects, headers = headers, return_response = True, **kwargs)\n    if not file_bytes: return None\n    with contextlib.suppress(Exception):\n        with tempfile.NamedTemporaryFile(delete=False) as f:\n            tmp_file = f.name\n            f.write(file_bytes)\n            f.flush()\n            if verbose: logger.info(f\"[{response.status_code}] Saved {url} to {tmp_file} in {t.duration_s}\", colored = True)\n            return tmp_file\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.download.adownload_url_to_tempfile","title":"<code>adownload_url_to_tempfile(url, follow_redirects=True, verbose=True, **kwargs)</code>  <code>async</code>","text":"<p>Asynchronously downloads a URL and saves it to a temporary file.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to download.</p> required <code>follow_redirects</code> <code>Optional[bool]</code> <p>Whether to follow redirects.</p> <code>True</code> <code>verbose</code> <code>Optional[bool]</code> <p>If True, logs success/failure messages.</p> <code>True</code> <code>**kwargs</code> <p>Additional arguments passed to the download function.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Optional[str]</code> <p>The absolute path to the temporary file, or None if download failed.</p> Source code in <code>src/lzo/io/download.py</code> <pre><code>async def adownload_url_to_tempfile(\n    url: str,\n    follow_redirects: Optional[bool] = True,\n    verbose: Optional[bool] = True,\n    **kwargs,\n) -&gt; Optional[str]:\n    \"\"\"\n    Asynchronously downloads a URL and saves it to a temporary file.\n\n    Args:\n        url: The URL to download.\n        follow_redirects: Whether to follow redirects.\n        verbose: If True, logs success/failure messages.\n        **kwargs: Additional arguments passed to the download function.\n\n    Returns:\n        The absolute path to the temporary file, or None if download failed.\n    \"\"\"\n    # from lzo.utils import logger\n    from lazyops.utils import Timer, logger\n    t = Timer()\n    tmp_file = None\n    headers = kwargs.pop('headers', None)\n    headers = headers or get_http_download_headers()\n    file_bytes, response = await adownload_url_to_bytes(url, follow_redirects = follow_redirects, headers = headers, return_response = True, **kwargs)\n    if not file_bytes: return None\n    async with aiofiles.tempfile.NamedTemporaryFile(delete=False) as f:\n        tmp_file = f.name\n        await f.write(file_bytes)\n        await f.flush()\n        if verbose: logger.info(f\"[{response.status_code}] Saved {url} to {tmp_file} in {t.duration_s}\", colored = True)\n        return tmp_file\n</code></pre>"},{"location":"api/lzo/io/#resolver","title":"Resolver","text":""},{"location":"api/lzo/io/#lzo.io.resolver","title":"<code>lzo.io.resolver</code>","text":""},{"location":"api/lzo/io/#lzo.io.resolver.normalize_url","title":"<code>normalize_url(url)</code>","text":"<p>Normalizes a URL string to a standard HTTPS format.</p> <p>Handles various edge cases like missing schemes, 'www://', and malformed prefixes.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL string to normalize.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The normalized URL starting with 'https://'.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def normalize_url(url: str) -&gt; str:\n    \"\"\"\n    Normalizes a URL string to a standard HTTPS format.\n\n    Handles various edge cases like missing schemes, 'www://', and malformed prefixes.\n\n    Args:\n        url: The URL string to normalize.\n\n    Returns:\n        The normalized URL starting with 'https://'.\n    \"\"\"\n    url = url.lower()\n    url = url.replace('http//', '').replace('https//', '').replace('htpps://', '').replace('htp://', '')\n    if '@' in url: url = url.split('@')[-1]\n    if url.startswith('www://'): url = url.replace('www://', 'www.')\n    if not url.startswith('http://') and not url.startswith('https://'): url = f'https://{url}'\n    return url.replace('http://', 'https://').rstrip('/')\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.extract_registered_domain","title":"<code>extract_registered_domain(url)</code>  <code>cached</code>","text":"<p>Extracts the registered domain (e.g., 'google.com' from 'sub.google.com') using tldextract.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to extract the domain from.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The registered domain string.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>@functools.lru_cache(500)\ndef extract_registered_domain(url: str) -&gt; str:\n    \"\"\"\n    Extracts the registered domain (e.g., 'google.com' from 'sub.google.com') using tldextract.\n\n    Args:\n        url: The URL to extract the domain from.\n\n    Returns:\n        The registered domain string.\n    \"\"\"\n    return tldextract.extract(url).registered_domain\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.extract_clean_domain","title":"<code>extract_clean_domain(url)</code>","text":"<p>Extracts the registered domain and removes any leading 'www.'.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to process.</p> required <p>Returns:</p> Type Description <code>str</code> <p>The cleaned domain string.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def extract_clean_domain(\n    url: str\n) -&gt; str:\n    \"\"\"\n    Extracts the registered domain and removes any leading 'www.'.\n\n    Args:\n        url: The URL to process.\n\n    Returns:\n        The cleaned domain string.\n    \"\"\"\n    domain = extract_registered_domain(url.lower())\n    if domain.startswith('www.'): domain = domain.replace('www.', '')\n    return domain.lower()\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.get_http_download_headers","title":"<code>get_http_download_headers()</code>","text":"<p>Retrieves HTTP headers suitable for mimicking a real browser.</p> <p>Uses <code>browserforge</code> if available; otherwise falls back to a hardcoded Chrome-like user agent.</p> <p>Returns:</p> Type Description <code>Dict[str, str]</code> <p>A dictionary of HTTP headers.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def get_http_download_headers() -&gt; Dict[str, str]:\n    \"\"\"\n    Retrieves HTTP headers suitable for mimicking a real browser.\n\n    Uses `browserforge` if available; otherwise falls back to a hardcoded Chrome-like user agent.\n\n    Returns:\n        A dictionary of HTTP headers.\n    \"\"\"\n    global _http_download_headers\n    if _http_download_headers is None:\n        try:\n            from browserforge.headers import HeaderGenerator\n            _http_download_headers = HeaderGenerator().generate(browser='chrome')\n        except ImportError:\n            _http_download_headers = {\n                'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36',\n                'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n                'accept-language': 'en-US,en;q=0.9',\n                'accept-encoding': 'gzip, deflate, br',\n                'cache-control': 'no-cache',\n            }\n    return _http_download_headers\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.validate_website_with_ping","title":"<code>validate_website_with_ping(url, timeout=2, count=4)</code>","text":"<p>Validates a website's reachability using ICMP ping.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL or hostname to ping.</p> required <code>timeout</code> <code>Optional[int]</code> <p>Timeout in seconds for each ping.</p> <code>2</code> <code>count</code> <code>Optional[int]</code> <p>Number of ping attempts.</p> <code>4</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the host is reachable (success count &gt;= 3), False otherwise.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def validate_website_with_ping(\n    url: str,\n    timeout: Optional[int] = 2,\n    count: Optional[int] = 4,\n) -&gt; bool:\n    \"\"\"\n    Validates a website's reachability using ICMP ping.\n\n    Args:\n        url: The URL or hostname to ping.\n        timeout: Timeout in seconds for each ping.\n        count: Number of ping attempts.\n\n    Returns:\n        True if the host is reachable (success count &gt;= 3), False otherwise.\n    \"\"\"\n    url = normalize_url(url)\n    ping_results = pythonping.ping(url, count = count, timeout = timeout)\n    return ping_results.success(3)\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.validate_website_with_socket","title":"<code>validate_website_with_socket(url)</code>","text":"<p>Validates a website's reachability by resolving its hostname via DNS.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to validate.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if DNS resolution succeeds, False otherwise.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def validate_website_with_socket(\n    url: str,\n) -&gt; bool:\n    \"\"\"\n    Validates a website's reachability by resolving its hostname via DNS.\n\n    Args:\n        url: The URL to validate.\n\n    Returns:\n        True if DNS resolution succeeds, False otherwise.\n    \"\"\"\n    url = extract_clean_domain(url)\n    with contextlib.suppress(Exception):\n        socket.gethostbyname(url)\n        return True\n    return False\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.validate_website_with_httpx","title":"<code>validate_website_with_httpx(url, timeout=15, headers=None, **kwargs)</code>","text":"<p>Validates a website by sending an HTTP HEAD (or GET) request.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to validate.</p> required <code>timeout</code> <code>Optional[int]</code> <p>Connection timeout in seconds.</p> <code>15</code> <code>headers</code> <code>Optional[Dict[str, str]]</code> <p>Optional HTTP headers.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the client.</p> <code>{}</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the server responds with a 2xx-4xx status (excluding 405 which triggers a GET retry), False on connection error.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def validate_website_with_httpx(\n    url: str,\n    timeout: Optional[int] = 15,\n    headers: Optional[Dict[str, str]] = None,\n    **kwargs,\n) -&gt; bool:\n    \"\"\"\n    Validates a website by sending an HTTP HEAD (or GET) request.\n\n    Args:\n        url: The URL to validate.\n        timeout: Connection timeout in seconds.\n        headers: Optional HTTP headers.\n        **kwargs: Additional arguments passed to the client.\n\n    Returns:\n        True if the server responds with a 2xx-4xx status (excluding 405 which triggers a GET retry), False on connection error.\n    \"\"\"\n    url = normalize_url(url)\n    try:\n        # Try with head first\n        headers = headers or get_http_download_headers()\n        response = aiohttpx.head(url, timeout = timeout, headers = headers,follow_redirects = True)\n        if response.status_code == 405:\n            response = aiohttpx.get(url, timeout = timeout, headers = headers, follow_redirects = True)\n        response.raise_for_status()\n        return True\n    except (aiohttpx.ConnectTimeout, aiohttpx.ReadTimeout) as e:\n        return False\n    except aiohttpx.HTTPStatusError as e:\n        return e.response.status_code &lt; 500\n    except Exception as e:\n        return False\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.avalidate_website_with_httpx","title":"<code>avalidate_website_with_httpx(url, timeout=15, headers=None, **kwargs)</code>  <code>async</code>","text":"<p>Asynchronously validates a website by sending an HTTP HEAD (or GET) request.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to validate.</p> required <code>timeout</code> <code>Optional[int]</code> <p>Connection timeout in seconds.</p> <code>15</code> <code>headers</code> <code>Optional[Dict[str, str]]</code> <p>Optional HTTP headers.</p> <code>None</code> <code>**kwargs</code> <p>Additional arguments passed to the client.</p> <code>{}</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the server responds with a 2xx-4xx status, False on connection error.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>async def avalidate_website_with_httpx(\n    url: str,\n    timeout: Optional[int] = 15,\n    headers: Optional[Dict[str, str]] = None,\n    **kwargs,\n) -&gt; bool:\n    \"\"\"\n    Asynchronously validates a website by sending an HTTP HEAD (or GET) request.\n\n    Args:\n        url: The URL to validate.\n        timeout: Connection timeout in seconds.\n        headers: Optional HTTP headers.\n        **kwargs: Additional arguments passed to the client.\n\n    Returns:\n        True if the server responds with a 2xx-4xx status, False on connection error.\n    \"\"\"\n    url = normalize_url(url)\n    try:\n        # Try with head first\n        headers = headers or get_http_download_headers()\n        response = await aiohttpx.async_head(url, timeout = timeout, headers = headers, follow_redirects = True)\n        if response.status_code == 405:\n            response = await aiohttpx.async_get(url, headers = headers, timeout = timeout, follow_redirects = True)\n        response.raise_for_status()\n        return True\n    except (aiohttpx.ConnectTimeout, aiohttpx.ReadTimeout) as e:\n        return False\n    except aiohttpx.HTTPStatusError as e:\n        return e.response.status_code &lt; 500\n    except Exception as e:\n        return False\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.validate_hostname","title":"<code>validate_hostname(url)</code>  <code>cached</code>","text":"<p>Validates that a hostname resolves to an IP address.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL or hostname.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if resolvable, False otherwise. Retries up to 5 times.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>@functools.lru_cache(maxsize=1200)\ndef validate_hostname(url: str) -&gt; bool:\n    \"\"\"\n    Validates that a hostname resolves to an IP address.\n\n    Args:\n        url: The URL or hostname.\n\n    Returns:\n        True if resolvable, False otherwise. Retries up to 5 times.\n    \"\"\"    \n    hostname = urlparse(url).hostname if '://' in url else url\n    for _attempts in range(5):\n        with contextlib.suppress(Exception):\n            socket.gethostbyname(hostname)\n            return True\n        time.sleep(1.5)\n    return False\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.validate_website_exists","title":"<code>validate_website_exists(url, timeout=15, headers=None, soft_validate=False)</code>","text":"<p>Comprehensive website validation checking ping first, then HTTP accessibility.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to check.</p> required <code>timeout</code> <code>Optional[int]</code> <p>Timeout for requests.</p> <code>15</code> <code>headers</code> <code>Optional[Dict[str, str]]</code> <p>Optional HTTP headers.</p> <code>None</code> <code>soft_validate</code> <code>Optional[bool]</code> <p>If True, only checks ping/DNS, skips HTTP check if ping succeeds.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the website appears to exist and be reachable.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def validate_website_exists(\n    url: str,\n    timeout: Optional[int] = 15,\n    headers: Optional[Dict[str, str]] = None,\n    soft_validate: Optional[bool] = False,\n) -&gt; bool:\n    \"\"\"\n    Comprehensive website validation checking ping first, then HTTP accessibility.\n\n    Args:\n        url: The URL to check.\n        timeout: Timeout for requests.\n        headers: Optional HTTP headers.\n        soft_validate: If True, only checks ping/DNS, skips HTTP check if ping succeeds.\n\n    Returns:\n        True if the website appears to exist and be reachable.\n    \"\"\"\n    url = normalize_url(url)\n    hn_valid = validate_website_with_ping(url)\n    if soft_validate or not hn_valid: return hn_valid\n    return validate_website_with_httpx(url, headers = headers, timeout = timeout)\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.avalidate_website_exists","title":"<code>avalidate_website_exists(url, timeout=15, headers=None, soft_validate=False)</code>  <code>async</code>","text":"<p>Async version of comprehensive website validation.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL to check.</p> required <code>timeout</code> <code>Optional[int]</code> <p>Timeout for requests.</p> <code>15</code> <code>headers</code> <code>Optional[Dict[str, str]]</code> <p>Optional HTTP headers.</p> <code>None</code> <code>soft_validate</code> <code>Optional[bool]</code> <p>If True, only checks ping/DNS, skips HTTP check if ping succeeds.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p>True if the website appears to exist and be reachable.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>async def avalidate_website_exists(\n    url: str,\n    timeout: Optional[int] = 15,\n    headers: Optional[Dict[str, str]] = None,\n    soft_validate: Optional[bool] = False,\n) -&gt; bool:\n    \"\"\"\n    Async version of comprehensive website validation.\n\n    Args:\n        url: The URL to check.\n        timeout: Timeout for requests.\n        headers: Optional HTTP headers.\n        soft_validate: If True, only checks ping/DNS, skips HTTP check if ping succeeds.\n\n    Returns:\n        True if the website appears to exist and be reachable.\n    \"\"\"\n    url = normalize_url(url)\n    hn_valid = validate_website_with_ping(url)\n    if soft_validate or not hn_valid: return hn_valid\n    return await avalidate_website_with_httpx(url, headers = headers, timeout = timeout)\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.resolve_domain","title":"<code>resolve_domain(url, attempts=None)</code>  <code>cached</code>","text":"<p>Resolves the final root URL of a website after following redirects.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The starting URL.</p> required <code>attempts</code> <code>Optional[int]</code> <p>Recursion counter for retries (internal use).</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The final resolved URL, or the original if resolution fails.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>@functools.lru_cache()\ndef resolve_domain(url: str, attempts: Optional[int] = None) -&gt; str:\n    \"\"\"\n    Resolves the final root URL of a website after following redirects.\n\n    Args:\n        url: The starting URL.\n        attempts: Recursion counter for retries (internal use).\n\n    Returns:\n        The final resolved URL, or the original if resolution fails.\n    \"\"\"\n    if url.startswith('www://'): url = url.replace('www://', '')\n    if not url.startswith('http'): url = f'https://{url}'\n    try:\n        with aiohttpx.Client(follow_redirects = True, verify = False) as client:\n            r = client.get(url, timeout = 5)\n        r.raise_for_status()\n        return str(r.url).rstrip('/')\n    except (aiohttpx.ConnectTimeout, aiohttpx.ReadTimeout) as e:\n        return url\n    except aiohttpx.HTTPStatusError as e:\n        return str(e.response.url).rstrip('/') if e.response.status_code &lt; 500 else url\n    except Exception as e:\n        attempts = attempts + 1 if attempts else 1\n        if attempts &gt; 2:\n            return None\n        new_url = f'https://{extract_registered_domain(url)}'\n        return resolve_domain(new_url, attempts = attempts)\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.aresolve_domain","title":"<code>aresolve_domain(url, attempts=None)</code>  <code>async</code>","text":"<p>Asynchronously resolves the final root URL of a website after following redirects.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The starting URL.</p> required <code>attempts</code> <code>Optional[int]</code> <p>Recursion counter for retries (internal use).</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The final resolved URL, or the original if resolution fails.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>@async_lru.alru_cache(maxsize=1200)\nasync def aresolve_domain(url: str, attempts: Optional[int] = None) -&gt; str:\n    \"\"\"\n    Asynchronously resolves the final root URL of a website after following redirects.\n\n    Args:\n        url: The starting URL.\n        attempts: Recursion counter for retries (internal use).\n\n    Returns:\n        The final resolved URL, or the original if resolution fails.\n    \"\"\"\n    if url.startswith('www://'): url = url.replace('www://', '')\n    if not url.startswith('http'): url = f'https://{url}'\n    try:\n        async with aiohttpx.Client(follow_redirects = True, verify = False) as client:\n            r = await client.async_get(url, timeout = 5)\n        r.raise_for_status()\n        return str(r.url).rstrip('/')\n    except (aiohttpx.ConnectTimeout, aiohttpx.ReadTimeout) as e:\n        return url\n    except aiohttpx.HTTPStatusError as e:\n        return str(e.response.url).rstrip('/') if e.response.status_code &lt; 500 else url\n    except Exception as e:\n        attempts = attempts + 1 if attempts else 1\n        if attempts &gt; 2:\n            return None\n        new_url = f'https://{extract_registered_domain(url)}'\n        return await aresolve_domain(new_url, attempts = attempts)\n</code></pre>"},{"location":"api/lzo/io/#lzo.io.resolver.determine_invalid_domains","title":"<code>determine_invalid_domains(urls, timeout=4)</code>","text":"<p>Filters a list of URLs and returns those that are unreachable.</p> <p>Parameters:</p> Name Type Description Default <code>urls</code> <code>List[str]</code> <p>List of URLs to check.</p> required <code>timeout</code> <code>Optional[int]</code> <p>Timeout for each check.</p> <code>4</code> <p>Returns:</p> Type Description <code>List[str]</code> <p>List of invalid/unreachable URLs.</p> Source code in <code>src/lzo/io/resolver.py</code> <pre><code>def determine_invalid_domains(\n    urls: List[str],\n    timeout: Optional[int] = 4,\n) -&gt; List[str]:\n    \"\"\"\n    Filters a list of URLs and returns those that are unreachable.\n\n    Args:\n        urls: List of URLs to check.\n        timeout: Timeout for each check.\n\n    Returns:\n        List of invalid/unreachable URLs.\n    \"\"\"\n    if not urls: return []\n    return [\n        url\n        for url in urls\n        if not validate_website_with_ping(url, timeout=timeout)\n    ]\n</code></pre>"},{"location":"api/lzo/registry/","title":"lzo.registry - Object Registry","text":"<p>The <code>lzo.registry</code> module provides the <code>MRegistry</code> core with hook support for pre/post instantiation along with helpers for registering clients and settings.</p>"},{"location":"api/lzo/registry/#module-reference","title":"Module Reference","text":""},{"location":"api/lzo/registry/#lzo.registry","title":"<code>lzo.registry</code>","text":"<p>Registry utilities shared across LazyOps modules.</p>"},{"location":"api/lzo/registry/#lzo.registry.MRegistry","title":"<code>MRegistry</code>","text":"<p>               Bases: <code>Generic[RT]</code></p> <p>Mutable registry that lazily initialises and caches objects.</p> <p>The registry stores three parallel maps:</p> <ul> <li><code>mregistry</code> for classes/functions registered ahead of time.</li> <li><code>uninit_registry</code> for dotted import paths that are resolved on demand.</li> <li><code>init_registry</code> for concrete instances that have been constructed.</li> </ul> <p>Hooks can be attached to modify kwargs before instantiation (<code>prehooks</code>) or the resulting object after instantiation (<code>posthooks</code>).</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>class MRegistry(t.Generic[RT]):\n    \"\"\"Mutable registry that lazily initialises and caches objects.\n\n    The registry stores three parallel maps:\n\n    - ``mregistry`` for classes/functions registered ahead of time.\n    - ``uninit_registry`` for dotted import paths that are resolved on demand.\n    - ``init_registry`` for concrete instances that have been constructed.\n\n    Hooks can be attached to modify kwargs before instantiation (``prehooks``)\n    or the resulting object after instantiation (``posthooks``).\n    \"\"\"\n\n    mregistry: t.ClassVar[t.Dict[str, t.Type[RT]]] = {}\n    uninit_registry: t.ClassVar[t.Dict[str, str]] = {}\n    init_registry: t.ClassVar[t.Dict[str, RT]] = {}\n\n    prehooks: t.ClassVar[t.Dict[str, t.Callable[..., t.Any]]] = {}\n    posthooks: t.ClassVar[t.Dict[str, t.Callable[..., t.Any]]] = {}\n\n    def __init__(\n        self,\n        name: str,\n        verbose: t.Optional[bool] = False,\n        **kwargs: t.Any,\n    ) -&gt; None:\n        \"\"\"Initialise the registry with a display name and verbosity flag.\n\n        Args:\n            name: Friendly name used when logging registration activity.\n            verbose: Enables additional logging when objects are created.\n            **kwargs: Forwarded for compatibility; unused presently.\n        \"\"\"\n\n        from lzl.io.ser import get_object_classname\n        from lzl.load import lazy_import\n        from lzl.logging import logger\n\n        self.name = name\n        self.logger = logger\n        self.get_classname = get_object_classname\n        self.lazy_import = lazy_import\n        self.verbose = verbose\n        self.idx: t.Dict[str, RT] = {}\n        self._extra: t.Dict[str, t.Any] = {}\n\n    def _register(self, key: str, value: RT) -&gt; None:\n        \"\"\"Store a class/constructor in the registry, replacing existing values.\"\"\"\n\n        self.mregistry[key] = value\n        if key in self.uninit_registry:\n            self.uninit_registry.pop(key)\n        if os.getenv('MUTE_LZ_REGISTRY', 'false').lower() in {'true', '1'}:\n            return\n        if not isinstance(value, str) and getattr(value, '_rverbose', self.verbose):\n            if not TempData.has_logged(f'lzo.registry.register:{key}'):\n                self.logger.info(\n                    f'Registered: {key}',\n                    colored=True,\n                    prefix=self.name,\n                )\n\n    def __setitem__(self, key: str, value: RT) -&gt; None:\n        \"\"\"Alias for :meth:`_register` so the registry mimics a mapping.\"\"\"\n\n        self._register(key, value)\n\n    def register_prehook(self, key: str, func: t.Union[t.Callable[..., t.Any], str]) -&gt; None:\n        \"\"\"Attach a callable executed before an object is instantiated.\"\"\"\n\n        self.prehooks[key] = func\n\n    def register_posthook(self, key: str, func: t.Union[t.Callable[..., t.Any], str]) -&gt; None:\n        \"\"\"Attach a callable executed after an object is instantiated.\"\"\"\n\n        self.posthooks[key] = func\n\n    def register_hook(\n        self,\n        key: str,\n        func: t.Union[t.Callable[..., t.Any], str],\n        kind: t.Literal['pre', 'post'] = 'pre',\n    ) -&gt; None:\n        \"\"\"Convenience wrapper for registering pre- or post-hooks.\"\"\"\n\n        if kind == 'pre':\n            self.register_prehook(key, func)\n        elif kind == 'post':\n            self.register_posthook(key, func)\n\n    def run_obj_init(\n        self,\n        key: str,\n        obj: t.Union[t.Type[RT], RT],\n        **kwargs: t.Any,\n    ) -&gt; RT:\n        \"\"\"\n        Instantiates an object (or invokes a callable) and executes configured hooks.\n\n        If a 'prehook' is registered for the key, it modifies the `kwargs` before instantiation.\n        If a 'posthook' is registered, it receives the instantiated object and can modify or replace it.\n\n        Args:\n            key: The registry key associated with the object.\n            obj: The callable/class to instantiate, or an existing instance.\n            **kwargs: Arguments to pass to the object constructor/callable.\n\n        Returns:\n            The initialized (and potentially modified) object.\n        \"\"\"\n\n        if key in self.prehooks:\n            if isinstance(self.prehooks[key], str):\n                self.prehooks[key] = self.lazy_import(self.prehooks[key])\n            kwargs = self.prehooks[key](**kwargs)\n\n        if isinstance(obj, ProxyObject):\n            if self.verbose:\n                self.logger.info(\n                    f'Skipping Initialization for Proxy Object: {key}',\n                    colored=True,\n                    prefix=self.name,\n                )\n        else:\n            obj = obj(**kwargs)\n\n        if key in self.posthooks:\n            if isinstance(self.posthooks[key], str):\n                self.posthooks[key] = self.lazy_import(self.posthooks[key])\n            obj = self.posthooks[key](obj)\n        return obj\n\n    def _register_initialized(self, key: str, value: RT) -&gt; None:\n        \"\"\"Cache an already-instantiated object for repeated retrieval.\"\"\"\n\n        self.init_registry[key] = value\n\n    def _get(\n        self,\n        key: str,\n        _raise_error: bool = True,\n        **kwargs: t.Any,\n    ) -&gt; RT:\n        \"\"\"Resolve the concrete object backing ``key`` without memoisation.\"\"\"\n\n        if key in self.init_registry:\n            return self.init_registry[key]\n\n        if key in self.uninit_registry:\n            _path = self.uninit_registry[key]\n            _obj = self.lazy_import(_path)\n            self.init_registry[key] = self.run_obj_init(key, _obj, **kwargs)\n            self.uninit_registry.pop(key, None)\n            return self.init_registry[key]\n\n        if key in self.mregistry:\n            _obj = self.mregistry[key]\n            self.init_registry[key] = self.run_obj_init(key, _obj, **kwargs)\n            return self.init_registry[key]\n\n        if not _raise_error:\n            return None\n        raise KeyError(f'Key {key} not found in {self.name}')\n\n    def get(self, key: str, **kwargs: t.Any) -&gt; RT:\n        \"\"\"Public accessor that memoises lookups for repeat calls.\"\"\"\n\n        if key in self.idx:\n            return self.idx[key]\n        if (item := self._get(key, _raise_error=False, **kwargs)) is not None:\n            self.idx[key] = item\n            return item\n        if possible_key := self.search_for_parent(key, raise_error=False):\n            if possible_key in self.idx:\n                self.idx[key] = self.idx[possible_key]\n                return self.idx[key]\n            if (item := self._get(possible_key, _raise_error=False, **kwargs)) is not None:\n                self.idx[key] = item\n                return item\n        raise KeyError(\n            f'Key {key} not found in {self.name}: '\n            f'init: `{list(self.init_registry.keys())}`, '\n            f'idx: `{list(self.idx.keys())}`'\n        )\n\n    def get_module_path(self, obj: t.Type[RT]) -&gt; Path:\n        \"\"\"Return the filesystem path where ``obj`` is defined.\"\"\"\n\n        return Path(inspect.getfile(obj)).parent\n\n    def search_for_parent(self, key: str, raise_error: bool = True) -&gt; t.Optional[str]:\n        \"\"\"Find a registry key that ends with ``key`` (supports partial lookups).\"\"\"\n\n        if self.init_registry:\n            for k in self.init_registry:\n                if k.endswith(key):\n                    return k\n\n        if self.uninit_registry:\n            for k in self.uninit_registry:\n                if k.endswith(key):\n                    return k\n\n        if self.mregistry:\n            for k in self.mregistry:\n                if k.endswith(key):\n                    return k\n\n        if not raise_error:\n            return None\n        raise KeyError(f'Key {key} not found in {self.name}')\n\n    def __getitem__(self, key: str) -&gt; RT:\n        \"\"\"Allow bracket-notation access (``registry[key]``).\"\"\"\n\n        return self.get(key)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.MRegistry.register_prehook","title":"<code>register_prehook(key, func)</code>","text":"<p>Attach a callable executed before an object is instantiated.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def register_prehook(self, key: str, func: t.Union[t.Callable[..., t.Any], str]) -&gt; None:\n    \"\"\"Attach a callable executed before an object is instantiated.\"\"\"\n\n    self.prehooks[key] = func\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.MRegistry.register_posthook","title":"<code>register_posthook(key, func)</code>","text":"<p>Attach a callable executed after an object is instantiated.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def register_posthook(self, key: str, func: t.Union[t.Callable[..., t.Any], str]) -&gt; None:\n    \"\"\"Attach a callable executed after an object is instantiated.\"\"\"\n\n    self.posthooks[key] = func\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.MRegistry.register_hook","title":"<code>register_hook(key, func, kind='pre')</code>","text":"<p>Convenience wrapper for registering pre- or post-hooks.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def register_hook(\n    self,\n    key: str,\n    func: t.Union[t.Callable[..., t.Any], str],\n    kind: t.Literal['pre', 'post'] = 'pre',\n) -&gt; None:\n    \"\"\"Convenience wrapper for registering pre- or post-hooks.\"\"\"\n\n    if kind == 'pre':\n        self.register_prehook(key, func)\n    elif kind == 'post':\n        self.register_posthook(key, func)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.MRegistry.run_obj_init","title":"<code>run_obj_init(key, obj, **kwargs)</code>","text":"<p>Instantiates an object (or invokes a callable) and executes configured hooks.</p> <p>If a 'prehook' is registered for the key, it modifies the <code>kwargs</code> before instantiation. If a 'posthook' is registered, it receives the instantiated object and can modify or replace it.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The registry key associated with the object.</p> required <code>obj</code> <code>Union[Type[RT], RT]</code> <p>The callable/class to instantiate, or an existing instance.</p> required <code>**kwargs</code> <code>Any</code> <p>Arguments to pass to the object constructor/callable.</p> <code>{}</code> <p>Returns:</p> Type Description <code>RT</code> <p>The initialized (and potentially modified) object.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def run_obj_init(\n    self,\n    key: str,\n    obj: t.Union[t.Type[RT], RT],\n    **kwargs: t.Any,\n) -&gt; RT:\n    \"\"\"\n    Instantiates an object (or invokes a callable) and executes configured hooks.\n\n    If a 'prehook' is registered for the key, it modifies the `kwargs` before instantiation.\n    If a 'posthook' is registered, it receives the instantiated object and can modify or replace it.\n\n    Args:\n        key: The registry key associated with the object.\n        obj: The callable/class to instantiate, or an existing instance.\n        **kwargs: Arguments to pass to the object constructor/callable.\n\n    Returns:\n        The initialized (and potentially modified) object.\n    \"\"\"\n\n    if key in self.prehooks:\n        if isinstance(self.prehooks[key], str):\n            self.prehooks[key] = self.lazy_import(self.prehooks[key])\n        kwargs = self.prehooks[key](**kwargs)\n\n    if isinstance(obj, ProxyObject):\n        if self.verbose:\n            self.logger.info(\n                f'Skipping Initialization for Proxy Object: {key}',\n                colored=True,\n                prefix=self.name,\n            )\n    else:\n        obj = obj(**kwargs)\n\n    if key in self.posthooks:\n        if isinstance(self.posthooks[key], str):\n            self.posthooks[key] = self.lazy_import(self.posthooks[key])\n        obj = self.posthooks[key](obj)\n    return obj\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.MRegistry.get","title":"<code>get(key, **kwargs)</code>","text":"<p>Public accessor that memoises lookups for repeat calls.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def get(self, key: str, **kwargs: t.Any) -&gt; RT:\n    \"\"\"Public accessor that memoises lookups for repeat calls.\"\"\"\n\n    if key in self.idx:\n        return self.idx[key]\n    if (item := self._get(key, _raise_error=False, **kwargs)) is not None:\n        self.idx[key] = item\n        return item\n    if possible_key := self.search_for_parent(key, raise_error=False):\n        if possible_key in self.idx:\n            self.idx[key] = self.idx[possible_key]\n            return self.idx[key]\n        if (item := self._get(possible_key, _raise_error=False, **kwargs)) is not None:\n            self.idx[key] = item\n            return item\n    raise KeyError(\n        f'Key {key} not found in {self.name}: '\n        f'init: `{list(self.init_registry.keys())}`, '\n        f'idx: `{list(self.idx.keys())}`'\n    )\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.MRegistry.get_module_path","title":"<code>get_module_path(obj)</code>","text":"<p>Return the filesystem path where <code>obj</code> is defined.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def get_module_path(self, obj: t.Type[RT]) -&gt; Path:\n    \"\"\"Return the filesystem path where ``obj`` is defined.\"\"\"\n\n    return Path(inspect.getfile(obj)).parent\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.MRegistry.search_for_parent","title":"<code>search_for_parent(key, raise_error=True)</code>","text":"<p>Find a registry key that ends with <code>key</code> (supports partial lookups).</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def search_for_parent(self, key: str, raise_error: bool = True) -&gt; t.Optional[str]:\n    \"\"\"Find a registry key that ends with ``key`` (supports partial lookups).\"\"\"\n\n    if self.init_registry:\n        for k in self.init_registry:\n            if k.endswith(key):\n                return k\n\n    if self.uninit_registry:\n        for k in self.uninit_registry:\n            if k.endswith(key):\n                return k\n\n    if self.mregistry:\n        for k in self.mregistry:\n            if k.endswith(key):\n                return k\n\n    if not raise_error:\n        return None\n    raise KeyError(f'Key {key} not found in {self.name}')\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.combine_parts","title":"<code>combine_parts(*parts, sep='.')</code>","text":"<p>Join non-empty fragments into a dotted identifier.</p> <p>Parameters:</p> Name Type Description Default <code>*parts</code> <code>Optional[str]</code> <p>Sequence of string fragments that may include <code>None</code> values.</p> <code>()</code> <code>sep</code> <code>str</code> <p>Delimiter inserted between fragments. Defaults to <code>'.'</code>.</p> <code>'.'</code> <p>Returns:</p> Type Description <code>str</code> <p>A single string containing the provided fragments joined by <code>sep</code>.</p> Source code in <code>src/lzo/registry/base.py</code> <pre><code>def combine_parts(*parts: t.Optional[str], sep: str = '.') -&gt; str:\n    \"\"\"Join non-empty fragments into a dotted identifier.\n\n    Args:\n        *parts: Sequence of string fragments that may include ``None`` values.\n        sep: Delimiter inserted between fragments. Defaults to ``'.'``.\n\n    Returns:\n        A single string containing the provided fragments joined by ``sep``.\n    \"\"\"\n\n    return sep.join(p for p in parts if p)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.get_app_client","title":"<code>get_app_client(client_name, module=None, submodule=None, **kwargs)</code>","text":"<p>Retrieve a client by name, instantiating it if needed.</p> <p>Parameters:</p> Name Type Description Default <code>client_name</code> <code>str</code> <p>Identifier passed to :func:<code>register_client</code>.</p> required <code>module</code> <code>Optional[str]</code> <p>Optional module prefix used during registration.</p> <code>None</code> <code>submodule</code> <code>Optional[str]</code> <p>Optional nested namespace used during registration.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Forwarded to the registered constructor when lazily importing.</p> <code>{}</code> <p>Returns:</p> Type Description <code>'RegisteredClient'</code> <p>Registered client instance associated with <code>client_name</code>.</p> Source code in <code>src/lzo/registry/clients.py</code> <pre><code>def get_app_client(\n    client_name: str,\n    module: t.Optional[str] = None,\n    submodule: t.Optional[str] = None,\n    **kwargs: t.Any,\n) -&gt; 'RegisteredClient':\n    \"\"\"Retrieve a client by name, instantiating it if needed.\n\n    Args:\n        client_name: Identifier passed to :func:`register_client`.\n        module: Optional module prefix used during registration.\n        submodule: Optional nested namespace used during registration.\n        **kwargs: Forwarded to the registered constructor when lazily importing.\n\n    Returns:\n        Registered client instance associated with ``client_name``.\n    \"\"\"\n\n    registry_name = combine_parts(module, submodule, client_name)\n    return _cregistry.get(registry_name, **kwargs)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.register_app_client","title":"<code>register_app_client(client_name, client_path, module=None, submodule=None)</code>","text":"<p>Register a lazily importable client path.</p> <p>Parameters:</p> Name Type Description Default <code>client_name</code> <code>str</code> <p>Friendly name used for lookup.</p> required <code>client_path</code> <code>str</code> <p>Dotted import path to the client class.</p> required <code>module</code> <code>Optional[str]</code> <p>Optional module prefix used to namespacing entries.</p> <code>None</code> <code>submodule</code> <code>Optional[str]</code> <p>Additional namespace segment for nested registries.</p> <code>None</code> Source code in <code>src/lzo/registry/clients.py</code> <pre><code>def register_app_client(\n    client_name: str,\n    client_path: str,\n    module: t.Optional[str] = None,\n    submodule: t.Optional[str] = None,\n) -&gt; None:\n    \"\"\"Register a lazily importable client path.\n\n    Args:\n        client_name: Friendly name used for lookup.\n        client_path: Dotted import path to the client class.\n        module: Optional module prefix used to namespacing entries.\n        submodule: Additional namespace segment for nested registries.\n    \"\"\"\n\n    registry_name = combine_parts(module, submodule, client_name)\n    if registry_name in _cregistry.mregistry:\n        return\n    _cregistry.uninit_registry[registry_name] = client_path\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.register_app_clients","title":"<code>register_app_clients(clients, module=None, submodule=None)</code>","text":"<p>Bulk register lazily loaded client paths.</p> <p>Parameters:</p> Name Type Description Default <code>clients</code> <code>Mapping[str, str]</code> <p>Mapping of client names to dotted import paths.</p> required <code>module</code> <code>Optional[str]</code> <p>Optional module prefix shared across entries.</p> <code>None</code> <code>submodule</code> <code>Optional[str]</code> <p>Optional nested namespace for the group.</p> <code>None</code> Source code in <code>src/lzo/registry/clients.py</code> <pre><code>def register_app_clients(\n    clients: t.Mapping[str, str],\n    module: t.Optional[str] = None,\n    submodule: t.Optional[str] = None,\n) -&gt; None:\n    \"\"\"Bulk register lazily loaded client paths.\n\n    Args:\n        clients: Mapping of client names to dotted import paths.\n        module: Optional module prefix shared across entries.\n        submodule: Optional nested namespace for the group.\n    \"\"\"\n\n    for client_name, client_path in clients.items():\n        register_app_client(client_name, client_path, module=module, submodule=submodule)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.register_client","title":"<code>register_client(client, **kwargs)</code>","text":"<p>Register a client class or instance for lazy lookup.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>Union[Type['RClientT'], 'RClientT']</code> <p>Client type or pre-instantiated object to register.</p> required <code>**kwargs</code> <code>Any</code> <p>Ignored but accepted for compatibility.</p> <code>{}</code> Source code in <code>src/lzo/registry/clients.py</code> <pre><code>def register_client(client: t.Union[t.Type['RClientT'], 'RClientT'], **kwargs: t.Any) -&gt; None:\n    \"\"\"Register a client class or instance for lazy lookup.\n\n    Args:\n        client: Client type or pre-instantiated object to register.\n        **kwargs: Ignored but accepted for compatibility.\n    \"\"\"\n\n    if not isinstance(client, type):\n        register_initialized_client(client, **kwargs)\n        return\n    cls_name = _cregistry.get_classname(client, is_type=True)\n    client_name = client.name if getattr(client, 'name', None) is not None else cls_name\n    cls_module = (\n        client._rmodule\n        if getattr(client, '_rmodule', None) is not None\n        else client.__module__.split('.')[0]\n    )\n    cls_submodule = client._rsubmodule if getattr(client, '_rsubmodule', None) is not None else None\n    registry_name = combine_parts(cls_module, cls_submodule, client_name)\n    if registry_name in _cregistry.mregistry:\n        _cregistry.logger.warning(\n            f'Client {client_name} already registered with `{registry_name}`'\n        )\n        return\n    client._rxtra['module'] = cls_module\n    client._rxtra['submodule'] = cls_submodule\n    client._rxtra['cls_name'] = cls_name\n    client._rxtra['client_name'] = client_name\n    client._rxtra['registry_name'] = registry_name\n    client._rxtra['module_path'] = _cregistry.get_module_path(client)\n    client._rxtra['registered'] = True\n    _cregistry[registry_name] = client\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.register_client_hook","title":"<code>register_client_hook(client_name, func, kind='post', module=None, submodule=None)</code>","text":"<p>Attach a hook to a registered client.</p> <p>Parameters:</p> Name Type Description Default <code>client_name</code> <code>str</code> <p>Registry key that identifies the client.</p> required <code>func</code> <code>Union[Callable[..., Any], str]</code> <p>Callable or dotted import path executed as the hook.</p> required <code>kind</code> <code>Literal['pre', 'post']</code> <p>Whether to run the hook before (<code>'pre'</code>) or after (<code>'post'</code>) instantiation.</p> <code>'post'</code> <code>module</code> <code>Optional[str]</code> <p>Optional module prefix used during registration.</p> <code>None</code> <code>submodule</code> <code>Optional[str]</code> <p>Optional nested namespace used during registration.</p> <code>None</code> Source code in <code>src/lzo/registry/clients.py</code> <pre><code>def register_client_hook(\n    client_name: str,\n    func: t.Union[t.Callable[..., t.Any], str],\n    kind: t.Literal['pre', 'post'] = 'post',\n    module: t.Optional[str] = None,\n    submodule: t.Optional[str] = None,\n) -&gt; None:\n    \"\"\"Attach a hook to a registered client.\n\n    Args:\n        client_name: Registry key that identifies the client.\n        func: Callable or dotted import path executed as the hook.\n        kind: Whether to run the hook before (``'pre'``) or after (``'post'``)\n            instantiation.\n        module: Optional module prefix used during registration.\n        submodule: Optional nested namespace used during registration.\n    \"\"\"\n\n    registry_name = combine_parts(module, submodule, client_name)\n    _cregistry.register_hook(registry_name, func, kind=kind)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.register_initialized_client","title":"<code>register_initialized_client(client, **kwargs)</code>","text":"<p>Record an already instantiated client in the registry.</p> <p>Parameters:</p> Name Type Description Default <code>client</code> <code>'RClientT'</code> <p>Concrete instance created by the caller.</p> required <code>**kwargs</code> <code>Any</code> <p>Currently unused; retained for API compatibility.</p> <code>{}</code> Source code in <code>src/lzo/registry/clients.py</code> <pre><code>def register_initialized_client(client: 'RClientT', **kwargs: t.Any) -&gt; None:\n    \"\"\"Record an already instantiated client in the registry.\n\n    Args:\n        client: Concrete instance created by the caller.\n        **kwargs: Currently unused; retained for API compatibility.\n    \"\"\"\n\n    if hasattr(client, '_rxtra'):\n        _cregistry._register_initialized(client._rxtra['registry_name'], client)\n        return\n    cls_name = _cregistry.get_classname(client, is_type=False)\n    cls_module = (\n        client._rmodule\n        if getattr(client, '_rmodule', None) is not None\n        else client.__class__.__module__.split('.')[0]\n    )\n    cls_submodule = (\n        client._rsubmodule if getattr(client, '_rsubmodule', None) is not None else None\n    )\n    client_name = client.name if getattr(client, 'name', None) is not None else cls_name\n\n    registry_name = combine_parts(cls_module, cls_submodule, client_name)\n    if registry_name in _cregistry.init_registry:\n        return\n    _cregistry._register_initialized(registry_name, client)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.get_app_settings","title":"<code>get_app_settings(module, submodule=None, **kwargs)</code>","text":"<p>Fetch settings for <code>module</code> (and optional <code>submodule</code>).</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>Top-level package name used during registration.</p> required <code>submodule</code> <code>Optional[str]</code> <p>Optional namespace component for nested settings.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Forwarded to the <code>RegisteredSettings</code> constructor when instantiation is required.</p> <code>{}</code> <p>Returns:</p> Type Description <code>'RegisteredSettings'</code> <p>Lazily constructed settings instance, cached for future retrievals.</p> Source code in <code>src/lzo/registry/settings.py</code> <pre><code>def get_app_settings(\n    module: str,\n    submodule: t.Optional[str] = None,\n    **kwargs: t.Any,\n) -&gt; 'RegisteredSettings':\n    \"\"\"Fetch settings for ``module`` (and optional ``submodule``).\n\n    Args:\n        module: Top-level package name used during registration.\n        submodule: Optional namespace component for nested settings.\n        **kwargs: Forwarded to the ``RegisteredSettings`` constructor when\n            instantiation is required.\n\n    Returns:\n        Lazily constructed settings instance, cached for future retrievals.\n    \"\"\"\n\n    registry_name = combine_parts(module, submodule)\n    return _sregistry.get(registry_name, **kwargs)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.register_app_settings","title":"<code>register_app_settings(module, settings_path, submodule=None)</code>","text":"<p>Register a lazily importable settings object.</p> <p>Parameters:</p> Name Type Description Default <code>module</code> <code>str</code> <p>Top-level package name used for lookup.</p> required <code>settings_path</code> <code>str</code> <p>Dotted path to the settings class.</p> required <code>submodule</code> <code>Optional[str]</code> <p>Optional nested namespace for the settings class.</p> <code>None</code> Source code in <code>src/lzo/registry/settings.py</code> <pre><code>def register_app_settings(\n    module: str,\n    settings_path: str,\n    submodule: t.Optional[str] = None,\n) -&gt; None:\n    \"\"\"Register a lazily importable settings object.\n\n    Args:\n        module: Top-level package name used for lookup.\n        settings_path: Dotted path to the settings class.\n        submodule: Optional nested namespace for the settings class.\n    \"\"\"\n\n    registry_name = combine_parts(module, submodule)\n    if registry_name in _sregistry.mregistry:\n        return\n    _sregistry.uninit_registry[registry_name] = settings_path\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.register_initialized_settings","title":"<code>register_initialized_settings(settings)</code>","text":"<p>Cache an already constructed settings object.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>'RSettingT'</code> <p>Instance of a :class:<code>RegisteredSettings</code> subclass.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If another settings instance is already registered for the same module/submodule combination.</p> Source code in <code>src/lzo/registry/settings.py</code> <pre><code>def register_initialized_settings(settings: 'RSettingT') -&gt; None:\n    \"\"\"Cache an already constructed settings object.\n\n    Args:\n        settings: Instance of a :class:`RegisteredSettings` subclass.\n\n    Raises:\n        ValueError: If another settings instance is already registered for the\n            same module/submodule combination.\n    \"\"\"\n\n    if hasattr(settings, '_rxtra'):\n        _sregistry._register_initialized(settings._rxtra['registry_name'], settings)\n        return\n    cls_module = (\n        settings._rmodule\n        if getattr(settings, '_rmodule', None) is not None\n        else settings.__module__.split('.')[0]\n    )\n    cls_submodule = settings._rsubmodule if getattr(settings, '_rsubmodule', None) is not None else None\n    registry_name = combine_parts(cls_module, cls_submodule)\n    if registry_name in _sregistry.init_registry:\n        raise ValueError(f'Module {registry_name} already has registered settings')\n    _sregistry._register_initialized(registry_name, settings)\n</code></pre>"},{"location":"api/lzo/registry/#lzo.registry.register_settings","title":"<code>register_settings(settings)</code>","text":"<p>Register settings for lazy instantiation and discovery.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Union[Type['RSettingT'], 'RSettingT']</code> <p>Settings class or instance to register. Classes are stored for lazy creation; instances are cached immediately.</p> required Source code in <code>src/lzo/registry/settings.py</code> <pre><code>def register_settings(settings: t.Union[t.Type['RSettingT'], 'RSettingT']) -&gt; None:\n    \"\"\"Register settings for lazy instantiation and discovery.\n\n    Args:\n        settings: Settings class or instance to register. Classes are stored for\n            lazy creation; instances are cached immediately.\n    \"\"\"\n\n    if not isinstance(settings, type):\n        register_initialized_settings(settings)\n        return\n    cls_name = _sregistry.get_classname(settings, is_type=True)\n    cls_module = (\n        settings._rmodule\n        if getattr(settings, '_rmodule', None) is not None\n        else settings.__module__.split('.')[0]\n    )\n    cls_submodule = settings._rsubmodule\n    registry_name = combine_parts(cls_module, cls_submodule)\n    if registry_name in _sregistry.mregistry:\n        _sregistry.logger.warning(\n            f'Settings {registry_name} already registered with {cls_module}'\n        )\n        return\n\n    module_config_path = Path(inspect.getfile(settings)).parent\n    settings._rxtra['module'] = cls_module\n    settings._rxtra['submodule'] = cls_submodule\n    settings._rxtra['cls_name'] = cls_name\n    settings._rxtra['module_config_path'] = module_config_path\n    settings._rxtra['registry_name'] = registry_name\n    settings._rxtra['registered'] = True\n\n    if '__main__' not in cls_module:\n        p = module_config_path\n        m_path, iters = None, 0\n        while p.name != cls_module and iters &lt; 4:\n            p = p.parent\n            iters += 1\n            if p.name == cls_module:\n                m_path = p\n                break\n        if m_path is not None:\n            settings._rxtra['module_path'] = m_path\n\n    _sregistry[cls_module] = settings\n</code></pre>"},{"location":"api/lzo/registry/#overview","title":"Overview","text":"<p>The registry pattern centralizes object lifecycle management with support for dependency injection, singleton patterns, and lifecycle hooks.</p>"},{"location":"api/lzo/registry/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzo/registry/#basic-registry","title":"Basic Registry","text":"<pre><code>from lzo.registry import MRegistry\n\n# Create a registry\nregistry = MRegistry()\n\n# Register an object\nregistry.register('config', {'key': 'value'})\n\n# Retrieve the object\nconfig = registry.get('config')\n</code></pre>"},{"location":"api/lzo/registry/#factory-registration","title":"Factory Registration","text":"<pre><code>from lzo.registry import MRegistry\n\nregistry = MRegistry()\n\n# Register a factory function\ndef create_client():\n    return DatabaseClient(host='localhost')\n\nregistry.register_factory('db', create_client)\n\n# Client is created on first access\nclient = registry.get('db')\n</code></pre>"},{"location":"api/lzo/registry/#lifecycle-hooks","title":"Lifecycle Hooks","text":"<pre><code>from lzo.registry import MRegistry\n\nregistry = MRegistry()\n\ndef pre_init_hook(name, **kwargs):\n    print(f\"Creating {name}\")\n    return kwargs\n\ndef post_init_hook(name, instance):\n    print(f\"Created {name}\")\n    instance.setup()\n    return instance\n\nregistry.register_hooks(\n    pre_init=pre_init_hook,\n    post_init=post_init_hook\n)\n</code></pre>"},{"location":"api/lzo/registry/#settings-registry","title":"Settings Registry","text":"<pre><code>from lzo.registry import settings\nfrom lzo.types import BaseSettings\n\nclass AppSettings(BaseSettings):\n    api_key: str\n    timeout: int = 30\n\n# Register settings\nsettings.register('app', AppSettings)\n\n# Access anywhere\napp_config = settings['app']\n</code></pre>"},{"location":"api/lzo/registry/#client-registry","title":"Client Registry","text":"<pre><code>from lzo.registry import clients\n\n# Register API clients\nclients.register('stripe', stripe_client)\nclients.register('sendgrid', sendgrid_client)\n\n# Access clients\nstripe = clients['stripe']\n</code></pre>"},{"location":"api/lzo/registry/#features","title":"Features","text":"<ul> <li>Lazy Initialization: Objects created only when accessed</li> <li>Singleton Support: Control whether objects are shared or recreated</li> <li>Lifecycle Hooks: Pre/post instantiation callbacks</li> <li>Type Safety: Full typing support</li> <li>Thread Safety: Safe for concurrent access</li> <li>Dependency Injection: Automatic resolution of dependencies</li> </ul>"},{"location":"api/lzo/registry/#registry-patterns","title":"Registry Patterns","text":""},{"location":"api/lzo/registry/#global-registries","title":"Global Registries","text":"<p>The module provides pre-configured global registries:</p> <ul> <li><code>settings</code>: For application settings and configuration</li> <li><code>clients</code>: For API clients and external services</li> <li><code>state</code>: For application state management</li> </ul>"},{"location":"api/lzo/registry/#custom-registries","title":"Custom Registries","text":"<p>Create custom registries for specific use cases:</p> <pre><code>from lzo.registry import MRegistry\n\n# Create a specialized registry\ncache_registry = MRegistry()\ncache_registry.register('user_cache', UserCache())\ncache_registry.register('session_cache', SessionCache())\n</code></pre>"},{"location":"api/lzo/registry/#advanced-features","title":"Advanced Features","text":""},{"location":"api/lzo/registry/#dependency-resolution","title":"Dependency Resolution","text":"<pre><code>registry.register('logger', create_logger)\nregistry.register('database', create_database, deps=['logger'])\n# Database will have logger injected\n</code></pre>"},{"location":"api/lzo/registry/#context-managers","title":"Context Managers","text":"<pre><code>with registry.scoped() as scoped_registry:\n    # Objects created in this scope are automatically cleaned up\n    scoped_registry.register('temp', TempResource())\n# TempResource.__exit__() called here\n</code></pre> <p>See the <code>src/lzo/registry/README.md</code> file for detailed information and run <code>make test-lzo-registry</code> to exercise the tests.</p>"},{"location":"api/lzo/state/","title":"lzo.state - State Management","text":"<p>The <code>lzo.state</code> module provides global state management and configuration contexts.</p>"},{"location":"api/lzo/state/#overview","title":"Overview","text":""},{"location":"api/lzo/state/#lzo.state","title":"<code>lzo.state</code>","text":"<p>Registry of Apps / Modules / Objects</p>"},{"location":"api/lzo/types/","title":"lzo.types - Type Definitions and Settings","text":"<p>The <code>lzo.types</code> module re-exports LazyOps pydantic wrappers such as <code>BaseSettings</code> and <code>BaseModel</code>, streamlining environment-aware configuration.</p>"},{"location":"api/lzo/types/#module-reference","title":"Module Reference","text":""},{"location":"api/lzo/types/#lzo.types","title":"<code>lzo.types</code>","text":""},{"location":"api/lzo/types/#lzo.types.BaseModel","title":"<code>BaseModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Thin wrapper over :class:<code>pydantic.BaseModel</code> with permissive extras.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>class BaseModel(_BaseModel):\n    \"\"\"Thin wrapper over :class:`pydantic.BaseModel` with permissive extras.\"\"\"\n\n    if PYDANTIC_VERSION == 2:\n        _extra: t.Dict[str, t.Any] = PrivateAttr(default_factory=dict)\n        model_config = ConfigDict(extra='allow', arbitrary_types_allowed=True)\n    else:\n        _extra: t.Dict[str, t.Any] = Field(default_factory=dict, exclude=True, hidden=True)\n\n        class Config:  # noqa: D106 - pydantic compatibility shim\n            extra = 'allow'\n            arbitrary_types_allowed = True\n\n    def get(self, name: str, default: t.Any = None) -&gt; t.Any:\n        \"\"\"Retrieve ``name`` if present, returning ``default`` otherwise.\"\"\"\n\n        return getattr(self, name, default)\n\n    @classmethod\n    def model_validate_batch(\n        cls: t.Type['ModelT'],\n        items: t.Iterable[t.Any],\n        *,\n        strict: t.Optional[bool] = None,\n        from_attributes: t.Optional[bool] = None,\n        context: t.Optional[t.Dict[str, t.Any]] = None,\n        **kwargs: t.Any,\n    ) -&gt; t.List['ModelT']:\n        \"\"\"Validate many payloads and return instantiated models.\"\"\"\n\n        return [\n            cls.model_validate(item, strict=strict, from_attributes=from_attributes, context=context)\n            for item in items\n        ]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseModel.get","title":"<code>get(name, default=None)</code>","text":"<p>Retrieve <code>name</code> if present, returning <code>default</code> otherwise.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>def get(self, name: str, default: t.Any = None) -&gt; t.Any:\n    \"\"\"Retrieve ``name`` if present, returning ``default`` otherwise.\"\"\"\n\n    return getattr(self, name, default)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseModel.model_validate_batch","title":"<code>model_validate_batch(items, *, strict=None, from_attributes=None, context=None, **kwargs)</code>  <code>classmethod</code>","text":"<p>Validate many payloads and return instantiated models.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@classmethod\ndef model_validate_batch(\n    cls: t.Type['ModelT'],\n    items: t.Iterable[t.Any],\n    *,\n    strict: t.Optional[bool] = None,\n    from_attributes: t.Optional[bool] = None,\n    context: t.Optional[t.Dict[str, t.Any]] = None,\n    **kwargs: t.Any,\n) -&gt; t.List['ModelT']:\n    \"\"\"Validate many payloads and return instantiated models.\"\"\"\n\n    return [\n        cls.model_validate(item, strict=strict, from_attributes=from_attributes, context=context)\n        for item in items\n    ]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseSettings","title":"<code>BaseSettings</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Augmented base settings with environment helpers and logging accessors.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>class BaseSettings(_BaseSettings):\n    \"\"\"Augmented base settings with environment helpers and logging accessors.\"\"\"\n\n    app_env: t.Optional[AppEnv] = None\n    debug_enabled: t.Optional[bool] = None\n\n    if t.TYPE_CHECKING:\n        _rxtra: t.Dict[str, t.Any]\n\n    @eproperty\n    def _is_registered(self) -&gt; bool:\n        \"\"\"Return ``True`` when instantiated via the registry infrastructure.\"\"\"\n\n        return hasattr(self, '_rxtra')\n\n    @eproperty\n    def module_path(self) -&gt; Path:\n        \"\"\"Filesystem path of the module that owns this settings object.\"\"\"\n\n        if self._is_registered and self._rxtra.get('module_path'):\n            return self._rxtra['module_path']\n        return super().module_path\n\n    @eproperty\n    def module_config_path(self) -&gt; Path:\n        \"\"\"Directory containing configuration files for this module.\"\"\"\n\n        if self._is_registered and self._rxtra.get('module_config_path'):\n            return self._rxtra['module_config_path']\n        return super().module_config_path\n\n    @eproperty\n    def module_name(self) -&gt; str:\n        \"\"\"Top-level package name inferred from the module namespace.\"\"\"\n\n        if self._is_registered and self._rxtra.get('module'):\n            return self._rxtra['module']\n        return super().module_name\n\n    @eproperty\n    def logger(self) -&gt; 'Logger':\n        \"\"\"Name-spaced logger for emitting structured diagnostics.\"\"\"\n\n        from lzl.logging import logger\n\n        return logger\n\n    @eproperty\n    def null_logger(self) -&gt; 'NullLogger':\n        \"\"\"No-op logger for silencing diagnostics when debug is disabled.\"\"\"\n\n        from lzl.logging import null_logger\n\n        return null_logger\n\n    @eproperty\n    def autologger(self) -&gt; 'Logger':\n        \"\"\"Return ``logger`` when in debug contexts, else ``null_logger``.\"\"\"\n\n        return self.logger if (self.debug_enabled or self.is_development_env) else self.null_logger\n\n    @eproperty\n    def app_module_name(self) -&gt; t.Optional[str]:\n        \"\"\"Override used to derive the environment prefix for this settings object.\"\"\"\n\n        return self._extra.get('app_module_name')\n\n    @eproperty\n    def ctx(self) -&gt; t.Optional['AppContext']:\n        \"\"\"Return the app context when the settings is registry managed.\"\"\"\n\n        if not self._is_registered:\n            return None\n        from lzo.types.settings.context import AppContextManager\n\n        return AppContextManager.get_ctx(self.module_name)\n\n    @model_validator(mode='after')\n    def validate_app_env(self) -&gt; 'BaseSettings':\n        \"\"\"Populate ``app_env`` based on module or explicit overrides.\"\"\"\n\n        if self.app_env is None:\n            try:\n                if self.app_module_name:\n                    self.app_env = AppEnv.from_module_name(self.app_module_name)\n                elif self.Config.env_prefix:\n                    self.app_env = get_app_env(self.Config.env_prefix.rstrip('_'))\n                else:\n                    self.app_env = get_app_env(self.app_module_name or self.module_name)\n            except Exception:  # pragma: no cover - defensive fallback\n                self.app_env = get_app_env('lzo')\n        elif isinstance(self.app_env, str):\n            self.app_env = AppEnv.from_env(self.app_env)\n        return self\n\n    @property\n    def is_local_env(self) -&gt; bool:\n        \"\"\"Return ``True`` when running in local/development contexts.\"\"\"\n\n        return self.app_env in {AppEnv.DEVELOPMENT, AppEnv.LOCAL} and not self.in_k8s\n\n    @property\n    def is_production_env(self) -&gt; bool:\n        \"\"\"Return ``True`` when production deployments are detected.\"\"\"\n\n        return self.app_env == AppEnv.PRODUCTION and self.in_k8s\n\n    @property\n    def is_development_env(self) -&gt; bool:\n        \"\"\"Return ``True`` when operating in development or CI modes.\"\"\"\n\n        return self.app_env in {AppEnv.DEVELOPMENT, AppEnv.LOCAL, AppEnv.CICD}\n\n    def set_app_env(self, env: AppEnv) -&gt; None:\n        \"\"\"Force the active application environment.\"\"\"\n\n        self.app_env = self.app_env.from_env(env)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.is_local_env","title":"<code>is_local_env</code>  <code>property</code>","text":"<p>Return <code>True</code> when running in local/development contexts.</p>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.is_production_env","title":"<code>is_production_env</code>  <code>property</code>","text":"<p>Return <code>True</code> when production deployments are detected.</p>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.is_development_env","title":"<code>is_development_env</code>  <code>property</code>","text":"<p>Return <code>True</code> when operating in development or CI modes.</p>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.module_path","title":"<code>module_path()</code>","text":"<p>Filesystem path of the module that owns this settings object.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_path(self) -&gt; Path:\n    \"\"\"Filesystem path of the module that owns this settings object.\"\"\"\n\n    if self._is_registered and self._rxtra.get('module_path'):\n        return self._rxtra['module_path']\n    return super().module_path\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.module_config_path","title":"<code>module_config_path()</code>","text":"<p>Directory containing configuration files for this module.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_config_path(self) -&gt; Path:\n    \"\"\"Directory containing configuration files for this module.\"\"\"\n\n    if self._is_registered and self._rxtra.get('module_config_path'):\n        return self._rxtra['module_config_path']\n    return super().module_config_path\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.module_name","title":"<code>module_name()</code>","text":"<p>Top-level package name inferred from the module namespace.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_name(self) -&gt; str:\n    \"\"\"Top-level package name inferred from the module namespace.\"\"\"\n\n    if self._is_registered and self._rxtra.get('module'):\n        return self._rxtra['module']\n    return super().module_name\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.logger","title":"<code>logger()</code>","text":"<p>Name-spaced logger for emitting structured diagnostics.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef logger(self) -&gt; 'Logger':\n    \"\"\"Name-spaced logger for emitting structured diagnostics.\"\"\"\n\n    from lzl.logging import logger\n\n    return logger\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.null_logger","title":"<code>null_logger()</code>","text":"<p>No-op logger for silencing diagnostics when debug is disabled.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef null_logger(self) -&gt; 'NullLogger':\n    \"\"\"No-op logger for silencing diagnostics when debug is disabled.\"\"\"\n\n    from lzl.logging import null_logger\n\n    return null_logger\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.autologger","title":"<code>autologger()</code>","text":"<p>Return <code>logger</code> when in debug contexts, else <code>null_logger</code>.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef autologger(self) -&gt; 'Logger':\n    \"\"\"Return ``logger`` when in debug contexts, else ``null_logger``.\"\"\"\n\n    return self.logger if (self.debug_enabled or self.is_development_env) else self.null_logger\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.app_module_name","title":"<code>app_module_name()</code>","text":"<p>Override used to derive the environment prefix for this settings object.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef app_module_name(self) -&gt; t.Optional[str]:\n    \"\"\"Override used to derive the environment prefix for this settings object.\"\"\"\n\n    return self._extra.get('app_module_name')\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.ctx","title":"<code>ctx()</code>","text":"<p>Return the app context when the settings is registry managed.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef ctx(self) -&gt; t.Optional['AppContext']:\n    \"\"\"Return the app context when the settings is registry managed.\"\"\"\n\n    if not self._is_registered:\n        return None\n    from lzo.types.settings.context import AppContextManager\n\n    return AppContextManager.get_ctx(self.module_name)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.validate_app_env","title":"<code>validate_app_env()</code>","text":"<p>Populate <code>app_env</code> based on module or explicit overrides.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@model_validator(mode='after')\ndef validate_app_env(self) -&gt; 'BaseSettings':\n    \"\"\"Populate ``app_env`` based on module or explicit overrides.\"\"\"\n\n    if self.app_env is None:\n        try:\n            if self.app_module_name:\n                self.app_env = AppEnv.from_module_name(self.app_module_name)\n            elif self.Config.env_prefix:\n                self.app_env = get_app_env(self.Config.env_prefix.rstrip('_'))\n            else:\n                self.app_env = get_app_env(self.app_module_name or self.module_name)\n        except Exception:  # pragma: no cover - defensive fallback\n            self.app_env = get_app_env('lzo')\n    elif isinstance(self.app_env, str):\n        self.app_env = AppEnv.from_env(self.app_env)\n    return self\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.BaseSettings.set_app_env","title":"<code>set_app_env(env)</code>","text":"<p>Force the active application environment.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>def set_app_env(self, env: AppEnv) -&gt; None:\n    \"\"\"Force the active application environment.\"\"\"\n\n    self.app_env = self.app_env.from_env(env)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.RBaseModel","title":"<code>RBaseModel</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Base model variant that exposes module-level metadata helpers.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>class RBaseModel(BaseModel):\n    \"\"\"Base model variant that exposes module-level metadata helpers.\"\"\"\n\n    @eproperty\n    def module_path(self) -&gt; Path:\n        \"\"\"Return the installation path where the module is located.\"\"\"\n\n        import pkg_resources\n\n        path = Path(pkg_resources.get_distribution(self.module_name).location)\n        if 'src' in path.name and path.joinpath(self.module_name).exists():\n            path = path.joinpath(self.module_name)\n        elif path.joinpath('src').exists() and path.joinpath('src', self.module_name).exists():\n            path = path.joinpath('src', self.module_name)\n        return path\n\n    @eproperty\n    def module_config_path(self) -&gt; Path:\n        \"\"\"Directory containing the module configuration files.\"\"\"\n\n        return Path(inspect.getfile(self.__class__)).parent\n\n    @eproperty\n    def module_name(self) -&gt; str:\n        \"\"\"Top-level module name inferred from the class namespace.\"\"\"\n\n        return self.__class__.__module__.split('.')[0]\n\n    @eproperty\n    def module_version(self) -&gt; str:\n        \"\"\"Resolve the installed package version for this module.\"\"\"\n\n        import pkg_resources\n\n        return pkg_resources.get_distribution(self.module_name).version\n\n    @eproperty\n    def module_pkg_name(self) -&gt; str:\n        \"\"\"Return the package-relative path segment hosting configuration.\"\"\"\n\n        config_path = self.module_config_path.as_posix()\n        module_path = self.module_path.as_posix()\n        return config_path.replace(module_path, '').strip().split('/', 2)[1]\n\n    @eproperty\n    def in_k8s(self) -&gt; bool:\n        \"\"\"Return whether the process is detected inside a Kubernetes pod.\"\"\"\n\n        from lzo.utils.system import is_in_kubernetes\n\n        return is_in_kubernetes()\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.RBaseModel.module_path","title":"<code>module_path()</code>","text":"<p>Return the installation path where the module is located.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_path(self) -&gt; Path:\n    \"\"\"Return the installation path where the module is located.\"\"\"\n\n    import pkg_resources\n\n    path = Path(pkg_resources.get_distribution(self.module_name).location)\n    if 'src' in path.name and path.joinpath(self.module_name).exists():\n        path = path.joinpath(self.module_name)\n    elif path.joinpath('src').exists() and path.joinpath('src', self.module_name).exists():\n        path = path.joinpath('src', self.module_name)\n    return path\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.RBaseModel.module_config_path","title":"<code>module_config_path()</code>","text":"<p>Directory containing the module configuration files.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_config_path(self) -&gt; Path:\n    \"\"\"Directory containing the module configuration files.\"\"\"\n\n    return Path(inspect.getfile(self.__class__)).parent\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.RBaseModel.module_name","title":"<code>module_name()</code>","text":"<p>Top-level module name inferred from the class namespace.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_name(self) -&gt; str:\n    \"\"\"Top-level module name inferred from the class namespace.\"\"\"\n\n    return self.__class__.__module__.split('.')[0]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.RBaseModel.module_version","title":"<code>module_version()</code>","text":"<p>Resolve the installed package version for this module.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_version(self) -&gt; str:\n    \"\"\"Resolve the installed package version for this module.\"\"\"\n\n    import pkg_resources\n\n    return pkg_resources.get_distribution(self.module_name).version\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.RBaseModel.module_pkg_name","title":"<code>module_pkg_name()</code>","text":"<p>Return the package-relative path segment hosting configuration.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef module_pkg_name(self) -&gt; str:\n    \"\"\"Return the package-relative path segment hosting configuration.\"\"\"\n\n    config_path = self.module_config_path.as_posix()\n    module_path = self.module_path.as_posix()\n    return config_path.replace(module_path, '').strip().split('/', 2)[1]\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.RBaseModel.in_k8s","title":"<code>in_k8s()</code>","text":"<p>Return whether the process is detected inside a Kubernetes pod.</p> Source code in <code>src/lzo/types/base.py</code> <pre><code>@eproperty\ndef in_k8s(self) -&gt; bool:\n    \"\"\"Return whether the process is detected inside a Kubernetes pod.\"\"\"\n\n    from lzo.utils.system import is_in_kubernetes\n\n    return is_in_kubernetes()\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.eproperty","title":"<code>eproperty</code>","text":"<p>               Bases: <code>property</code></p> <p>Works similarly to property(), but computes the value only once.</p> <p>Designed specifically for <code>pydantic</code> models using <code>PrivateAttr</code>. It expects that the <code>_extra</code> attribute is a <code>PrivateAttr</code> that is used to store the computed value.</p> <p>This essentially memorizes the value of the property by storing the result of its computation in the <code>_extra</code> of the object instance.  This is useful for computing the value of some property that should otherwise be invariant.  For example, the two examples below are equivalent::</p> <pre><code>&gt;&gt;&gt; class LazyTest(BaseModel):\n...     _extra: Dict[str, Any] = PrivateAttr(default_factory = dict)\n...     @property\n...     def complicated_property(self):\n...         if 'complicated_property' not in self._extra:\n...             print('Computing the value for complicated_property...')\n...             self._extra['complicated_property'] = 42\n...         return self._extra['complicated_property']\n...\n...     @eproperty('_extra')\n...     def complicated_property(self):\n...         print('Computing the value for complicated_property...')\n...         return 42\n...\n&gt;&gt;&gt; lt = LazyTest()\n&gt;&gt;&gt; lt.complicated_property\nComputing the value for complicated_property...\n42\n&gt;&gt;&gt; lt.complicated_property\n42\n</code></pre> <p>As the example shows, the second time <code>complicated_property</code> is accessed, the <code>print</code> statement is not executed.  Only the return value from the first access off <code>complicated_property</code> is returned.</p> <p>By default, a setter and deleter are used which simply overwrite and delete, respectively, the value stored in <code>_extra</code>. Any user-specified setter or deleter is executed before executing these default actions. The one exception is that the default setter is not run if the user setter already sets the new value in <code>_extra</code> and returns that value and the returned value is not <code>None</code>.</p> Source code in <code>src/lzl/types/properties.py</code> <pre><code>class eproperty(property):\n    \"\"\"\n    Works similarly to property(), but computes the value only once.\n\n    Designed specifically for `pydantic` models using `PrivateAttr`.\n    It expects that the `_extra` attribute is a `PrivateAttr` that is\n    used to store the computed value.\n\n    This essentially memorizes the value of the property by storing the result\n    of its computation in the ``_extra`` of the object instance.  This is\n    useful for computing the value of some property that should otherwise be\n    invariant.  For example, the two examples below are equivalent::\n\n        &gt;&gt;&gt; class LazyTest(BaseModel):\n        ...     _extra: Dict[str, Any] = PrivateAttr(default_factory = dict)\n        ...     @property\n        ...     def complicated_property(self):\n        ...         if 'complicated_property' not in self._extra:\n        ...             print('Computing the value for complicated_property...')\n        ...             self._extra['complicated_property'] = 42\n        ...         return self._extra['complicated_property']\n        ...\n        ...     @eproperty('_extra')\n        ...     def complicated_property(self):\n        ...         print('Computing the value for complicated_property...')\n        ...         return 42\n        ...\n        &gt;&gt;&gt; lt = LazyTest()\n        &gt;&gt;&gt; lt.complicated_property\n        Computing the value for complicated_property...\n        42\n        &gt;&gt;&gt; lt.complicated_property\n        42\n\n    As the example shows, the second time ``complicated_property`` is accessed,\n    the ``print`` statement is not executed.  Only the return value from the\n    first access off ``complicated_property`` is returned.\n\n    By default, a setter and deleter are used which simply overwrite and\n    delete, respectively, the value stored in ``_extra``. Any user-specified\n    setter or deleter is executed before executing these default actions.\n    The one exception is that the default setter is not run if the user setter\n    already sets the new value in ``_extra`` and returns that value and the\n    returned value is not ``None``.\n    \"\"\"\n\n    def __init__(self, fget, fset=None, fdel=None, doc=None, key: t.Optional[str] = None):\n        super().__init__(fget, fset, fdel, doc)\n        self._key = key or self.fget.__name__\n\n    def __get__(self, obj: 'BaseModel', owner=None):\n        \"\"\"\n        Returns the value\n        \"\"\"\n        try:\n            if self._key not in obj._extra: \n                obj._extra[self._key] = self.fget(obj)\n            return obj._extra.get(self._key)\n        except AttributeError:\n            if obj is None:\n                return self\n            raise\n\n    def __set__(self, obj: 'BaseModel', val):\n        \"\"\"\n        Sets the value\n        \"\"\"\n        if self.fset:\n            ret = self.fset(obj, val)\n            if ret is not None and obj._extra.get(self._key) is ret:\n                # By returning the value set the setter signals that it\n                # took over setting the value in obj.__dict__; this\n                # mechanism allows it to override the input value\n                return\n            val = ret\n        obj._extra[self._key] = val\n\n\n    def __delete__(self, obj: 'BaseModel'):\n        \"\"\"\n        Deletes the value\n        \"\"\"\n        if self.fdel: self.fdel(obj)\n        obj._extra.pop(self._key, None)    # Delete if present\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.AppEnv","title":"<code>AppEnv</code>","text":"<p>               Bases: <code>str</code>, <code>Enum</code></p> Source code in <code>src/lzl/types/common.py</code> <pre><code>class AppEnv(str, Enum):\n    CICD = \"cicd\"\n    DEVELOPMENT = \"development\"\n    STAGING = \"staging\"\n    PRODUCTION = \"production\"\n    LOCAL = \"local\"\n    TEST = \"test\"\n\n    @classmethod\n    def from_env(cls, env_value: str) -&gt; \"AppEnv\":\n        \"\"\"\n        Determines the AppEnv from a string value, handling various formats and partial matches.\n\n        Args:\n            env_value: The string value to parse (e.g., \"production\", \"prod\", \"ci/cd\").\n\n        Returns:\n            The corresponding AppEnv member.\n\n        Raises:\n            ValueError: If the value cannot be mapped to a known environment.\n        \"\"\"\n        env_value = env_value.lower()\n        if \"cicd\" in env_value or \"ci/cd\" in env_value: return cls.CICD\n        if \"prod\" in env_value: return cls.PRODUCTION\n        if \"dev\" in env_value: return cls.DEVELOPMENT\n        if \"staging\" in env_value: return cls.STAGING\n        if \"local\" in env_value: return cls.LOCAL\n        if \"test\" in env_value: return cls.TEST\n        raise ValueError(f\"Invalid app environment: {env_value} ({type(env_value)})\")\n\n    @classmethod\n    def from_hostname(cls, hostname: str) -&gt; \"AppEnv\":\n        \"\"\"\n        Get the app environment from the hostname\n        \"\"\"\n        hostname = hostname.lower()\n        if \"dev\" in hostname: return cls.DEVELOPMENT\n        if \"staging\" in hostname: return cls.STAGING\n        if \"test\" in hostname: return cls.TEST\n        return cls.LOCAL if \"local\" in hostname else cls.PRODUCTION\n\n\n    @classmethod\n    def from_module_name(cls, module_name: str) -&gt; 'AppEnv':\n        \"\"\"\n        Retrieves the app environment\n        \"\"\"\n        module_name = module_name.replace(\".\", \"_\").upper()\n        for key in {\n            \"SERVER_ENV\",\n            f\"{module_name}_ENV\",\n            \"APP_ENV\",\n            \"ENVIRONMENT\",\n        }:\n            if env_value := os.getenv(key):\n                return cls.from_env(env_value)\n\n        from lzo.utils.system import is_in_kubernetes, get_host_name\n        if is_in_kubernetes():\n            hn = get_host_name()\n            try:\n                parts = hn.split(\"-\")\n                for p in parts:\n                    if all(\n                        e not in p.lower()\n                        for e in {'development', 'test', 'staging', 'local', 'dev', 'prod', 'production'}\n                    ):\n                        parts.remove(p)\n                return cls.from_env(parts[0]) if len(parts) &gt; 0 else cls.PRODUCTION\n                # return cls.PRODUCTION\n                # return cls.from_env(parts[2]) if len(parts) &gt; 3 else cls.PRODUCTION\n            except Exception as e:\n                return cls.from_hostname(hn)\n\n        return cls.LOCAL\n\n    def __eq__(self, other: Any) -&gt; bool:\n        \"\"\"\n        Equality operator\n        \"\"\"\n        if isinstance(other, str): return self.value == other.lower()\n        return self.value == other.value if isinstance(other, AppEnv) else False\n\n    @property\n    def is_devel(self) -&gt; bool:\n        \"\"\"\n        Returns True if the app environment is development\n        \"\"\"\n        return self in [self.LOCAL, self.CICD, self.DEVELOPMENT, self.STAGING, self.TEST]\n\n    @property\n    def is_local(self) -&gt; bool:\n        \"\"\"\n        Returns True if the app environment is local\n        \"\"\"\n        return self in [self.LOCAL, self.CICD]\n\n    @property\n    def name(self) -&gt; str:\n        \"\"\"\n        Returns the name in lower\n        \"\"\"\n        return self.value.lower()\n\n    @property\n    def short_name(self) -&gt; str:\n        \"\"\"\n        Returns the short name in lower\n        \"\"\"\n        if self == self.DEVELOPMENT: return 'dev'\n        return 'prod' if self == self.PRODUCTION else self.name\n\n    def select(self, values: Dict[Union[str, 'AppEnv'], Any], default: Optional[Any] = None) -&gt; Any:\n        \"\"\"\n        Returns the value for the app env\n        \"\"\"\n        return next((value for key, value in values.items() if key == self), default)\n\n\n    @classmethod\n    def extend(cls, name: str, value: Any):\n        \"\"\"\n        Extends the enum with a new value\n        \"\"\"\n        if not _EXTEND_SUPPORTED: raise ImportError('aenum is not installed. Please install it to use this feature')\n        extend_enum(cls, name, value)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.AppEnv.is_devel","title":"<code>is_devel</code>  <code>property</code>","text":"<p>Returns True if the app environment is development</p>"},{"location":"api/lzo/types/#lzo.types.AppEnv.is_local","title":"<code>is_local</code>  <code>property</code>","text":"<p>Returns True if the app environment is local</p>"},{"location":"api/lzo/types/#lzo.types.AppEnv.name","title":"<code>name</code>  <code>property</code>","text":"<p>Returns the name in lower</p>"},{"location":"api/lzo/types/#lzo.types.AppEnv.short_name","title":"<code>short_name</code>  <code>property</code>","text":"<p>Returns the short name in lower</p>"},{"location":"api/lzo/types/#lzo.types.AppEnv.from_env","title":"<code>from_env(env_value)</code>  <code>classmethod</code>","text":"<p>Determines the AppEnv from a string value, handling various formats and partial matches.</p> <p>Parameters:</p> Name Type Description Default <code>env_value</code> <code>str</code> <p>The string value to parse (e.g., \"production\", \"prod\", \"ci/cd\").</p> required <p>Returns:</p> Type Description <code>AppEnv</code> <p>The corresponding AppEnv member.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the value cannot be mapped to a known environment.</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef from_env(cls, env_value: str) -&gt; \"AppEnv\":\n    \"\"\"\n    Determines the AppEnv from a string value, handling various formats and partial matches.\n\n    Args:\n        env_value: The string value to parse (e.g., \"production\", \"prod\", \"ci/cd\").\n\n    Returns:\n        The corresponding AppEnv member.\n\n    Raises:\n        ValueError: If the value cannot be mapped to a known environment.\n    \"\"\"\n    env_value = env_value.lower()\n    if \"cicd\" in env_value or \"ci/cd\" in env_value: return cls.CICD\n    if \"prod\" in env_value: return cls.PRODUCTION\n    if \"dev\" in env_value: return cls.DEVELOPMENT\n    if \"staging\" in env_value: return cls.STAGING\n    if \"local\" in env_value: return cls.LOCAL\n    if \"test\" in env_value: return cls.TEST\n    raise ValueError(f\"Invalid app environment: {env_value} ({type(env_value)})\")\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.AppEnv.from_hostname","title":"<code>from_hostname(hostname)</code>  <code>classmethod</code>","text":"<p>Get the app environment from the hostname</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef from_hostname(cls, hostname: str) -&gt; \"AppEnv\":\n    \"\"\"\n    Get the app environment from the hostname\n    \"\"\"\n    hostname = hostname.lower()\n    if \"dev\" in hostname: return cls.DEVELOPMENT\n    if \"staging\" in hostname: return cls.STAGING\n    if \"test\" in hostname: return cls.TEST\n    return cls.LOCAL if \"local\" in hostname else cls.PRODUCTION\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.AppEnv.from_module_name","title":"<code>from_module_name(module_name)</code>  <code>classmethod</code>","text":"<p>Retrieves the app environment</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef from_module_name(cls, module_name: str) -&gt; 'AppEnv':\n    \"\"\"\n    Retrieves the app environment\n    \"\"\"\n    module_name = module_name.replace(\".\", \"_\").upper()\n    for key in {\n        \"SERVER_ENV\",\n        f\"{module_name}_ENV\",\n        \"APP_ENV\",\n        \"ENVIRONMENT\",\n    }:\n        if env_value := os.getenv(key):\n            return cls.from_env(env_value)\n\n    from lzo.utils.system import is_in_kubernetes, get_host_name\n    if is_in_kubernetes():\n        hn = get_host_name()\n        try:\n            parts = hn.split(\"-\")\n            for p in parts:\n                if all(\n                    e not in p.lower()\n                    for e in {'development', 'test', 'staging', 'local', 'dev', 'prod', 'production'}\n                ):\n                    parts.remove(p)\n            return cls.from_env(parts[0]) if len(parts) &gt; 0 else cls.PRODUCTION\n            # return cls.PRODUCTION\n            # return cls.from_env(parts[2]) if len(parts) &gt; 3 else cls.PRODUCTION\n        except Exception as e:\n            return cls.from_hostname(hn)\n\n    return cls.LOCAL\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.AppEnv.select","title":"<code>select(values, default=None)</code>","text":"<p>Returns the value for the app env</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>def select(self, values: Dict[Union[str, 'AppEnv'], Any], default: Optional[Any] = None) -&gt; Any:\n    \"\"\"\n    Returns the value for the app env\n    \"\"\"\n    return next((value for key, value in values.items() if key == self), default)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.AppEnv.extend","title":"<code>extend(name, value)</code>  <code>classmethod</code>","text":"<p>Extends the enum with a new value</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>@classmethod\ndef extend(cls, name: str, value: Any):\n    \"\"\"\n    Extends the enum with a new value\n    \"\"\"\n    if not _EXTEND_SUPPORTED: raise ImportError('aenum is not installed. Please install it to use this feature')\n    extend_enum(cls, name, value)\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.get_schema_extra","title":"<code>get_schema_extra(schema, _)</code>","text":"<p>Helper to get the extra schema</p> Source code in <code>src/lzl/types/base.py</code> <pre><code>def get_schema_extra(schema: typing.Dict[str, typing.Any], _):\n    \"\"\"\n    Helper to get the extra schema\n    \"\"\"\n    props = {\n        k: v\n        for k, v in schema.get('properties', {}).items()\n        if not v.get(\"hidden\", False) and not k.startswith('_')\n    }\n    schema[\"properties\"] = props\n</code></pre>"},{"location":"api/lzo/types/#lzo.types.get_app_env","title":"<code>get_app_env(module_name)</code>","text":"<p>Retrieves the app environment</p> Source code in <code>src/lzl/types/common.py</code> <pre><code>def get_app_env(\n    module_name: str,\n) -&gt; AppEnv:\n    \"\"\"\n    Retrieves the app environment\n    \"\"\"\n    module_name = module_name.replace(\".\", \"_\").upper()\n    for key in {\n        \"SERVER_ENV\",\n        f\"{module_name}_ENV\",\n        \"APP_ENV\",\n        \"ENVIRONMENT\",\n    }:\n        if env_value := os.getenv(key):\n            return AppEnv.from_env(env_value)\n\n    from lzo.utils.system import is_in_kubernetes, get_host_name\n    if is_in_kubernetes():\n        # Name should be\n        # scout-&lt;service&gt;-&lt;index&gt;\n        # or \n        # scout-&lt;service&gt;-&lt;env&gt;-&lt;index&gt;\n        hn = get_host_name()\n        try:\n            parts = hn.split(\"-\")\n            return AppEnv.from_env(parts[1]) if len(parts) &gt; 2 else AppEnv.PRODUCTION\n        except Exception as e:\n            return AppEnv.from_hostname(hn)\n        # parts = get_host_name().split(\"-\")\n        # return AppEnv.from_env(parts[2]) if len(parts) &gt; 3 else AppEnv.PRODUCTION\n\n    return AppEnv.LOCAL\n</code></pre>"},{"location":"api/lzo/types/#overview","title":"Overview","text":"<p>The types module provides enhanced Pydantic models with additional functionality for configuration management, validation, and serialization.</p>"},{"location":"api/lzo/types/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzo/types/#basic-settings","title":"Basic Settings","text":"<pre><code>from lzo.types import BaseSettings\n\nclass DatabaseSettings(BaseSettings):\n    host: str = \"localhost\"\n    port: int = 5432\n    username: str\n    password: str\n    database: str\n\n    class Config:\n        env_prefix = \"DB_\"\n\n# Automatically loads from environment variables\n# DB_HOST, DB_PORT, DB_USERNAME, DB_PASSWORD, DB_DATABASE\nsettings = DatabaseSettings()\n</code></pre>"},{"location":"api/lzo/types/#base-model","title":"Base Model","text":"<pre><code>from lzo.types import BaseModel\n\nclass User(BaseModel):\n    id: int\n    username: str\n    email: str\n    active: bool = True\n\nuser = User(id=1, username=\"john\", email=\"john@example.com\")\n</code></pre>"},{"location":"api/lzo/types/#environment-aware-configuration","title":"Environment-Aware Configuration","text":"<pre><code>from lzo.types import BaseSettings\nfrom lzo.types.common import AppEnv\n\nclass AppSettings(BaseSettings):\n    env: AppEnv = AppEnv.DEVELOPMENT\n    debug: bool = True\n\n    @property\n    def is_production(self) -&gt; bool:\n        return self.env == AppEnv.PRODUCTION\n\nsettings = AppSettings()\nif settings.is_production:\n    # Production-specific logic\n    pass\n</code></pre>"},{"location":"api/lzo/types/#nested-configuration","title":"Nested Configuration","text":"<pre><code>from lzo.types import BaseSettings, BaseModel\n\nclass RedisConfig(BaseModel):\n    host: str = \"localhost\"\n    port: int = 6379\n    db: int = 0\n\nclass CacheConfig(BaseModel):\n    ttl: int = 3600\n    redis: RedisConfig\n\nclass AppSettings(BaseSettings):\n    cache: CacheConfig\n\nsettings = AppSettings()\nprint(settings.cache.redis.host)\n</code></pre>"},{"location":"api/lzo/types/#validation-and-serialization","title":"Validation and Serialization","text":"<pre><code>from lzo.types import BaseModel\nfrom pydantic import validator\n\nclass APIConfig(BaseModel):\n    url: str\n    timeout: int = 30\n\n    @validator('url')\n    def validate_url(cls, v):\n        if not v.startswith(('http://', 'https://')):\n            raise ValueError('URL must start with http:// or https://')\n        return v\n\n# Validate\nconfig = APIConfig(url=\"https://api.example.com\")\n\n# Serialize\nconfig_dict = config.model_dump()\nconfig_json = config.model_dump_json()\n</code></pre>"},{"location":"api/lzo/types/#features","title":"Features","text":"<ul> <li>Environment Variables: Automatic loading from environment</li> <li>Type Validation: Runtime type checking with Pydantic</li> <li>Default Values: Sensible defaults with override capability</li> <li>Nested Models: Support for complex configuration structures</li> <li>Serialization: Convert to/from dict, JSON, YAML</li> <li>Immutability: Optional frozen models for thread safety</li> </ul>"},{"location":"api/lzo/types/#configuration-patterns","title":"Configuration Patterns","text":""},{"location":"api/lzo/types/#development-vs-production","title":"Development vs Production","text":"<pre><code>from lzo.types import BaseSettings\nfrom lzo.types.common import AppEnv\n\nclass Settings(BaseSettings):\n    env: AppEnv = AppEnv.DEVELOPMENT\n\n    @property\n    def database_url(self) -&gt; str:\n        if self.env == AppEnv.PRODUCTION:\n            return \"postgresql://prod-server/db\"\n        return \"postgresql://localhost/dev_db\"\n</code></pre>"},{"location":"api/lzo/types/#secret-management","title":"Secret Management","text":"<pre><code>from lzo.types import BaseSettings\nfrom pydantic import SecretStr\n\nclass APISettings(BaseSettings):\n    api_key: SecretStr\n\n    class Config:\n        env_file = \".env\"\n        env_file_encoding = \"utf-8\"\n\nsettings = APISettings()\n# Use get_secret_value() to access the secret\napi_key = settings.api_key.get_secret_value()\n</code></pre>"},{"location":"api/lzo/types/#multi-environment-support","title":"Multi-Environment Support","text":"<pre><code>from lzo.types import BaseSettings\nfrom pathlib import Path\n\nclass Settings(BaseSettings):\n    class Config:\n        env_file = Path(\".env\")\n        env_file_encoding = \"utf-8\"\n        case_sensitive = False\n\n        @classmethod\n        def customise_sources(cls, init_settings, env_settings, file_secret_settings):\n            # Customize the order of configuration sources\n            return (init_settings, env_settings, file_secret_settings)\n</code></pre>"},{"location":"api/lzo/types/#best-practices","title":"Best Practices","text":"<ol> <li>Use environment variables for sensitive configuration</li> <li>Provide sensible defaults for optional settings</li> <li>Validate configuration at startup, not at use time</li> <li>Use nested models for related configuration groups</li> <li>Document your settings with docstrings and field descriptions</li> </ol> <p>Quick-start examples live in <code>src/lzo/types/README.md</code> and can be validated with <code>make test-lzo-types</code>.</p>"},{"location":"api/lzo/utils/","title":"lzo.utils - Utility Helpers","text":"<p>The <code>lzo.utils</code> module collects lightweight helper modules (retry decorators, key generators, formatting utilities) that avoid heavy dependencies.</p>"},{"location":"api/lzo/utils/#module-reference","title":"Module Reference","text":""},{"location":"api/lzo/utils/#lzo.utils","title":"<code>lzo.utils</code>","text":""},{"location":"api/lzo/utils/#lzo.utils.NullLogger","title":"<code>NullLogger</code>","text":"<p>               Bases: <code>Logger</code>, <code>LoggingMixin</code></p> <p>Logger that delegates output to hooks without emitting messages.</p> Source code in <code>src/lzl/logging/null_logger.py</code> <pre><code>class NullLogger(logging.Logger, LoggingMixin):\n    \"\"\"Logger that delegates output to hooks without emitting messages.\"\"\"\n\n    def _format_item(\n        self,\n        msg: MsgItem,\n        max_length: int | None = None,\n        colored: bool | None = False,\n        level: str | None = None,\n        _is_part: bool | None = False,\n    ) -&gt; str:\n        return format_item(msg, max_length=max_length, colored=colored, level=level, _is_part=_is_part)\n\n    def _format_message(\n        self,\n        message: MsgItem,\n        *args: MsgItem,\n        prefix: str | None = None,\n        max_length: int | None = None,\n        level: str | None = None,\n        colored: bool | None = False,\n        extra: dict[str, t.Any] | None = None,\n    ) -&gt; str:\n        return format_message(\n            message,\n            *args,\n            prefix=prefix,\n            max_length=max_length,\n            level=level,\n            colored=colored,\n            extra=extra,\n        )\n\n    def _get_level(self, level: t.Union[str, int]) -&gt; str:\n        return get_logging_level(level)\n\n    def log(\n        self,\n        level: t.Union[str, int],\n        message: t.Any,\n        *args: MsgItem,\n        prefix: str | None = None,\n        max_length: int | None = None,\n        colored: bool | None = False,\n        hook: t.Callable[[str], None] | None = None,\n        **kwargs: t.Any,\n    ) -&gt; None:  # noqa: N805\n        if not hook:\n            return\n        resolved_level = self._get_level(level)\n        extra = kwargs.get(\"extra\")\n        rendered = self._format_message(\n            message,\n            *args,\n            prefix=prefix,\n            max_length=max_length,\n            colored=colored,\n            level=resolved_level,\n            extra=extra,\n        )\n        self.run_logging_hooks(rendered, hook=hook)\n\n    def info(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n        self.log(\"INFO\", *args, **kwargs)\n\n    def debug(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n        self.log(\"DEBUG\", *args, **kwargs)\n\n    def warning(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n        self.log(\"WARNING\", *args, **kwargs)\n\n    def error(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n        self.log(\"ERROR\", *args, **kwargs)\n\n    def trace(\n        self,\n        msg: t.Union[str, t.Any],\n        error: type[BaseException] | None = None,\n        level: str = \"ERROR\",\n        limit: int | None = None,\n        chain: bool | None = True,\n        colored: bool | None = False,\n        prefix: str | None = None,\n        max_length: int | None = None,\n        hook: t.Callable[[str], None] | None = None,\n        **kwargs: t.Any,\n    ) -&gt; None:\n        if not hook:\n            return\n        depth = kwargs.pop(\"depth\", None)\n        if depth is not None:\n            limit = depth\n        extra = kwargs.get(\"extra\")\n        if isinstance(msg, str):\n            rendered = msg\n            if extra:\n                extra_rendered = format_item(extra, max_length=max_length, colored=colored, level=level)\n                extra_rendered = extra_rendered.lstrip(\"\\n\")\n                if extra_rendered:\n                    rendered = f\"{rendered}\\n{extra_rendered}\" if rendered else extra_rendered\n        else:\n            rendered = self._format_message(\n                msg,\n                colored=colored,\n                prefix=prefix,\n                max_length=max_length,\n                level=level,\n                extra=extra,\n            )\n        rendered += f\"\\n{traceback.format_exc(chain=chain, limit=limit)}\"\n        if error:\n            rendered += f\" - {error}\"\n        self.run_logging_hooks(rendered, hook=hook)\n\n    def exception(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n        self.log(\"ERROR\", *args, **kwargs)\n\n    def success(self, *args: t.Any, **kwargs: t.Any) -&gt; None:\n        self.log(\"SUCCESS\", *args, **kwargs)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger","title":"<code>Logger</code>","text":"<p>               Bases: <code>Logger</code>, <code>LoggingMixin</code></p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>class Logger(_Logger, LoggingMixin):\n\n    name: str = None\n    settings: Type['BaseSettings'] = None\n    conditions: Dict[str, Tuple[Union[Callable, bool], str]] = {}\n    default_trace_depth: Optional[int] = None\n    is_global: bool = False\n    _colored_opts = None\n    _current_level: Optional[str] = None\n\n    @property\n    def colored_opts(self):\n        \"\"\"\n        Returns the colored options\n        \"\"\"\n        if not self._colored_opts:\n            (exception, depth, record, lazy, colors, raw, capture, patchers, extra) = self._options\n            self._colored_opts = (exception, depth, record, lazy, True, raw, capture, patchers, extra)\n        return self._colored_opts\n\n    def _get_opts(self, colored: Optional[bool] = False, **kwargs):\n        \"\"\"\n        Returns the options\n        \"\"\"\n        return self.colored_opts if colored else self._options\n\n    def get_log_mode(self, level: str = \"info\"):\n        \"\"\"\n        Returns the log mode based on the level\n        \"\"\"\n        return self.dev if level.upper() in {'DEV'} else getattr(self, level.lower())\n\n    def add_if_condition(\n        self, \n        name: str, \n        condition: Union[Callable, bool],\n        level: Optional[Union[str, int]] = 'INFO',\n    ):\n        \"\"\"\n        Adds a condition to the logger\n        \"\"\"\n        self.conditions[name] = (condition, self._get_level(level))\n\n    def remove_if_condition(self, name: str):\n        \"\"\"\n        Removes a condition from the logger\n        \"\"\"\n        if name in self.conditions:\n            del self.conditions[name]\n\n    def _is_dev_condition(self, record: logging.LogRecord) -&gt; bool:\n        \"\"\"\n        Returns whether the dev condition is met\n        \"\"\"\n        if not self.settings: return True\n        if record.levelname == 'DEV':\n            for key in {'api_dev_mode', 'debug_enabled'}:\n                if (\n                    hasattr(self.settings, key)\n                    and getattr(self.settings, key) is False\n                ):\n                    return False\n        return True\n\n    def _filter_if(self, name: str, record: Optional[logging.LogRecord] = None, message: Optional[Any] = None, level: Optional[Union[str, int]] = None) -&gt; Tuple[bool, str]:\n        \"\"\"\n        Filters out messages based on conditions\n        \"\"\"\n        if name in self.conditions:\n            condition, clevel = self.conditions[name]\n            if isinstance(condition, bool):\n                return condition, clevel\n            elif isinstance(condition, type(None)):\n                return False, clevel\n            elif isinstance(condition, Callable):\n                return condition(record or message), clevel\n        return True, (record.levelname if record else self._get_level(level or 'INFO'))\n\n    def _filter_module_name(self, name: str) -&gt; bool:\n        \"\"\"\n        Filter based on module name\n\n        - True if the module is not registered and is_global is False \n        - False if the module is registered and is_global is False\n        \"\"\"\n        _is_registered = is_registered_logger_module(name)\n        if self.is_global: \n            return _is_registered is not False\n        return _is_registered is False\n\n\n    def _filter(self, record: logging.LogRecord, name: Optional[str] = None) -&gt; bool:\n        \"\"\"\n        Filters out messages based on conditions\n\n        - True if the message should be filtered out\n        - False if the message should be logged\n        \"\"\"\n        if self.check_silenced(record):\n            return True\n        if self._filter_module_name(record['name']): \n            return True\n\n        if name is not None:\n            return self._filter_if(name, record)[0]\n        if not self.conditions: return False\n        return not any(\n            isinstance(value, bool)\n            and value is False\n            or not isinstance(value, bool)\n            and isinstance(value, Callable)\n            and value(record) is False\n            for key, value in self.conditions.items()\n        )\n\n    def _filter_dev(self, record: logging.LogRecord, **kwargs):\n        if not self.settings:\n            return True\n        if record.levelname == 'DEV':\n            for key in {'api_dev_mode', 'debug_enabled'}:\n                if (\n                    hasattr(self.settings, key)\n                    and getattr(self.settings, key) is False\n                ):\n                    return False\n        return True\n\n    def opt(\n        self,\n        *,\n        exception=None,\n        record=False,\n        lazy=False,\n        colors=False,\n        raw=False,\n        capture=True,\n        depth=0,\n        ansi=False\n    ):\n        \"\"\"\n        Return a new logger with the specified options changed.\n        \"\"\"\n        if ansi: colors = True\n        args = self._options[-2:]\n        return type(self)(self._core, exception, depth, record, lazy, colors, raw, capture, *args)\n\n\n\n    \"\"\"\n    Newly Added APIs\n    \"\"\"\n\n    def _get_level(self, level: Union[str, int]) -&gt; str:\n        \"\"\"\n        Returns the log level\n        \"\"\"\n        return get_logging_level(level)\n\n    def _format_item(\n        self,\n        msg: 'MsgItem',\n        max_length: Optional[int] = None,\n        colored: Optional[bool] = False,\n        level: Optional[str] = None,\n        _is_part: Optional[bool] = False,\n    ) -&gt; str:  # sourcery skip: extract-duplicate-method, low-code-quality, split-or-ifs\n        \"\"\"\n        Formats an item\n        \"\"\"\n        return format_item(msg, max_length = max_length, colored = colored, level = level, _is_part = _is_part)\n\n\n    def _format_message(\n        self, \n        message: 'MsgItem',\n        *args,\n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        level: Optional[str] = None,\n        colored: Optional[bool] = False,\n        extra: Optional[Dict[str, Any]] = None,\n    ) -&gt; str:\n        \"\"\"\n        Formats the message\n\n        \"example |b|msg|e|\"\n        -&gt; \"example &lt;blue&gt;msg&lt;/&gt;&lt;reset&gt;\"\n        \"\"\"\n        return format_message(\n            message,\n            *args,\n            prefix = prefix,\n            max_length = max_length,\n            level = level,\n            colored = colored,\n            extra = extra,\n        )\n\n    def log_if(\n        self, \n        name: str, \n        message: 'MsgItem',\n        *args, \n        level: Optional[Union[str, int]] = None, \n        **kwargs\n    ):  # noqa: N805\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``level`` if condition is met.\n        \"\"\"\n        condition, clevel = self._filter_if(name, message = message, level = level)\n        if condition:\n            return self.log((level or clevel), message, *args, **kwargs)\n\n    def log(\n        self, \n        level: Union[str, int], \n        message: 'MsgItem',\n        *args, \n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        colored: Optional[bool] = False,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):  # noqa: N805\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``level``.\n        \"\"\"\n        level = self._get_level(level)\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = level,\n            extra = extra,\n        )\n        try:\n            self._log(level, False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            # level_id, static_level_no, from_decorator, options, message, args, kwargs\n            static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 20)\n            self._log(level, static_log_no, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def info(\n        self, \n        message: 'MsgItem',\n        *args, \n        colored: Optional[bool] = None, \n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):  # noqa: N805\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``'INFO'``.\n        \"\"\"\n        if colored is None and isinstance(message, str) and '|e|' in message: colored = True\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            *args,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'INFO',\n            extra = extra,\n        )\n        if not is_global_muted():\n            try:\n                self._log(\"INFO\", False, self._get_opts(colored = colored), message, args, kwargs)\n            except TypeError:\n                # Compatibility with &lt; 0.6.0\n                self._log(\"INFO\", 20, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def success(\n        self, \n        message: 'MsgItem', \n        *args, \n        colored: Optional[bool] = False, \n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):  # noqa: N805\n        r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'SUCCESS'``.\"\"\"\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            *args,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'SUCCESS',\n            extra = extra,\n        )\n        if not is_global_muted():\n            try:\n                self._log(\"SUCCESS\", False, self._get_opts(colored = colored), message, args, kwargs)\n            except TypeError:\n                # Compatibility with &lt; 0.6.0\n                self._log(\"SUCCESS\", 20, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def warning(\n        self, \n        message, \n        *args, \n        colored: Optional[bool] = False, \n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):  # noqa: N805\n        r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'WARNING'``.\"\"\"\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'WARNING',\n            extra = extra,\n        )\n\n        try:\n            self._log(\"WARNING\", False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            self._log(\"WARNING\", 30, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def error(\n        self,\n        message: Any,\n        *args,\n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        colored: Optional[bool] = False,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        exc_info: Optional[bool] = False,\n        **kwargs\n    ) -&gt; None:\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``'ERROR'``.\n        \"\"\"\n        extra = kwargs.pop('extra', None)\n        message = self._format_message(\n            message,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'ERROR',\n            extra = extra,\n        )\n        if exc_info: message += f\"\\n{traceback.format_exc()}\"\n\n        try:\n            self._log(\"ERROR\", False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            self._log(\"ERROR\", 40, False, self._get_opts(colored = colored), message, args, kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n    def trace(\n        self, \n        msg: 'MsgItem',\n        error: Optional[Type[Exception]] = None, \n        level: str = \"ERROR\",\n        limit: Optional[int] = None,\n        chain: Optional[bool] = True,\n        colored: Optional[bool] = False,\n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs,\n    ) -&gt; None:\n        \"\"\"\n        This method logs the traceback of an exception.\n\n        :param error: The exception to log.\n        \"\"\"\n        _depth = kwargs.pop('depth', None)\n        extra = kwargs.pop('extra', None)\n        if _depth is not None: limit = _depth\n        if isinstance(msg, str):\n            _msg = msg\n            if extra:\n                extras_rendered = format_item(extra, max_length = max_length, colored = colored, level = level)\n                extras_rendered = extras_rendered.lstrip('\\n')\n                if extras_rendered:\n                    if _msg:\n                        _msg += f\"\\n{extras_rendered}\"\n                    else:\n                        _msg = extras_rendered\n        else:\n            _msg = self._format_message(\n                msg,\n                colored = colored,\n                level = level,\n                prefix = prefix,\n                max_length = max_length,\n                extra = extra,\n            )\n        # pprint.pformat(msg)\n        _msg += f\"\\n{traceback.format_exc(chain = chain, limit = limit)}\"\n        if error: _msg += f\" - {error}\"\n\n        try:\n            self._log(level, False, self._get_opts(colored = colored), _msg, (), {})\n        except TypeError:\n            static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 40)\n            self._log(level, static_log_no, False, self._get_opts(colored = colored), _msg, (), {})\n        self.run_logging_hooks(_msg, hook = hook)\n\n    def exception(\n        self,\n        message: 'MsgItem',\n        *args,\n        colored: Optional[bool] = False,\n        prefix: Optional[str] = None,\n        max_length: Optional[int] = None,\n        hook: Optional[Union[Callable, List[Callable]]] = None,\n        **kwargs\n    ):\n        \"\"\"\n        Log ``message.format(*args, **kwargs)`` with severity ``'ERROR'``.\n        \"\"\"\n        extra = kwargs.get('extra')\n        message = self._format_message(\n            message,\n            *args,\n            prefix = prefix,\n            max_length = max_length,\n            colored = colored,\n            level = 'ERROR',\n            extra = extra,\n        )\n        super().exception(message, *args, **kwargs)\n        self.run_logging_hooks(message, hook = hook)\n\n\n    def __call__(self, message: 'MsgItem', *args, level: str = 'info', **kwargs):\n        r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'INFO'``.\"\"\"\n        if isinstance(message, list):\n            __message = \"\".join(f'- {item}\\n' for item in message)\n        elif isinstance(message, dict):\n            __message = \"\".join(f'- {key}: {value}\\n' for key, value in message.items())\n        else:\n            __message = str(message)\n        _log = self.get_log_mode(level)\n        _log(__message.strip(), *args, **kwargs)\n\n    def _logcompat(\n        self, level, from_decorator, options, message, args, kwargs\n    ):\n        \"\"\"\n        Compatible to &lt; 0.6.0\n        \"\"\"\n        try:\n            self._log(level, from_decorator, options, message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            # level_id, static_level_no, from_decorator, options, message, args, kwargs\n            static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 20)\n            self._log(level, static_log_no, from_decorator, options, message, args, kwargs)\n\n\n    \"\"\"\n    Utilties\n    \"\"\"\n\n    def change_logger_level(\n        self,\n        level: str,\n    ):\n        \"\"\"\n        Changes the logger level\n\n        :TODO\n        \"\"\"\n        return\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.colored_opts","title":"<code>colored_opts</code>  <code>property</code>","text":"<p>Returns the colored options</p>"},{"location":"api/lzo/utils/#lzo.utils.Logger.get_log_mode","title":"<code>get_log_mode(level='info')</code>","text":"<p>Returns the log mode based on the level</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def get_log_mode(self, level: str = \"info\"):\n    \"\"\"\n    Returns the log mode based on the level\n    \"\"\"\n    return self.dev if level.upper() in {'DEV'} else getattr(self, level.lower())\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.add_if_condition","title":"<code>add_if_condition(name, condition, level='INFO')</code>","text":"<p>Adds a condition to the logger</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def add_if_condition(\n    self, \n    name: str, \n    condition: Union[Callable, bool],\n    level: Optional[Union[str, int]] = 'INFO',\n):\n    \"\"\"\n    Adds a condition to the logger\n    \"\"\"\n    self.conditions[name] = (condition, self._get_level(level))\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.remove_if_condition","title":"<code>remove_if_condition(name)</code>","text":"<p>Removes a condition from the logger</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def remove_if_condition(self, name: str):\n    \"\"\"\n    Removes a condition from the logger\n    \"\"\"\n    if name in self.conditions:\n        del self.conditions[name]\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.opt","title":"<code>opt(*, exception=None, record=False, lazy=False, colors=False, raw=False, capture=True, depth=0, ansi=False)</code>","text":"<p>Return a new logger with the specified options changed.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def opt(\n    self,\n    *,\n    exception=None,\n    record=False,\n    lazy=False,\n    colors=False,\n    raw=False,\n    capture=True,\n    depth=0,\n    ansi=False\n):\n    \"\"\"\n    Return a new logger with the specified options changed.\n    \"\"\"\n    if ansi: colors = True\n    args = self._options[-2:]\n    return type(self)(self._core, exception, depth, record, lazy, colors, raw, capture, *args)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.log_if","title":"<code>log_if(name, message, *args, level=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>level</code> if condition is met.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def log_if(\n    self, \n    name: str, \n    message: 'MsgItem',\n    *args, \n    level: Optional[Union[str, int]] = None, \n    **kwargs\n):  # noqa: N805\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``level`` if condition is met.\n    \"\"\"\n    condition, clevel = self._filter_if(name, message = message, level = level)\n    if condition:\n        return self.log((level or clevel), message, *args, **kwargs)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.log","title":"<code>log(level, message, *args, prefix=None, max_length=None, colored=False, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>level</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def log(\n    self, \n    level: Union[str, int], \n    message: 'MsgItem',\n    *args, \n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    colored: Optional[bool] = False,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):  # noqa: N805\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``level``.\n    \"\"\"\n    level = self._get_level(level)\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = level,\n        extra = extra,\n    )\n    try:\n        self._log(level, False, self._get_opts(colored = colored), message, args, kwargs)\n    except TypeError:\n        # Compatibility with &lt; 0.6.0\n        # level_id, static_level_no, from_decorator, options, message, args, kwargs\n        static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 20)\n        self._log(level, static_log_no, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.info","title":"<code>info(message, *args, colored=None, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'INFO'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def info(\n    self, \n    message: 'MsgItem',\n    *args, \n    colored: Optional[bool] = None, \n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):  # noqa: N805\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``'INFO'``.\n    \"\"\"\n    if colored is None and isinstance(message, str) and '|e|' in message: colored = True\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        *args,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'INFO',\n        extra = extra,\n    )\n    if not is_global_muted():\n        try:\n            self._log(\"INFO\", False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            self._log(\"INFO\", 20, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.success","title":"<code>success(message, *args, colored=False, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'SUCCESS'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def success(\n    self, \n    message: 'MsgItem', \n    *args, \n    colored: Optional[bool] = False, \n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):  # noqa: N805\n    r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'SUCCESS'``.\"\"\"\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        *args,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'SUCCESS',\n        extra = extra,\n    )\n    if not is_global_muted():\n        try:\n            self._log(\"SUCCESS\", False, self._get_opts(colored = colored), message, args, kwargs)\n        except TypeError:\n            # Compatibility with &lt; 0.6.0\n            self._log(\"SUCCESS\", 20, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.warning","title":"<code>warning(message, *args, colored=False, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'WARNING'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def warning(\n    self, \n    message, \n    *args, \n    colored: Optional[bool] = False, \n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):  # noqa: N805\n    r\"\"\"Log ``message.format(*args, **kwargs)`` with severity ``'WARNING'``.\"\"\"\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'WARNING',\n        extra = extra,\n    )\n\n    try:\n        self._log(\"WARNING\", False, self._get_opts(colored = colored), message, args, kwargs)\n    except TypeError:\n        # Compatibility with &lt; 0.6.0\n        self._log(\"WARNING\", 30, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.error","title":"<code>error(message, *args, prefix=None, max_length=None, colored=False, hook=None, exc_info=False, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'ERROR'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def error(\n    self,\n    message: Any,\n    *args,\n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    colored: Optional[bool] = False,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    exc_info: Optional[bool] = False,\n    **kwargs\n) -&gt; None:\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``'ERROR'``.\n    \"\"\"\n    extra = kwargs.pop('extra', None)\n    message = self._format_message(\n        message,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'ERROR',\n        extra = extra,\n    )\n    if exc_info: message += f\"\\n{traceback.format_exc()}\"\n\n    try:\n        self._log(\"ERROR\", False, self._get_opts(colored = colored), message, args, kwargs)\n    except TypeError:\n        self._log(\"ERROR\", 40, False, self._get_opts(colored = colored), message, args, kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.trace","title":"<code>trace(msg, error=None, level='ERROR', limit=None, chain=True, colored=False, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>This method logs the traceback of an exception.</p> <p>:param error: The exception to log.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def trace(\n    self, \n    msg: 'MsgItem',\n    error: Optional[Type[Exception]] = None, \n    level: str = \"ERROR\",\n    limit: Optional[int] = None,\n    chain: Optional[bool] = True,\n    colored: Optional[bool] = False,\n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs,\n) -&gt; None:\n    \"\"\"\n    This method logs the traceback of an exception.\n\n    :param error: The exception to log.\n    \"\"\"\n    _depth = kwargs.pop('depth', None)\n    extra = kwargs.pop('extra', None)\n    if _depth is not None: limit = _depth\n    if isinstance(msg, str):\n        _msg = msg\n        if extra:\n            extras_rendered = format_item(extra, max_length = max_length, colored = colored, level = level)\n            extras_rendered = extras_rendered.lstrip('\\n')\n            if extras_rendered:\n                if _msg:\n                    _msg += f\"\\n{extras_rendered}\"\n                else:\n                    _msg = extras_rendered\n    else:\n        _msg = self._format_message(\n            msg,\n            colored = colored,\n            level = level,\n            prefix = prefix,\n            max_length = max_length,\n            extra = extra,\n        )\n    # pprint.pformat(msg)\n    _msg += f\"\\n{traceback.format_exc(chain = chain, limit = limit)}\"\n    if error: _msg += f\" - {error}\"\n\n    try:\n        self._log(level, False, self._get_opts(colored = colored), _msg, (), {})\n    except TypeError:\n        static_log_no = REVERSE_LOGLEVEL_MAPPING.get(level, 40)\n        self._log(level, static_log_no, False, self._get_opts(colored = colored), _msg, (), {})\n    self.run_logging_hooks(_msg, hook = hook)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.exception","title":"<code>exception(message, *args, colored=False, prefix=None, max_length=None, hook=None, **kwargs)</code>","text":"<p>Log <code>message.format(*args, **kwargs)</code> with severity <code>'ERROR'</code>.</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def exception(\n    self,\n    message: 'MsgItem',\n    *args,\n    colored: Optional[bool] = False,\n    prefix: Optional[str] = None,\n    max_length: Optional[int] = None,\n    hook: Optional[Union[Callable, List[Callable]]] = None,\n    **kwargs\n):\n    \"\"\"\n    Log ``message.format(*args, **kwargs)`` with severity ``'ERROR'``.\n    \"\"\"\n    extra = kwargs.get('extra')\n    message = self._format_message(\n        message,\n        *args,\n        prefix = prefix,\n        max_length = max_length,\n        colored = colored,\n        level = 'ERROR',\n        extra = extra,\n    )\n    super().exception(message, *args, **kwargs)\n    self.run_logging_hooks(message, hook = hook)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.Logger.change_logger_level","title":"<code>change_logger_level(level)</code>","text":"<p>Changes the logger level</p> <p>:TODO</p> Source code in <code>src/lzl/logging/base.py</code> <pre><code>def change_logger_level(\n    self,\n    level: str,\n):\n    \"\"\"\n    Changes the logger level\n\n    :TODO\n    \"\"\"\n    return\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.change_logger_level","title":"<code>change_logger_level(name=None, level='INFO', verbose=False, **kwargs)</code>","text":"<p>Update the minimum level for the global or named logger.</p> Source code in <code>src/lzl/logging/main.py</code> <pre><code>def change_logger_level(\n    name: str | None = None,\n    level: str | int = \"INFO\",\n    verbose: bool = False,\n    **kwargs: t.Any,\n) -&gt; None:\n    \"\"\"Update the minimum level for the global or named logger.\"\"\"\n    global logger, logger_level\n    if isinstance(level, str): level = level.upper()\n    # Skip if the level is the same\n    if level == logger_level: return\n    name = name or 'lzl'\n    name = name.split('.')[0]\n    logger_level = level\n    if name != 'lzl':\n        __logger = get_logger(name, logger_level, **kwargs)\n    else:\n        __logger = logger\n    if verbose: __logger.info(f\"[{name}] Changing logger level from {logger_level} -&gt; {level}\")\n    __logger._core.min_level = float(REVERSE_LOGLEVEL_MAPPING[logger_level.upper()])\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.add_api_log_filters","title":"<code>add_api_log_filters(modules=('gunicorn', 'uvicorn'), routes=('/healthz',), status_codes=None, verbose=False)</code>","text":"<p>Attach filters to common HTTP server loggers to hide noisy endpoints.</p> Source code in <code>src/lzl/logging/state.py</code> <pre><code>def add_api_log_filters(\n    modules: t.Optional[t.Union[t.Sequence[str], str]] = (\"gunicorn\", \"uvicorn\"),\n    routes: t.Optional[t.Union[t.Sequence[str], str]] = (\"/healthz\",),\n    status_codes: t.Optional[t.Union[t.Sequence[int], int]] = None,\n    verbose: bool = False,\n) -&gt; None:  # sourcery skip: default-mutable-arg\n    \"\"\"Attach filters to common HTTP server loggers to hide noisy endpoints.\"\"\"\n\n    modules_list = [modules] if isinstance(modules, str) else list(modules or [])\n    routes_list = [routes] if isinstance(routes, str) else list(routes or [])\n    status_list = [status_codes] if isinstance(status_codes, int) else list(status_codes or [])\n\n    def filter_api_record(record: logging.LogRecord) -&gt; bool:\n        if routes_list:\n            for route in routes_list:\n                if route in record.args:\n                    return False\n        if status_list:\n            for sc in status_list:\n                if sc in record.args:\n                    return False\n        return True\n\n    for module in modules_list:\n        target = module\n        if module == \"gunicorn\":\n            target = \"gunicorn.glogging.Logger\"\n        elif module == \"uvicorn\":\n            target = \"uvicorn.logging.Logger\"\n        api_logger = logging.getLogger(target)\n        from .main import default_logger\n\n        if verbose:\n            default_logger.info(\n                \"Adding API filters to %s for routes=%s status_codes=%s\",\n                target,\n                routes_list or None,\n                status_list or None,\n            )\n        api_logger.addFilter(filter_api_record)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.extract_function_kwargs","title":"<code>extract_function_kwargs(func, **kwargs)</code>","text":"<p>Split <code>kwargs</code> into arguments accepted by <code>func</code> and leftovers.</p> Source code in <code>src/lzo/utils/helpers/base.py</code> <pre><code>def extract_function_kwargs(\n    func: t.Callable[..., t.Any],\n    **kwargs: t.Any,\n) -&gt; t.Tuple[t.Dict[str, t.Any], t.Dict[str, t.Any]]:\n    \"\"\"Split ``kwargs`` into arguments accepted by ``func`` and leftovers.\"\"\"\n\n    func_kwargs = {k: v for k, v in kwargs.items() if k in func.__code__.co_varnames}\n    extra_kwargs = {k: v for k, v in kwargs.items() if k not in func_kwargs}\n    return func_kwargs, extra_kwargs\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.create_secret","title":"<code>create_secret(nbytes=16)</code>","text":"<p>Generate a hexadecimal token using <code>secrets.token_hex</code>.</p> Source code in <code>src/lzo/utils/helpers/base.py</code> <pre><code>def create_secret(nbytes: t.Optional[int] = 16) -&gt; str:\n    \"\"\"Generate a hexadecimal token using ``secrets.token_hex``.\"\"\"\n\n    import secrets\n\n    return secrets.token_hex(nbytes)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.create_unique_id","title":"<code>create_unique_id(method='uuid4', alph_only=False, length=None)</code>","text":"<p>Generate a UUID-based identifier with optional filtering/truncation.</p> Source code in <code>src/lzo/utils/helpers/base.py</code> <pre><code>def create_unique_id(\n    method: t.Optional[str] = 'uuid4',\n    alph_only: bool = False,\n    length: t.Optional[int] = None,\n) -&gt; str:\n    \"\"\"Generate a UUID-based identifier with optional filtering/truncation.\"\"\"\n\n    import uuid\n\n    meth = getattr(uuid, method, None)\n    if not meth:\n        raise ValueError(f'Invalid UUID method: {method}')\n    val = str(meth())\n    if alph_only:\n        val = ''.join(c for c in val if c.isalpha())\n    if length:\n        while len(val) &lt; length:\n            val += str(meth())\n            if alph_only:\n                val = ''.join(c for c in val if c.isalpha())\n            if val.endswith('-'):\n                val = val[:-1]\n        val = val[:length]\n    return val\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.fail_after","title":"<code>fail_after(delay=5.0)</code>","text":"<p>Raise a timeout if <code>func</code> does not finish within <code>delay</code> seconds.</p> Source code in <code>src/lzo/utils/helpers/base.py</code> <pre><code>def fail_after(delay: t.Union[int, float] = 5.0) -&gt; t.Callable[[t.Callable[..., t.Any]], t.Callable[..., t.Any]]:\n    \"\"\"Raise a timeout if ``func`` does not finish within ``delay`` seconds.\"\"\"\n\n    import concurrent.futures\n\n    def decorator(func: t.Callable[..., t.Any]) -&gt; t.Callable[..., t.Any]:\n        @functools.wraps(func)\n        def wrapper(*args: t.Any, **kwargs: t.Any) -&gt; t.Any:\n            executor = concurrent.futures.ThreadPoolExecutor(max_workers=1)\n            try:\n                future = executor.submit(func, *args, **kwargs)\n                return future.result(timeout=delay)\n            finally:\n                executor.shutdown(wait=False, cancel_futures=True)\n\n        return wrapper\n\n    return decorator\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.timer","title":"<code>timer(start=None, auto_checkpoint=True, format_ms=False, format_pretty=True, format_short=0, verbose=None)</code>","text":"<p>Timer class for timing code</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>Optional[float]</code> <p>The starting time of the timer. Defaults to None.</p> <code>None</code> <code>auto_checkpoint</code> <code>Optional[bool]</code> <p>Whether to automatically add a checkpoint when accessing the duration. Defaults to True.</p> <code>True</code> <code>format_ms</code> <code>Optional[bool]</code> <p>Whether to include milliseconds in the string representation of the duration. Defaults to False.</p> <code>False</code> <code>format_pretty</code> <code>Optional[bool]</code> <p>Whether to use a pretty format for the string representation of the duration. Defaults to True.</p> <code>True</code> <code>format_short</code> <code>Optional[int]</code> <p>0: Default format (full unit with spaces)      2 days, 18 hours, 49 minutes, 15.01 seconds 1: Pretty format (shortened unit with spaces)     2 days 18 hrs 49 mins 15.01 secs 2: Short format (1 letter unit, single space)     2d 18h 49m 15s 3: Short format (1 letter unit, no space)     2d18h49m15s Defaults to 1.</p> <code>0</code> Source code in <code>src/lzo/utils/helpers/timing.py</code> <pre><code>def timer(\n    start: Optional[float] = None,\n    auto_checkpoint: Optional[bool] = True,\n    format_ms: Optional[bool] = False,\n    format_pretty: Optional[bool] = True,\n    format_short: Optional[int] = 0,\n    verbose: bool = None,\n):\n    \"\"\"\n    Timer class for timing code\n\n    Args:\n        start (Optional[float], optional):\n            The starting time of the timer. Defaults to None.\n        auto_checkpoint (Optional[bool], optional):\n            Whether to automatically add a checkpoint when accessing the duration.\n            Defaults to True.\n        format_ms (Optional[bool], optional):\n            Whether to include milliseconds in the string representation of the duration.\n            Defaults to False.\n        format_pretty (Optional[bool], optional):\n            Whether to use a pretty format for the string representation of the duration.\n            Defaults to True.\n        format_short (Optional[int], optional):\n            0: Default format (full unit with spaces) \n                2 days, 18 hours, 49 minutes, 15.01 seconds\n            1: Pretty format (shortened unit with spaces)\n                2 days 18 hrs 49 mins 15.01 secs\n            2: Short format (1 letter unit, single space)\n                2d 18h 49m 15s\n            3: Short format (1 letter unit, no space)\n                2d18h49m15s\n            Defaults to 1.\n\n    \"\"\"\n    return Timer(\n        start = start,\n        auto_checkpoint = auto_checkpoint,\n        format_ms = format_ms,\n        format_pretty = format_pretty,\n        format_short = format_short,\n        verbose = verbose,\n    )\n</code></pre>"},{"location":"api/lzo/utils/#overview","title":"Overview","text":"<p>The utils module provides a comprehensive set of utility functions and decorators that are commonly used across projects. These utilities are designed to be lightweight and have minimal dependencies.</p>"},{"location":"api/lzo/utils/#submodules","title":"Submodules","text":""},{"location":"api/lzo/utils/#helpers","title":"Helpers","text":"<p>General-purpose helper functions:</p>"},{"location":"api/lzo/utils/#lzo.utils.helpers","title":"<code>lzo.utils.helpers</code>","text":""},{"location":"api/lzo/utils/#key-generation","title":"Key Generation","text":"<p>Generate consistent keys for caching and identification:</p>"},{"location":"api/lzo/utils/#lzo.utils.keygen","title":"<code>lzo.utils.keygen</code>","text":""},{"location":"api/lzo/utils/#lzo.utils.keygen.Base64","title":"<code>Base64</code>","text":"<p>Convenience wrapper for base64 encoding/decoding strings.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>class Base64:\n    \"\"\"Convenience wrapper for base64 encoding/decoding strings.\"\"\"\n\n    encoding: str = 'utf-8'\n\n    @classmethod\n    def encode(cls, text: str, encoding: str = 'utf-8', *args: t.Any, **kwargs: t.Any) -&gt; str:\n        \"\"\"Encode ``text`` using ``base64.b64encode``.\"\"\"\n\n        return base64.b64encode(text.encode(encoding=encoding), *args, **kwargs).decode(encoding=encoding)\n\n    @classmethod\n    def decode(\n        cls,\n        data: t.Union[str, bytes],\n        encoding: str = 'utf-8',\n        *args: t.Any,\n        **kwargs: t.Any,\n    ) -&gt; str:\n        \"\"\"Decode base64 data back into a UTF-8 string.\"\"\"\n\n        if isinstance(data, str):\n            data = data.encode(encoding=encoding)\n        return base64.b64decode(data, *args, **kwargs).decode(encoding=encoding)\n\n    @classmethod\n    def dumps(cls, data: str, encoding: str = 'utf-8', *args: t.Any, **kwargs: t.Any) -&gt; str:\n        \"\"\"Alias for :meth:`encode` to mirror JSON-like APIs.\"\"\"\n\n        return cls.encode(data, encoding=encoding, *args, **kwargs)\n\n    @classmethod\n    def loads(\n        cls,\n        data: t.Union[str, bytes],\n        encoding: str = 'utf-8',\n        *args: t.Any,\n        **kwargs: t.Any,\n    ) -&gt; str:\n        \"\"\"Alias for :meth:`decode` to mirror JSON-like APIs.\"\"\"\n\n        return cls.decode(data, encoding=encoding, *args, **kwargs)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Base64.encode","title":"<code>encode(text, encoding='utf-8', *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Encode <code>text</code> using <code>base64.b64encode</code>.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef encode(cls, text: str, encoding: str = 'utf-8', *args: t.Any, **kwargs: t.Any) -&gt; str:\n    \"\"\"Encode ``text`` using ``base64.b64encode``.\"\"\"\n\n    return base64.b64encode(text.encode(encoding=encoding), *args, **kwargs).decode(encoding=encoding)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Base64.decode","title":"<code>decode(data, encoding='utf-8', *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Decode base64 data back into a UTF-8 string.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef decode(\n    cls,\n    data: t.Union[str, bytes],\n    encoding: str = 'utf-8',\n    *args: t.Any,\n    **kwargs: t.Any,\n) -&gt; str:\n    \"\"\"Decode base64 data back into a UTF-8 string.\"\"\"\n\n    if isinstance(data, str):\n        data = data.encode(encoding=encoding)\n    return base64.b64decode(data, *args, **kwargs).decode(encoding=encoding)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Base64.dumps","title":"<code>dumps(data, encoding='utf-8', *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Alias for :meth:<code>encode</code> to mirror JSON-like APIs.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef dumps(cls, data: str, encoding: str = 'utf-8', *args: t.Any, **kwargs: t.Any) -&gt; str:\n    \"\"\"Alias for :meth:`encode` to mirror JSON-like APIs.\"\"\"\n\n    return cls.encode(data, encoding=encoding, *args, **kwargs)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Base64.loads","title":"<code>loads(data, encoding='utf-8', *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Alias for :meth:<code>decode</code> to mirror JSON-like APIs.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef loads(\n    cls,\n    data: t.Union[str, bytes],\n    encoding: str = 'utf-8',\n    *args: t.Any,\n    **kwargs: t.Any,\n) -&gt; str:\n    \"\"\"Alias for :meth:`decode` to mirror JSON-like APIs.\"\"\"\n\n    return cls.decode(data, encoding=encoding, *args, **kwargs)\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate","title":"<code>Generate</code>","text":"<p>Helpers for creating pseudo-random identifiers and secrets.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>class Generate:\n    \"\"\"Helpers for creating pseudo-random identifiers and secrets.\"\"\"\n\n    default_method: str = 'uuid4'\n\n    @classmethod\n    def uuid(cls, method: t.Optional[str] = None, *args: t.Any, **kwargs: t.Any) -&gt; str:\n        \"\"\"Return a UUID string using ``method`` (falls back to ``uuid4``).\"\"\"\n\n        method_name = method or cls.default_method\n        generator = getattr(_uuid, method_name, getattr(_uuid, cls.default_method))\n        return str(generator(*args, **kwargs))\n\n    @classmethod\n    def uuid_passcode(\n        cls,\n        length: t.Optional[int] = None,\n        clean: bool = True,\n        method: t.Optional[str] = None,\n        raw: bool = False,\n    ) -&gt; str:\n        \"\"\"Return a UUID-derived passcode with optional cleanup/truncation.\"\"\"\n\n        value = cls.uuid(method=method)\n        if raw:\n            return value\n        if clean:\n            value = value.replace('-', '').strip()\n        if length:\n            value = value[:length]\n        return value\n\n    @classmethod\n    def alphanumeric_passcode(cls, length: int = 16, alpha_only: bool = False) -&gt; str:\n        \"\"\"Return a random ASCII alphanumeric string of ``length`` characters.\"\"\"\n\n        select = string.ascii_letters if alpha_only else ALPHA_NUMERIC\n        return ''.join(secrets.choice(select) for _ in range(length))\n\n    @classmethod\n    def token(cls, length: int = 32, safe: bool = False, clean: bool = True) -&gt; str:\n        \"\"\"Generate URL-safe or hex tokens suitable for API keys.\"\"\"\n\n        value = secrets.token_hex(length) if safe else secrets.token_urlsafe(length)\n        if clean:\n            for char in value:\n                if char not in ALPHA_NUMERIC:\n                    value = value.replace(char, secrets.choice(ALPHA_NUMERIC))\n        return value\n\n    @classmethod\n    def openssl_random_key(cls, length: int = 64, base: bool = True) -&gt; str:\n        \"\"\"Mimic ``openssl rand`` with optional base64 encoding.\"\"\"\n\n        key = secrets.token_hex(length)\n        if base:\n            key = Base64.encode(key)\n        return key\n\n    @classmethod\n    def keypair(cls, key_length: int = 16, secret_length: int = 36) -&gt; t.Dict[str, str]:\n        \"\"\"Return a random key/secret pair using ``alphanumeric_passcode``.\"\"\"\n\n        return {\n            'key': cls.alphanumeric_passcode(key_length),\n            'secret': cls.alphanumeric_passcode(secret_length),\n        }\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate.uuid","title":"<code>uuid(method=None, *args, **kwargs)</code>  <code>classmethod</code>","text":"<p>Return a UUID string using <code>method</code> (falls back to <code>uuid4</code>).</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef uuid(cls, method: t.Optional[str] = None, *args: t.Any, **kwargs: t.Any) -&gt; str:\n    \"\"\"Return a UUID string using ``method`` (falls back to ``uuid4``).\"\"\"\n\n    method_name = method or cls.default_method\n    generator = getattr(_uuid, method_name, getattr(_uuid, cls.default_method))\n    return str(generator(*args, **kwargs))\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate.uuid_passcode","title":"<code>uuid_passcode(length=None, clean=True, method=None, raw=False)</code>  <code>classmethod</code>","text":"<p>Return a UUID-derived passcode with optional cleanup/truncation.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef uuid_passcode(\n    cls,\n    length: t.Optional[int] = None,\n    clean: bool = True,\n    method: t.Optional[str] = None,\n    raw: bool = False,\n) -&gt; str:\n    \"\"\"Return a UUID-derived passcode with optional cleanup/truncation.\"\"\"\n\n    value = cls.uuid(method=method)\n    if raw:\n        return value\n    if clean:\n        value = value.replace('-', '').strip()\n    if length:\n        value = value[:length]\n    return value\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate.alphanumeric_passcode","title":"<code>alphanumeric_passcode(length=16, alpha_only=False)</code>  <code>classmethod</code>","text":"<p>Return a random ASCII alphanumeric string of <code>length</code> characters.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef alphanumeric_passcode(cls, length: int = 16, alpha_only: bool = False) -&gt; str:\n    \"\"\"Return a random ASCII alphanumeric string of ``length`` characters.\"\"\"\n\n    select = string.ascii_letters if alpha_only else ALPHA_NUMERIC\n    return ''.join(secrets.choice(select) for _ in range(length))\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate.token","title":"<code>token(length=32, safe=False, clean=True)</code>  <code>classmethod</code>","text":"<p>Generate URL-safe or hex tokens suitable for API keys.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef token(cls, length: int = 32, safe: bool = False, clean: bool = True) -&gt; str:\n    \"\"\"Generate URL-safe or hex tokens suitable for API keys.\"\"\"\n\n    value = secrets.token_hex(length) if safe else secrets.token_urlsafe(length)\n    if clean:\n        for char in value:\n            if char not in ALPHA_NUMERIC:\n                value = value.replace(char, secrets.choice(ALPHA_NUMERIC))\n    return value\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate.openssl_random_key","title":"<code>openssl_random_key(length=64, base=True)</code>  <code>classmethod</code>","text":"<p>Mimic <code>openssl rand</code> with optional base64 encoding.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef openssl_random_key(cls, length: int = 64, base: bool = True) -&gt; str:\n    \"\"\"Mimic ``openssl rand`` with optional base64 encoding.\"\"\"\n\n    key = secrets.token_hex(length)\n    if base:\n        key = Base64.encode(key)\n    return key\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.Generate.keypair","title":"<code>keypair(key_length=16, secret_length=36)</code>  <code>classmethod</code>","text":"<p>Return a random key/secret pair using <code>alphanumeric_passcode</code>.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>@classmethod\ndef keypair(cls, key_length: int = 16, secret_length: int = 36) -&gt; t.Dict[str, str]:\n    \"\"\"Return a random key/secret pair using ``alphanumeric_passcode``.\"\"\"\n\n    return {\n        'key': cls.alphanumeric_passcode(key_length),\n        'secret': cls.alphanumeric_passcode(secret_length),\n    }\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.generate_htpasswd_key","title":"<code>generate_htpasswd_key(secret, salt=None, rounds=10, repeat=1)</code>","text":"<p>Generates bcrypt hashes suitable for <code>htpasswd</code> file entries.</p> <p>Parameters:</p> Name Type Description Default <code>secret</code> <code>str</code> <p>The plaintext password to hash.</p> required <code>salt</code> <code>Optional[str]</code> <p>Optional custom salt (if None, a random salt is generated).</p> <code>None</code> <code>rounds</code> <code>int</code> <p>The cost factor (logarithmic) for the bcrypt algorithm.</p> <code>10</code> <code>repeat</code> <code>int</code> <p>Number of hashes to generate.</p> <code>1</code> <p>Yields:</p> Type Description <code>str</code> <p>Bcrypt hashed strings.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>def generate_htpasswd_key(\n    secret: str,\n    salt: t.Optional[str] = None,\n    rounds: int = 10,\n    repeat: int = 1,\n) -&gt; t.Generator[str, None, None]:\n    \"\"\"\n    Generates bcrypt hashes suitable for `htpasswd` file entries.\n\n    Args:\n        secret: The plaintext password to hash.\n        salt: Optional custom salt (if None, a random salt is generated).\n        rounds: The cost factor (logarithmic) for the bcrypt algorithm.\n        repeat: Number of hashes to generate.\n\n    Yields:\n        Bcrypt hashed strings.\n    \"\"\"\n    for _ in range(repeat):\n        if salt:\n            hashed = bcrypt.hashpw(secret.encode(), salt.encode())\n        else:\n            hashed = bcrypt.hashpw(secret.encode(), bcrypt.gensalt(rounds = rounds))\n        yield hashed.decode()\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.keygen.validate_htpasswd_key","title":"<code>validate_htpasswd_key(secret, hashed)</code>","text":"<p>Validates a plaintext password against a bcrypt hash.</p> <p>Parameters:</p> Name Type Description Default <code>secret</code> <code>str</code> <p>The plaintext password to check.</p> required <code>hashed</code> <code>str</code> <p>The bcrypt hash to validate against.</p> required <p>Returns:</p> Type Description <code>bool</code> <p>True if the password matches the hash, False otherwise.</p> Source code in <code>src/lzo/utils/keygen.py</code> <pre><code>def validate_htpasswd_key(\n    secret: str,\n    hashed: str,\n) -&gt; bool:\n    \"\"\"\n    Validates a plaintext password against a bcrypt hash.\n\n    Args:\n        secret: The plaintext password to check.\n        hashed: The bcrypt hash to validate against.\n\n    Returns:\n        True if the password matches the hash, False otherwise.\n    \"\"\"\n    return bcrypt.checkpw(secret.encode(), hashed.encode())\n</code></pre>"},{"location":"api/lzo/utils/#hashing","title":"Hashing","text":"<p>Efficient hashing utilities:</p>"},{"location":"api/lzo/utils/#lzo.utils.hashing","title":"<code>lzo.utils.hashing</code>","text":""},{"location":"api/lzo/utils/#lzo.utils.hashing.create_object_hash","title":"<code>create_object_hash(obj, _sep=':', _hash_length=None)</code>","text":"<p>Creates a deterministic hash for a given object using xxhash.</p> <p>Supports dictionaries, lists, tuples, sets, and Pydantic models.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>ObjT</code> <p>The object to hash.</p> required <code>_sep</code> <code>Optional[str]</code> <p>Separator used when joining iterable elements (default: ':').</p> <code>':'</code> <code>_hash_length</code> <code>Optional[int]</code> <p>Length/type of hash (8=32bit, 16=64bit, 32/None=128bit).</p> <code>None</code> <p>Returns:</p> Type Description <code>str</code> <p>The resulting hexadecimal hash string.</p> Source code in <code>src/lzo/utils/hashing.py</code> <pre><code>def create_object_hash(\n    obj: ObjT,\n    _sep: Optional[str] = ':',\n    _hash_length: Optional[int] = None,\n) -&gt; str:\n    \"\"\"\n    Creates a deterministic hash for a given object using xxhash.\n\n    Supports dictionaries, lists, tuples, sets, and Pydantic models.\n\n    Args:\n        obj: The object to hash.\n        _sep: Separator used when joining iterable elements (default: ':').\n        _hash_length: Length/type of hash (8=32bit, 16=64bit, 32/None=128bit).\n\n    Returns:\n        The resulting hexadecimal hash string.\n    \"\"\"\n    if _hash_length is None or _hash_length == 32: _hasher = xxhash.xxh3_128_hexdigest\n    elif _hash_length == 16: _hasher = xxhash.xxh3_64_hexdigest\n    elif _hash_length == 8: _hasher = xxhash.xxh32_hexdigest\n\n    if isinstance(obj, dict):\n        return _hasher(str(obj))\n    if isinstance(obj, (list, tuple, set)):\n        return f'{_sep}'.join(create_object_hash(item, _sep = _sep) for item in obj)\n    if isinstance(obj, BaseModel) or hasattr(obj, \"model_dump\"):\n        return _hasher(obj.model_dump_json(exclude_none=True))\n    return _hasher(str(obj))\n</code></pre>"},{"location":"api/lzo/utils/#lzo.utils.hashing.create_hash_from_args_and_kwargs","title":"<code>create_hash_from_args_and_kwargs(*args, _typed=False, _key_base=None, _exclude=None, _exclude_none=True, _sep=':', _hash_length=None, **kwargs)</code>","text":"<p>Creates a deterministic hash from function arguments and keyword arguments.</p> <p>Useful for caching mechanisms where the cache key depends on input arguments.</p> <p>Parameters:</p> Name Type Description Default <code>*args</code> <p>Positional arguments to include in the hash.</p> <code>()</code> <code>_typed</code> <code>Optional[bool]</code> <p>If True, includes the type of positional arguments in the hash key.</p> <code>False</code> <code>_key_base</code> <code>Optional[tuple]</code> <p>An optional initial tuple to prepend to the hash key.</p> <code>None</code> <code>_exclude</code> <code>Optional[List[str]]</code> <p>A list of keyword argument names to exclude from the hash.</p> <code>None</code> <code>_exclude_none</code> <code>Optional[bool]</code> <p>If True, excludes keyword arguments with None values.</p> <code>True</code> <code>_sep</code> <code>Optional[str]</code> <p>Separator used for joining hash components.</p> <code>':'</code> <code>_hash_length</code> <code>Optional[int]</code> <p>Length/type of hash (8=32bit, 16=64bit, 32/None=128bit).</p> <code>None</code> <code>**kwargs</code> <p>Keyword arguments to include in the hash.</p> <code>{}</code> <p>Returns:</p> Type Description <code>str</code> <p>The resulting hexadecimal hash string.</p> Source code in <code>src/lzo/utils/hashing.py</code> <pre><code>def create_hash_from_args_and_kwargs(\n    *args,\n    _typed: Optional[bool] = False,\n    _key_base: Optional[tuple] = None,\n    _exclude: Optional[List[str]] = None,\n    _exclude_none: Optional[bool] = True,\n    _sep: Optional[str] = ':',\n    _hash_length: Optional[int] = None,\n    **kwargs,\n) -&gt; str:\n    \"\"\"\n    Creates a deterministic hash from function arguments and keyword arguments.\n\n    Useful for caching mechanisms where the cache key depends on input arguments.\n\n    Args:\n        *args: Positional arguments to include in the hash.\n        _typed: If True, includes the type of positional arguments in the hash key.\n        _key_base: An optional initial tuple to prepend to the hash key.\n        _exclude: A list of keyword argument names to exclude from the hash.\n        _exclude_none: If True, excludes keyword arguments with None values.\n        _sep: Separator used for joining hash components.\n        _hash_length: Length/type of hash (8=32bit, 16=64bit, 32/None=128bit).\n        **kwargs: Keyword arguments to include in the hash.\n\n    Returns:\n        The resulting hexadecimal hash string.\n    \"\"\"\n    hash_key = _key_base or ()\n    if args: \n        hash_key += tuple(type(arg) for arg in args) if _typed else args\n    if kwargs:\n        if _exclude: kwargs = {k: v for k, v in kwargs.items() if k not in _exclude}\n        if _exclude_none: kwargs = {k: v for k, v in kwargs.items() if v is not None}\n        sorted_items = sorted(kwargs.items())\n        for item in sorted_items:\n            hash_key += item\n\n    key = f'{_sep}'.join(str(k) for k in hash_key)\n    return create_object_hash(key, _sep = _sep, _hash_length = _hash_length)\n</code></pre>"},{"location":"api/lzo/utils/#serialization","title":"Serialization","text":"<p>Data serialization helpers:</p>"},{"location":"api/lzo/utils/#lzo.utils.serialization","title":"<code>lzo.utils.serialization</code>","text":""},{"location":"api/lzo/utils/#usage-examples","title":"Usage Examples","text":""},{"location":"api/lzo/utils/#retry-decorator","title":"Retry Decorator","text":"<pre><code>from lzo.utils import retryable\n\n@retryable(max_attempts=3, backoff=2.0)\ndef api_call():\n    response = requests.get(\"https://api.example.com\")\n    response.raise_for_status()\n    return response.json()\n\n# Automatically retries on failure with exponential backoff\ndata = api_call()\n</code></pre>"},{"location":"api/lzo/utils/#key-generation_1","title":"Key Generation","text":"<pre><code>from lzo.utils.keygen import generate_key\n\n# Generate a unique key\nkey = generate_key(\"user\", user_id=123, action=\"login\")\n# Returns: \"user:123:login\" or similar\n\n# Use for caching\ncache[generate_key(\"data\", id=456)] = data\n</code></pre>"},{"location":"api/lzo/utils/#hashing_1","title":"Hashing","text":"<pre><code>from lzo.utils.hashing import hash_dict\n\n# Generate consistent hash for dictionary\ndata = {\"key\": \"value\", \"number\": 42}\nhash_value = hash_dict(data)\n\n# Same data always produces same hash\nassert hash_dict(data) == hash_value\n</code></pre>"},{"location":"api/lzo/utils/#formatting","title":"Formatting","text":"<pre><code>from lzo.utils.helpers.formatting import format_bytes, format_duration\n\n# Format bytes for display\nprint(format_bytes(1234567))  # \"1.18 MB\"\n\n# Format duration\nprint(format_duration(3665))  # \"1h 1m 5s\"\n</code></pre>"},{"location":"api/lzo/utils/#batching","title":"Batching","text":"<pre><code>from lzo.utils.helpers.batching import batch_items\n\nitems = range(100)\nfor batch in batch_items(items, batch_size=10):\n    process_batch(batch)\n</code></pre>"},{"location":"api/lzo/utils/#timing","title":"Timing","text":"<pre><code>from lzo.utils.helpers.timing import Timer\n\nwith Timer() as timer:\n    expensive_operation()\n\nprint(f\"Operation took {timer.elapsed:.2f} seconds\")\n</code></pre>"},{"location":"api/lzo/utils/#date-helpers","title":"Date Helpers","text":"<pre><code>from lzo.utils.helpers.dates import parse_date, format_date\n\n# Parse various date formats\ndate = parse_date(\"2024-01-15\")\n\n# Format consistently\nformatted = format_date(date, fmt=\"%Y-%m-%d\")\n</code></pre>"},{"location":"api/lzo/utils/#environment-variables","title":"Environment Variables","text":"<pre><code>from lzo.utils.helpers.envvars import get_env_bool, get_env_int\n\n# Get typed environment variables with defaults\ndebug = get_env_bool(\"DEBUG\", default=False)\nport = get_env_int(\"PORT\", default=8000)\n</code></pre>"},{"location":"api/lzo/utils/#caching","title":"Caching","text":"<pre><code>from lzo.utils.helpers.caching import memoize\n\n@memoize\ndef expensive_function(x, y):\n    # Results are cached\n    return x * y\n\nresult = expensive_function(5, 10)  # Computed\nresult = expensive_function(5, 10)  # Cached\n</code></pre>"},{"location":"api/lzo/utils/#features","title":"Features","text":"<ul> <li>Retry Logic: Automatic retry with exponential backoff</li> <li>Key Generation: Consistent key generation for caching</li> <li>Hashing: Fast, consistent hashing of complex objects</li> <li>Formatting: Human-readable formatting utilities</li> <li>Batching: Efficient batch processing</li> <li>Timing: Performance measurement</li> <li>Date Handling: Consistent date parsing and formatting</li> <li>Environment Variables: Type-safe environment variable access</li> <li>Caching: Simple memoization decorator</li> </ul>"},{"location":"api/lzo/utils/#design-principles","title":"Design Principles","text":"<p>The utils module follows these principles:</p> <ol> <li>Lightweight: Minimal dependencies</li> <li>Reusable: Generic, composable functions</li> <li>Type-Safe: Full typing support</li> <li>Well-Tested: Comprehensive test coverage</li> <li>Documented: Clear examples and docstrings</li> </ol>"},{"location":"api/lzo/utils/#performance-considerations","title":"Performance Considerations","text":"<ul> <li>Hash functions use xxhash for speed</li> <li>Caching decorators use LRU cache for efficiency</li> <li>Batching helpers minimize memory overhead</li> <li>Timer utilities have minimal overhead</li> </ul> <p>The fa\u00e7ade README at <code>src/lzo/utils/README.md</code> highlights the most common entry points; run <code>make test-lzo-utils</code> to confirm everything behaves as documented.</p>"}]}